import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.jit
def fused_maxpool_scale_clamp_kernel(
    input_ptr,
    output_ptr,
    scale_ptr,
    clamp_min,
    clamp_max,
    input_batch_stride,
    input_channel_stride,
    input_height,
    input_width,
    output_batch_stride,
    output_channel_stride,
    output_height,
    output_width,
    n_elements,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements

    # Calculate output tensor indices
    idx_batch = offsets // output_batch_stride
    remainder = offsets % output_batch_stride
    idx_channel = remainder // output_channel_stride
    idx_spatial = remainder % output_channel_stride
    idx_h = idx_spatial // output_width
    idx_w = idx_spatial % output_width

    # Calculate input window start position
    in_h = idx_h * 2
    in_w = idx_w * 2

    # Compute input pointers
    input_batch_ptr = input_ptr + idx_batch * input_batch_stride
    input_channel_ptr = input_batch_ptr + idx_channel * input_channel_stride
    base_ptr = input_channel_ptr + in_h * input_width + in_w

    # Load 2x2 window values with boundary checks
    window_mask = mask & (in_w + 1 < input_width) & (in_h + 1 < input_height)
    val0 = tl.load(base_ptr, mask=mask)
    val1 = tl.load(base_ptr + 1, mask=mask & (in_w + 1 < input_width))
    val2 = tl.load(base_ptr + input_width, mask=mask & (in_h + 1 < input_height))
    val3 = tl.load(base_ptr + input_width + 1, mask=window_mask)

    # Compute max value
    max_val0 = tl.maximum(val0, val1)
    max_val1 = tl.maximum(val2, val3)
    max_val = tl.maximum(max_val0, max_val1)

    # Load scale and apply
    scale_val = tl.load(scale_ptr + idx_channel)
    scaled_val = max_val * scale_val

    # Apply clamping
    clamped_val = tl.minimum(tl.maximum(scaled_val, clamp_min), clamp_max)

    # Store result
    tl.store(output_ptr + offsets, clamped_val, mask=mask)

class ModelNew(nn.Module):
    """
    Model that performs convolution, group normalization, scaling, max pooling, and clamping.
    """
    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.group_norm = nn.GroupNorm(num_groups, out_channels)
        self.scale = nn.Parameter(torch.ones(scale_shape))
        self.maxpool_kernel_size = maxpool_kernel_size
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max

    def forward(self, x):
        """
        Args:
            x: Input tensor of shape (batch_size, in_channels, height, width).
        Returns:
            Output tensor of shape (batch_size, out_channels, height', width').
        """
        x = self.conv(x)
        x = self.group_norm(x)
        
        # Fused maxpool + scale + clamp with Triton
        x = x.contiguous()
        batch, channels, height, width = x.shape
        out_height = height // self.maxpool_kernel_size
        out_width = width // self.maxpool_kernel_size
        output = torch.empty((batch, channels, out_height, out_width), 
                            device=x.device, dtype=x.dtype)
        
        n_elements = output.numel()
        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)
        
        fused_maxpool_scale_clamp_kernel[grid](
            x, output, self.scale.view(-1), self.clamp_min, self.clamp_max,
            x.stride(0), x.stride(1), height, width,
            output.stride(0), output.stride(1), out_height, out_width,
            n_elements,
            BLOCK_SIZE=1024
        )
        return output

batch_size = 128
in_channels = 3
out_channels = 16
height, width = 32, 32
kernel_size = 3
num_groups = 8
scale_shape = (out_channels, 1, 1)
maxpool_kernel_size = 2
clamp_min = 0.0
clamp_max = 1.0

def get_inputs():
    return [torch.randn(batch_size, in_channels, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]
