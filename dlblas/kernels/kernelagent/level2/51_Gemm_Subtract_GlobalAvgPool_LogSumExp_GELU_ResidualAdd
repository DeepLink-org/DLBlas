import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def fused_gemm_subtract_mean_gelu_kernel(
    x_ptr,
    weight_vector_ptr,
    output_ptr,
    bias_sum,
    subtract_sum,
    out_features,
    in_features,
    stride_x,
    stride_w,
    stride_out,
    BLOCK_SIZE: tl.constexpr
):
    pid = tl.program_id(0)
    row_start = pid * stride_x
    col_offsets = tl.arange(0, BLOCK_SIZE)
    mask = col_offsets < in_features
    x_vals = tl.load(x_ptr + row_start + col_offsets, mask=mask, other=0.0)
    w_vals = tl.load(weight_vector_ptr + col_offsets, mask=mask, other=0.0)
    dot = tl.sum(x_vals * w_vals)
    total = dot + bias_sum - subtract_sum
    mean_val = total / out_features
    sqrt2 = 1.4142135623730951
    gelu_val = mean_val * 0.5 * (1.0 + tl.erf(mean_val / sqrt2))
    tl.store(output_ptr + pid * stride_out, gelu_val)

class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, bias=True):
        super(ModelNew, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.gemm = nn.Linear(in_features, out_features, bias=bias)
        self.subtract = nn.Parameter(torch.randn(out_features))
        
        # Precompute weight vector and sums
        self.register_buffer('weight_vector', self.gemm.weight.sum(dim=0))
        self.bias_sum = self.gemm.bias.sum().item() if bias else 0.0
        self.subtract_sum = self.subtract.sum().item()

    def forward(self, x):
        original_x = x.clone().detach()
        output = torch.empty(x.size(0), device=x.device, dtype=torch.float32)
        BLOCK_SIZE = triton.next_power_of_2(self.in_features)
        grid = (x.size(0),)
        fused_gemm_subtract_mean_gelu_kernel[grid](
            x_ptr=x,
            weight_vector_ptr=self.weight_vector,
            output_ptr=output,
            bias_sum=self.bias_sum,
            subtract_sum=self.subtract_sum,
            out_features=self.out_features,
            in_features=self.in_features,
            stride_x=x.stride(0),
            stride_w=self.weight_vector.stride(0),
            stride_out=output.stride(0),
            BLOCK_SIZE=BLOCK_SIZE
        )
        output = output.unsqueeze(1)
        x = output + original_x
        return x

batch_size = 128
in_features = 1024
out_features = 512

def get_inputs():
    return [torch.randn(batch_size, in_features)]

def get_init_inputs():
    return [in_features, out_features]
