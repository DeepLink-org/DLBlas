import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def transposed_conv3d_kernel(
    input_ptr, weight_ptr, bias_ptr, output_ptr,
    input_batch_stride, input_c_stride, input_d_stride, input_h_stride, input_w_stride,
    weight_oc_stride, weight_ic_stride, weight_kd_stride, weight_kh_stride, weight_kw_stride,
    output_batch_stride, output_oc_stride, output_d_stride, output_h_stride, output_w_stride,
    kernel_size, stride, padding, 
    in_channels, out_channels,
    D_in, H_in, W_in,
    D_out, H_out, W_out,
    total_elements,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(0)
    idx = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)
    mask = idx < total_elements
    
    # Calculate 5D indices from linear index
    elements_per_batch = out_channels * D_out * H_out * W_out
    batch_idx = idx // elements_per_batch
    remainder = idx % elements_per_batch
    
    elements_per_channel = D_out * H_out * W_out
    channel_idx = remainder // elements_per_channel
    spatial_idx = remainder % elements_per_channel
    
    d_out = spatial_idx // (H_out * W_out)
    hw_idx = spatial_idx % (H_out * W_out)
    h_out = hw_idx // W_out
    w_out = hw_idx % W_out

    # Initialize accumulator
    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)
    
    # Iterate over input channels and kernel dimensions
    for c_in in range(in_channels):
        for kd in range(kernel_size):
            for kh in range(kernel_size):
                for kw in range(kernel_size):
                    # Calculate input indices
                    d_in = (d_out + padding - kd) // stride
                    h_in = (h_out + padding - kh) // stride
                    w_in = (w_out + padding - kw) // stride
                    
                    # Check boundaries
                    in_bounds = (d_in >= 0) & (d_in < D_in) & \
                                (h_in >= 0) & (h_in < H_in) & \
                                (w_in >= 0) & (w_in < W_in)
                    
                    # Calculate offsets
                    input_offset = batch_idx * input_batch_stride + \
                                  c_in * input_c_stride + \
                                  d_in * input_d_stride + \
                                  h_in * input_h_stride + \
                                  w_in * input_w_stride
                    
                    weight_offset = channel_idx * weight_oc_stride + \
                                   c_in * weight_ic_stride + \
                                   kd * weight_kd_stride + \
                                   kh * weight_kh_stride + \
                                   kw * weight_kw_stride
                    
                    # Load and accumulate
                    input_val = tl.load(input_ptr + input_offset, mask=mask & in_bounds, other=0.0)
                    weight_val = tl.load(weight_ptr + weight_offset, mask=mask, other=0.0)
                    acc += input_val * weight_val

    # Add bias
    bias_val = tl.load(bias_ptr + channel_idx, mask=mask, other=0.0)
    acc += bias_val
    
    # Store results
    output_offset = batch_idx * output_batch_stride + \
                    channel_idx * output_oc_stride + \
                    d_out * output_d_stride + \
                    h_out * output_h_stride + \
                    w_out * output_w_stride
    tl.store(output_ptr + output_offset, acc, mask=mask)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        
        # Initialize weights and bias
        self.weight = nn.Parameter(torch.empty(
            out_channels, in_channels, kernel_size, kernel_size, kernel_size
        ))
        self.bias = nn.Parameter(torch.empty(out_channels))
        
        # Initialize parameters
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
        bound = 1 / math.sqrt(fan_in)
        nn.init.uniform_(self.bias, -bound, bound)
        
        self.max_pool1 = nn.MaxPool3d(kernel_size=2)
        self.max_pool2 = nn.MaxPool3d(kernel_size=3)

    def forward(self, x):
        # Ensure contiguous memory layout
        x = x.contiguous()
        
        # Calculate output dimensions
        D_in, H_in, W_in = x.shape[2:]
        D_out = (D_in - 1) * self.stride - 2 * self.padding + self.kernel_size
        H_out = (H_in - 1) * self.stride - 2 * self.padding + self.kernel_size
        W_out = (W_in - 1) * self.stride - 2 * self.padding + self.kernel_size
        
        # Create output tensor
        output = torch.empty(
            (x.size(0), self.out_channels, D_out, H_out, W_out),
            device=x.device, dtype=x.dtype
        )
        
        # Launch kernel
        total_elements = output.numel()
        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)
        
        transposed_conv3d_kernel[grid](
            x, self.weight, self.bias, output,
            x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),
            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), 
            self.weight.stride(3), self.weight.stride(4),
            output.stride(0), output.stride(1), output.stride(2), 
            output.stride(3), output.stride(4),
            self.kernel_size, self.stride, self.padding,
            self.in_channels, self.out_channels,
            D_in, H_in, W_in,
            D_out, H_out, W_out,
            total_elements,
            BLOCK_SIZE=128
        )
        
        x = self.max_pool1(output)
        x = self.max_pool2(x)
        x = torch.sum(x, dim=1, keepdim=True)
        return x

batch_size = 16
in_channels = 8
out_channels = 16
depth, height, width = 16, 32, 32
kernel_size = 3
stride = 2
padding = 1

def get_inputs():
    return [torch.randn(batch_size, in_channels, depth, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding]
