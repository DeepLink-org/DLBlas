import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, 
                 stride: int = 1, padding: int = 0, output_padding: int = 0, 
                 groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.output_padding = output_padding
        self.groups = groups
        
        # Weight tensor initialization
        self.weight = nn.Parameter(
            torch.empty(in_channels, out_channels // groups, kernel_size, kernel_size)
        )
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.bias = None
            
        # Initialize parameters
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Calculate output dimensions
        h_in, w_in = x.shape[2], x.shape[3]
        h_out = (h_in - 1) * self.stride - 2 * self.padding + self.kernel_size + self.output_padding
        w_out = (w_in - 1) * self.stride - 2 * self.padding + self.kernel_size + self.output_padding
        
        # Create output tensor
        output = torch.empty((x.shape[0], self.out_channels, h_out, w_out), 
                             device=x.device, dtype=x.dtype)
        
        # Ensure contiguous memory layout
        x = x.contiguous()
        weight = self.weight.contiguous()
        
        # Prepare bias tensor
        bias = self.bias.contiguous() if self.bias is not None else None
        
        # Grid configuration remains 1D (per output row)
        grid = (x.shape[0] * self.out_channels * h_out,)
        
        # Launch Triton kernel WITHOUT setting BLOCK_SIZE
        _transposed_conv2d_forward[grid](
            x, weight, bias, output,
            x.shape[0], self.in_channels, self.out_channels, self.groups,
            h_in, w_in, h_out, w_out,
            self.stride, self.padding, self.kernel_size
        )
        
        return output

@triton.autotune(
    configs=[
        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),
        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),
        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),
        triton.Config({'BLOCK_SIZE': 64}, num_warps=8),
        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),
        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),
    ],
    key=['h_out', 'w_out'],
)
@triton.jit
def _transposed_conv2d_forward(
    # Tensors
    input_ptr, weight_ptr, bias_ptr, output_ptr,
    # Dimensions
    batch_size, in_channels, out_channels, groups,
    h_in, w_in, h_out, w_out,
    # Convolution parameters
    stride, padding, kernel_size,
    # Blocking
    BLOCK_SIZE: tl.constexpr,
):
    # Program ID and decomposition
    pid = tl.program_id(0)
    total_rows = batch_size * out_channels * h_out
    row_id = pid
    
    # Only process valid rows
    if row_id >= total_rows:
        return
        
    # Decompose row index
    b = row_id // (out_channels * h_out)
    oc = (row_id // h_out) % out_channels
    oh = row_id % h_out
    
    # Group calculations
    group_size = out_channels // groups
    g = oc // group_size
    r_oc = oc % group_size
    in_chans_per_group = in_channels // groups
    group_offset = g * in_chans_per_group
    
    # Process row in fixed-size blocks
    for ow_start in range(0, w_out, BLOCK_SIZE):
        ow_offsets = ow_start + tl.arange(0, BLOCK_SIZE)
        ow_mask = ow_offsets < w_out
        
        # Initialize output block
        output_block = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)
        
        # Loop over kernel spatial dimensions
        for kh in range(kernel_size):
            for kw in range(kernel_size):
                # Calculate input height position
                ih_val = oh - kh + padding
                divisible_by_stride = (ih_val % stride == 0)
                if divisible_by_stride:
                    ih = ih_val // stride
                    within_bounds = (ih >= 0) & (ih < h_in)
                    if within_bounds:
                        # Calculate input width positions for this block
                        iw_vals = ow_offsets - kw + padding
                        iw_mask = (iw_vals >= 0) & (iw_vals < w_in * stride)
                        valid_iw = iw_vals // stride
                        valid_mask = iw_mask & (valid_iw >= 0) & (valid_iw < w_in)
                        
                        # Process input channels
                        for ic in range(in_chans_per_group):
                            # Absolute channel index
                            abs_ic = group_offset + ic
                            
                            # Input pointer calculations
                            input_offset = (
                                b * in_channels * h_in * w_in + 
                                abs_ic * h_in * w_in + 
                                ih * w_in + 
                                valid_iw
                            )
                            input_vals = tl.load(
                                input_ptr + input_offset, 
                                mask=valid_mask, 
                                other=0.0
                            )
                            
                            # Weight pointer calculations
                            weight_offset = (
                                abs_ic * (out_channels // groups) * kernel_size * kernel_size +
                                r_oc * kernel_size * kernel_size +
                                kh * kernel_size +
                                kw
                            )
                            weight_val = tl.load(weight_ptr + weight_offset)
                            
                            # Accumulate results
                            output_block += tl.where(valid_mask, input_vals * weight_val, 0.0)
        
        # Apply bias if available
        if bias_ptr is not None:
            bias_val = tl.load(bias_ptr + oc)
            output_block += bias_val
        
        # Store results
        output_offset = (
            b * out_channels * h_out * w_out + 
            oc * h_out * w_out + 
            oh * w_out + 
            ow_offsets
        )
        tl.store(
            output_ptr + output_offset, 
            output_block, 
            mask=ow_mask
        )

# Test code
batch_size = 16
in_channels = 32
out_channels = 64
kernel_size = 3
height_in = 128
width_in = 256

def get_inputs():
    x = torch.randn(batch_size, in_channels, height_in, width_in)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]
