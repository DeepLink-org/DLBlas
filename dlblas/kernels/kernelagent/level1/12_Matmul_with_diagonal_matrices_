import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.jit
def diag_matmul_kernel(
    A_ptr,
    B_ptr,
    C_ptr,
    N, M,
    stride_B0, stride_B1,
    stride_C0, stride_C1,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(0)
    if pid >= N:
        return

    a_val = tl.load(A_ptr + pid)
    row_start_B = pid * stride_B0
    row_start_C = pid * stride_C0

    for col_block in range(0, tl.cdiv(M, BLOCK_SIZE)):
        col_offset = col_block * BLOCK_SIZE
        col_indices = col_offset + tl.arange(0, BLOCK_SIZE)
        mask = col_indices < M

        b_vals = tl.load(
            B_ptr + row_start_B + col_indices * stride_B1,
            mask=mask,
            other=0.0
        )
        c_vals = a_val * b_vals
        tl.store(
            C_ptr + row_start_C + col_indices * stride_C1,
            c_vals,
            mask=mask
        )

class ModelNew(nn.Module):
    def __init__(self):
        super(ModelNew, self).__init__()
    
    def forward(self, A, B):
        N, M = B.shape
        C = torch.empty_like(B)
        
        if B.numel() == 0:
            return C

        BLOCK_SIZE = 1024
        grid = (N,)
        diag_matmul_kernel[grid](
            A, B, C,
            N, M,
            B.stride(0), B.stride(1),
            C.stride(0), C.stride(1),
            BLOCK_SIZE=BLOCK_SIZE
        )
        return C

M = 4096
N = 4096

def get_inputs():
    A = torch.randn(N)
    B = torch.randn(N, M)
    return [A, B]

def get_init_inputs():
    return []  # No special initialization inputs needed
