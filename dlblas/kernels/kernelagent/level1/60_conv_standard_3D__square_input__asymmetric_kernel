import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def conv3d_kernel(
    x_ptr,
    w_ptr,
    b_ptr,
    y_ptr,
    stride_n: tl.constexpr, stride_cin: tl.constexpr, stride_d: tl.constexpr, stride_h: tl.constexpr, stride_w: tl.constexpr,
    stride_cout: tl.constexpr, stride_ic: tl.constexpr, stride_kd: tl.constexpr, stride_kh: tl.constexpr, stride_kw: tl.constexpr,
    N: tl.constexpr, C_in: tl.constexpr, D_in: tl.constexpr, H_in: tl.constexpr, W_in: tl.constexpr,
    C_out: tl.constexpr, D_out: tl.constexpr, H_out: tl.constexpr, W_out: tl.constexpr,
    K_d: tl.constexpr, K_h: tl.constexpr, K_w: tl.constexpr,
    stride_d_val: tl.constexpr, stride_h_val: tl.constexpr, stride_w_val: tl.constexpr,
    pad_d: tl.constexpr, pad_h: tl.constexpr, pad_w: tl.constexpr,
    dilation_d: tl.constexpr, dilation_h: tl.constexpr, dilation_w: tl.constexpr,
    groups: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,
    USE_BIAS: tl.constexpr,
):
    pid = tl.program_id(0)
    pid_n = pid // (C_out * D_out * H_out * W_out)
    pid_rest = pid % (C_out * D_out * H_out * W_out)
    pid_c = pid_rest // (D_out * H_out * W_out)
    pid_spatial = pid_rest % (D_out * H_out * W_out)
    pid_d = pid_spatial // (H_out * W_out)
    pid_hw = pid_spatial % (H_out * W_out)
    pid_h = pid_hw // W_out
    pid_w = pid_hw % W_out
    
    group_id = pid_c // (C_out // groups)
    cin_start = group_id * (C_in // groups)
    cin_end = (group_id + 1) * (C_in // groups)
    
    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)
    
    for kd in range(K_d):
        d_in = pid_d * stride_d_val - pad_d + kd * dilation_d
        for kh in range(K_h):
            h_in = pid_h * stride_h_val - pad_h + kh * dilation_h
            for kw in range(K_w):
                w_in = pid_w * stride_w_val - pad_w + kw * dilation_w
                
                if d_in >= 0 and d_in < D_in and h_in >=0 and h_in < H_in and w_in >=0 and w_in < W_in:
                    for c_block in range(cin_start, cin_end, BLOCK_SIZE):
                        c_off = c_block + tl.arange(0, BLOCK_SIZE)
                        c_mask = c_off < cin_end
                        
                        x_ptr_block = x_ptr + pid_n * stride_n + d_in * stride_d + h_in * stride_h + w_in * stride_w
                        w_ptr_block = w_ptr + pid_c * stride_cout + kd * stride_kd + kh * stride_kh + kw * stride_kw
                        
                        x_vals = tl.load(x_ptr_block + c_off * stride_cin, mask=c_mask, other=0.0)
                        w_vals = tl.load(w_ptr_block + c_off * stride_ic, mask=c_mask, other=0.0)
                        
                        acc += x_vals * w_vals
    
    # Efficient reduction using associative scan
    acc_val = tl.sum(acc, axis=0)
    
    if USE_BIAS:
        bias = tl.load(b_ptr + pid_c)
        acc_val += bias
        
    y_offset = pid_n * (C_out * D_out * H_out * W_out) + pid_c * (D_out * H_out * W_out) + pid_d * (H_out * W_out) + pid_h * W_out + pid_w
    tl.store(y_ptr + y_offset, acc_val)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = (stride, stride, stride) if isinstance(stride, int) else stride
        self.padding = (padding, padding, padding) if isinstance(padding, int) else padding
        self.dilation = (dilation, dilation, dilation) if isinstance(dilation, int) else dilation
        self.groups = groups
        self.has_bias = bias

        self.weight = nn.Parameter(torch.empty(
            out_channels,
            in_channels // groups,
            kernel_size[0],
            kernel_size[1],
            kernel_size[2]
        ))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.bias = None
            
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        N, C_in, D_in, H_in, W_in = x.shape
        K_d, K_h, K_w = self.kernel_size
        stride_d, stride_h, stride_w = self.stride
        pad_d, pad_h, pad_w = self.padding
        dilation_d, dilation_h, dilation_w = self.dilation
        
        D_out = (D_in + 2 * pad_d - dilation_d * (K_d - 1) - 1) // stride_d + 1
        H_out = (H_in + 2 * pad_h - dilation_h * (K_h - 1) - 1) // stride_h + 1
        W_out = (W_in + 2 * pad_w - dilation_w * (K_w - 1) - 1) // stride_w + 1
        
        y = torch.empty((N, self.out_channels, D_out, H_out, W_out), 
                        device=x.device, dtype=x.dtype)
        
        total_elements = N * self.out_channels * D_out * H_out * W_out
        grid = (triton.cdiv(total_elements, 256) * 256,)  # Align grid to 256
        
        bias_ptr = self.bias.data_ptr() if self.bias is not None else None
        BLOCK_SIZE = 16  # Power of two for efficient memory access
        
        conv3d_kernel[grid](
            x, self.weight, bias_ptr, y,
            x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),
            self.weight.stride(0), self.weight.stride(1),
            self.weight.stride(2), self.weight.stride(3), self.weight.stride(4),
            N, C_in, D_in, H_in, W_in,
            self.out_channels, D_out, H_out, W_out,
            K_d, K_h, K_w,
            stride_d, stride_h, stride_w,
            pad_d, pad_h, pad_w,
            dilation_d, dilation_h, dilation_w,
            self.groups,
            BLOCK_SIZE,
            self.has_bias
        )
        
        return y

# Test code
batch_size = 16
in_channels = 3
out_channels = 64
kernel_size = (3, 5, 7)  # Asymmetric kernel
width = 64
height = 64
depth = 64

def get_inputs():
    x = torch.randn(batch_size, in_channels, width, height, depth)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization
