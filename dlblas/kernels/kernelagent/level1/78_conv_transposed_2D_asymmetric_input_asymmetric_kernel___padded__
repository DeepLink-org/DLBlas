import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def _transposed_conv2d_forward(
    x_ptr,
    weight_ptr,
    output_ptr,
    B, C_in, C_out, H_in, W_in, H_out, W_out,
    stride_h, stride_w,
    padding_h, padding_w,
    kernel_h, kernel_w,
    x_stride_b, x_stride_c, x_stride_h, x_stride_w,
    weight_stride_cin, weight_stride_cout, weight_stride_h, weight_stride_w,
    output_stride_b, output_stride_c, output_stride_h, output_stride_w,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(0)
    
    # Compute output indices
    pid_b = pid // (C_out * H_out * W_out)
    pid_rest = pid % (C_out * H_out * W_out)
    pid_c = pid_rest // (H_out * W_out)
    pid_hw = pid_rest % (H_out * W_out)
    pid_h = pid_hw // W_out
    pid_w = pid_hw % W_out

    accumulator = 0.0
    # Iterate over kernel height
    for k_h in range(0, kernel_h):
        h_offset = pid_h + padding_h - k_h
        rem_h = tl.abs(h_offset) % stride_h
        if rem_h == 0:
            h_in = h_offset // stride_h
            if (h_in >= 0) & (h_in < H_in):
                # Iterate over kernel width
                for k_w in range(0, kernel_w):
                    w_offset = pid_w + padding_w - k_w
                    rem_w = tl.abs(w_offset) % stride_w
                    if rem_w == 0:
                        w_in = w_offset // stride_w
                        if (w_in >= 0) & (w_in < W_in):
                            # Process input channels in blocks
                            for c_in in range(0, C_in, BLOCK_SIZE):
                                c_offsets = c_in + tl.arange(0, BLOCK_SIZE)
                                c_mask = c_offsets < C_in

                                # Load input block
                                x_offset = pid_b * x_stride_b + c_offsets * x_stride_c + h_in * x_stride_h + w_in * x_stride_w
                                x_val = tl.load(x_ptr + x_offset, mask=c_mask, other=0.0)

                                # Load weight block (use different variable name)
                                weight_offset = c_offsets * weight_stride_cin + pid_c * weight_stride_cout + k_h * weight_stride_h + k_w * weight_stride_w
                                w_val = tl.load(weight_ptr + weight_offset, mask=c_mask, other=0.0)

                                # Accumulate
                                accumulator += tl.sum(x_val * w_val)

    # Store result
    output_offset = pid_b * output_stride_b + pid_c * output_stride_c + pid_h * output_stride_h + pid_w * output_stride_w
    tl.store(output_ptr + output_offset, accumulator)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        
        self.weight = nn.Parameter(torch.empty(in_channels, out_channels, kernel_size[0], kernel_size[1]))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
            
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if bias:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, C_in, H_in, W_in = x.shape
        kernel_h, kernel_w = self.kernel_size
        stride_h, stride_w = self.stride
        padding_h, padding_w = self.padding
        
        # Calculate output dimensions
        H_out = (H_in - 1) * stride_h - 2 * padding_h + kernel_h
        W_out = (W_in - 1) * stride_w - 2 * padding_w + kernel_w
        
        output = torch.empty((B, self.out_channels, H_out, W_out), 
                             device=x.device, dtype=x.dtype)
        
        total_elements = B * self.out_channels * H_out * W_out
        grid = lambda meta: (total_elements,)
        
        # Launch kernel
        _transposed_conv2d_forward[grid](
            x, self.weight, output,
            B, C_in, self.out_channels, H_in, W_in, H_out, W_out,
            stride_h, stride_w,
            padding_h, padding_w,
            kernel_h, kernel_w,
            x.stride(0), x.stride(1), x.stride(2), x.stride(3),
            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), self.weight.stride(3),
            output.stride(0), output.stride(1), output.stride(2), output.stride(3),
            BLOCK_SIZE=16
        )
        
        # Add bias if needed
        if self.bias is not None:
            output += self.bias[None, :, None, None]
            
        return output

# Test code
batch_size = 16
in_channels = 32
out_channels = 64
kernel_size = (3, 5)
height = 128
width = 256
stride = (1, 1)
padding = (1, 2)

def get_inputs():
    x = torch.randn(batch_size, in_channels, height, width)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding]
