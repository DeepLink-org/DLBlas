import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def _transposed_conv1d_kernel(
    x_ptr,
    weight_ptr,
    output_ptr,
    batch_size,
    in_channels,
    out_channels,
    L_in,
    L_out,
    stride,
    padding,
    kernel_size,
    groups,
    x_batch_stride,
    x_channel_stride,
    x_length_stride,
    weight_in_channel_stride,
    weight_out_channel_stride,
    weight_kernel_stride,
    output_batch_stride,
    output_channel_stride,
    output_length_stride,
    BLOCK_SIZE: tl.constexpr,
):
    pid_batch = tl.program_id(0)
    pid_out_channel = tl.program_id(1)
    pid_out_length = tl.program_id(2)
    
    out_channels_per_group = out_channels // groups
    group_idx = pid_out_channel // out_channels_per_group
    channel_in_group = pid_out_channel % out_channels_per_group
    
    in_channels_per_group = in_channels // groups
    start_channel = group_idx * in_channels_per_group
    
    acc = 0.0
    ch_offsets = tl.arange(0, BLOCK_SIZE)
    
    for k in range(0, kernel_size):
        l_out = pid_out_length
        numerator = l_out - k + padding
        if numerator >= 0 and numerator % stride == 0:
            l_in = numerator // stride
            if l_in < L_in:
                for c_start in range(0, in_channels_per_group, BLOCK_SIZE):
                    ch_mask = ch_offsets < (in_channels_per_group - c_start)
                    channel_idx = start_channel + c_start + ch_offsets
                    
                    x_offset = pid_batch * x_batch_stride + channel_idx * x_channel_stride + l_in * x_length_stride
                    weight_offset = channel_idx * weight_in_channel_stride + channel_in_group * weight_out_channel_stride + k * weight_kernel_stride
                    
                    x_vals = tl.load(x_ptr + x_offset, mask=ch_mask, other=0.0)
                    w_vals = tl.load(weight_ptr + weight_offset, mask=ch_mask, other=0.0)
                    
                    acc += tl.sum(x_vals * w_vals)
    
    out_offset = pid_batch * output_batch_stride + pid_out_channel * output_channel_stride + pid_out_length * output_length_stride
    tl.store(output_ptr + out_offset, acc)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, output_padding: int = 0, groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.output_padding = output_padding
        self.groups = groups
        
        # Weight tensor shape: (in_channels, out_channels // groups, kernel_size)
        self.weight = nn.Parameter(torch.empty(in_channels, out_channels // groups, kernel_size))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
            
        # Initialize parameters
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if bias:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
            nn.init.uniform_(self.bias, -bound, bound)
            
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        L_in = x.size(2)
        L_out = (L_in - 1) * self.stride - 2 * self.padding + self.kernel_size + self.output_padding
        
        output = torch.empty(x.size(0), self.out_channels, L_out, 
                             device=x.device, dtype=x.dtype)
        
        grid = (x.size(0), self.out_channels, L_out)
        
        _transposed_conv1d_kernel[grid](
            x,
            self.weight,
            output,
            x.size(0),
            self.in_channels,
            self.out_channels,
            L_in,
            L_out,
            self.stride,
            self.padding,
            self.kernel_size,
            self.groups,
            x.stride(0),
            x.stride(1),
            x.stride(2),
            self.weight.stride(0),
            self.weight.stride(1),
            self.weight.stride(2),
            output.stride(0),
            output.stride(1),
            output.stride(2),
            BLOCK_SIZE=64
        )
        
        if self.bias is not None:
            output += self.bias.unsqueeze(0).unsqueeze(2)
            
        return output

# Test code
batch_size = 16
in_channels = 64
out_channels = 3
kernel_size = 3
length = 128

def get_inputs():
    x = torch.randn(batch_size, in_channels, length)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization
