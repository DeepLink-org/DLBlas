import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def conv_transpose3d_kernel(
    x_ptr,
    w_ptr,
    bias_ptr,
    y_ptr,
    stride_d, stride_h, stride_w,
    pad_d, pad_h, pad_w,
    out_pad_d, out_pad_h, out_pad_w,
    groups,
    B, IC, D_in, H_in, W_in,
    OC, D_out, H_out, W_out,
    KD, KH, KW,
    BLOCK_D: tl.constexpr,
    BLOCK_H: tl.constexpr,
    BLOCK_W: tl.constexpr,
    BLOCK_OC: tl.constexpr,
    VECTORIZE: tl.constexpr,
):
    pid_b = tl.program_id(0)
    pid_oc = tl.program_id(1)
    pid_d = tl.program_id(2)
    pid_h = tl.program_id(3)
    pid_w = tl.program_id(4)
    
    d_start = pid_d * BLOCK_D
    h_start = pid_h * BLOCK_H
    w_start = pid_w * BLOCK_W
    oc_start = pid_oc * BLOCK_OC

    # Create masks for spatial and channel blocks
    d_offsets = d_start + tl.arange(0, BLOCK_D)
    h_offsets = h_start + tl.arange(0, BLOCK_H)
    w_offsets = w_start + tl.arange(0, BLOCK_W)
    oc_offsets = oc_start + tl.arange(0, BLOCK_OC)
    
    d_mask = d_offsets < D_out
    h_mask = h_offsets < H_out
    w_mask = w_offsets < W_out
    oc_mask = oc_offsets < OC

    group_id = pid_oc // (OC // groups)
    ic_start = group_id * (IC // groups)
    ic_end = (group_id + 1) * (IC // groups)

    # Initialize output block to zero
    acc = tl.zeros((BLOCK_D, BLOCK_H, BLOCK_W, BLOCK_OC), dtype=tl.float32)
    
    # Loop through kernel dimensions
    for kd in range(KD):
        for kh in range(KH):
            for kw in range(KW):
                # Compute input spatial indices
                d_in_val = (d_offsets[:, None, None, None] + pad_d - kd)
                h_in_val = (h_offsets[None, :, None, None] + pad_h - kh)
                w_in_val = (w_offsets[None, None, :, None] + pad_w - kw)
                
                # Check divisibility and bounds
                d_in_ok = (d_in_val % stride_d == 0) & (d_in_val >= 0)
                h_in_ok = (h_in_val % stride_h == 0) & (h_in_val >= 0)
                w_in_ok = (w_in_val % stride_w == 0) & (w_in_val >= 0)
                
                d_in = tl.where(d_in_ok, d_in_val // stride_d, -1)
                h_in = tl.where(h_in_ok, h_in_val // stride_h, -1)
                w_in = tl.where(w_in_ok, w_in_val // stride_w, -1)
                
                in_bounds = (d_in < D_in) & (h_in < H_in) & (w_in < W_in) & \
                            (d_in >= 0) & (h_in >= 0) & (w_in >= 0)
                
                # Process vectorized input channels
                for ic_block in range(ic_start, ic_end, VECTORIZE):
                    ic_offsets = ic_block + tl.arange(0, VECTORIZE)
                    ic_mask = ic_offsets < ic_end
                    
                    # Load weights
                    w_ptrs = w_ptr + \
                        (ic_offsets[:, None, None, None]) * (OC * KD * KH * KW) + \
                        (oc_offsets[None, :, None, None, None] % (OC // groups)) * (KD * KH * KW) + \
                        (kd * KH * KW + kh * KW + kw)
                    w = tl.load(w_ptrs, mask=ic_mask[:, None, None, None] & oc_mask[None, :, None, None], other=0.0)
                    
                    # Load inputs
                    x_ptrs = x_ptr + \
                        pid_b * (IC * D_in * H_in * W_in) + \
                        (ic_offsets[:, None, None, None]) * (D_in * H_in * W_in) + \
                        (d_in[None, :, :, :] * (H_in * W_in) + \
                         h_in[None, :, :, :] * W_in + \
                         w_in[None, :, :, :])
                    x = tl.load(x_ptrs, 
                               mask=ic_mask[:, None, None, None] & in_bounds[None, :, :, :] & 
                                    d_mask[None, :, None, None] & h_mask[None, None, :, None] & w_mask[None, None, None, :],
                               other=0.0)
                    
                    # Compute partial results
                    partial = tl.sum(x[:, :, :, :, None] * w[None, :, :, :, :], axis=0)
                    acc += partial

    # Add bias if present
    if bias_ptr is not None:
        b_ptrs = bias_ptr + oc_offsets
        bias = tl.load(b_ptrs, mask=oc_mask, other=0.0)
        acc += bias[None, None, None, :]
    
    # Store results
    for d_idx in range(BLOCK_D):
        for h_idx in range(BLOCK_H):
            for w_idx in range(BLOCK_W):
                for oc_idx in range(BLOCK_OC):
                    if d_offsets[d_idx] < D_out and h_offsets[h_idx] < H_out and w_offsets[w_idx] < W_out and oc_offsets[oc_idx] < OC:
                        out_pos = pid_b * (OC * D_out * H_out * W_out) + \
                                  oc_offsets[oc_idx] * (D_out * H_out * W_out) + \
                                  d_offsets[d_idx] * (H_out * W_out) + \
                                  h_offsets[h_idx] * W_out + \
                                  w_offsets[w_idx]
                        tl.store(y_ptr + out_pos, acc[d_idx, h_idx, w_idx, oc_idx])


class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), 
                 padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.output_padding = output_padding
        self.groups = groups
        
        # Calculate output dimensions
        def get_dim(in_dim, stride, pad, out_pad, kernel):
            return (in_dim - 1) * stride - 2 * pad + kernel + out_pad
        
        self.d_out = get_dim(1, stride[0], padding[0], output_padding[0], kernel_size[0])
        self.h_out = get_dim(1, stride[1], padding[1], output_padding[1], kernel_size[1])
        self.w_out = get_dim(1, stride[2], padding[2], output_padding[2], kernel_size[2])
        
        # Initialize weights
        self.weight = nn.Parameter(torch.empty(
            in_channels, 
            out_channels // groups,
            kernel_size[0], kernel_size[1], kernel_size[2]
        ))
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        
        # Initialize bias
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
            fan_in = in_channels // groups * kernel_size[0] * kernel_size[1] * kernel_size[2]
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)
        else:
            self.register_parameter('bias', None)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, IC, D_in, H_in, W_in = x.shape
        KD, KH, KW = self.kernel_size
        D_out = (D_in - 1) * self.stride[0] - 2 * self.padding[0] + KD + self.output_padding[0]
        H_out = (H_in - 1) * self.stride[1] - 2 * self.padding[1] + KH + self.output_padding[1]
        W_out = (W_in - 1) * self.stride[2] - 2 * self.padding[2] + KW + self.output_padding[2]
        
        y = torch.empty((B, self.out_channels, D_out, H_out, W_out), 
                       device=x.device, dtype=x.dtype)
        
        # Configure kernel grid
        BLOCK_D, BLOCK_H, BLOCK_W = 8, 8, 8
        BLOCK_OC = 16
        VECTORIZE = 4
        
        grid = lambda opt: (
            B,
            triton.cdiv(self.out_channels, BLOCK_OC),
            triton.cdiv(D_out, BLOCK_D),
            triton.cdiv(H_out, BLOCK_H),
            triton.cdiv(W_out, BLOCK_W),
        )
        
        # Launch kernel
        conv_transpose3d_kernel[grid](
            x, self.weight, self.bias, y,
            self.stride[0], self.stride[1], self.stride[2],
            self.padding[0], self.padding[1], self.padding[2],
            self.output_padding[0], self.output_padding[1], self.output_padding[2],
            self.groups,
            B, IC, D_in, H_in, W_in,
            self.out_channels, D_out, H_out, W_out,
            KD, KH, KW,
            BLOCK_D=BLOCK_D,
            BLOCK_H=BLOCK_H,
            BLOCK_W=BLOCK_W,
            BLOCK_OC=BLOCK_OC,
            VECTORIZE=VECTORIZE,
        )
        return y

# Test code
batch_size = 16
in_channels = 32
out_channels = 16
kernel_size = (3, 5, 7)  # Asymmetric kernel size
depth_in = 16
height_in = 32
width_in = 64

def get_inputs():
    x = torch.randn(batch_size, in_channels, depth_in, height_in, width_in)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization
