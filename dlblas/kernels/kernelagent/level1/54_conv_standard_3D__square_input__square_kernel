import torch
import torch.nn as nn
import triton
import triton.language as tl
import math

@triton.jit
def conv3d_kernel(
    x_ptr, weight_ptr, output_ptr,
    # Tensor dimensions
    B, C_in, D, H, W,
    C_out, K,
    stride_d, stride_h, stride_w,
    padding_d, padding_h, padding_w,
    dilation_d, dilation_h, dilation_w,
    # Output dimensions
    D_out, H_out, W_out,
    # Block sizes
    BLOCK_C: tl.constexpr, BLOCK_DHW: tl.constexpr
):
    # Compute program IDs
    pid_b = tl.program_id(0)
    pid_c = tl.program_id(1)
    pid_dhw = tl.program_id(2)
    
    # Decompose DHW dimension
    DHW_out = D_out * H_out * W_out
    dhw_offsets = pid_dhw * BLOCK_DHW + tl.arange(0, BLOCK_DHW)
    
    # Compute spatial indices
    w_out = dhw_offsets % W_out
    h_out = (dhw_offsets // W_out) % H_out
    d_out = dhw_offsets // (H_out * W_out)
    
    # Channel block
    c_offsets = pid_c * BLOCK_C + tl.arange(0, BLOCK_C)
    
    # Create masks
    c_mask = c_offsets < C_out
    dhw_mask = dhw_offsets < DHW_out
    
    # Initialize accumulator
    acc = tl.zeros((BLOCK_C, BLOCK_DHW), dtype=tl.float32)
    
    # Loop over input channels and kernel dimensions
    for c_in in range(C_in):
        for kd in range(K):
            for kh in range(K):
                for kw in range(K):
                    # Calculate input positions
                    d_in = d_out * stride_d + kd * dilation_d - padding_d
                    h_in = h_out * stride_h + kh * dilation_h - padding_h
                    w_in = w_out * stride_w + kw * dilation_w - padding_w
                    
                    # Check boundaries
                    d_bound = (d_in >= 0) & (d_in < D)
                    h_bound = (h_in >= 0) & (h_in < H)
                    w_bound = (w_in >= 0) & (w_in < W)
                    in_bounds = d_bound & h_bound & w_bound & dhw_mask
                    
                    # Compute input pointer offset
                    x_offset = pid_b * C_in * D * H * W + c_in * D * H * W
                    x_offset += d_in * H * W + h_in * W + w_in
                    
                    # Load input values with boundary masking
                    x_val = tl.load(x_ptr + x_offset, mask=in_bounds, other=0.0)
                    
                    # Optimized weight loading: vector per output channel block
                    weight_offset_base = c_in * (K*K*K) + kd*(K*K) + kh*K + kw
                    weight_offset = c_offsets * (C_in * K*K*K) + weight_offset_base
                    weight_val = tl.load(weight_ptr + weight_offset, mask=c_mask, other=0.0)
                    
                    # Accumulate with broadcasting
                    acc += weight_val[:, None] * x_val
    
    # Store results
    output_offset = pid_b * C_out * D_out * H_out * W_out
    output_offset += c_offsets[:, None] * DHW_out + dhw_offsets[None, :]
    
    tl.store(output_ptr + output_offset, acc, mask=c_mask[:, None] & dhw_mask[None, :])


class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, 
                 padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups
        
        # Weight parameters
        self.weight = nn.Parameter(
            torch.empty(out_channels, in_channels // groups, kernel_size, kernel_size, kernel_size)
        )
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter('bias', None)
        
        # Initialize parameters
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Extract parameters
        stride_d, stride_h, stride_w = self.stride, self.stride, self.stride
        padding_d, padding_h, padding_w = self.padding, self.padding, self.padding
        dilation_d, dilation_h, dilation_w = self.dilation, self.dilation, self.dilation
        
        # Compute output dimensions
        B, C_in, D, H, W = x.shape
        D_out = (D + 2 * padding_d - dilation_d * (self.kernel_size - 1) - 1) // stride_d + 1
        H_out = (H + 2 * padding_h - dilation_h * (self.kernel_size - 1) - 1) // stride_h + 1
        W_out = (W + 2 * padding_w - dilation_w * (self.kernel_size - 1) - 1) // stride_w + 1
        
        # Allocate output tensor
        output = torch.empty((B, self.out_channels, D_out, H_out, W_out), 
                             device=x.device, dtype=x.dtype)
        
        # Optimized block sizes for better GPU utilization
        BLOCK_C = 32
        BLOCK_DHW = 128
        
        # Calculate grid dimensions
        grid_b = B
        grid_c = triton.cdiv(self.out_channels, BLOCK_C)
        DHW_out = D_out * H_out * W_out
        grid_dhw = triton.cdiv(DHW_out, BLOCK_DHW)
        grid = (grid_b, grid_c, grid_dhw)
        
        # Launch kernel
        conv3d_kernel[grid](
            x, self.weight, output,
            B, C_in, D, H, W,
            self.out_channels, self.kernel_size,
            stride_d, stride_h, stride_w,
            padding_d, padding_h, padding_w,
            dilation_d, dilation_h, dilation_w,
            D_out, H_out, W_out,
            BLOCK_C, BLOCK_DHW
        )
        
        # Add bias if needed
        if self.bias is not None:
            output += self.bias.view(1, -1, 1, 1, 1)
        
        return output

# Test code
batch_size = 16
in_channels = 3
out_channels = 64
kernel_size = 3
depth = 64
width = 64
height = 64

def get_inputs():
    x = torch.randn(batch_size, in_channels, depth, width, height)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization
