{"id": "bee331ce-2f2c-483c-b698-38ed54311e16", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _instance_norm_kernel(\n    x_ptr,\n    output_ptr,\n    stride_n, stride_c, stride_h, stride_w,\n    H, W,\n    eps: tl.constexpr,\n    BLOCK_SIZE_W: tl.constexpr,\n):\n    sample_idx = tl.program_id(0)\n    feature_idx = tl.program_id(1)\n    \n    base_ptr = x_ptr + sample_idx * stride_n + feature_idx * stride_c\n    out_base_ptr = output_ptr + sample_idx * stride_n + feature_idx * stride_c\n    total_elements = H * W\n    \n    # Initialize accumulators\n    sum_val = 0.0\n    sum_sq = 0.0\n    \n    # First pass: compute statistics\n    for h in range(H):\n        for w_block in range(0, tl.cdiv(W, BLOCK_SIZE_W)):\n            w_offsets = w_block * BLOCK_SIZE_W + tl.arange(0, BLOCK_SIZE_W)\n            w_mask = w_offsets < W\n            \n            # Contiguous memory access within row\n            ptr = base_ptr + h * stride_h + w_offsets * stride_w\n            vals = tl.load(ptr, mask=w_mask, other=0.0)\n            \n            # Vectorized reductions\n            sum_val += tl.sum(vals, axis=0)\n            sum_sq += tl.sum(vals * vals, axis=0)\n    \n    # Compute mean and variance\n    mean = sum_val / total_elements\n    variance = (sum_sq / total_elements) - (mean * mean)\n    var_safe = tl.maximum(variance, 0.0)\n    std = tl.sqrt(var_safe + eps)\n    \n    # Second pass: normalize and store\n    for h in range(H):\n        for w_block in range(0, tl.cdiv(W, BLOCK_SIZE_W)):\n            w_offsets = w_block * BLOCK_SIZE_W + tl.arange(0, BLOCK_SIZE_W)\n            w_mask = w_offsets < W\n            \n            ptr = base_ptr + h * stride_h + w_offsets * stride_w\n            out_ptr = out_base_ptr + h * stride_h + w_offsets * stride_w\n            \n            vals = tl.load(ptr, mask=w_mask, other=0.0)\n            normalized = (vals - mean) / std\n            tl.store(out_ptr, normalized, mask=w_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_features: int):\n        super(ModelNew, self).__init__()\n        self.num_features = num_features\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.contiguous()\n        output = torch.empty_like(x)\n        B, C, H, W = x.shape\n        \n        # Configure kernel - optimized for memory coalescing\n        grid = (B, C)\n        BLOCK_SIZE_W = 128  # Optimized for contiguous access\n        \n        # Launch kernel\n        _instance_norm_kernel[grid](\n            x, output,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            H, W,\n            eps=1e-5,\n            BLOCK_SIZE_W=BLOCK_SIZE_W\n        )\n        return output\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "3df826e2-80e9-4b83-b23c-56b8c09136df", "generation": 3, "timestamp": 1754638811.0229514, "iteration_found": 28, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.061, "runtime_ms": 0.704, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.043, "speed_up": 0.061, "custom_timing": 0.704}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.126, "runtime_ms": 0.341, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.043, "speed_up": 0.126, "custom_timing": 0.341}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}