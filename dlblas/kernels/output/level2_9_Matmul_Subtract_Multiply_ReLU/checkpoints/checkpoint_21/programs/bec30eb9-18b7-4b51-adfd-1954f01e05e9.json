{"id": "bec30eb9-18b7-4b51-adfd-1954f01e05e9", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    mask_n = offs_n < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        mask_k = offs_k < in_features\n        \n        x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n        x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n        \n        w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n        w = tl.load(w_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n        \n        acc += tl.sum(w * x[None, :], axis=1)\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (\n            batch_size, \n            triton.cdiv(self.out_features, META['BLOCK_SIZE_N'])\n        )\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "1d3b1c75-3b0c-447b-b710-a92c17cbd2ff", "generation": 3, "timestamp": 1754586792.0227313, "iteration_found": 9, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_9_Matmul_Subtract_Multiply_ReLU", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "max_difference": ["11.837291", "14.175343", "15.662739", "11.692104", "17.017200"], "avg_difference": ["0.735714", "0.787472", "0.812492", "0.815615", "0.847697"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.077, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_9_Matmul_Subtract_Multiply_ReLU", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "max_difference": ["11.837291", "14.175343", "15.662739", "11.692104", "17.017200"], "avg_difference": ["0.735714", "0.787472", "0.812492", "0.815615", "0.847697"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.077, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level2_9_Matmul_Subtract_Multiply_ReLU', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'max_difference': ['11.837291', '14.175343', '15.662739', '11.692104', '17.017200'], 'avg_difference': ['0.735714', '0.787472', '0.812492', '0.815615', '0.847697'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.077, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_9_Matmul_Subtract_Multiply_ReLU', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'max_difference': ['11.837291', '14.175343', '15.662739', '11.692104', '17.017200'], 'avg_difference': ['0.735714', '0.787472', '0.812492', '0.815615', '0.847697'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.077, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    mask_n = offs_n < out_features\n    \n    x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n    w_ptrs = w_ptr + offs_n * stride_wn + offs_k[:, None] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_remaining = in_features - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        mask_k = offs_k < k_valid\n        \n        x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n        w = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n, other=0.0)\n        \n        acc += tl.sum(w * x[:, None], axis=0)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (\n            batch_size, \n            triton.cdiv(self.out_features, META['BLOCK_SIZE_N'])\n        )\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_9_Matmul_Subtract_Multiply_ReLU', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'max_difference': ['11.837291', '14.175343', '15.662739', '11.692104', '17.017200'], 'avg_difference': ['0.735714', '0.787472', '0.812492', '0.815615', '0.847697'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.077, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    mask_n = offs_n < out_features\n    \n    x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n    w_ptrs = w_ptr + offs_n * stride_wn + offs_k[:, None] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_remaining = in_features - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        mask_k = offs_k < k_valid\n        \n        x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n        w = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n, other=0.0)\n        \n        acc += tl.sum(w * x[:, None], axis=0)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (\n            batch_size, \n            triton.cdiv(self.out_features, META['BLOCK_SIZE_N'])\n        )\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given that the current program compiles but fails correctness (output mismatch).\n The kernel is intended to perform: linear (matmul) + subtract + multiply + ReLU.\n\n The current kernel:\n   - Uses two-dimensional grid: (batch_size, triton.cdiv(out_features, BLOCK_SIZE_N))\n   - Each program loads a block of the weight matrix and a block of the input, then accumulates.\n   - Then adds bias, subtracts a value, multiplies by a value, and applies ReLU.\n\n The correctness issue might stem from:\n   - Incorrect handling of the input matrix dimensions (in_features vs. out_features).\n   - The way we are iterating over the K dimension (in_features) might have an off-by-one.\n   - The masking in the inner loop might not be correct.\n\n Let's analyze the kernel:\n\n  pid_b = program_id(0)  --> batch index\n  pid_n = program_id(1)  --> block index for output features\n\n  offs_n = [pid_n * BLOCK_SIZE_N + 0 ... BLOCK_SIZE_N-1]  --> indices in the output feature dimension\n  offs_k = [0 ... BLOCK_SIZE_K-1]  --> indices in the input feature dimension\n\n  x_ptrs: points to the input for this batch and the current block of features (offs_k)\n  w_ptrs: points to the weight matrix at row offs_n and column offs_k.\n\n  Then we iterate over blocks of K (input features). For each block:\n      Load a vector of x (size BLOCK_SIZE_K) and a matrix of w (size BLOCK_SIZE_K x BLOCK_SIZE_N).\n      Then we do: w * x[:, None] and sum along the k dimension (axis=0) to get a vector of length BLOCK_SIZE_N.\n\n  However, note that the accumulation: \n        acc += tl.sum(w * x[:, None], axis=0)\n      This is equivalent to: \n        for j in range(BLOCK_SIZE_N): \n            for i in range(BLOCK_SIZE_K):\n                acc[j] += w[i, j] * x[i]\n\n      But note: the weight matrix is of shape [out_features, in_features]. We are loading a block of rows (offs_n) and a block of columns (offs_k).\n\n  The problem: the inner product for one output element (one row of weight and the entire input vector) is split across multiple blocks in K.\n  This accumulation seems correct.\n\n  After the loop, we add the bias (if present) and then do: \n        acc = (acc - subtract_value) * multiply_value\n        acc = tl.maximum(acc, 0.0)\n\n  The correctness issue might be due to:\n    - The subtract_value and multiply_value are scalars, so we subtract the same scalar from every element and then multiply by the same scalar.\n\n  However, the problem says the max_difference is large (like 11.8, 14.1, etc.) so it's not a small numerical error.\n\n  Another possibility: the indexing of the input tensor.\n\n  The input tensor x has shape [batch_size, in_features]. The stride_xb is x.stride(0) and stride_xk is x.stride(1). \n  We are computing:\n        x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n\n  This is correct.\n\n  The weight tensor has shape [out_features, in_features]. We are using:\n        w_ptrs = w_ptr + offs_n * stride_wn + offs_k[:, None] * stride_wk\n  Note: stride_wn is the stride for the first dimension (out_features) and stride_wk for the second (in_features). This is correct.\n\n  The output is stored at:\n        offs_on = pid_b * stride_ob + offs_n * stride_on\n  which is [batch_index, feature_index] in the output tensor.\n\n  Why the correctness failure?\n\n  One possibility: the inner loop does not correctly handle the last block when in_features is not divisible by BLOCK_SIZE_K.\n\n  We have:\n        k_remaining = in_features - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        mask_k = offs_k < k_valid\n\n  Then we load x and w with mask_k and mask_k[:, None] & mask_n respectively.\n\n  This masking should be correct.\n\n  Another possibility: the initial setting of x_ptrs and w_ptrs. Note that we are starting at the beginning of the row for the input and the beginning of the weight block.\n\n  But then we update:\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n\n  This moves the x pointer to the next block in the same row (for the same batch) and the w pointer to the next block in the same set of rows but next block of columns.\n\n  This also seems correct.\n\n  What about the bias?\n        We load the bias at offs_n (which is the output feature indices). This is correct.\n\n  However, note that the kernel uses:\n        if b_ptr is not None: ... \n\n  In the model, we are passing self.bias. So it is present.\n\n  The problem might be that the subtract_value and multiply_value are applied after the bias? The reference PyTorch code (not shown) might be:\n\n        output = torch.matmul(x, weight.t()) + bias\n        output = (output - subtract_value) * multiply_value\n        output = torch.relu(output)\n\n  So the kernel matches.\n\n  Another possibility: the kernel is using tl.float32 for accumulation? But the input and weight are likely float32? (We are not told the dtype, but the model uses x.dtype for output, and the kernel uses float32 for accumulation and then stores as output (which is same as x.dtype?))\n\n  The output tensor is created as: \n        output = torch.empty(..., device=x.device, dtype=x.dtype)\n\n  And the kernel stores 'acc' which is float32. But if x.dtype is float16, then we are storing float32 into float16? That would be a problem.\n\n  How do we know the dtype? The test case uses: \n        batch_size=128, in_features=10, out_features=5, subtract_value=2.0, multiply_value=1.5.\n\n  The input is generated by: torch.randn(batch_size, in_features) -> which is float32.\n\n  Therefore, the output is also float32. So the kernel uses float32 and stores float32 -> correct.\n\n  So what is the issue?\n\n  Let me look at the grid configuration:\n\n        grid = (batch_size, triton.cdiv(self.out_features, META['BLOCK_SIZE_N']))\n\n  This is correct.\n\n  Another possibility: the weight matrix is stored in row-major, and we are accessing it in row-major? But note the strides:\n\n        stride_wn = self.weight.stride(0)   # for out_features dimension -> likely 1 if row-major? Actually, in PyTorch, for a tensor of shape [out_features, in_features], the stride(0) is in_features and stride(1) is 1 if it's row-major? \n\n  Wait: the weight tensor is of shape [out_features, in_features]. In row-major, the first row has in_features elements, then the next row. So the stride for the first dimension (out_features) should be in_features? But that is the number of columns. Actually, the stride(0) is the step in memory to get to the next row, which is in_features (if contiguous). \n\n  However, in the kernel, we are accessing the weight matrix as:\n\n        w_ptrs = w_ptr + offs_n * stride_wn + offs_k[:, None] * stride_wk\n\n  If the weight matrix is row-major (contiguous), then:\n        stride_wn = in_features (because to move to next row we skip in_features elements) and stride_wk = 1.\n\n  But in the kernel, we are using:\n        stride_wn = self.weight.stride(0)   # which is in_features? \n        stride_wk = self.weight.stride(1)   # which is 1?\n\n  However, note the way we index: \n        w_ptr[ row_index * stride_wn + col_index * stride_wk ]\n\n  This is correct for row-major.\n\n  But what if the weight matrix is not contiguous? We are using .stride(0) and .stride(1). In PyTorch, if the tensor is non-contiguous, the strides might be different.\n\n  We should ensure the weight is contiguous? The model initializes with torch.randn and then uses as nn.Parameter. We are not told if it is contiguous. \n\n  However, in the kernel call, we are passing the weight as is. We should make sure the kernel can handle non-contiguous tensors? \n\n  Alternatively, we can force the weight to be contiguous in the forward pass? But the current code does not.\n\n  But note: the test case is small (10 in_features, 5 out_features) so it might be contiguous.\n\n  How about the input? We are doing x.contiguous()? The current code does not. The input might be non-contiguous? \n\n  In the model, we are not making x contiguous. The kernel uses the strides. It should be able to handle non-contiguous, but let's check the input:\n\n        x is passed as is.\n\n  The problem: the kernel might be loading the input with a stride that is not 1? \n\n  For the input, we have:\n        stride_xb = x.stride(0)   # for batch dimension\n        stride_xk = x.stride(1)   # for feature dimension\n\n  Then we compute:\n        x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n\n  This is correct.\n\n  But if the input is non-contiguous, the stride_xk might not be 1? That is okay.\n\n  However, the inner loop updates:\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n\n  This moves to the next block of features in the same batch.\n\n  This is correct.\n\n  Given the complexity, let's try to simplify and fix the kernel by making the accumulation more obviously correct.\n\n  Alternatively, we can try to break down the kernel and see if the matmul part is correct without the activation.\n\n  The problem says the reference is a sequence: Matmul, Subtract, Multiply, ReLU.\n\n  We are doing all in one kernel. Maybe we can split the kernel into two: first do the linear, then do the activation in a separate kernel? But that would be slower.\n\n  Alternatively, we can write a simple matmul kernel and see if that part is correct.\n\n  However, we are constrained to change only the Triton kernel source within the block.\n\n  Another idea: the kernel uses a two-dimensional grid. The accumulation variable 'acc' is per output feature in a block. But note that the entire output for one example is computed by multiple program_ids in the pid_n dimension. This is correct.\n\n  What if the out_features is not divisible by BLOCK_SIZE_N? We have mask_n that masks the last block. This is correct.\n\n  But note: the bias is loaded only once per output feature. This is correct.\n\n  The subtract_value and multiply_value are passed as scalars to the kernel. They are the same for every element.\n\n  The issue might be that the subtract_value and multiply_value are not applied correctly? \n\n  In the kernel, we do:\n        acc = (acc - subtract_value) * multiply_value\n\n  Then ReLU.\n\n  But the reference does:\n        output = (output - subtract_value) * multiply_value\n        output = torch.relu(output)\n\n  This is the same.\n\n  Given the above, I suspect the problem might be in the way we are doing the matmul.\n\n  Specifically, note that the weight matrix is of shape [out_features, in_features]. The input is [batch_size, in_features]. We need to compute: x * weight^T.\n\n  The kernel does:\n        w_ptrs = w_ptr + offs_n * stride_wn + offs_k[:, None] * stride_wk\n\n  This loads a block of the weight matrix. The block has rows = offs_n (of length BLOCK_SIZE_N) and columns = offs_k (of length BLOCK_SIZE_K). \n\n  Then we multiply the vector x (which is of length BLOCK_SIZE_K) by each column of the weight block? Actually, no:\n\n        We do: w * x[:, None]  -> This gives a matrix of size [BLOCK_SIZE_K, BLOCK_SIZE_N] where element (i, j) = w[i,j] * x[i].\n        Then we sum along axis=0 -> which gives a vector of length BLOCK_SIZE_N: [ sum_i w[i,0]*x[i], sum_i w[i,1]*x[i], ... ]\n\n  This is the inner product of the input vector and the j-th row of the weight block? Actually, note that the j-th row of the weight block is the row at index offs_n[j] in the weight matrix. But we are loading a block of the weight matrix that is not contiguous in memory? \n\n  However, the weight matrix is stored row-major. The block we are loading is a contiguous set of rows? No, because we are loading rows at indices offs_n (which are contiguous) and columns at indices offs_k (which are contiguous). So the block is contiguous? \n\n  But note: the kernel uses the strides of the weight matrix. If the weight matrix is contiguous, then the block we are loading is contiguous? \n\n  Alternatively, we can change the kernel to use a different approach: use a 3-dimensional grid? But that is not necessary.\n\n  After careful thought, I suspect the problem might be in the inner loop: the accumulation is done by adding the result of tl.sum(w * x[:, None], axis=0). This is a vector of length BLOCK_SIZE_N. However, note that the entire inner product for one output feature is the sum over all the blocks in K. So we are accumulating partial sums. This is correct.\n\n  Another possibility: the kernel does not initialize the accumulation to zero? But we do: \n        acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n  Then we accumulate in the loop.\n\n  Given the above, I think we need to debug with a small example. However, we cannot run the code.\n\n  Alternatively, we can try to refactor the kernel to a more standard matmul kernel and see if that helps.\n\n  Let's change the kernel to use a standard block matrix multiplication:\n\n        pid_b = program_id(0)   # batch index\n        pid_n = program_id(1)   # output feature block index\n\n        offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n        # Initialize accumulator\n        acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n        # Loop over K\n        for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n            offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n            mask_k = offs_k < in_features\n\n            # Load a block of the input for this batch and this K block\n            x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n            x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n\n            # Load a block of weights: for the rows in [offs_n] and columns in [offs_k]\n            w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n            w = tl.load(w_ptrs, mask=mask_k[None, :] & (offs_n[:, None] < out_features), other=0.0)\n\n            # Compute the partial dot product\n            acc += tl.sum(w * x[None, :], axis=1)\n\n        ... then add bias, etc.\n\n  The main change: \n        We compute the current k block offset inside the loop: offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        Then we load x for that block.\n        Then we load a block of weight: for the rows in offs_n and columns in offs_k. Note: the weight block is [BLOCK_SIZE_N, BLOCK_SIZE_K] and we load it with the mask for columns and rows.\n\n  The accumulation: \n        acc += tl.sum(w * x[None, :], axis=1)   # which is a vector of length BLOCK_SIZE_N: each row j: sum_i w[j,i] * x[i]\n\n  This is the standard way.\n\n  The current kernel does not recompute offs_k for each block? It uses a fixed offs_k = [0, BLOCK_SIZE_K-1] and then updates the pointers. That might be the problem: because in the inner loop, we are always loading the same relative offsets in the k dimension? \n\n  In the current kernel, we start at the beginning of the row for x and the beginning of the weight block. Then we move the pointers by BLOCK_SIZE_K. But the initial offs_k is [0,1,...,BLOCK_SIZE_K-1] and then we use the same offs_k for the next block? That would be wrong because the next block should be at [BLOCK_SIZE_K, BLOCK_SIZE_K+1, ...].\n\n  So the current kernel does not offset the k index by the block index? \n\n  Correction: the current kernel uses:\n        x_ptrs = ... (starting at the beginning of the row)\n        w_ptrs = ... (starting at the beginning of the weight block)\n\n        for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n            ... then we load with the current x_ptrs and w_ptrs (which point to the current block)\n\n            then update:\n                x_ptrs += BLOCK_SIZE_K * stride_xk\n                w_ptrs += BLOCK_SIZE_K * stride_wk\n\n  This is equivalent to iterating through the row by blocks. The k index is not used to compute an offset? It is used only to compute k_remaining and mask.\n\n  This is a common pattern and should be correct.\n\n  However, note that the weight matrix is stored in row-major. The weight block we are loading in the first iteration is the first BLOCK_SIZE_K columns of the rows offs_n. Then the next block is the next BLOCK_SIZE_K columns? That is correct.\n\n  But why would it fail? \n\n  Let me try with a small example:\n\n        in_features=10, BLOCK_SIZE_K=4 -> 3 blocks.\n\n        Block0: k=0: loads columns [0,1,2,3] -> mask_k: [True, True, True, True] for the first block? Then k_remaining=10, k_valid=4.\n\n        Block1: k=1: loads columns [4,5,6,7] -> mask_k: [True, True, True, True]\n\n        Block2: k=2: loads columns [8,9] -> k_remaining=10-8=2, so mask_k: [True, True, False, False]\n\n  This is correct.\n\n  The issue might be that the weight matrix is stored in column-major? But we are using row-major strides. \n\n  Given the above, I suspect the problem is that the kernel is using the same offs_k for every block? The offs_k is fixed to [0, BLOCK_SIZE_K-1]. In the first block, we use [0,1,2,3] and in the next block we use the same [0,1,2,3] but at a different base address? That would be wrong because we want to load the next set of columns.\n\n  How do we fix? We should not use a fixed offs_k. Instead, we should compute the current column index as k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K) and then use that to mask? \n\n  But note: the current kernel does not use the absolute column index for anything except the mask? The mask is computed based on the remaining elements. The pointer arithmetic is done by updating the base pointer.\n\n  However, the mask is computed only based on the remaining elements, not on the absolute index. This is acceptable.\n\n  But what about the weight matrix? We are loading the weight block at the same relative offset within the row? Actually, no: the weight matrix is stored in row-major. When we update w_ptrs by BLOCK_SIZE_K * stride_wk, we are moving to the next block of columns in the same set of rows.\n\n  This is correct.\n\n  Therefore, I am running out of ideas.\n\n  Given the time, I will try to refactor the kernel to use the more standard method of computing the absolute k index in the loop and see if that fixes the correctness.\n\n  We'll change the kernel as follows:\n\n        pid_b = tl.program_id(0)\n        pid_n = tl.program_id(1)\n\n        offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        mask_n = offs_n < out_features\n\n        # We will accumulate in a vector of length BLOCK_SIZE_N\n        acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n        # Loop over K in blocks\n        for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n            # Compute the current column indices in the input and weight\n            offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n            mask_k = offs_k < in_features\n\n            # Load input: [BLOCK_SIZE_K]\n            x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n            x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n\n            # Load weight: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n            w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n            w = tl.load(w_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n\n            # Compute: acc_j = sum_i w[j, i] * x[i]\n            # We do: w is [BLOCK_SIZE_N, BLOCK_SIZE_K] and x is [BLOCK_SIZE_K] -> we want to do dot products per row of w with x.\n            acc += tl.sum(w * x[None, :], axis=1)\n\n        ... then add bias, activation, etc.\n\n  This is the standard method.\n\n  We are also changing the way we load the weight: we use offs_n[:, None] and offs_k[None, :] to form a 2D index.\n\n  We hope this will fix the issue.\n\n  We must be cautious: the inner loop now recomputes offs_k for each block. The pointer arithmetic is done by computing the absolute indices.\n\n  We remove the pointer updates because we are recomputing the pointers in each iteration.\n\n  We also remove the initial setting of x_ptrs and w_ptrs outside the loop.\n\n  This version is more straightforward.\n\n  Let's change the kernel accordingly.\n\n  We'll keep the same autotune configs.\n\n  We also note that the kernel might be slower because we are recomputing offs_k and the pointers in the loop? But it is small.\n\n  We also note that the mask for the weight is now: mask_n[:, None] & mask_k[None, :] -> which is a 2D mask.\n\n  We'll change the kernel and hope it passes correctness.\n\n  We also note: the output indexing remains the same.\n\n  We'll change the kernel function body.\n\n  IMPORTANT: We cannot change the function signature.\n\n  Steps in the kernel:\n\n      pid_b = ... \n      pid_n = ...\n\n      offs_n = ... \n      mask_n = ...\n\n      acc = tl.zeros(...)\n\n      for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n          offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n          mask_k = offs_k < in_features\n\n          x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n          x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n\n          w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n          w = tl.load(w_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n\n          acc += tl.sum(w * x[None, :], axis=1)\n\n      ... rest (bias, activation) unchanged.\n\n  We also note: the weight matrix is stored in row-major, so we are using:\n        w_ptr + row_index * stride_wn + col_index * stride_wk\n      and stride_wn = weight.stride(0) (which is the step for a row) and stride_wk = weight.stride(1) (step for a column).\n\n  This is correct.\n\n  We'll rewrite the kernel accordingly.\n\n  We'll also remove the old pointer updates inside the loop (we don't need them because we recompute the pointers each time).\n\n  Let's write the new kernel.\n\n  Note: We are changing the kernel body significantly. We hope this will fix the correctness.\n\n  If it doesn't, we might need to revisit.\n\n  We'll also note that the kernel uses a lot of registers? But for small BLOCK_SIZE_K and BLOCK_SIZE_N it should be okay.\n\n  Given the small size (in_features=10, out_features=5) and block sizes (minimum 16, 32) we might be doing extra work? But the masking should take care.\n\n  We'll try.\n\n  We are not changing the class ModelNew or the grid function.\n\n  We are only changing the fused_linear_kernel.\n\n  We'll output the entire block.\n\n  IMPORTANT: We must not change the function signature or the grid configuration.\n\n  We are changing the kernel body only.\n\n  Let's write the new code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    mask_n = offs_n < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        offs_k = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        mask_k = offs_k < in_features\n        \n        x_ptrs = x_ptr + pid_b * stride_xb + offs_k * stride_xk\n        x = tl.load(x_ptrs, mask=mask_k, other=0.0)\n        \n        w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n        w = tl.load(w_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n        \n        acc += tl.sum(w * x[None, :], axis=1)\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (\n            batch_size, \n            triton.cdiv(self.out_features, META['BLOCK_SIZE_N'])\n        )\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}