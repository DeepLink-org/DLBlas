{"id": "3412616d-cade-41a4-8691-83d7d63dbb69", "code": "@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element (same for all features in row)\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (each feature has its own weight)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(w_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = out_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)", "language": "python", "parent_id": "84760ce1-6abb-411c-9bdf-d06e6d0feaf1", "generation": 1, "timestamp": 1754588082.7014458, "iteration_found": 20, "metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0557, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.077, "speed_up": 1.382, "custom_timing": 0.0557}}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.0557\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.077, 'speed_up': 1.382, 'custom_timing': 0.0557}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_9_Matmul_Subtract_Multiply_ReLU', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\\n    return _semantic.arange(start, end)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 583, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpqt6vjyvf.py\", line 69, in forward\\n    fused_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 25:16:\\n):\\n    pid_b = tl.program_id(0)\\n    pid_n = tl.program_id(1)\\n\\n    if pid_b >= batch_size or pid_n >= out_features:\\n        return\\n\\n    x_row_ptr = x_ptr + pid_b * stride_xb\\n    w_row_ptr = w_ptr + pid_n * stride_wn\\n\\n    # Vectorized row loading and dot product\\n    k_offsets = tl.arange(0, in_features)\\n                ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\\n    return _semantic.arange(start, end)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 583, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 0.077, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 51.2000, speed_up: 1.3120, runtime_ms: 0.0587, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.077, 'speed_up': 1.312, 'custom_timing': 0.0587}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 54.6000, speed_up: 1.3460, runtime_ms: 0.0572, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.077, 'speed_up': 1.346, 'custom_timing': 0.0572}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 54.6000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element (same for all features in row)\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (each feature has its own weight)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(w_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = out_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            BLOCK_F = triton.next_power_of_2(self.out_features)\n            grid = (batch_size,)\n            \n            _forward_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1),\n                BLOCK_F=BLOCK_F,\n            )\n        else:\n            # Fallback for CPU (not expected in this context)\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (54.6000), Performs well on speed_up (1.3460), Performs well on runtime_ms (0.0572), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.077, 'speed_up': 1.346, 'custom_timing': 0.0572})\n\n\n### Program 2 (Score: 51.2000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of\n):\n    pid_b = tl.program_id(0)   # batch index\n    pid_f = tl.program_id(1)   # feature index\n    \n    if pid_b >= batch_size or pid_f >= out_features:\n        return\n\n    # Compute base pointers\n    x_row_ptr = x_ptr + pid_b * stride_xb\n    w_row_ptr = w_ptr + pid_f * stride_wf\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element\n        w_val = tl.load(w_row_ptr + k * stride_ws)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + pid_f * stride_bs)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_ptr_val = out_ptr + pid_b * stride_ob + pid_f * stride_of\n    tl.store(out_ptr_val, y)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            grid = (batch_size, self.out_features)\n            \n            _forward_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                batch_size,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1)\n            )\n        else:\n            # Fallback for CPU\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (51.2000), Performs well on speed_up (1.3120), Performs well on runtime_ms (0.0587), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.077, 'speed_up': 1.312, 'custom_timing': 0.0587})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef fused_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    subtract_value,\n    multiply_value,\n    stride_xb, stride_xk,\n    stride_wn, stride_wk,\n    stride_ob, stride_on,\n    batch_size: tl.constexpr,\n    out_features: tl.constexpr,\n    in_features: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    if pid_b >= batch_size or pid_n >= out_features:\n        return\n        \n    x_row_ptr = x_ptr + pid_b * stride_xb\n    w_row_ptr = w_ptr + pid_n * stride_wn\n    \n    # Vectorized row loading and dot product\n    k_offsets = tl.arange(0, in_features)\n    x_vals = tl.load(x_row_ptr + k_offsets * stride_xk)\n    w_vals = tl.load(w_row_ptr + k_offsets * stride_wk)\n    acc = tl.sum(x_vals * w_vals)\n    \n    b_val = tl.load(b_ptr + pid_n)\n    acc += b_val\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    output_offset = pid_b * stride_ob + pid_n * stride_on\n    tl.store(output_ptr + output_offset, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size, self.out_features)\n        \n        fused_kernel[grid](\n            x, \n            self.weight, \n            self.bias, \n            output,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            batch_size=batch_size,\n            out_features=self.out_features,\n            in_features=self.in_features,\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_9_Matmul_Subtract_Multiply_ReLU', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\\n    return _semantic.arange(start, end)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 583, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpqt6vjyvf.py\", line 69, in forward\\n    fused_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 25:16:\\n):\\n    pid_b = tl.program_id(0)\\n    pid_n = tl.program_id(1)\\n\\n    if pid_b >= batch_size or pid_n >= out_features:\\n        return\\n\\n    x_row_ptr = x_ptr + pid_b * stride_xb\\n    w_row_ptr = w_ptr + pid_n * stride_wn\\n\\n    # Vectorized row loading and dot product\\n    k_offsets = tl.arange(0, in_features)\\n                ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\\n    return _semantic.arange(start, end)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 583, in arange\\n    raise ValueError(\"arange\\'s range must be a power of 2\")\\nValueError: arange\\'s range must be a power of 2\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 0.077, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    batch_size,\n    in_features: tl.constexpr,\n    out_features: tl.constexpr,\n    stride_x,\n    stride_w,\n    stride_b,\n    stride_out,\n    BLOCK_SIZE: tl.constexpr,\n    **meta\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    if pid_batch >= batch_size or pid_feature >= out_features:\n        return\n\n    accumulator = 0.0\n    for k in range(0, in_features):\n        x_val = tl.load(x_ptr + pid_batch * stride_x + k)\n        w_val = tl.load(weight_ptr + pid_feature * stride_w + k)\n        accumulator += x_val * w_val\n        \n    b_val = tl.load(bias_ptr + pid_feature * stride_b)\n    accumulator += b_val\n    tl.store(output_ptr + pid_batch * stride_out + pid_feature, accumulator)\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features, _ = weight.shape\n    \n    x = x.contiguous()\n    weight = weight.contiguous()\n    bias = bias.contiguous()\n    \n    output = torch.empty(batch_size, out_features, device=x.device, dtype=x.dtype)\n    \n    grid = (batch_size, out_features)\n    stride_x = in_features\n    stride_w = in_features\n    stride_b = 1\n    stride_out = out_features\n    \n    linear_kernel[grid](\n        x_ptr=x,\n        weight_ptr=weight,\n        bias_ptr=bias,\n        output_ptr=output,\n        batch_size=batch_size,\n        in_features=in_features,\n        out_features=out_features,\n        stride_x=stride_x,\n        stride_w=stride_w,\n        stride_b=stride_b,\n        stride_out=stride_out,\n        BLOCK_SIZE=in_features\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        \n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    mask_n = offs_n < out_features\n    \n    x_ptrs = x_ptr + pid_b * stride_xb + offs_k[:, None] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + offs_k[:, None] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_remaining = in_features - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        mask_k = offs_k < k_valid\n        \n        x = tl.load(x_ptrs, mask=mask_k[:, None] & (offs_n[None, :] < out_features), other=0.0)\n        w = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :], other=0.0)\n        \n        acc += tl.sum(w * x, axis=0)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size, triton.cdiv(self.out_features, 128))\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n            BLOCK_SIZE_N=128,\n            BLOCK_SIZE_K=32,\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 54.6000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element (same for all features in row)\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (each feature has its own weight)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(w_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = out_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            BLOCK_F = triton.next_power_of_2(self.out_features)\n            grid = (batch_size,)\n            \n            _forward_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1),\n                BLOCK_F=BLOCK_F,\n            )\n        else:\n            # Fallback for CPU (not expected in this context)\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 51.2000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of\n):\n    pid_b = tl.program_id(0)   # batch index\n    pid_f = tl.program_id(1)   # feature index\n    \n    if pid_b >= batch_size or pid_f >= out_features:\n        return\n\n    # Compute base pointers\n    x_row_ptr = x_ptr + pid_b * stride_xb\n    w_row_ptr = w_ptr + pid_f * stride_wf\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element\n        w_val = tl.load(w_row_ptr + k * stride_ws)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + pid_f * stride_bs)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_ptr_val = out_ptr + pid_b * stride_ob + pid_f * stride_of\n    tl.store(out_ptr_val, y)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            grid = (batch_size, self.out_features)\n            \n            _forward_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                batch_size,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1)\n            )\n        else:\n            # Fallback for CPU\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32}, num_warps=1),\n        triton.Config({'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb,\n    stride_xk,\n    stride_wn,\n    stride_wk,\n    stride_ob,\n    stride_on,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    mask_n = offs_n < out_features\n    \n    x_ptrs = x_ptr + pid_b * stride_xb + offs_k[:, None] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + offs_k[:, None] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_remaining = in_features - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        mask_k = offs_k < k_valid\n        \n        x = tl.load(x_ptrs, mask=mask_k[:, None] & (offs_n[None, :] < out_features), other=0.0)\n        w = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :], other=0.0)\n        \n        acc += tl.sum(w * x, axis=0)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    if b_ptr is not None:\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n    \n    acc = (acc - subtract_value) * multiply_value\n    acc = tl.maximum(acc, 0.0)\n    \n    offs_on = pid_b * stride_ob + offs_n * stride_on\n    tl.store(output_ptr + offs_on, acc, mask=mask_n)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size, triton.cdiv(self.out_features, 128))\n        \n        fused_linear_kernel[grid](\n            x,\n            self.weight,\n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.subtract_value,\n            self.multiply_value,\n            x.stride(0),\n            x.stride(1),\n            self.weight.stride(0),\n            self.weight.stride(1),\n            output.stride(0),\n            output.stride(1),\n            BLOCK_SIZE_N=128,\n            BLOCK_SIZE_K=32,\n        )\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef fused_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (vectorized)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(weight_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = output_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            BLOCK_F = triton.next_power_of_2(self.out_features)\n            grid = (batch_size,)\n            \n            fused_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1),\n                BLOCK_F=BLOCK_F,\n            )\n        else:\n            # Fallback for CPU\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    batch_size,\n    in_features: tl.constexpr,\n    out_features: tl.constexpr,\n    stride_x,\n    stride_w,\n    stride_b,\n    stride_out,\n    BLOCK_SIZE: tl.constexpr,\n    **meta\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    if pid_batch >= batch_size or pid_feature >= out_features:\n        return\n\n    accumulator = 0.0\n    for k in range(0, in_features):\n        x_val = tl.load(x_ptr + pid_batch * stride_x + k)\n        w_val = tl.load(weight_ptr + pid_feature * stride_w + k)\n        accumulator += x_val * w_val\n        \n    b_val = tl.load(bias_ptr + pid_feature * stride_b)\n    accumulator += b_val\n    tl.store(output_ptr + pid_batch * stride_out + pid_feature, accumulator)\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features, _ = weight.shape\n    \n    x = x.contiguous()\n    weight = weight.contiguous()\n    bias = bias.contiguous()\n    \n    output = torch.empty(batch_size, out_features, device=x.device, dtype=x.dtype)\n    \n    grid = (batch_size, out_features)\n    stride_x = in_features\n    stride_w = in_features\n    stride_b = 1\n    stride_out = out_features\n    \n    linear_kernel[grid](\n        x_ptr=x,\n        weight_ptr=weight,\n        bias_ptr=bias,\n        output_ptr=output,\n        batch_size=batch_size,\n        in_features=in_features,\n        out_features=out_features,\n        stride_x=stride_x,\n        stride_w=stride_w,\n        stride_b=stride_b,\n        stride_out=stride_out,\n        BLOCK_SIZE=in_features\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        \n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Model that performs a matrix multiplication, subtraction, multiplication, and ReLU activation.\n    \"\"\"\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = x - self.subtract_value\n        x = x * self.multiply_value\n        x = torch.relu(x)\n        return x\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a PyTorch model that does:\n  1. Linear transformation (matrix multiplication + bias)\n  2. Subtract a constant\n  3. Multiply by a constant\n  4. ReLU activation\n\nThe current implementation uses `nn.Linear` which is not optimized for the specific operations.\n\nWe are going to rewrite the entire model using a Triton kernel that fuses all these operations.\n\nWe have two high-performing examples from the history (Program 1 and Program 2) that achieved good speedups.\n\nWe note that:\n- The problem size is small: batch_size=128, in_features=10, out_features=5.\n- Therefore, using a kernel that processes an entire row of the output at once (like Program 1) might be efficient because the number of output features is small (5). We can use a power-of-2 block size for the features (e.g., 8) and have each program handle one batch row.\n\nWe choose the approach from Program 1 (the top performer) which uses:\n  - One program per batch row.\n  - Vectorized across the output features (with a block size of next_power_of_2(out_features)).\n  - Loop over the in_features (10) for each row.\n\nWe will adapt that kernel to include the subtract, multiply, and ReLU.\n\nThe kernel from Program 1:\n\n```python\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element (same for all features in row)\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (each feature has its own weight)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(w_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = out_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)\n```\n\nWe will use this kernel and integrate it into the ModelNew.\n\nSteps:\n1. We will remove the `nn.Linear` and use our own parameters (weight and bias).\n2. We will write the Triton kernel as above.\n3. In the forward pass, we will set the grid to (batch_size,) and the block size to the next power of two of out_features.\n\nNote: We must be cautious because the out_features is 5, so BLOCK_F should be 8.\n\nWe also note that the input and output tensors must be contiguous.\n\nLet's write the code accordingly.\n\nImportant: The problem size is small, so we don't expect huge gains, but the fused operations and avoiding the overhead of multiple kernels should help.\n\nWe'll also include the reset_parameters method to initialize the weights and biases.\n\nLet's code accordingly.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef fused_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xf,\n    stride_wf, \n    stride_ws,\n    stride_bs,\n    stride_ob, \n    stride_of,\n    BLOCK_F: tl.constexpr,\n):\n    pid = tl.program_id(0)   # row index in batch\n    feature_index = tl.arange(0, BLOCK_F)\n    mask = feature_index < out_features\n\n    # Compute base pointer for current row in x\n    x_row_ptr = x_ptr + pid * stride_xb\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_F,), dtype=tl.float32)\n    \n    # Loop over columns (in_features)\n    for k in range(0, in_features):\n        # Load input element\n        x_val = tl.load(x_row_ptr + k * stride_xf)\n        \n        # Load weight element (vectorized)\n        w_offset = feature_index * stride_wf + k * stride_ws\n        w_val = tl.load(w_ptr + w_offset, mask=mask, other=0)\n        \n        # Accumulate\n        acc += x_val * w_val\n    \n    # Load bias\n    bias_val = tl.load(b_ptr + feature_index * stride_bs, mask=mask, other=0)\n    acc += bias_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.where(y > 0, y, 0.0)   # ReLU\n    \n    # Store result\n    out_row_ptr = out_ptr + pid * stride_ob\n    tl.store(out_row_ptr + feature_index * stride_of, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            BLOCK_F = triton.next_power_of_2(self.out_features)\n            grid = (batch_size,)\n            \n            fused_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1),\n                BLOCK_F=BLOCK_F,\n            )\n        else:\n            # Fallback for CPU\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}