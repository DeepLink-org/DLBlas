{"id": "3874ac3e-0be8-4fc1-9e3e-83aebd9d22ff", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef fused_forward_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    subtract_value,\n    multiply_value,\n    stride_xb, \n    stride_xk,\n    stride_wn, \n    stride_wk,\n    stride_b,\n    stride_ob, \n    stride_of,\n    BLOCK_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)   # batch index\n    pid_n = tl.program_id(1)   # output feature index\n    \n    # Check boundaries\n    if pid_b >= batch_size or pid_n >= out_features:\n        return\n        \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Process input features in blocks\n    for k in range(0, in_features, BLOCK_K):\n        k_offsets = k + tl.arange(0, BLOCK_K)\n        mask = k_offsets < in_features\n        \n        # Load input block (contiguous)\n        x_vals = tl.load(\n            x_ptr + pid_b * stride_xb + k_offsets * stride_xk,\n            mask=mask,\n            other=0.0\n        )\n        \n        # Load weight block (contiguous)\n        w_vals = tl.load(\n            w_ptr + pid_n * stride_wn + k_offsets * stride_wk,\n            mask=mask,\n            other=0.0\n        )\n        \n        # Accumulate dot product\n        acc += tl.sum(x_vals * w_vals)\n    \n    # Load bias\n    b_val = tl.load(b_ptr + pid_n * stride_b)\n    acc += b_val\n    \n    # Apply operations\n    y = (acc - subtract_value) * multiply_value\n    y = tl.maximum(y, 0.0)   # ReLU\n    \n    # Store result\n    out_offset = pid_b * stride_ob + pid_n * stride_of\n    tl.store(out_ptr + out_offset, y)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, subtract_value, multiply_value):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.subtract_value = subtract_value\n        self.multiply_value = multiply_value\n        \n        # Initialize parameters\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        batch_size = x.shape[0]\n        output = torch.empty((batch_size, self.out_features), device=x.device, dtype=x.dtype)\n        \n        if x.is_cuda:\n            # Use 2D grid for better parallelism\n            grid = (batch_size, self.out_features)\n            BLOCK_K = triton.next_power_of_2(self.in_features)\n            \n            fused_forward_kernel[grid](\n                x, \n                self.weight, \n                self.bias, \n                output,\n                batch_size,\n                self.in_features,\n                self.out_features,\n                self.subtract_value,\n                self.multiply_value,\n                x.stride(0), \n                x.stride(1),\n                self.weight.stride(0), \n                self.weight.stride(1),\n                self.bias.stride(0),\n                output.stride(0), \n                output.stride(1),\n                BLOCK_K=BLOCK_K,\n            )\n        else:\n            # Fallback for CPU\n            linear_out = torch.nn.functional.linear(x, self.weight, self.bias)\n            output = torch.relu((linear_out - self.subtract_value) * self.multiply_value)\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\nsubtract_value = 2.0\nmultiply_value = 1.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, subtract_value, multiply_value]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "e0b8f391-f138-4751-a99d-4553ed422374", "generation": 3, "timestamp": 1754589079.0111988, "iteration_found": 25, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 47.89999999999999, "speed_up": 1.279, "runtime_ms": 0.0602, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.077, "speed_up": 1.279, "custom_timing": 0.0602}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 56.00000000000001, "speed_up": 1.36, "runtime_ms": 0.0566, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.077, "speed_up": 1.36, "custom_timing": 0.0566}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}