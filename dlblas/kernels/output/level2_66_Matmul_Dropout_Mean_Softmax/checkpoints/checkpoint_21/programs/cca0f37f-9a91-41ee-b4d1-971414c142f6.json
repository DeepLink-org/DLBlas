{"id": "cca0f37f-9a91-41ee-b4d1-971414c142f6", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['batch_size', 'in_features', 'out_features'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n        \n        # Load input block\n        x_ptrs = x_ptr + batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block - no transpose needed\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # FP16 matrix multiplication with FP32 accumulation\n        x_block_fp16 = x_block.to(tl.float16)\n        w_block_fp16 = w_block.to(tl.float16)\n        acc += tl.dot(x_block_fp16, w_block_fp16, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    # Let autotuner choose best configuration\n    grid = (\n        triton.cdiv(batch_size, 64),  # Starting point, autotuner will override\n        triton.cdiv(out_features, 64),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "9b6252dd-387d-416c-9741-0ef475ca6fc1", "generation": 3, "timestamp": 1754584709.1253576, "iteration_found": 20, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.708, "runtime_ms": 0.101, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0715, "speed_up": 0.708, "custom_timing": 0.101}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_66_Matmul_Dropout_Mean_Softmax", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp7cmft02w.py\", line 110, in forward\n    x = linear_triton(x, self.weight, self.bias)\n  File \"/tmp/tmp7cmft02w.py\", line 86, in linear_triton\n    linear_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\n    raise ValueError(f\"Conflicting meta-parameters: {', '.join(conflicts)}.\"\nValueError: Conflicting meta-parameters: BLOCK_SIZE_FEAT, BLOCK_SIZE_K, BLOCK_SIZE_BATCH. Make sure that you don't re-define auto-tuned symbols.\n", "runtime_error_name": "builtins.ValueError", "reference_timing_ms": 0.0715, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level2_66_Matmul_Dropout_Mean_Softmax', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp7cmft02w.py\", line 110, in forward\\n    x = linear_triton(x, self.weight, self.bias)\\n  File \"/tmp/tmp7cmft02w.py\", line 86, in linear_triton\\n    linear_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\\n    raise ValueError(f\"Conflicting meta-parameters: {\\', \\'.join(conflicts)}.\"\\nValueError: Conflicting meta-parameters: BLOCK_SIZE_FEAT, BLOCK_SIZE_K, BLOCK_SIZE_BATCH. Make sure that you don\\'t re-define auto-tuned symbols.\\n', 'runtime_error_name': 'builtins.ValueError', 'reference_timing_ms': 0.0715, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8020, runtime_ms: 0.0892, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.802, 'custom_timing': 0.0892}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8330, runtime_ms: 0.0858, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.833, 'custom_timing': 0.0858}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.6810, runtime_ms: 0.1050, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.681, 'custom_timing': 0.105}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n    ],\n    key=['batch_size', 'in_features', 'out_features'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n        \n        # Load input block\n        x_ptrs = x_ptr + (batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1)\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_ptrs = w_ptr + (feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1)\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Convert to FP16 and use tensor cores\n        x_block_f16 = x_block.to(tl.float16)\n        w_block_f16 = w_block.to(tl.float16)\n        acc += tl.dot(x_block_f16, w_block_f16, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + (batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1)\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    # Dynamic grid based on autotuned parameters\n    grid = lambda meta: (\n        triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n        triton.cdiv(out_features, meta['BLOCK_SIZE_FEAT']),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.6810), Performs well on runtime_ms (0.1050), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.681, 'custom_timing': 0.105})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    B, N, K,\n    stride_xb, stride_xk,\n    stride_wn, stride_wk,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_b = pid_b * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        offs_k = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load x block: [BLOCK_SIZE_M, BLOCK_SIZE_K]\n        x_ptrs = x_ptr + offs_b[:, None] * stride_xb + offs_k[None, :] * stride_xk\n        mask_x = (offs_b[:, None] < B) & (offs_k[None, :] < K)\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        \n        # Load w block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n        w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < K)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        # Transpose and compute matrix product\n        w_block_t = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block_t, allow_tf32=True)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + offs_n\n    mask_b = offs_n < N\n    b_block = tl.load(b_ptrs, mask=mask_b, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = out_ptr + offs_b[:, None] * stride_outb + offs_n[None, :] * stride_outn\n    mask_out = (offs_b[:, None] < B) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\ndef linear_triton(x, weight, bias):\n    B, K = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    grid = (triton.cdiv(B, 32), triton.cdiv(N, 32))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        B, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        BLOCK_SIZE_M=32, BLOCK_SIZE_N=32, BLOCK_SIZE_K=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8330), Performs well on runtime_ms (0.0858), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.833, 'custom_timing': 0.0858})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    # Transpose weight matrix block by swapping indices\n    w_ptrs = w_ptr + offs_k[:, None] * stride_wk + offs_n[None, :] * stride_wn\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < K\n        mask_x = (offs_m[:, None] < M) & mask_k[None, :]\n        mask_w = mask_k[:, None] & (offs_n[None, :] < N)\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = (triton.cdiv(M, 16), triton.cdiv(N, 16))\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=32\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8020), Performs well on runtime_ms (0.0892), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.802, 'custom_timing': 0.0892})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    M, N,\n    stride_xb, stride_xm,\n    stride_wn, stride_wm,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    n_off = pid_n * BLOCK_SIZE_N\n    n_offs = n_off + tl.arange(0, BLOCK_SIZE_N)\n    mask_n = n_offs < N\n    \n    out = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for m in range(0, M, BLOCK_SIZE_M):\n        m_offs = m + tl.arange(0, BLOCK_SIZE_M)\n        mask_m = m_offs < M\n        \n        x_vals = tl.load(x_ptr + pid_b * stride_xb + m_offs * stride_xm, mask=mask_m, other=0.0)\n        w_ptrs = weight_ptr + n_offs[:, None] * stride_wn + m_offs[None, :] * stride_wm\n        w_block = tl.load(w_ptrs, mask=mask_n[:, None] & mask_m[None, :], other=0.0)\n        \n        out += tl.sum(x_vals[None, :] * w_block, axis=1)\n    \n    bias_vals = tl.load(bias_ptr + n_offs, mask=mask_n, other=0.0)\n    out += bias_vals\n    \n    out_ptrs = output_ptr + pid_b * stride_outb + n_offs * stride_outn\n    tl.store(out_ptrs, out, mask=mask_n)\n\ndef linear_triton(x, weight, bias):\n    B, M = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    stride_xb = x.stride(0)\n    stride_xm = x.stride(1)\n    stride_wn = weight.stride(0)\n    stride_wm = weight.stride(1)\n    stride_outb = output.stride(0)\n    stride_outn = output.stride(1)\n    \n    grid = (B, triton.cdiv(N, 32))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        M, N,\n        stride_xb, stride_xm,\n        stride_wn, stride_wm,\n        stride_outb, stride_outn,\n        BLOCK_SIZE_M=32, BLOCK_SIZE_N=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < K\n        mask_x = (offs_m[:, None] < M) & mask_k[None, :]\n        mask_w = (offs_n[:, None] < N) & mask_k[None, :]\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = (triton.cdiv(M, 16), triton.cdiv(N, 16))\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=32\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    M, N,\n    stride_xb, stride_xm,\n    stride_wn, stride_wm,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    n_off = pid_n * BLOCK_SIZE_N\n    n_offs = n_off + tl.arange(0, BLOCK_SIZE_N)\n    mask_n = n_offs < N\n    \n    out = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for m in range(0, M, BLOCK_SIZE_M):\n        m_offs = m + tl.arange(0, BLOCK_SIZE_M)\n        mask_m = m_offs < M\n        \n        x_vals = tl.load(x_ptr + pid_b * stride_xb + m_offs * stride_xm, mask=mask_m, other=0.0)\n        w_ptrs = weight_ptr + n_offs[:, None] * stride_wn + m_offs[None, :] * stride_wm\n        w_block = tl.load(w_ptrs, mask=mask_n[:, None] & mask_m[None, :], other=0.0)\n        \n        out += tl.sum(x_vals[None, :] * w_block, axis=1)\n    \n    bias_vals = tl.load(bias_ptr + n_offs, mask=mask_n, other=0.0)\n    out += bias_vals\n    \n    out_ptrs = output_ptr + pid_b * stride_outb + n_offs * stride_outn\n    tl.store(out_ptrs, out, mask=mask_n)\n\ndef linear_triton(x, weight, bias):\n    B, M = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    stride_xb = x.stride(0)\n    stride_xm = x.stride(1)\n    stride_wn = weight.stride(0)\n    stride_wm = weight.stride(1)\n    stride_outb = output.stride(0)\n    stride_outn = output.stride(1)\n    \n    grid = (B, triton.cdiv(N, 32))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        M, N,\n        stride_xb, stride_xm,\n        stride_wn, stride_wm,\n        stride_outb, stride_outn,\n        BLOCK_SIZE_M=32, BLOCK_SIZE_N=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 32}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 32, 'BLOCK_SIZE_K': 64}, num_warps=4, num_stages=3),\n    ],\n    key=['batch_size', 'in_features', 'out_features'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n        \n        # Load input block\n        x_ptrs = x_ptr + (batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1)\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_ptrs = w_ptr + (feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1)\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Convert to FP16 and use tensor cores\n        x_block_f16 = x_block.to(tl.float16)\n        w_block_f16 = w_block.to(tl.float16)\n        acc += tl.dot(x_block_f16, w_block_f16, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + (batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1)\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    # Dynamic grid based on autotuned parameters\n    grid = lambda meta: (\n        triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n        triton.cdiv(out_features, meta['BLOCK_SIZE_FEAT']),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < K\n        mask_x = (offs_m[:, None] < M) & mask_k[None, :]\n        mask_w = (offs_n[:, None] < N) & mask_k[None, :]\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = (triton.cdiv(M, 16), triton.cdiv(N, 16))\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=32\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 0.0000, Type: Exploratory)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that performs matrix multiplication, applies dropout, calculates the mean, and then applies softmax.\n    \"\"\"\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nUnique approach: Excellent compiled (1.000), Excellent correctness (1.000), Alternative passed approach\n\n\n### Inspiration 5 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    B, N, K,\n    stride_xb, stride_xk,\n    stride_wn, stride_wk,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_b = pid_b * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        offs_k = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load x block: [BLOCK_SIZE_M, BLOCK_SIZE_K]\n        x_ptrs = x_ptr + offs_b[:, None] * stride_xb + offs_k[None, :] * stride_xk\n        mask_x = (offs_b[:, None] < B) & (offs_k[None, :] < K)\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        \n        # Load w block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n        w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < K)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        # Transpose and compute matrix product\n        w_block_t = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block_t, allow_tf32=True)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + offs_n\n    mask_b = offs_n < N\n    b_block = tl.load(b_ptrs, mask=mask_b, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = out_ptr + offs_b[:, None] * stride_outb + offs_n[None, :] * stride_outn\n    mask_out = (offs_b[:, None] < B) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\ndef linear_triton(x, weight, bias):\n    B, K = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    grid = (triton.cdiv(B, 32), triton.cdiv(N, 32))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        B, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        BLOCK_SIZE_M=32, BLOCK_SIZE_N=32, BLOCK_SIZE_K=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['batch_size', 'in_features', 'out_features'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_mask = k_offsets < (in_features - k)\n        k_current = k + k_offsets\n        \n        # Load input block\n        x_ptrs = x_ptr + batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block and transpose for proper matrix multiplication\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        w_block = tl.trans(w_block)\n        \n        # FP16 matrix multiplication with FP32 accumulation\n        x_block_fp16 = x_block.to(tl.float16)\n        w_block_fp16 = w_block.to(tl.float16)\n        acc += tl.dot(x_block_fp16, w_block_fp16, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    # Let autotuner choose best configuration\n    grid = (\n        triton.cdiv(batch_size, 64),  # Starting point, autotuner will override\n        triton.cdiv(out_features, 64),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        BLOCK_SIZE_BATCH=64,  # Defaults, autotuner will override\n        BLOCK_SIZE_FEAT=64,\n        BLOCK_SIZE_K=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that has a compilation error due to conflicting meta-parameters in the autotuner.\n The error message: \"ValueError: Conflicting meta-parameters: BLOCK_SIZE_FEAT, BLOCK_SIZE_K, BLOCK_SIZE_BATCH. Make sure that you don't re-define auto-tuned symbols.\"\n\n The issue is that the autotuner is trying to tune the block sizes, but in the kernel we are using `k_offsets` and `k_current` in a way that might be causing a conflict.\n\n Looking at the current kernel, we see:\n   - We have three block size parameters: BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT, BLOCK_SIZE_K.\n   - The loop over `k` uses `BLOCK_SIZE_K` and we have a mask `k_mask = k_offsets < (in_features - k)`. This mask is incorrect because `k_offsets` is of size `BLOCK_SIZE_K` and we are comparing with `(in_features - k)`, which might be negative? Actually, we want to check that `k_current < in_features`.\n\n Let's break down the problems:\n\n 1. The error about conflicting meta-parameters: This might be because in the autotuner we are using the same names as the kernel arguments, but the autotuner expects that the symbols it tunes are not redefined in the kernel. However, in the kernel we are using these as `tl.constexpr` so it should be okay. But note the error says \"Conflicting meta-parameters: BLOCK_SIZE_FEAT, BLOCK_SIZE_K, BLOCK_SIZE_BATCH\". This is because in the autotuner configs we are defining these as the keys, but in the kernel we are also using them as parameters. This is the standard way, so why the error?\n\n 2. The mask for `k_mask` is incorrect. We should instead do:\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n\n 3. The weight matrix is stored in shape [out_features, in_features]. In the kernel, we are loading a block of weight as:\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n    This gives a block of shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] (if we consider the offsets). Then we transpose it to [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. But note: the dot product we are doing is:\n        x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K]\n        w_block (after transpose): [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] -> then we take the transpose to get [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? Actually, the `tl.trans` function transposes the matrix so that the block becomes [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Actually, the Triton `dot` operation requires the second matrix to be transposed? Let me check: the dot product of [M, K] and [K, N] is [M, N]. In our case, we have:\n        x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K]\n        w_block: [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]   (because we did `tl.trans` on a [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] matrix? Actually, the `tl.trans` of a [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] matrix would be [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. So we have to do:\n\n        We have two options:\n        Option A: Load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then do not transpose? Then we can do: `tl.dot(x_block, w_block, trans_b=True)`\n        Option B: Load the weight block as [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] and then use it without transpose? Then we can do: `tl.dot(x_block, w_block)`\n\n    But note: the weight matrix is stored in row-major with shape [out_features, in_features]. So the element at (i, j) is at `w_ptr + i * stride_w0 + j * stride_w1`. When we load a block for a specific `feat_offsets` (which are the rows of weight) and `k_current` (which are the columns), we are loading a block of shape [len(feat_offsets), len(k_current)] = [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. Then we transpose it to [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. Then we are trying to multiply:\n        x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] \n        w_block: [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]\n        -> dot product: [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT]\n\n    This is correct. However, note that the Triton dot operation does not require transposing the second matrix if it is already in the shape [K, N]. So we are doing it correctly.\n\n 4. However, the error about conflicting meta-parameters is the main issue. The autotuner is not happy. This might be because we are using the same names for the block sizes in the autotuner config and in the kernel, but the kernel also uses them in the loop and in the masks. The autotuner might be trying to set them to different values and then the kernel redefines them? But they are `tl.constexpr`.\n\n After checking the Triton documentation and examples, the standard practice is to use the same names. So why the error?\n\n Looking at the error trace: it comes from the autotuner when trying to benchmark. The autotuner says that there are conflicting meta-parameters. This might be because we are passing the block sizes as arguments to the kernel and also the autotuner is trying to set them. But note that in the kernel they are defined as `tl.constexpr` and we are passing them from the grid function. The autotuner expects that the symbols it tunes are not overridden.\n\n How we call the kernel in the function `linear_triton`:\n        linear_kernel[grid](\n            ...,\n            BLOCK_SIZE_BATCH=64,  # Defaults, autotuner will override\n            BLOCK_SIZE_FEAT=64,\n            BLOCK_SIZE_K=32\n        )\n\n This is incorrect because we are setting the block sizes to fixed values (64,64,32) and then the autotuner is trying to set them to the values in the config. This causes a conflict.\n\n The solution is to remove the default values in the kernel call and let the autotuner set them. We should pass the block sizes as the ones provided by the autotuner. But note: the grid function is defined as:\n        grid = lambda meta: (\n            triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n            triton.cdiv(out_features, meta['BLOCK_SIZE_FEAT']),\n        )\n\n And then we call the kernel with `linear_kernel[grid](...)` and without providing the block sizes? Actually, the autotuner will provide the block sizes as meta-parameters. We should not pass them again.\n\n How to fix:\n    In the kernel call, we should not pass the block sizes as keyword arguments. Instead, the autotuner will pass them via the meta dictionary. So we remove the block size arguments from the kernel call.\n\n However, in the current code we have:\n        linear_kernel[grid](\n            ...,\n            BLOCK_SIZE_BATCH=64,  # This is wrong\n            BLOCK_SIZE_FEAT=64,\n            BLOCK_SIZE_K=32\n        )\n\n We should remove these.\n\n Let me rewrite the kernel call without the block sizes. We only pass the non-meta arguments.\n\n Steps for the current program:\n\n 1. Remove the block size arguments from the kernel call.\n 2. Fix the mask for `k_mask`: use `k_current = k + k_offsets` and then `k_mask = k_current < in_features`.\n 3. Also, note that the weight matrix is stored as [out_features, in_features]. The way we load the weight block is: \n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n    This gives a block of shape [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Actually, no: \n        feat_offsets[None, :] has shape [1, BLOCK_SIZE_FEAT]\n        k_current[:, None] has shape [BLOCK_SIZE_K, 1]\n        Then the pointer arithmetic: \n            for each element in feat_offsets and k_current, we compute the address.\n\n    The resulting block is of shape [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Actually, when we load with `tl.load(w_ptrs, mask=w_mask)`, we are loading a block of shape [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? But note: the offsets are broadcasted. The way we constructed `w_ptrs` is by adding two arrays of shape [1, BLOCK_SIZE_FEAT] and [BLOCK_SIZE_K, 1]. This gives a pointer array of shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. So we are loading a block of [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. Then we transpose it to [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Actually, we do:\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        w_block = tl.trans(w_block)\n\n    This transposes the block to [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. But we want to multiply the x_block [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] by a weight block that is [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? Actually, we don't have that. We have a block of the weight matrix that is a contiguous block of [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? That is not contiguous in the original matrix? \n\n    The original weight matrix is stored in row-major. We are loading a block that spans multiple rows (over the feature dimension) and multiple columns (over the in_features). The correct way is to load a block of [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] without transposing. Then we can use it as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then we would need to transpose to get [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] for the dot product? \n\n    But note: the dot product in Triton is:\n        tl.dot(a, b) where a is [M, K] and b is [K, N] -> result [M, N]\n\n    In our case, we have:\n        a = x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K]\n        b = w_block: we want [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]\n\n    How do we get b? If we load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] (which is the natural way because each row of the weight matrix is a feature row), then we have to transpose it to [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. So we are doing:\n        w_block = tl.load( ... )   # [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Actually, no: the way we constructed the pointers gives [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. \n\n    Let me clarify the pointer arithmetic:\n\n        w_ptrs = w_ptr + (feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1)\n\n        This is an outer addition: we are creating a pointer for every combination of an offset in feat_offsets and k_current.\n\n        The resulting pointer array has dimensions: [len(k_current), len(feat_offsets)] = [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]\n\n        Then we load a block of that shape. Then we do `tl.trans(w_block)`, which would make it [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. That is not what we want.\n\n    We want the weight block to be [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? Then we can use it directly? But then the dot product would be:\n\n        x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] \n        w_block: [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] \n        -> dot product: [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT] \n\n    So we don't need to transpose. Therefore, we can remove the transpose.\n\n    Alternatively, we can change the way we load the weight block to be [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then transpose to [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. But that is inefficient.\n\n    Actually, the natural way for the weight matrix is to be stored in row-major. We want to load a block that is contiguous in memory? But note: we are loading a block that is not contiguous because we are taking a set of rows (feat_offsets) and a set of columns (k_current). The way we are doing it is with pointer arithmetic that gives a 2D block. This is standard.\n\n    However, the key is that we want the weight block to be of shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] for the dot product? But that would be non-contiguous in the original matrix because the rows of the weight matrix are of length in_features (K). We are taking a block of columns? Actually, we are taking a set of rows and a set of columns? The block we are loading is a set of rows (each row is contiguous in the columns we are taking? no, because we are taking non-contiguous columns?).\n\n    Actually, we are taking a contiguous block of columns? Only if the columns we are taking are contiguous? But we are using `k_current = k + tl.arange(0, BLOCK_SIZE_K)`, which is contiguous. So the block we are loading from the weight matrix is a set of rows (non necessarily contiguous) and a contiguous set of columns? But the way we index with `k_current[:, None]` and `feat_offsets[None, :]` gives a block that is not contiguous in memory? \n\n    We can change the way we load the weight block to be in a way that we can use without transpose and also efficient. The best is to load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then transpose it to [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] for the dot product? But that is an extra operation.\n\n    Alternatively, we can note that the weight matrix is stored in row-major, so the contiguous dimension is the column (in_features). We can load the weight block by having the feature dimension in the rows and the k dimension in the columns? Then we would have [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. Then we can use `tl.dot(x_block, w_block, trans_b=True)`? \n\n    But that would require the weight block to be [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then we do `trans_b=True` meaning we use the transpose of the weight block which is [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. Then the dot product is [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT]. \n\n    So we can avoid the explicit transpose by using `trans_b=True` and not transposing the weight block.\n\n    Let me change:\n\n        Option: Remove the transpose of w_block and use `trans_b=True` in the dot.\n\n    Steps:\n\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)   # shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? Actually, no: we constructed the pointers to be [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? But the way we did the pointers, we get a block of [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. \n\n        But note: the weight matrix is stored in row-major. The element at (i, j) is at w_ptr + i * stride_w0 + j * stride_w1. When we do:\n            w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        This gives a block where the first dimension (varying fastest) is the column (k) and then the row (feature)? Actually, no: the arithmetic is: for a fixed row i (in feat_offsets) and column j (in k_current), the pointer is w_ptr + i * stride_w0 + j * stride_w1. But when we have an array of i and j, the resulting pointer array is of shape [len(feat_offsets)] for the rows and [len(k_current)] for the columns? Actually, we are broadcasting: \n            feat_offsets[None, :] -> [1, BLOCK_SIZE_FEAT]\n            k_current[:, None] -> [BLOCK_SIZE_K, 1]\n            Then the sum -> [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]\n\n        So we are loading a block of shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. This is not contiguous in the original matrix? The original matrix has row stride of stride_w0 and column stride of stride_w1. We are jumping in the row dimension by stride_w0 for each element in the feature dimension and in the column dimension by stride_w1 for each element in the k dimension. This is a standard 2D block.\n\n        Then we can use this block without transpose? But the dot product requires the second matrix to be [K, N] and we have a block that is [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. So if we do:\n            tl.dot(x_block, w_block) \n        then it would be:\n            [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] * [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] -> [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT]\n\n        So we don't need to transpose the weight block? But note: the weight block we loaded is for a set of features (rows) and a set of columns? Actually, the weight matrix is of shape [out_features, in_features]. The block we loaded is for a set of rows (features) and a set of columns (k). But we have loaded it as [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? That is, the first dimension of the block is the column index? That is not what we want. We want the weight block to be [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? Because the dot product requires the inner dimension to be the same.\n\n        Actually, the weight block should be of shape [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] so that we can do:\n            x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] * weight_block: [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]^T -> [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT]\n\n        So we want to load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then use `trans_b=True`.\n\n        How to load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]? We can change the pointer arithmetic:\n\n            w_ptrs = w_ptr + (feat_offsets[:, None] * stride_w0 + k_current[None, :] * stride_w1)\n\n        Then the block will be [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]. Then we can do:\n\n            w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)   # [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]\n            ... then in the dot, we use `tl.dot(x_block, w_block, trans_b=True)`\n\n        But note: the mask for w_mask must be adjusted: \n            w_mask = (feat_offsets[:, None] < out_features) & (k_current[None, :] < in_features)\n\n        Alternatively, we can keep the original pointer arithmetic and then transpose the block? But we are trying to avoid the transpose.\n\n    Given the complexity, let's stick to the way that is known to work: load the weight block as [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] and then transpose it to [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] and then do the dot without transposing. But that requires an explicit transpose.\n\n    However, the Triton dot operation does not support transposing the second matrix by an argument? It does: `trans_b` is an argument to `tl.dot`.\n\n    So I propose:\n\n        Change the weight block loading to have the shape [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] by:\n            w_ptrs = w_ptr + feat_offsets[:, None] * stride_w0 + k_current[None, :] * stride_w1\n            w_mask = (feat_offsets[:, None] < out_features) & (k_current[None, :] < in_features)\n\n        Then we can do:\n            w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)   # [BLOCK_SIZE_FEAT, BLOCK_SIZE_K]\n            acc += tl.dot(x_block, w_block, trans_b=True)\n\n        This avoids the explicit transpose.\n\n    But note: the dot product with `trans_b=True` means the second matrix is transposed, so we are doing:\n        [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] * [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] (because transposing [BLOCK_SIZE_FEAT, BLOCK_SIZE_K] gives [BLOCK_SIZE_K, BLOCK_SIZE_FEAT])\n\n    This is what we want.\n\n 5. However, to minimize changes and given the time, let's focus on the compilation error and the mask. We can leave the weight block loading as is and remove the explicit transpose and then use the dot with the weight block in the shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT] without transposing? That would be the natural way.\n\n    How did we load the weight block? We did:\n\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n\n        This gives a block of shape [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]. And we want to do:\n\n        x_block: [BLOCK_SIZE_BATCH, BLOCK_SIZE_K] \n        w_block: [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]\n        -> dot product: [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT]\n\n        So we can remove the transpose and then do:\n\n            acc += tl.dot(x_block, w_block)\n\n    This is simpler.\n\n    Therefore, we remove the line: `w_block = tl.trans(w_block)`\n\n    And then use `tl.dot(x_block, w_block)`\n\n    But note: the mask for the weight block was:\n\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n\n        This is for a block of [BLOCK_SIZE_K, BLOCK_SIZE_FEAT]? Yes.\n\n    So we change:\n\n        Remove the transpose of w_block.\n\n 6. Summary of changes:\n\n    a) Remove the block size arguments from the kernel call.\n    b) Fix the k_mask: compute k_current and then k_mask = k_current < in_features.\n    c) Remove the transpose of w_block and use the dot product without transposing.\n\n 7. Also, note that in the current code, the loop variable `k` is used to compute `k_current = k + k_offsets`. We must do that.\n\n 8. The corrected kernel code for the loop:\n\n        for k in range(0, in_features, BLOCK_SIZE_K):\n            k_current = k + k_offsets\n            k_mask = k_current < in_features\n\n            ... rest ...\n\n 9. And remove the transpose of w_block.\n\n 10. And in the kernel call, remove the three block size arguments.\n\n Let's rewrite the current program accordingly.\n\n However, note: the autotuner configs use the block sizes, so we must keep them in the kernel signature. We just remove them from the call.\n\n Revised kernel call:\n\n        linear_kernel[grid](\n            x, weight, bias, output,\n            batch_size, in_features, out_features,\n            x.stride(0), x.stride(1),\n            weight.stride(0), weight.stride(1),\n            output.stride(0), output.stride(1),\n            # Removed the block size arguments\n        )\n\n But note: the kernel expects the block sizes as the last three arguments? We are not passing them? How will they get set? The autotuner will set them via the meta dictionary.\n\n This is the standard way in Triton: the autotuner will provide the values for the `tl.constexpr` arguments that are tuned.\n\n Therefore, we remove the block size arguments in the call.\n\n Let's write the corrected code.\n\n IMPORTANT: We are only allowed to change the code within the EVOLVE-BLOCK.\n\n We'll do:\n\n   - In the kernel: \n        Inside the loop, change the k_mask computation and remove the transpose of w_block.\n   - In the kernel call: remove the three block size arguments.\n\n But note: the kernel also has a line that does:\n        k_mask = k_offsets < (in_features - k)\n\n    We change that to:\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n\n And then use k_current in the pointer.\n\n And remove the `w_block = tl.trans(w_block)`.\n\n Let's do it.\n</think>\nThe error occurred due to conflicting meta-parameters in the autotuner configuration. The solution involves:\n\n1. Removing explicit block size arguments from the kernel call to allow autotuner to handle them\n2. Fixing the k_mask calculation by using k_current = k + k_offsets\n3. Removing unnecessary transpose of weight block since pointer arithmetic already provides proper shape\n4. Maintaining all other functionality while improving performance\n\nHere's the corrected implementation:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEAT': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEAT': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['batch_size', 'in_features', 'out_features'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_current = k + k_offsets\n        k_mask = k_current < in_features\n        \n        # Load input block\n        x_ptrs = x_ptr + batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block - no transpose needed\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # FP16 matrix multiplication with FP32 accumulation\n        x_block_fp16 = x_block.to(tl.float16)\n        w_block_fp16 = w_block.to(tl.float16)\n        acc += tl.dot(x_block_fp16, w_block_fp16, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    # Let autotuner choose best configuration\n    grid = (\n        triton.cdiv(batch_size, 64),  # Starting point, autotuner will override\n        triton.cdiv(out_features, 64),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}