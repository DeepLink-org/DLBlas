{"id": "1e3734ce-344c-4935-80be-9d1da6ed4af6", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_size = min(BLOCK_SIZE_K, k_remaining)\n        \n        mask_x = (offs_m[:, None] < M) & (offs_k[None, :] < k_size)\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < k_size)\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        # Transpose weight block for correct matrix multiplication\n        w_block_t = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block_t, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    # Add bias\n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = out_ptr + (offs_m[:, None] * stride_om + offs_n[None, :] * stride_on)\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        \n        # Use fixed block sizes optimized for small matrices\n        BLOCK_M, BLOCK_N, BLOCK_K = 64, 64, 64\n        grid = (triton.cdiv(M, BLOCK_M) * triton.cdiv(N, BLOCK_N),)\n        \n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=BLOCK_M, BLOCK_SIZE_N=BLOCK_N, BLOCK_SIZE_K=BLOCK_K\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "cb2dc942-3d96-4ab4-b932-fa02533b3e09", "generation": 3, "timestamp": 1754584429.7119653, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.826, "runtime_ms": 0.0866, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0715, "speed_up": 0.826, "custom_timing": 0.0866}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.633, "runtime_ms": 0.113, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0715, "speed_up": 0.633, "custom_timing": 0.113}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.6330\n- runtime_ms: 0.1130\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.633, 'custom_timing': 0.113}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.6330, runtime_ms: 0.1130, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.633, 'custom_timing': 0.113}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8440, runtime_ms: 0.0847, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.844, 'custom_timing': 0.0847}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8530, runtime_ms: 0.0838, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.853, 'custom_timing': 0.0838}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    B, M, N,\n    stride_xb, stride_xm,\n    stride_wn, stride_wm,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_b = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_b[:, None] * stride_xb + offs_k[None, :] * stride_xm\n    w_ptrs = weight_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wm\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, M, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < M\n        mask_x = (offs_b[:, None] < B) & mask_k[None, :]\n        mask_w = (offs_n[:, None] < N) & mask_k[None, :]\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        w_block = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xm\n        w_ptrs += BLOCK_SIZE_K * stride_wm\n    \n    bias_ptrs = bias_ptr + offs_n\n    bias_block = tl.load(bias_ptrs, mask=offs_n < N, other=0.0)\n    acc += bias_block[None, :]\n    \n    out_ptrs = output_ptr + offs_b[:, None] * stride_outb + offs_n[None, :] * stride_outn\n    mask_out = (offs_b[:, None] < B) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\ndef linear_triton(x, weight, bias):\n    B, M = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    stride_xb = x.stride(0)\n    stride_xm = x.stride(1)\n    stride_wn = weight.stride(0)\n    stride_wm = weight.stride(1)\n    stride_outb = output.stride(0)\n    stride_outn = output.stride(1)\n    \n    grid = (triton.cdiv(B, 16), triton.cdiv(N, 16))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        B, M, N,\n        stride_xb, stride_xm,\n        stride_wn, stride_wm,\n        stride_outb, stride_outn,\n        BLOCK_SIZE_B=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=16\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8530), Performs well on runtime_ms (0.0838), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.853, 'custom_timing': 0.0838})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < K\n        mask_x = (offs_m[:, None] < M) & mask_k[None, :]\n        mask_w = (offs_n[:, None] < N) & mask_k[None, :]\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        # Transpose weight block for correct matrix multiplication\n        w_block_t = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block_t, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = (triton.cdiv(M, 16), triton.cdiv(N, 16))\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=32\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8440), Performs well on runtime_ms (0.0847), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.844, 'custom_timing': 0.0847})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 64}, num_warps=2),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        k_remaining = K - k * BLOCK_SIZE_K\n        k_size = min(BLOCK_SIZE_K, k_remaining)\n        \n        mask_x = (offs_m[:, None] < M) & (offs_k[None, :] < k_size)\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < k_size)\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        w_block = tl.trans(w_block)\n        \n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    out_ptrs = out_ptr + (offs_m[:, None] * stride_om + offs_n[None, :] * stride_on)\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),)\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1)\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.6330), Performs well on runtime_ms (0.1130), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0715, 'speed_up': 0.633, 'custom_timing': 0.113})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_mask = k_offsets < (in_features - k)\n        k_current = k + k_offsets\n        \n        # Load input block\n        x_ptrs = x_ptr + batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        acc += tl.dot(x_block, w_block, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    BLOCK_SIZE_BATCH = 32\n    BLOCK_SIZE_FEAT = 32\n    BLOCK_SIZE_K = 32\n    \n    grid = (\n        triton.cdiv(batch_size, BLOCK_SIZE_BATCH),\n        triton.cdiv(out_features, BLOCK_SIZE_FEAT),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT, BLOCK_SIZE_K\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    batch_size,\n    in_features,\n    out_features,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEAT: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feat_offsets = pid1 * BLOCK_SIZE_FEAT + tl.arange(0, BLOCK_SIZE_FEAT)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    batch_mask = batch_offsets < batch_size\n    feat_mask = feat_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_mask = k_offsets < (in_features - k)\n        k_current = k + k_offsets\n        \n        # Load input block\n        x_ptrs = x_ptr + batch_offsets[:, None] * stride_x0 + k_current[None, :] * stride_x1\n        x_mask = batch_mask[:, None] & k_mask[None, :]\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_ptrs = w_ptr + feat_offsets[None, :] * stride_w0 + k_current[:, None] * stride_w1\n        w_mask = feat_mask[None, :] & k_mask[:, None]\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        acc += tl.dot(x_block, w_block, out_dtype=tl.float32)\n    \n    # Load and add bias\n    b_ptrs = b_ptr + feat_offsets\n    b_block = tl.load(b_ptrs, mask=feat_mask, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = output_ptr + batch_offsets[:, None] * stride_out0 + feat_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, acc, mask=batch_mask[:, None] & feat_mask[None, :])\n\ndef linear_triton(x, weight, bias):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n    \n    BLOCK_SIZE_BATCH = 32\n    BLOCK_SIZE_FEAT = 32\n    BLOCK_SIZE_K = 32\n    \n    grid = (\n        triton.cdiv(batch_size, BLOCK_SIZE_BATCH),\n        triton.cdiv(out_features, BLOCK_SIZE_FEAT),\n    )\n    \n    linear_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        BLOCK_SIZE_BATCH, BLOCK_SIZE_FEAT, BLOCK_SIZE_K\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    B, M, N,\n    stride_xb, stride_xm,\n    stride_wn, stride_wm,\n    stride_outb, stride_outn,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    offs_b = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + offs_b[:, None] * stride_xb + offs_k[None, :] * stride_xm\n    w_ptrs = weight_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wm\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, M, BLOCK_SIZE_K):\n        mask_k = (k + offs_k) < M\n        mask_x = (offs_b[:, None] < B) & mask_k[None, :]\n        mask_w = (offs_n[:, None] < N) & mask_k[None, :]\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        w_block = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xm\n        w_ptrs += BLOCK_SIZE_K * stride_wm\n    \n    bias_ptrs = bias_ptr + offs_n\n    bias_block = tl.load(bias_ptrs, mask=offs_n < N, other=0.0)\n    acc += bias_block[None, :]\n    \n    out_ptrs = output_ptr + offs_b[:, None] * stride_outb + offs_n[None, :] * stride_outn\n    mask_out = (offs_b[:, None] < B) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\ndef linear_triton(x, weight, bias):\n    B, M = x.shape\n    N = weight.shape[0]\n    output = torch.empty(B, N, device=x.device, dtype=x.dtype)\n    \n    stride_xb = x.stride(0)\n    stride_xm = x.stride(1)\n    stride_wn = weight.stride(0)\n    stride_wm = weight.stride(1)\n    stride_outb = output.stride(0)\n    stride_outn = output.stride(1)\n    \n    grid = (triton.cdiv(B, 16), triton.cdiv(N, 16))\n    linear_kernel[grid](\n        x, weight, bias, output,\n        B, M, N,\n        stride_xb, stride_xm,\n        stride_wn, stride_wm,\n        stride_outb, stride_outn,\n        BLOCK_SIZE_B=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=16\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = linear_triton(x, self.weight, self.bias)\n        x = self.dropout(x)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 64}, num_warps=2),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        k_remaining = K - k * BLOCK_SIZE_K\n        k_size = min(BLOCK_SIZE_K, k_remaining)\n        \n        mask_x = (offs_m[:, None] < M) & (offs_k[None, :] < k_size)\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < k_size)\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        w_block = tl.trans(w_block)\n        \n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    out_ptrs = out_ptr + (offs_m[:, None] * stride_om + offs_n[None, :] * stride_on)\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),)\n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1)\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that uses a Triton kernel for linear layer, followed by dropout, mean, and softmax.\n The current performance shows a speed_up of 0.633 (which is slower than the reference) and we want to improve it.\n\n Observations:\n - The current Triton kernel for the linear layer is using autotune, but the performance is still not good.\n - The kernel uses a 1D grid (with pid = (pid_m * num_pid_n + pid_n)) and loops over K dimension.\n - The kernel transposes the weight block for each iteration, which might be inefficient.\n\n Steps for improvement:\n 1. We note that the matrix multiplication in the linear layer is: \n        x (M, K) @ weight (N, K).T   -> output (M, N)\n    But in the kernel, we are loading a block of weight of shape (BLOCK_SIZE_N, BLOCK_SIZE_K) and then transposing it to (BLOCK_SIZE_K, BLOCK_SIZE_N) for the dot product.\n    However, the weight matrix is stored in row-major (out_features, in_features). We are loading a block that is contiguous in the weight matrix? Actually, the weight is stored as (N, K) and we are loading a block of (BLOCK_SIZE_N, BLOCK_SIZE_K). Then we transpose it to (BLOCK_SIZE_K, BLOCK_SIZE_N). The dot product then becomes: \n        (BLOCK_SIZE_M, BLOCK_SIZE_K) @ (BLOCK_SIZE_K, BLOCK_SIZE_N) -> (BLOCK_SIZE_M, BLOCK_SIZE_N)\n    This is correct.\n\n 2. However, we might improve by changing the way we load the weight matrix to avoid the transpose. We can pre-transpose the weight matrix? But that would be done on the host and we are not allowed to change the function signature or the parameters.\n\n 3. Alternatively, we can change the kernel to use a different memory access pattern for the weight matrix. We can note that the weight matrix is accessed in a transposed manner. We can load the weight matrix in a way that we get a block of (BLOCK_SIZE_K, BLOCK_SIZE_N) without having to transpose? But the memory layout is row-major, so if we want a block of (BLOCK_SIZE_K, BLOCK_SIZE_N) we would have to do a transposed load? Triton doesn't have direct support for that.\n\n 4. Another idea: use a different tiling strategy. The current kernel uses a 1D grid and then recalculates the offsets for M and N. This might not be optimal for the GPU.\n\n 5. We note that the best performing program in the history (Attempt 1) had a speed_up of 0.853, which is better than the current 0.633. Let's look at the differences.\n\n 6. The top program (Program 1) in the history uses a 2D grid and fixed block sizes (16,16,16). It also does not use autotune. However, we are using autotune now and it is performing worse. Maybe the autotune configurations are not optimal for this small matrix? The matrix sizes are (128,100) and (50,100). This is very small.\n\n 7. For small matrices, the overhead of launching a kernel with many blocks and the autotune might be too high. We might try to use a fixed configuration that is known to work well for small sizes.\n\n 8. Alternatively, we can try to use a kernel that is optimized for small sizes. We note that the entire matrix multiplication can be done by a single block? But 128*50=6400, which is too big for one block.\n\n 9. Another idea: use a kernel that is designed for batch matrix multiplication. But our batch size is 128 and the matrices are (100,50). Actually, we are doing a batch of 128 independent matrix multiplications? No, we are doing a single matrix multiplication: (128,100) @ (100,50) -> (128,50). So it's one big matrix multiplication.\n\n10. We might try to increase the block sizes to reduce the number of blocks. Currently, the autotune configs are:\n        - (64,64,64) with 4 warps\n        - (32,128,32) with 4 warps\n        - (128,32,32) with 4 warps\n        - (16,16,64) with 2 warps\n\n    For M=128, N=50, K=100:\n        - With (64,64,64): \n            grid = (ceil(128/64) * ceil(50/64)) = (2 * 1) = 2\n        - With (32,128,32): \n            grid = (ceil(128/32) * ceil(50/128)) = (4 * 1) = 4\n        - With (128,32,32): \n            grid = (ceil(128/128) * ceil(50/32)) = (1 * 2) = 2\n        - With (16,16,64): \n            grid = (ceil(128/16) * ceil(50/16)) = (8 * 4) = 32\n\n    The one with 32 blocks might be too many. The best would be to have as few blocks as possible? But also each block should have enough work.\n\n11. The current kernel has a loop over K in blocks. The inner loop is over the K dimension. The number of iterations is ceil(K / BLOCK_SIZE_K). For K=100:\n        - BLOCK_SIZE_K=64: 2 iterations\n        - BLOCK_SIZE_K=32: 4 iterations\n        - BLOCK_SIZE_K=16: 7 iterations\n\n12. We might try to use a fixed configuration that minimizes the number of blocks and the number of iterations. The (64,64,64) configuration has only 2 blocks and 2 iterations. But note: N=50 is less than 64, so each block would have to compute 64 columns? But we only have 50. So we are wasting some.\n\n13. We can try to remove autotune and use a fixed configuration that is good for small sizes. For example, use BLOCK_SIZE_M=128 (so only one block in M) and BLOCK_SIZE_N=32 (so 2 blocks in N) and BLOCK_SIZE_K=32 (so 4 iterations). That would be 2 blocks in total. We can try that.\n\n14. Alternatively, we can look at the top performing program in the history (Program 1) that had a speed_up of 0.853. It used:\n        grid = (triton.cdiv(B, 16), triton.cdiv(N, 16))\n        BLOCK_SIZE_B=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=16\n\n    For our case: \n        B (M) = 128, N=50 -> grid = (ceil(128/16)=8, ceil(50/16)=4) = 32 blocks.\n\n    But that program had a speed_up of 0.853, which is better than 0.633.\n\n15. Let's try to use that fixed configuration and see if we can get a better speed.\n\n16. However, note that the current program uses a 1D grid and the top program uses a 2D grid. The 2D grid might be more efficient for the GPU scheduler.\n\n17. We will change the kernel to use a 2D grid and fixed block sizes of (16, 16) for M and N, and 16 for K. We remove autotune for now to keep it simple.\n\n18. We also note that the kernel in the top program (Program 1) did not have a loop over K with a variable block size for K? Actually, it did. It looped over K in steps of BLOCK_SIZE_K (16). So 100/16 -> 7 iterations.\n\n19. We will write the kernel with a 2D grid and fixed block sizes.\n\n20. We must be cautious about the memory access pattern. The top program (Program 1) used:\n        offs_b = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n        offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n        x_ptrs = x_ptr + offs_b[:, None] * stride_xb + offs_k[None, :] * stride_xm\n        w_ptrs = weight_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wm\n\n    Then loaded and did:\n        w_block = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n\n21. We will do the same.\n\n22. Steps for the rewrite:\n    - Remove the autotune decorator.\n    - Change the kernel to use a 2D grid: pid0 for M (batch) and pid1 for N (out_features).\n    - Use fixed block sizes: 16 for M, 16 for N, and 16 for K.\n    - We must also adjust the grid function: grid = (triton.cdiv(M, 16), triton.cdiv(N, 16))\n\n23. We note that the current kernel also adds the bias. We do the same.\n\n24. We must maintain the same function signature for the kernel? But note the parameters are different. We are changing the grid to 2D and the block sizes are fixed.\n\n25. However, the problem says: \n        \u274c NEVER change @triton.jit function signatures or parameter names\n\n    But we are changing the way the program id is used? The signature of the kernel function is the same, but the meaning of the program id changes? Actually, the kernel function signature must remain the same. We cannot change the grid from 1D to 2D arbitrarily because the program id is 1D in the current kernel. We must use a 1D grid or change the kernel to use 2D program ids? \n\n    The current kernel uses:\n        pid = tl.program_id(0)   # 1D grid\n\n    We want to use a 2D grid? But that would require changing the kernel to have two program ids. We are not allowed to change the function signature. So we cannot.\n\n26. Alternatively, we can keep the 1D grid and then compute the 2D indices as:\n        pid_m = pid // num_pid_n\n        pid_n = pid % num_pid_n\n\n    which is what the current kernel does. So we are already doing that.\n\n27. Then why is the current kernel slow? Maybe because of the autotune and the specific block sizes? Let's try to use a fixed configuration that is known to be better.\n\n28. We will try to use the configuration that worked well in the top program: BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=16. We remove autotune and fix these block sizes.\n\n29. We also note that the top program (Program 1) had a speed_up of 0.853. We are currently at 0.633. So by fixing the block sizes to 16,16,16 we might get back to 0.853.\n\n30. We remove autotune and fix the block sizes to 16,16,16.\n\n31. Also, we note that the current kernel uses:\n        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n            k_remaining = K - k * BLOCK_SIZE_K\n            k_size = min(BLOCK_SIZE_K, k_remaining)\n            ... and then uses k_size for mask\n\n    This is safe. But the top program did not have the k_remaining? It did:\n        for k in range(0, M, BLOCK_SIZE_K):\n            mask_k = (k + offs_k) < M\n\n    Actually, the top program used the entire BLOCK_SIZE_K for the inner loop and then masked. We are doing the same.\n\n32. We will remove autotune and set fixed block sizes: 16,16,16.\n\n33. We also note that the grid function in the current program is:\n        grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),)\n\n    We will change it to:\n        grid = (triton.cdiv(M, 16) * triton.cdiv(N, 16),)\n\n    But note: the kernel expects a 1D grid.\n\n34. Let's rewrite the current program without autotune and with fixed block sizes (16,16,16).\n\n35. We also note that the current kernel uses:\n        w_block = tl.trans(w_block)\n\n    and then does the dot product. This is the same as the top program.\n\n36. We will also adjust the number of warps? The top program did not specify. We can try with 4 warps? But the top program in the history did not specify.\n\n37. We set the kernel without autotune and with fixed block sizes.\n\n38. We also note that the current kernel has a line:\n        offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n\n    and then later when loading bias, it recalculates offs_n? Actually, it does recalculate because the offs_n might have been changed in the loop? But no, we are reusing the variable name. Let me check:\n\n        In the kernel:\n            offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)   # first definition\n\n            ... then in the loop, we don't change offs_n.\n\n            Then after the loop:\n                offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)   # recalculated? \n\n        Actually, the current kernel recalculates offs_n and offs_m after the loop? Why? Because the original offs_m and offs_n might have been modified? They are not, because they are defined at the beginning and then not changed. So we can remove the recalculation.\n\n        But the current kernel does recalculate:\n\n            offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)   # recalculated for bias and output?\n            ... then for bias: \n                b_ptrs = b_ptr + offs_n\n            ... then for output: \n                offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)   # recalculated\n                offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)   # recalculated again\n\n        This is redundant. We can use the original offs_m and offs_n. But it doesn't hurt.\n\n39. We will keep the kernel as is but remove autotune and fix the block sizes.\n\n40. We change the kernel to:\n\n        @triton.jit\n        def linear_kernel(... same parameters ...):\n            ... same code ...\n\n    and remove the autotune decorator.\n\n41. Then in the call site, we set:\n        grid = (triton.cdiv(M, 16) * triton.cdiv(N, 16),)\n        linear_kernel[grid](... , BLOCK_SIZE_M=16, BLOCK_SIZE_N=16, BLOCK_SIZE_K=16)\n\n42. We also set the number of warps? The top program did not set, so we leave it to the default.\n\n43. Alternatively, we can set num_warps=4 because the top program in the history (Program 1) had a fixed grid and block and achieved 0.853. We don't know the number of warps it used. But the current kernel without autotune might use the default (which is 8?).\n\n44. We try without specifying the number of warps first.\n\n45. We also note that the current kernel uses:\n        acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n\n    and then accumulates in float32. This is correct.\n\n46. We write the new code.\n\n47. We note that the current program also has the rest of the model (dropout, mean, softmax). We are not changing that because the problem is the linear layer.\n\n48. We hope that by removing autotune and using fixed block sizes (16,16,16) we get a speedup.\n\n49. If we look at the history, the top program (Program 1) had a speed_up of 0.853. We hope to get at least that.\n\n50. We output the entire EVOLVE-BLOCK.\n\n Note: We are only allowed to change the Triton kernel source within the block? But we are also changing the call site (removing autotune and setting fixed block sizes). That is within the block.\n\n Let's rewrite.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n    \n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_size = min(BLOCK_SIZE_K, k_remaining)\n        \n        mask_x = (offs_m[:, None] < M) & (offs_k[None, :] < k_size)\n        mask_w = (offs_n[:, None] < N) & (offs_k[None, :] < k_size)\n        \n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n        w_block = tl.load(w_ptrs, mask=mask_w, other=0.0)\n        \n        # Transpose weight block for correct matrix multiplication\n        w_block_t = tl.trans(w_block)\n        acc += tl.dot(x_block, w_block_t, allow_tf32=True)\n        \n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    # Add bias\n    b_ptrs = b_ptr + offs_n\n    b_block = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b_block[None, :]\n    \n    # Store output\n    out_ptrs = out_ptr + (offs_m[:, None] * stride_om + offs_n[None, :] * stride_on)\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, dropout_p):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.dropout = nn.Dropout(dropout_p)\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, self.out_features, device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.out_features\n        \n        # Use fixed block sizes optimized for small matrices\n        BLOCK_M, BLOCK_N, BLOCK_K = 64, 64, 64\n        grid = (triton.cdiv(M, BLOCK_M) * triton.cdiv(N, BLOCK_N),)\n        \n        linear_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=BLOCK_M, BLOCK_SIZE_N=BLOCK_N, BLOCK_SIZE_K=BLOCK_K\n        )\n        \n        x = self.dropout(output)\n        x = torch.mean(x, dim=1, keepdim=True)\n        x = torch.softmax(x, dim=1)\n        return x\n\nbatch_size = 128\nin_features = 100\nout_features = 50\ndropout_p = 0.2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, dropout_p]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}