{"id": "9eb4f08a-7582-4ba0-bf3a-aaffada5de88", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _adaptive_avg_pool2d_1x1_kernel(\n    input_ptr,\n    output_ptr,\n    channels,\n    input_height,\n    input_width,\n    input_batch_stride,\n    input_channel_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    BLOCK_CHANNELS: tl.constexpr,\n):\n    batch_idx = tl.program_id(0)\n    channel_block_idx = tl.program_id(1)\n    \n    channel_offsets = tl.arange(0, BLOCK_CHANNELS)\n    channel_idx = channel_block_idx * BLOCK_CHANNELS + channel_offsets\n    channel_mask = channel_idx < channels\n    \n    input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n    output_batch_ptr = output_ptr + batch_idx * output_batch_stride\n    \n    accum = tl.zeros((BLOCK_CHANNELS,), dtype=tl.float32)\n    num_elements = input_height * input_width\n    \n    for h in range(input_height):\n        for w in range(input_width):\n            ptrs = input_batch_ptr + channel_idx * input_channel_stride + h * input_height_stride + w * input_width_stride\n            vals = tl.load(ptrs, mask=channel_mask, other=0.0)\n            accum += vals\n    \n    avg = accum / num_elements\n    output_ptrs = output_batch_ptr + channel_idx * output_channel_stride\n    tl.store(output_ptrs, avg, mask=channel_mask)\n\ndef adaptive_avg_pool2d_1x1(x):\n    batch, channels, height, width = x.shape\n    output = torch.empty((batch, channels, 1, 1), device=x.device, dtype=x.dtype)\n    \n    BLOCK_CHANNELS = 128\n    grid = (batch, triton.cdiv(channels, BLOCK_CHANNELS))\n    \n    _adaptive_avg_pool2d_1x1_kernel[grid](\n        x, output,\n        channels, height, width,\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n        output.stride(0), output.stride(1),\n        BLOCK_CHANNELS=BLOCK_CHANNELS\n    )\n    return output\n\nclass AdaptiveAvgPool2d1x1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return adaptive_avg_pool2d_1x1(x)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        MobileNetV2 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes. Default is 1000.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            \"\"\"\n            This function ensures that the number of channels is divisible by the divisor.\n            \"\"\"\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            # Make sure that round down does not go down by more than 10%.\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            \"\"\"\n            Inverted Residual Block for MobileNetV2.\n            \"\"\"\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                # Pointwise convolution\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(nn.ReLU6(inplace=True))\n\n            layers.extend([\n                # Depthwise convolution\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # Pointwise linear convolution\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        # MobileNetV2 architecture\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # Building first layer\n        features = [nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n                    nn.BatchNorm2d(input_channel),\n                    nn.ReLU6(inplace=True)]\n\n        # Building inverted residual blocks\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        # Building last several layers\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(nn.ReLU6(inplace=True))\n\n        # Replace PyTorch adaptive pooling with Triton implementation\n        features.append(AdaptiveAvgPool2d1x1())\n\n        self.features = nn.Sequential(*features)\n\n        # Linear layer\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MobileNetV2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "80fd95ad-b1e9-4dcb-8d37-c0b31da068fd", "generation": 3, "timestamp": 1754587960.1225026, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.829, "runtime_ms": 3.57, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 2.96, "speed_up": 0.829, "custom_timing": 3.57}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 0.0000\n- correctness: 0.0000\n- score: -100.0000\n- stage: no_valid_triton_code\n- feedback: You need to generate real and valid triton code for the core function. The key word 'import triton' is not found.\n- Areas identified for improvement: - Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.6170, runtime_ms: 4.8000, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.617, 'custom_timing': 4.8}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7170, runtime_ms: 4.1300, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.717, 'custom_timing': 4.13}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7870, runtime_ms: 3.7600, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.787, 'custom_timing': 3.76}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _adaptive_avg_pool2d_1x1_kernel(\n    input_ptr,\n    output_ptr,\n    channels,\n    input_height,\n    input_width,\n    input_batch_stride,\n    input_channel_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    VECTOR_SIZE: tl.constexpr,\n):\n    batch_idx = tl.program_id(0)\n    channel_idx = tl.program_id(1)\n    \n    input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n    input_channel_ptr = input_batch_ptr + channel_idx * input_channel_stride\n    output_ptr_pos = output_ptr + batch_idx * output_batch_stride + channel_idx * output_channel_stride\n\n    total = 0.0\n    num_elements = input_height * input_width\n    \n    # Vectorized accumulation\n    for offset in range(0, num_elements, VECTOR_SIZE):\n        vec_indices = offset + tl.arange(0, VECTOR_SIZE)\n        mask = vec_indices < num_elements\n        \n        # Convert linear indices to 2D coordinates\n        h = vec_indices // input_width\n        w = vec_indices % input_width\n        ptrs = input_channel_ptr + h * input_height_stride + w * input_width_stride\n        \n        # Vectorized load\n        vec = tl.load(ptrs, mask=mask, other=0.0)\n        total += tl.sum(vec, axis=0)\n\n    # Compute average and store\n    avg = total / num_elements\n    tl.store(output_ptr_pos, avg)\n\ndef adaptive_avg_pool2d_1x1(x):\n    batch, channels, height, width = x.shape\n    output = torch.empty((batch, channels, 1, 1), device=x.device, dtype=x.dtype)\n    \n    # Use 2D grid for better parallelism\n    grid = (batch, channels)\n    \n    # Choose vector size (power of 2 <= 16)\n    vector_size = min(16, triton.next_power_of_2(width))\n    \n    _adaptive_avg_pool2d_1x1_kernel[grid](\n        x, output,\n        channels, height, width,\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n        output.stride(0), output.stride(1),\n        VECTOR_SIZE=vector_size\n    )\n    return output\n\nclass AdaptiveAvgPool2d1x1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return adaptive_avg_pool2d_1x1(x)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        MobileNetV2 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes. Default is 1000.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            \"\"\"\n            This function ensures that the number of channels is divisible by the divisor.\n            \"\"\"\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            # Make sure that round down does not go down by more than 10%.\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            \"\"\"\n            Inverted Residual Block for MobileNetV2.\n            \"\"\"\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                # Pointwise convolution\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(nn.ReLU6(inplace=True))\n\n            layers.extend([\n                # Depthwise convolution\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # Pointwise linear convolution\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        # MobileNetV2 architecture\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # Building first layer\n        features = [nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n                    nn.BatchNorm2d(input_channel),\n                    nn.ReLU6(inplace=True)]\n\n        # Building inverted residual blocks\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        # Building last several layers\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(nn.ReLU6(inplace=True))\n\n        # Replace PyTorch adaptive pooling with Triton implementation\n        features.append(AdaptiveAvgPool2d1x1())\n\n        self.features = nn.Sequential(*features)\n\n        # Linear layer\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MobileNetV2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7870), Performs well on runtime_ms (3.7600), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.787, 'custom_timing': 3.76})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    zero = 0.0\n    six = 6.0\n    x = tl.where(x > zero, x, zero)\n    x = tl.where(x < six, x, six)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass TritonReLU6(nn.Module):\n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        _relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(TritonReLU6())\n\n            layers.extend([\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                TritonReLU6(),\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        features = [\n            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(input_channel),\n            TritonReLU6()\n        ]\n\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(TritonReLU6())\n        features.append(nn.AdaptiveAvgPool2d((1, 1)))\n\n        self.features = nn.Sequential(*features)\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7170), Performs well on runtime_ms (4.1300), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.717, 'custom_timing': 4.13})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 2048, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 4096, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 2048, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 4096, 'VEC_SIZE': 8}, num_warps=4),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef _relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE * VEC_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE * VEC_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.minimum(tl.maximum(x, 0.0), 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass TritonReLU6(nn.Module):\n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE'] * meta['VEC_SIZE']),)\n        _relu6_kernel[grid](x, output, n_elements)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(TritonReLU6())\n\n            layers.extend([\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                TritonReLU6(),\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        features = [\n            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(input_channel),\n            TritonReLU6()\n        ]\n\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(TritonReLU6())\n        features.append(nn.AdaptiveAvgPool2d((1, 1)))\n\n        self.features = nn.Sequential(*features)\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.6170), Performs well on runtime_ms (4.8000), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.96, 'speed_up': 0.617, 'custom_timing': 4.8})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -100.0000)\n```python\nif 0 <= h < in_height and 0 <= w < in_width:\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    zero = 0.0\n    six = 6.0\n    x = tl.where(x > zero, x, zero)\n    x = tl.where(x < six, x, six)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass TritonReLU6(nn.Module):\n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        _relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(TritonReLU6())\n\n            layers.extend([\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                TritonReLU6(),\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        features = [\n            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(input_channel),\n            TritonReLU6()\n        ]\n\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(TritonReLU6())\n        features.append(nn.AdaptiveAvgPool2d((1, 1)))\n\n        self.features = nn.Sequential(*features)\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _adaptive_avg_pool2d_1x1_kernel(\n    input_ptr,\n    output_ptr,\n    channels,\n    input_height,\n    input_width,\n    input_batch_stride,\n    input_channel_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    VECTOR_SIZE: tl.constexpr,\n):\n    batch_idx = tl.program_id(0)\n    channel_idx = tl.program_id(1)\n    \n    input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n    input_channel_ptr = input_batch_ptr + channel_idx * input_channel_stride\n    output_ptr_pos = output_ptr + batch_idx * output_batch_stride + channel_idx * output_channel_stride\n\n    total = 0.0\n    num_elements = input_height * input_width\n    \n    # Vectorized accumulation\n    for offset in range(0, num_elements, VECTOR_SIZE):\n        vec_indices = offset + tl.arange(0, VECTOR_SIZE)\n        mask = vec_indices < num_elements\n        \n        # Convert linear indices to 2D coordinates\n        h = vec_indices // input_width\n        w = vec_indices % input_width\n        ptrs = input_channel_ptr + h * input_height_stride + w * input_width_stride\n        \n        # Vectorized load\n        vec = tl.load(ptrs, mask=mask, other=0.0)\n        total += tl.sum(vec, axis=0)\n\n    # Compute average and store\n    avg = total / num_elements\n    tl.store(output_ptr_pos, avg)\n\ndef adaptive_avg_pool2d_1x1(x):\n    batch, channels, height, width = x.shape\n    output = torch.empty((batch, channels, 1, 1), device=x.device, dtype=x.dtype)\n    \n    # Use 2D grid for better parallelism\n    grid = (batch, channels)\n    \n    # Choose vector size (power of 2 <= 16)\n    vector_size = min(16, triton.next_power_of_2(width))\n    \n    _adaptive_avg_pool2d_1x1_kernel[grid](\n        x, output,\n        channels, height, width,\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n        output.stride(0), output.stride(1),\n        VECTOR_SIZE=vector_size\n    )\n    return output\n\nclass AdaptiveAvgPool2d1x1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return adaptive_avg_pool2d_1x1(x)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        MobileNetV2 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes. Default is 1000.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            \"\"\"\n            This function ensures that the number of channels is divisible by the divisor.\n            \"\"\"\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            # Make sure that round down does not go down by more than 10%.\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            \"\"\"\n            Inverted Residual Block for MobileNetV2.\n            \"\"\"\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                # Pointwise convolution\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(nn.ReLU6(inplace=True))\n\n            layers.extend([\n                # Depthwise convolution\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # Pointwise linear convolution\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        # MobileNetV2 architecture\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # Building first layer\n        features = [nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n                    nn.BatchNorm2d(input_channel),\n                    nn.ReLU6(inplace=True)]\n\n        # Building inverted residual blocks\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        # Building last several layers\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(nn.ReLU6(inplace=True))\n\n        # Replace PyTorch adaptive pooling with Triton implementation\n        features.append(AdaptiveAvgPool2d1x1())\n\n        self.features = nn.Sequential(*features)\n\n        # Linear layer\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MobileNetV2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\nif 0 <= h < in_height and 0 <= w < in_width:\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a context that we are to rewrite a PyTorch model for MobileNetV2 to use Triton for certain operations to improve performance.\n The current program has a Triton implementation for adaptive average pooling (1x1) and for ReLU6, but the performance (speed_up) is less than 1 (i.e., slower than the reference).\n\n The feedback for the current program is: \n   \"You need to generate real and valid triton code for the core function. The key word 'import triton' is not found.\"\n\n However, looking at the provided code in the evolution history, we see that the Triton code is present but the performance is not good.\n\n The goal is to improve the speed_up to at least 1.05 (5% speedup) and ideally 15% or more.\n\n Steps:\n 1. We note that the current program (in the top performing ones) are using Triton for either adaptive average pooling or ReLU6, but the overall model is slower.\n 2. We must consider that the adaptive average pooling at the end of the model is a global average pool (over 7x7 in the last feature map) and is done for each channel and batch.\n 3. The Triton kernel for adaptive average pooling (1x1) in the top program (Program 1) is:\n        @triton.jit\n        def _adaptive_avg_pool2d_1x1_kernel(...)\n    and it is called in the model by replacing the PyTorch adaptive pooling with:\n        features.append(AdaptiveAvgPool2d1x1())\n\n 4. The ReLU6 Triton kernel (in Program 2 and 3) is used throughout the model.\n\n However, the overall model is slower. This suggests that either:\n    a) The Triton kernels are not efficient enough (especially the ReLU6 which is applied many times) and are causing overhead.\n    b) The adaptive pooling kernel is not efficient for the 7x7 input.\n\n Let's analyze the adaptive pooling kernel for 1x1:\n    - It uses a 2D grid (batch, channels) and each thread block handles one channel in one batch.\n    - It vectorizes the accumulation by loading multiple elements at once (VECTOR_SIZE, which is set to min(16, next_power_of_2(width))).\n    - For a 7x7 input, the total elements per channel is 49. The vector size would be 16? Then we would have 4 iterations (49/16 -> 4, because 16*3=48 and then one more for the last element).\n\n    However, note that 49 is not a multiple of 16. The kernel uses a loop and mask.\n\n    But the problem is that 49 elements is a very small number. Launching a Triton kernel for each (batch, channel) might be inefficient because:\n        - The grid is (batch, channel). For a batch of 10 and 1280 channels, we launch 12,800 kernels? Each kernel only does 49 operations.\n\n    This could lead to a lot of overhead.\n\n 5. We should consider an alternative approach for the adaptive average pooling:\n    - Instead of having a 2D grid, we could have a 1D grid and have each thread block handle multiple channels for one batch (or multiple batches?).\n    - But note: the input is (batch, channels, height, width) and we are reducing the last two dimensions to 1x1.\n\n 6. Alternatively, we might try to fuse the ReLU6 and the pooling? But that would require a more complex kernel and might not be straightforward.\n\n 7. Another idea: the ReLU6 kernel is applied element-wise. The current Triton ReLU6 kernel is launched with:\n        grid = (triton.cdiv(n_elements, BLOCK_SIZE * VEC_SIZE), )\n    and uses vectorized loads and stores.\n\n    However, the ReLU6 operation is very simple and memory-bound. The PyTorch implementation might already be very efficient.\n\n 8. Given the above, I suspect that the main bottleneck is the adaptive average pooling kernel.\n\n How to improve the adaptive average pooling kernel?\n    - We note that the input size for the pooling is (batch, channels, 7, 7) (since the input image is 224x224 and the network downsamples 32 times -> 224/32=7).\n    - We can change the kernel to process multiple channels per program.\n\n    Proposed new kernel for adaptive average pooling (1x1) for small spatial size (7x7):\n\n        We use a 2D grid: \n            - axis0: batch\n            - axis1: channel_blocks (each block processes multiple channels)\n\n        Let BLOCK_CHANNELS be the number of channels per block.\n\n        The kernel would:\n            for channel_offset in [0:BLOCK_CHANNELS] (within the block):\n                channel_idx = block_idx * BLOCK_CHANNELS + channel_offset\n                if channel_idx < channels:\n                    accumulate over the 49 elements for that channel.\n\n        But note: 49 is small, so we can do a simple loop without vectorization.\n\n        We can precompute the total number of elements (49) and then do:\n\n            total = 0.0\n            for h in range(7):\n                for w in range(7):\n                    # load the element at (h, w) for this channel and batch\n                    # add to total\n\n        This avoids the complex indexing and vectorization overhead for such a small spatial size.\n\n        However, we must be cautious: 7*7=49, and doing 49 iterations in a loop is acceptable.\n\n        The kernel:\n\n            @triton.jit\n            def _adaptive_avg_pool2d_1x1_kernel(\n                input_ptr,\n                output_ptr,\n                channels,\n                input_height,\n                input_width,\n                input_batch_stride,\n                input_channel_stride,\n                input_height_stride,\n                input_width_stride,\n                output_batch_stride,\n                output_channel_stride,\n                BLOCK_CHANNELS: tl.constexpr,\n            ):\n                batch_idx = tl.program_id(0)\n                channel_block_idx = tl.program_id(1)\n\n                # channel indices in this block\n                channel_offset = tl.arange(0, BLOCK_CHANNELS)\n                channel_idx = channel_block_idx * BLOCK_CHANNELS + channel_offset\n\n                # mask for valid channels in this block\n                channel_mask = channel_idx < channels\n\n                # input pointer for this batch\n                input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n\n                # output pointer for this batch\n                output_batch_ptr = output_ptr + batch_idx * output_batch_stride\n\n                # Initialize accumulators for the channels in this block\n                accum = tl.zeros((BLOCK_CHANNELS,), dtype=tl.float32)\n\n                # Loop over the spatial dimensions\n                for h in range(input_height):\n                    for w in range(input_width):\n                        # pointers for the current (h, w) for all channels in the block\n                        ptrs = input_batch_ptr + channel_idx * input_channel_stride + h * input_height_stride + w * input_width_stride\n                        # Load a vector of values for the channels in the block\n                        vals = tl.load(ptrs, mask=channel_mask, other=0.0)\n                        accum += vals\n\n                # Compute average\n                n_elements = input_height * input_width\n                avg = accum / n_elements\n\n                # Store the result for each channel in the block\n                output_ptrs = output_batch_ptr + channel_idx * output_channel_stride\n                tl.store(output_ptrs, avg, mask=channel_mask)\n\n        Then we launch with:\n            grid = (batch, triton.cdiv(channels, BLOCK_CHANNELS))\n\n        We set BLOCK_CHANNELS to 128 (or 256) so that we have enough parallelism and each block does 49 * BLOCK_CHANNELS operations.\n\n        This should reduce the number of kernel launches and improve utilization.\n\n 9. We must also note that the input and output tensors must be contiguous or we must use their strides.\n\n 10. We will replace the existing adaptive pooling kernel with this new one.\n\n 11. For the ReLU6, we might revert to PyTorch's built-in because the Triton version might not be providing a speedup and could be causing overhead.\n\n 12. Alternatively, we can remove the Triton ReLU6 and use the PyTorch one, and focus on the pooling.\n\n 13. Given the above, let's create a new model that:\n        - Uses the new adaptive average pooling kernel (with block processing over channels).\n        - Does not use Triton for ReLU6 (we remove the TritonReLU6 and use nn.ReLU6).\n\n 14. We hope that the new pooling kernel will be faster and bring the overall model speedup above 1.\n\n Implementation:\n\n    We will write the new adaptive average pooling kernel as described.\n\n    We set BLOCK_CHANNELS to 128 (tunable? but 128 is a good start).\n\n    We remove the TritonReLU6 and use the standard nn.ReLU6.\n\n    We note: the model in the top program (Program 1) already uses the standard ReLU6 in the inverted residual blocks.\n\n    So we can take Program 1 and replace the adaptive pooling kernel with the new one.\n\n 15. Code for the new adaptive pooling:\n\n        @triton.jit\n        def _adaptive_avg_pool2d_1x1_kernel(\n            input_ptr,\n            output_ptr,\n            channels,\n            input_height,\n            input_width,\n            input_batch_stride,\n            input_channel_stride,\n            input_height_stride,\n            input_width_stride,\n            output_batch_stride,\n            output_channel_stride,\n            BLOCK_CHANNELS: tl.constexpr,\n        ):\n            batch_idx = tl.program_id(0)\n            channel_block_idx = tl.program_id(1)\n\n            # channel indices in this block\n            channel_offset = tl.arange(0, BLOCK_CHANNELS)\n            channel_idx = channel_block_idx * BLOCK_CHANNELS + channel_offset\n\n            # mask for valid channels in this block\n            channel_mask = channel_idx < channels\n\n            # input pointer for this batch\n            input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n\n            # output pointer for this batch\n            output_batch_ptr = output_ptr + batch_idx * output_batch_stride\n\n            # Initialize accumulator for the channels in this block\n            accum = tl.zeros((BLOCK_CHANNELS,), dtype=tl.float32)\n\n            # Loop over the spatial dimensions\n            for h in range(input_height):\n                for w in range(input_width):\n                    # pointers for the current (h, w) for all channels in the block\n                    ptrs = input_batch_ptr + channel_idx * input_channel_stride + h * input_height_stride + w * input_width_stride\n                    # Load a vector of values for the channels in the block\n                    vals = tl.load(ptrs, mask=channel_mask, other=0.0)\n                    accum += vals\n\n            # Compute average\n            n_elements = input_height * input_width\n            avg = accum / n_elements\n\n            # Store the result for each channel in the block\n            output_ptrs = output_batch_ptr + channel_idx * output_channel_stride\n            tl.store(output_ptrs, avg, mask=channel_mask)\n\n        Then in the function adaptive_avg_pool2d_1x1:\n\n            def adaptive_avg_pool2d_1x1(x):\n                batch, channels, height, width = x.shape\n                output = torch.empty((batch, channels, 1, 1), device=x.device, dtype=x.dtype)\n\n                # Check if the tensor is contiguous? We use strides so we don't require contiguous, but it's better to.\n                # We'll assume it's contiguous in memory layout, but we use the given strides.\n\n                # Set BLOCK_CHANNELS to 128\n                BLOCK_CHANNELS = 128\n                grid = (batch, triton.cdiv(channels, BLOCK_CHANNELS))\n\n                _adaptive_avg_pool2d_1x1_kernel[grid](\n                    x, output,\n                    channels, height, width,\n                    x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n                    output.stride(0), output.stride(1),\n                    BLOCK_CHANNELS=BLOCK_CHANNELS\n                )\n                return output\n\n 16. We will also remove the autotune for the ReLU6 and use the standard ReLU6 to avoid any overhead from Triton for ReLU6.\n\n 17. We base our model on Program 1 (which uses standard ReLU6 and the Triton adaptive pooling) and replace the pooling kernel.\n\n 18. We note: the input to the pooling is after a ReLU6 and is of shape (batch, 1280, 7, 7).\n\n 19. We must ensure that the kernel uses the correct data type. The input tensor might be float32 or float16? The model uses float32.\n\n 20. We write the kernel in Triton with the above design.\n\n Let's code accordingly.\n\n IMPORTANT: We are only allowed to change the Triton kernel and the function that calls it (adaptive_avg_pool2d_1x1) and the model class (ModelNew) must be named as such.\n\n We are going to output the entire code block for the model, but note that the evolution system will only take the code between EVOLVE-BLOCK markers.\n\n However, note that the current program in the task is only a fragment: \n        \"if 0 <= h < in_height and 0 <= w < in_width:\"\n\n So we are actually starting from one of the top programs (Program 1) and modifying the adaptive pooling kernel.\n\n We choose Program 1 as the base because it uses the standard ReLU6 and only Triton for the pooling.\n\n We replace the pooling kernel and the function that calls it.\n\n We hope that this will improve the performance of the pooling and hence the entire model.\n\n Let's write the code accordingly.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _adaptive_avg_pool2d_1x1_kernel(\n    input_ptr,\n    output_ptr,\n    channels,\n    input_height,\n    input_width,\n    input_batch_stride,\n    input_channel_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    BLOCK_CHANNELS: tl.constexpr,\n):\n    batch_idx = tl.program_id(0)\n    channel_block_idx = tl.program_id(1)\n    \n    channel_offsets = tl.arange(0, BLOCK_CHANNELS)\n    channel_idx = channel_block_idx * BLOCK_CHANNELS + channel_offsets\n    channel_mask = channel_idx < channels\n    \n    input_batch_ptr = input_ptr + batch_idx * input_batch_stride\n    output_batch_ptr = output_ptr + batch_idx * output_batch_stride\n    \n    accum = tl.zeros((BLOCK_CHANNELS,), dtype=tl.float32)\n    num_elements = input_height * input_width\n    \n    for h in range(input_height):\n        for w in range(input_width):\n            ptrs = input_batch_ptr + channel_idx * input_channel_stride + h * input_height_stride + w * input_width_stride\n            vals = tl.load(ptrs, mask=channel_mask, other=0.0)\n            accum += vals\n    \n    avg = accum / num_elements\n    output_ptrs = output_batch_ptr + channel_idx * output_channel_stride\n    tl.store(output_ptrs, avg, mask=channel_mask)\n\ndef adaptive_avg_pool2d_1x1(x):\n    batch, channels, height, width = x.shape\n    output = torch.empty((batch, channels, 1, 1), device=x.device, dtype=x.dtype)\n    \n    BLOCK_CHANNELS = 128\n    grid = (batch, triton.cdiv(channels, BLOCK_CHANNELS))\n    \n    _adaptive_avg_pool2d_1x1_kernel[grid](\n        x, output,\n        channels, height, width,\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n        output.stride(0), output.stride(1),\n        BLOCK_CHANNELS=BLOCK_CHANNELS\n    )\n    return output\n\nclass AdaptiveAvgPool2d1x1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return adaptive_avg_pool2d_1x1(x)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        MobileNetV2 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes. Default is 1000.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        def _make_divisible(v, divisor, min_value=None):\n            \"\"\"\n            This function ensures that the number of channels is divisible by the divisor.\n            \"\"\"\n            if min_value is None:\n                min_value = divisor\n            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n            # Make sure that round down does not go down by more than 10%.\n            if new_v < 0.9 * v:\n                new_v += divisor\n            return new_v\n\n        def _inverted_residual_block(inp, oup, stride, expand_ratio):\n            \"\"\"\n            Inverted Residual Block for MobileNetV2.\n            \"\"\"\n            hidden_dim = int(inp * expand_ratio)\n            use_res_connect = stride == 1 and inp == oup\n\n            layers = []\n            if expand_ratio != 1:\n                # Pointwise convolution\n                layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n                layers.append(nn.BatchNorm2d(hidden_dim))\n                layers.append(nn.ReLU6(inplace=True))\n\n            layers.extend([\n                # Depthwise convolution\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True),\n                # Pointwise linear convolution\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            ])\n\n            if use_res_connect:\n                return nn.Sequential(*layers), True\n            else:\n                return nn.Sequential(*layers), False\n\n        # MobileNetV2 architecture\n        input_channel = 32\n        last_channel = 1280\n        inverted_residual_setting = [\n            # t, c, n, s\n            [1, 16, 1, 1],\n            [6, 24, 2, 2],\n            [6, 32, 3, 2],\n            [6, 64, 4, 2],\n            [6, 96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # Building first layer\n        features = [nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n                    nn.BatchNorm2d(input_channel),\n                    nn.ReLU6(inplace=True)]\n\n        # Building inverted residual blocks\n        for t, c, n, s in inverted_residual_setting:\n            output_channel = _make_divisible(c, 8)\n            for i in range(n):\n                stride = s if i == 0 else 1\n                features.append(_inverted_residual_block(input_channel, output_channel, stride, expand_ratio=t)[0])\n                input_channel = output_channel\n\n        # Building last several layers\n        features.append(nn.Conv2d(input_channel, last_channel, 1, 1, 0, bias=False))\n        features.append(nn.BatchNorm2d(last_channel))\n        features.append(nn.ReLU6(inplace=True))\n\n        # Replace PyTorch adaptive pooling with Triton implementation\n        features.append(AdaptiveAvgPool2d1x1())\n\n        self.features = nn.Sequential(*features)\n\n        # Linear layer\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.0),\n            nn.Linear(last_channel, num_classes),\n        )\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MobileNetV2 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}