{"id": "8ff1701f-20b5-4a3d-b685-7cf8e24a420a", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv2d_kernel(\n    input_ptr, weight_ptr, bias_conv_ptr,\n    running_mean_ptr, running_var_ptr, weight_bn_ptr, bias_bn_ptr,\n    output_ptr,\n    eps, scaling_factor,\n    batch_size, in_channels, height, width,\n    out_channels, kernel_size,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_woc, stride_wic, stride_wkh, stride_wkw,\n    stride_ob, stride_oc, stride_oh, stride_ow,\n    output_height, output_width,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    total_elements = batch_size * out_channels * output_height * output_width\n    if pid >= total_elements:\n        return\n    \n    # Calculate indices\n    b = pid // (out_channels * output_height * output_width)\n    pid_rest = pid % (out_channels * output_height * output_width)\n    oc = pid_rest // (output_height * output_width)\n    pid_rest2 = pid_rest % (output_height * output_width)\n    y = pid_rest2 // output_width\n    x = pid_rest2 % output_width\n\n    # Initialize accumulator\n    acc = 0.0\n    for ic in range(in_channels):\n        for ky in range(kernel_size):\n            for kx in range(kernel_size):\n                iy = y + ky\n                ix = x + kx\n                within_bounds = (iy >= 0) & (iy < height) & (ix >= 0) & (ix < width)\n                \n                # Load input with coalesced access\n                input_offset = b * stride_xb + ic * stride_xc + iy * stride_xh + ix * stride_xw\n                input_val = tl.load(input_ptr + input_offset, mask=within_bounds, other=0.0)\n                \n                # Load weight\n                weight_offset = oc * stride_woc + ic * stride_wic + ky * stride_wkh + kx * stride_wkw\n                weight_val = tl.load(weight_ptr + weight_offset)\n                \n                acc += input_val * weight_val\n\n    # Add convolution bias\n    bias_conv_val = tl.load(bias_conv_ptr + oc)\n    acc += bias_conv_val\n\n    # Fused batch norm and scaling\n    mean = tl.load(running_mean_ptr + oc)\n    var_val = tl.load(running_var_ptr + oc)\n    gamma = tl.load(weight_bn_ptr + oc)\n    beta = tl.load(bias_bn_ptr + oc)\n    \n    inv_std = 1.0 / tl.sqrt(var_val + eps)\n    normalized = (acc - mean) * gamma * inv_std + beta\n    scaled = normalized * scaling_factor\n\n    # Store result\n    output_offset = b * stride_ob + oc * stride_oc + y * stride_oh + x * stride_ow\n    tl.store(output_ptr + output_offset, scaled)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(ModelNew, self).__init__()\n        # Convolution parameters\n        self.weight_conv = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        self.bias_conv = nn.Parameter(torch.empty(out_channels))\n        \n        # Initialize parameters\n        nn.init.kaiming_uniform_(self.weight_conv, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight_conv)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias_conv, -bound, bound)\n        \n        # Batch normalization\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n        self.kernel_size = kernel_size\n\n    def forward(self, x):\n        if self.training:\n            # Training path - use standard layers\n            x = nn.functional.conv2d(\n                x, self.weight_conv, self.bias_conv,\n                padding=0, stride=1, dilation=1\n            )\n            x = self.bn(x)\n            x = x * self.scaling_factor\n            return x\n        \n        # Inference path - fused Triton kernel\n        batch_size, _, height, width = x.shape\n        output_height = height - self.kernel_size + 1\n        output_width = width - self.kernel_size + 1\n        \n        # Create output tensor\n        output = torch.empty(\n            batch_size, self.bn.num_features, output_height, output_width,\n            device=x.device, dtype=x.dtype\n        )\n        \n        # Compute total elements\n        total_elements = batch_size * self.bn.num_features * output_height * output_width\n        \n        # Compute strides\n        stride_x = x.stride()\n        stride_w = self.weight_conv.stride()\n        stride_o = output.stride()\n        \n        # Launch kernel\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        conv2d_kernel[grid](\n            x, self.weight_conv, self.bias_conv,\n            self.bn.running_mean, self.bn.running_var, \n            self.bn.weight, self.bn.bias,\n            output,\n            self.bn.eps, self.scaling_factor,\n            batch_size, x.shape[1], height, width,\n            self.bn.num_features, self.kernel_size,\n            stride_x[0], stride_x[1], stride_x[2], stride_x[3],\n            stride_w[0], stride_w[1], stride_w[2], stride_w[3],\n            stride_o[0], stride_o[1], stride_o[2], stride_o[3],\n            output_height, output_width,\n            BLOCK_SIZE=1024\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "6227fed2-a8d4-474f-81e5-20860297e3a8", "generation": 1, "timestamp": 1754578573.1708722, "iteration_found": 8, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.779, "runtime_ms": 0.108, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0841, "speed_up": 0.779, "custom_timing": 0.108}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.111, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0841, "speed_up": 0.758, "custom_timing": 0.111}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}