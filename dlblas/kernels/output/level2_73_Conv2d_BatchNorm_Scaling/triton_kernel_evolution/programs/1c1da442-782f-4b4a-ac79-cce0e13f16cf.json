{"id": "1c1da442-782f-4b4a-ac79-cce0e13f16cf", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv2d_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    batch_size, in_channels, height, width,\n    out_channels, kernel_size,\n    output_height, output_width,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_woc, stride_wic, stride_wkh, stride_wkw,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_elements = batch_size * out_channels * output_height * output_width\n    if pid >= total_elements:\n        return\n\n    # Calculate output indices\n    b = pid // (out_channels * output_height * output_width)\n    rest = pid % (out_channels * output_height * output_width)\n    oc = rest // (output_height * output_width)\n    rest2 = rest % (output_height * output_width)\n    oh = rest2 // output_width\n    ow = rest2 % output_width\n\n    # Initialize accumulator\n    acc = 0.0\n\n    # Process kernel\n    for ic in range(in_channels):\n        for kh in range(kernel_size):\n            for kw in range(kernel_size):\n                ih = oh + kh\n                iw = ow + kw\n                within_bounds = (ih >= 0) & (ih < height) & (iw >= 0) & (iw < width)\n                \n                # Load input value\n                input_offset = b * stride_xb + ic * stride_xc + ih * stride_xh + iw * stride_xw\n                input_val = tl.load(x_ptr + input_offset, mask=within_bounds, other=0.0)\n                \n                # Load weight value\n                weight_offset = oc * stride_woc + ic * stride_wic + kh * stride_wkh + kw * stride_wkw\n                weight_val = tl.load(weight_ptr + weight_offset)\n                \n                # Accumulate\n                acc += input_val * weight_val\n\n    # Add bias and store\n    bias_val = tl.load(bias_ptr + oc)\n    output_offset = b * out_channels * output_height * output_width + oc * output_height * output_width + oh * output_width + ow\n    tl.store(output_ptr + output_offset, acc + bias_val)\n\ndef custom_conv2d(x, weight, bias):\n    batch_size, in_channels, height, width = x.shape\n    out_channels, _, kernel_size, _ = weight.shape\n    output_height = height - kernel_size + 1\n    output_width = width - kernel_size + 1\n    \n    # Precompute strides\n    stride_xb, stride_xc, stride_xh, stride_xw = x.stride()\n    stride_woc, stride_wic, stride_wkh, stride_wkw = weight.stride()\n    \n    # Create output tensor\n    output = torch.empty(batch_size, out_channels, output_height, output_width, \n                         device=x.device, dtype=x.dtype)\n    \n    total_elements = output.numel()\n    grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n    \n    # Launch kernel\n    conv2d_kernel[grid](\n        x, weight, bias, output,\n        batch_size, in_channels, height, width,\n        out_channels, kernel_size,\n        output_height, output_width,\n        stride_xb, stride_xc, stride_xh, stride_xw,\n        stride_woc, stride_wic, stride_wkh, stride_wkw,\n        BLOCK_SIZE=128\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        self.bias = nn.Parameter(torch.empty(out_channels))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        \n        self.bn = nn.BatchNorm2d(out_channels)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = custom_conv2d(x, self.weight, self.bias)\n        x = self.bn(x)\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "f7a88d26-b4de-41f4-a4d2-32afa6b80610", "generation": 2, "timestamp": 1754578485.685926, "iteration_found": 11, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_73_Conv2d_BatchNorm_Scaling", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "max_difference": ["3.674377", "14.316162", "13.944876", "17.719950", "14.009552"], "avg_difference": ["0.009700", "2.256711", "2.252642", "2.245259", "2.250286"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0841, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_73_Conv2d_BatchNorm_Scaling", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_issue": "Output shape mismatch: Expected torch.Size([128, 16, 30, 30]), got torch.Size([128, 16, 32, 32])", "correctness_issue_name": "correctness_issue", "reference_timing_ms": 0.0841, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}