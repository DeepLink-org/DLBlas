{"id": "af41515c-89cf-4b5e-ba8d-277fbd899468", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef add_fn(a, b):\n    return a + b\n\n@triton.jit\ndef _masked_cumsum_kernel(\n    x_ptr,\n    mask_ptr,\n    output_ptr,\n    n_cols,\n    x_row_stride,\n    mask_row_stride,\n    output_row_stride,\n    BLOCK_SIZE: tl.constexpr\n):\n    row_idx = tl.program_id(0)\n    # Compute starting pointers for current row\n    x_row_ptr = x_ptr + row_idx * x_row_stride\n    mask_row_ptr = mask_ptr + row_idx * mask_row_stride\n    output_row_ptr = output_ptr + row_idx * output_row_stride\n\n    total_prev = 0.0\n    chunk_start = 0\n    # Process row in chunks of BLOCK_SIZE\n    while chunk_start < n_cols:\n        chunk_size = min(BLOCK_SIZE, n_cols - chunk_start)\n        chunk_offsets = tl.arange(0, BLOCK_SIZE)\n        chunk_mask = chunk_offsets < chunk_size\n\n        # Load data and mask for current chunk\n        x_vals = tl.load(x_row_ptr + chunk_start + chunk_offsets, mask=chunk_mask, other=0.0)\n        mask_vals = tl.load(mask_row_ptr + chunk_start + chunk_offsets, mask=chunk_mask, other=0)\n        mask_vals = mask_vals.to(tl.int1)\n\n        # Apply mask and compute cumulative sum\n        masked_vals = tl.where(mask_vals, x_vals, 0.0)\n        chunk_cumsum = tl.associative_scan(masked_vals, 0, add_fn)\n        total_chunk = tl.sum(masked_vals)\n\n        # Add previous total and store\n        chunk_cumsum = chunk_cumsum + total_prev\n        tl.store(output_row_ptr + chunk_start + chunk_offsets, chunk_cumsum, mask=chunk_mask)\n\n        # Update running total for next chunk\n        total_prev += total_chunk\n        chunk_start += BLOCK_SIZE\n\nclass ModelNew(nn.Module):\n    def __init__(self, dim):\n        super(ModelNew, self).__init__()\n        self.dim = dim\n\n    def forward(self, x, mask):\n        if self.dim != 1 or x.dim() != 2:\n            return torch.cumsum(x * mask, dim=self.dim)\n        \n        # Ensure contiguous tensors\n        x = x.contiguous()\n        mask = mask.contiguous()\n        output = torch.empty_like(x)\n        \n        n_rows, n_cols = x.shape\n        # Use optimal fixed block size\n        BLOCK_SIZE = 1024\n        \n        # Launch kernel\n        grid = (n_rows,)\n        _masked_cumsum_kernel[grid](\n            x, mask, output, n_cols,\n            x.stride(0), mask.stride(0), output.stride(0),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\ninput_shape = (4000,)\ndim = 1\n\ndef get_inputs():\n    x = torch.randn(batch_size, *input_shape)\n    mask = torch.randint(0, 2, x.shape).bool()\n    return [x, mask]\n\ndef get_init_inputs():\n    return [dim]\n\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "794f24eb-dbdb-4666-8bbe-2e4d01877ccb", "generation": 3, "timestamp": 1754990210.3424294, "iteration_found": 25, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.533, "runtime_ms": 0.0441, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0235, "speed_up": 0.533, "custom_timing": 0.0441}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.538, "runtime_ms": 0.0437, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0235, "speed_up": 0.538, "custom_timing": 0.0437}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}