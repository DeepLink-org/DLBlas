{"id": "af6fc20c-a4f2-4fee-90fa-66b7696f50bd", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 128, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128, 'VEC_SIZE': 4}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128, 'VEC_SIZE': 8}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 8}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 4}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 8}, num_warps=8),\n    ],\n    key=['num_spatial'],\n)\n@triton.jit\ndef _fused_kernel(\n    x0_ptr,\n    bias_ptr,\n    output_ptr,\n    num_spatial,\n    out_channels,\n    BLOCK_SIZE: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_channel = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    spatial_start = pid_block * BLOCK_SIZE\n    base_offset = (pid_batch * out_channels + pid_channel) * num_spatial\n    \n    bias_val = tl.load(bias_ptr + pid_channel)\n    \n    for i in range(0, BLOCK_SIZE, VEC_SIZE):\n        off = spatial_start + i\n        vec_offsets = off + tl.arange(0, VEC_SIZE)\n        vec_mask = vec_offsets < num_spatial\n        \n        ptr = x0_ptr + base_offset + vec_offsets\n        x0_vec = tl.load(ptr, mask=vec_mask, other=0.0)\n        \n        term = 2 * x0_vec + (bias_val + 1.0)\n        result_vec = x0_vec * term\n        \n        out_ptr = output_ptr + base_offset + vec_offsets\n        tl.store(out_ptr, result_vec, mask=vec_mask)\n\ndef _fused_operation(x, bias):\n    x_cont = x.contiguous()\n    bias_flat = bias.view(-1)\n    output = torch.empty_like(x_cont)\n    batch_size, out_channels, depth, height, width = x_cont.shape\n    num_spatial = depth * height * width\n    \n    grid = lambda meta: (batch_size, out_channels, triton.cdiv(num_spatial, meta['BLOCK_SIZE']))\n    _fused_kernel[grid](\n        x_cont, bias_flat, output, \n        num_spatial, out_channels\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = _fused_operation(x, self.bias)\n        return x\n\nbatch_size = 16\nin_channels = 32\nout_channels = 64\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "17f0f41f-297b-4d4f-8e33-ab3b559ed6ac", "generation": 2, "timestamp": 1754571397.710707, "iteration_found": 29, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.044, "runtime_ms": 3.78, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.166, "speed_up": 0.044, "custom_timing": 3.78}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.107, "runtime_ms": 1.55, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.166, "speed_up": 0.107, "custom_timing": 1.55}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}