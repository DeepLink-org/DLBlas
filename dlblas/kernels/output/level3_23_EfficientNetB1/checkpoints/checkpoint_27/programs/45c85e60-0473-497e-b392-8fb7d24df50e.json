{"id": "45c85e60-0473-497e-b392-8fb7d24df50e", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n    \n    # Calculate output indices from combined dimension\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n    \n    # Create masks for boundary checks\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_h = pid_h < output_height\n    mask_w = pid_w < output_width\n    mask = mask_b & mask_c & mask_h & mask_w\n    \n    # Calculate input position with stride and padding\n    input_h = pid_h * stride - padding\n    input_w = pid_w * stride - padding\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over 3x3 kernel\n    for kh in range(3):\n        for kw in range(3):\n            h = input_h + kh\n            w = input_w + kw\n            \n            # Check if within input boundaries\n            in_bounds = (h >= 0) & (h < input_height) & (w >= 0) & (w < input_width)\n            \n            if in_bounds:\n                # Calculate input index\n                input_idx = pid_b * input_channels * input_height * input_width + \\\n                           pid_c * input_height * input_width + \\\n                           h * input_width + w\n                input_val = tl.load(input_ptr + input_idx)\n                \n                # Calculate weight index\n                weight_idx = pid_c * 9 + kh * 3 + kw\n                weight_val = tl.load(weight_ptr + weight_idx)\n                \n                acc += input_val * weight_val\n    \n    # Calculate output index\n    output_idx = pid_b * input_channels * output_height * output_width + \\\n                pid_c * output_height * output_width + \\\n                pid_h * output_width + pid_w\n    tl.store(output_ptr + output_idx, acc, mask=mask)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.Tensor(in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(in_channels))\n        else:\n            self.bias = None\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / (fan_in**0.5)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, in_height, in_width = x.shape\n        assert in_channels == self.in_channels\n        \n        out_height = (in_height + 2*self.padding - 3) // self.stride + 1\n        out_width = (in_width + 2*self.padding - 3) // self.stride + 1\n        output = torch.zeros((batch, in_channels, out_height, out_width), device=x.device, dtype=x.dtype)\n        \n        # Updated grid configuration with 3 dimensions\n        grid = (batch, in_channels, out_height * out_width)\n        \n        # Launch Triton kernel\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, in_height, in_width,\n            self.stride, self.padding,\n            out_height, out_width,\n            BLOCK_SIZE_H=1, BLOCK_SIZE_W=1\n        )\n        \n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n            \n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a48d00b8-ac58-44b2-9de4-385ef21c7c34", "generation": 3, "timestamp": 1754591631.1297889, "iteration_found": 26, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.123, "runtime_ms": 12.2, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 1.5, "speed_up": 0.123, "custom_timing": 12.2}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_23_EfficientNetB1", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1630, in program_id\n    return _semantic.program_id(axis)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 40, in program_id\n    raise ValueError(f\"program_id axis must be 0, 1, or 2 but got {axis}\")\nValueError: program_id axis must be 0, 1, or 2 but got 3\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpapxx7vn6.py\", line 139, in forward\n    x = self.mbconv1(x)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\n    input = module(input)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpapxx7vn6.py\", line 95, in forward\n    depthwise_conv_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 11:12:\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_h = tl.program_id(2)\n    pid_w = tl.program_id(3)\n            ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1630, in program_id\n    return _semantic.program_id(axis)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 40, in program_id\n    raise ValueError(f\"program_id axis must be 0, 1, or 2 but got {axis}\")\nValueError: program_id axis must be 0, 1, or 2 but got 3\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 1.5, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level3_23_EfficientNetB1', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1630, in program_id\\n    return _semantic.program_id(axis)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 40, in program_id\\n    raise ValueError(f\"program_id axis must be 0, 1, or 2 but got {axis}\")\\nValueError: program_id axis must be 0, 1, or 2 but got 3\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpapxx7vn6.py\", line 139, in forward\\n    x = self.mbconv1(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\\n    input = module(input)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpapxx7vn6.py\", line 95, in forward\\n    depthwise_conv_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 11:12:\\ndef depthwise_conv_kernel(\\n    input_ptr, weight_ptr, output_ptr,\\n    input_batch, input_channels, input_height, input_width,\\n    stride, padding,\\n    output_height, output_width,\\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\\n):\\n    pid_b = tl.program_id(0)\\n    pid_c = tl.program_id(1)\\n    pid_h = tl.program_id(2)\\n    pid_w = tl.program_id(3)\\n            ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1630, in program_id\\n    return _semantic.program_id(axis)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 40, in program_id\\n    raise ValueError(f\"program_id axis must be 0, 1, or 2 but got {axis}\")\\nValueError: program_id axis must be 0, 1, or 2 but got 3\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 1.5, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.1300, runtime_ms: 11.5000, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.13, 'custom_timing': 11.5}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7980, runtime_ms: 1.8800, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.798, 'custom_timing': 1.88}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8110, runtime_ms: 1.8500, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.811, 'custom_timing': 1.85}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.maximum(x, 0.0)\n    x = tl.minimum(x, 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8110), Performs well on runtime_ms (1.8500), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.811, 'custom_timing': 1.85})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    zero = tl.full(x.shape, 0, dtype=x.dtype)\n    six = tl.full(x.shape, 6.0, dtype=x.dtype)\n    x = tl.where(x < zero, zero, x)\n    x = tl.where(x > six, six, x)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7980), Performs well on runtime_ms (1.8800), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.798, 'custom_timing': 1.88})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n    \n    # Check boundaries for early exit\n    if pid_b >= input_batch or pid_c >= input_channels or pid_hw >= (output_height * output_width):\n        return\n    \n    # Calculate output indices\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n    \n    # Calculate input position\n    input_h = pid_h * stride - padding\n    input_w = pid_w * stride - padding\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Convolution loop\n    for kh in range(3):\n        for kw in range(3):\n            h = input_h + kh\n            w = input_w + kw\n            \n            # Check input boundaries\n            if h >= 0 and h < input_height and w >= 0 and w < input_width:\n                input_idx = pid_b * input_channels * input_height * input_width + \\\n                           pid_c * input_height * input_width + \\\n                           h * input_width + w\n                weight_idx = pid_c * 9 + kh * 3 + kw\n                acc += tl.load(input_ptr + input_idx) * tl.load(weight_ptr + weight_idx)\n    \n    # Store result\n    output_idx = pid_b * input_channels * output_height * output_width + \\\n                pid_c * output_height * output_width + \\\n                pid_h * output_width + pid_w\n    tl.store(output_ptr + output_idx, acc)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.Tensor(in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(in_channels))\n        else:\n            self.bias = None\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / (fan_in**0.5)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, in_height, in_width = x.shape\n        assert in_channels == self.in_channels\n        \n        # Calculate output dimensions\n        out_height = (in_height + 2*self.padding - 3) // self.stride + 1\n        out_width = (in_width + 2*self.padding - 3) // self.stride + 1\n        output = torch.zeros((batch, in_channels, out_height, out_width), device=x.device, dtype=x.dtype)\n        \n        # Configure grid (3 dimensions: batch, channels, flattened height-width)\n        grid = (batch, in_channels, out_height * out_width)\n        \n        # Launch kernel\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, in_height, in_width,\n            self.stride, self.padding,\n            out_height, out_width\n        )\n        \n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n            \n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.1300), Performs well on runtime_ms (11.5000), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.5, 'speed_up': 0.13, 'custom_timing': 11.5})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=2),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.minimum(tl.maximum(x, 0.0), 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)  # Fixed method name\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.maximum(x, 0.0)\n    x = tl.minimum(x, 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    zero = tl.full(x.shape, 0, dtype=x.dtype)\n    six = tl.full(x.shape, 6.0, dtype=x.dtype)\n    x = tl.where(x < zero, zero, x)\n    x = tl.where(x > six, six, x)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.maximum(x, 0.0)\n    x = tl.minimum(x, 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 3 (Score: 1.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_batch, output_channels, output_height, output_width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_b = pid // (output_channels * output_height * output_width // BLOCK_SIZE)\n    pid_c = (pid % (output_channels * output_height * output_width // BLOCK_SIZE)) // (output_height * output_width // BLOCK_SIZE)\n    pid_hw = pid % (output_height * output_width // BLOCK_SIZE)\n    \n    # Vectorized loads/stores\n    for idx in range(BLOCK_SIZE):\n        hw_idx = pid_hw * BLOCK_SIZE + idx\n        h_out = hw_idx // output_width\n        w_out = hw_idx % output_width\n        \n        acc = 0.0\n        for kh in range(3):\n            for kw in range(3):\n                h_in = h_out * stride - padding + kh\n                w_in = w_out * stride - padding + kw\n                if h_in >= 0 and h_in < input_height and w_in >=0 and w_in < input_width:\n                    input_offset = pid_b * input_channels * input_height * input_width + \\\n                                  pid_c * input_height * input_width + \\\n                                  h_in * input_width + w_in\n                    weight_offset = pid_c * 9 + kh * 3 + kw\n                    acc += tl.load(input_ptr + input_offset) * tl.load(weight_ptr + weight_offset)\n        \n        output_offset = pid_b * output_channels * output_height * output_width + \\\n                        pid_c * output_height * output_width + \\\n                        h_out * output_width + w_out\n        tl.store(output_ptr + output_offset, acc)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.empty(in_channels, 1, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(in_channels))\n        else:\n            self.bias = None\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n            \n    def forward(self, x):\n        batch, in_channels, H, W = x.shape\n        H_out = (H + 2 * self.padding - 3) // self.stride + 1\n        W_out = (W + 2 * self.padding - 3) // self.stride + 1\n        output = torch.empty(batch, in_channels, H_out, W_out, device=x.device, dtype=x.dtype)\n        \n        grid = (batch * in_channels * (H_out * W_out) // 256,)\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, H, W,\n            self.stride, self.padding,\n            batch, in_channels, H_out, W_out,\n            BLOCK_SIZE=256\n        )\n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, 3, stride, 1),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Alternative compiled approach, Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=2),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.minimum(tl.maximum(x, 0.0), 6.0)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ReLU6Triton(nn.Module):\n    def __init__(self):\n        super(ReLU6Triton, self).__init__()\n    \n    def forward(self, x):\n        output = torch.empty_like(x)\n        n_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)  # Fixed method name\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            ReLU6Triton(),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 1.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_h = tl.program_id(2)\n    pid_w = tl.program_id(3)\n    \n    # Create masks for boundary checks\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_h = pid_h < output_height\n    mask_w = pid_w < output_width\n    mask = mask_b & mask_c & mask_h & mask_w\n    \n    # Calculate input position with stride and padding\n    input_h = pid_h * stride - padding\n    input_w = pid_w * stride - padding\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over 3x3 kernel\n    for kh in range(3):\n        for kw in range(3):\n            h = input_h + kh\n            w = input_w + kw\n            \n            # Check if within input boundaries\n            in_bounds = (h >= 0) & (h < input_height) & (w >= 0) & (w < input_width)\n            \n            if in_bounds:\n                # Calculate input index with vectorized access\n                input_idx = pid_b * input_channels * input_height * input_width + \\\n                           pid_c * input_height * input_width + \\\n                           h * input_width + w\n                input_val = tl.load(input_ptr + input_idx)\n                \n                # Calculate weight index\n                weight_idx = pid_c * 9 + kh * 3 + kw\n                weight_val = tl.load(weight_ptr + weight_idx)\n                \n                acc += input_val * weight_val\n    \n    # Calculate output index\n    output_idx = pid_b * input_channels * output_height * output_width + \\\n                pid_c * output_height * output_width + \\\n                pid_h * output_width + pid_w\n    tl.store(output_ptr + output_idx, acc, mask=mask)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.Tensor(in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(in_channels))\n        else:\n            self.bias = None\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, in_height, in_width = x.shape\n        assert in_channels == self.in_channels\n        \n        out_height = (in_height + 2*self.padding - 3) // self.stride + 1\n        out_width = (in_width + 2*self.padding - 3) // self.stride + 1\n        output = torch.zeros((batch, in_channels, out_height, out_width), device=x.device, dtype=x.dtype)\n        \n        # Configure grid and block sizes for Triton kernel\n        grid = lambda opt: (\n            batch, \n            in_channels, \n            out_height, \n            triton.cdiv(out_width, opt['BLOCK_SIZE_W'])\n        )\n        \n        # Launch Triton kernel\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, in_height, in_width,\n            self.stride, self.padding,\n            out_height, out_width,\n            BLOCK_SIZE_H=1, BLOCK_SIZE_W=64\n        )\n        \n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n            \n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\n# Test code\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Alternative compiled approach, Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_h = tl.program_id(2)\n    pid_w = tl.program_id(3)\n    \n    # Create masks for boundary checks\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_h = pid_h < output_height\n    mask_w = pid_w < output_width\n    mask = mask_b & mask_c & mask_h & mask_w\n    \n    # Calculate input position with stride and padding\n    input_h = pid_h * stride - padding\n    input_w = pid_w * stride - padding\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over 3x3 kernel\n    for kh in range(3):\n        for kw in range(3):\n            h = input_h + kh\n            w = input_w + kw\n            \n            # Check if within input boundaries\n            in_bounds = (h >= 0) & (h < input_height) & (w >= 0) & (w < input_width)\n            \n            if in_bounds:\n                # Calculate input index with vectorized access\n                input_idx = pid_b * input_channels * input_height * input_width + \\\n                           pid_c * input_height * input_width + \\\n                           h * input_width + w\n                input_val = tl.load(input_ptr + input_idx)\n                \n                # Calculate weight index\n                weight_idx = pid_c * 9 + kh * 3 + kw\n                weight_val = tl.load(weight_ptr + weight_idx)\n                \n                acc += input_val * weight_val\n    \n    # Calculate output index\n    output_idx = pid_b * input_channels * output_height * output_width + \\\n                pid_c * output_height * output_width + \\\n                pid_h * output_width + pid_w\n    tl.store(output_ptr + output_idx, acc, mask=mask)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.Tensor(in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(in_channels))\n        else:\n            self.bias = None\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / (fan_in**0.5)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, in_height, in_width = x.shape\n        assert in_channels == self.in_channels\n        \n        out_height = (in_height + 2*self.padding - 3) // self.stride + 1\n        out_width = (in_width + 2*self.padding - 3) // self.stride + 1\n        output = torch.zeros((batch, in_channels, out_height, out_width), device=x.device, dtype=x.dtype)\n        \n        # Configure grid and block sizes for Triton kernel\n        grid = (batch, in_channels, out_height, triton.cdiv(out_width, 64))\n        \n        # Launch Triton kernel\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, in_height, in_width,\n            self.stride, self.padding,\n            out_height, out_width,\n            BLOCK_SIZE_H=1, BLOCK_SIZE_W=64\n        )\n        \n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n            \n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a current program that fails to compile due to a Triton error: \n    ValueError: program_id axis must be 0, 1, or 2 but got 3\n\nThe issue is in the kernel `depthwise_conv_kernel` where we are using 4 program IDs (axis=0,1,2,3). \nTriton currently only supports up to 3 dimensions for the program_id.\n\nLooking at the kernel launch configuration in the `TritonDepthwiseConv2d.forward` method:\n    grid = (batch, in_channels, out_height, triton.cdiv(out_width, 64))\n\nThis grid has 4 dimensions, which is not allowed.\n\nWe need to reduce the grid to 3 dimensions. We can combine two of the dimensions.\n\nIn the kernel, we have:\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_h = tl.program_id(2)\n    pid_w = tl.program_id(3)   <--- This is the problem.\n\nWe can combine the height and width into a single dimension by computing:\n    pid_hw = tl.program_id(2)\nand then:\n    pid_h = pid_hw // out_width\n    pid_w = pid_hw % out_width\n\nBut note: in the current grid, we have the fourth dimension as `triton.cdiv(out_width, 64)`. \nActually, we don't need to split the width dimension in the grid. Instead, we can have:\n\n    grid = (batch, in_channels, out_height * out_width)\n\nBut wait, the kernel also uses a block size for the width (BLOCK_SIZE_W=64). We are processing multiple width elements per program?\n\nLooking at the kernel signature, we have:\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr\n\nHowever, in the kernel body, we are not using these block sizes to create a block of work. \nInstead, each program is processing one output element (one (h, w) location).\n\nActually, the current kernel does not use the block sizes for vectorization. It processes one element per program.\n\nWe have two options:\n\nOption 1: Change the grid to 3D by flattening the height and width. Then in the kernel, we compute:\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n    pid_h = pid_hw // out_width\n    pid_w = pid_hw % out_width\n\nBut note: the grid dimension for the third axis would be `out_height * out_width`. This might be very large.\n\nOption 2: Use the block processing and keep the grid to 3D by combining the height and width in a blocked manner.\n\nHowever, the kernel is currently written for one output element per thread. We might want to process a block of output elements per thread.\n\nBut the problem says: \"NEVER change @triton.jit function signatures or parameter names\", and \"NEVER modify grid configuration, output tensor shapes, or PID logic\".\n\nWait, the constraints say:\n    \u274c NEVER change @triton.jit function signatures or parameter names\n    \u274c NEVER modify grid configuration, output tensor shapes, or PID logic\n\nBut the current grid configuration is causing an error. We must fix it.\n\nGiven the constraints, we are allowed to change the grid configuration? Actually, the constraint says \"NEVER modify grid configuration\", but we are forced to because the current grid has 4 dimensions which is invalid.\n\nAlternatively, we can reinterpret the grid to be 3D and adjust the kernel accordingly.\n\nLet me propose:\n\nWe change the grid to:\n    grid = (batch, in_channels, out_height * triton.cdiv(out_width, 64))\n\nBut wait, that is still 3D. Then in the kernel, we do:\n\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw_block = tl.program_id(2)\n\n    # We break pid_hw_block into:\n    pid_h = pid_hw_block // (triton.cdiv(out_width, 64))\n    block_w = pid_hw_block % (triton.cdiv(out_width, 64))\n\n    # Then the starting w index for the block is block_w * BLOCK_SIZE_W\n    # and we loop over BLOCK_SIZE_W in the width dimension?\n\nBut the kernel is currently not written to process a block. It only processes one (h, w).\n\nAlternatively, we can change the kernel to process a block of width elements? That would be a more efficient approach.\n\nHowever, the problem says: \"Small iterative steps: Modify \u226420 lines per revision\".\n\nWe are currently facing a compilation error, so we must fix that first.\n\nGiven the time, let's try to fix by flattening the height and width into one dimension.\n\nWe change the grid to:\n    grid = (batch, in_channels, out_height * out_width)\n\nand then in the kernel, we do:\n\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n\nBut note: the kernel also has two block size parameters (BLOCK_SIZE_H, BLOCK_SIZE_W) that are passed as constants. We are not using them in the computation? Actually, we are not. We can remove them? But the constraint says we cannot change the function signature.\n\nAlternatively, we can leave them as constants and just ignore them? But that would be inefficient.\n\nBut the problem says: \"NEVER change @triton.jit function signatures or parameter names\". So we cannot remove them.\n\nWe must keep the parameters, but we can change the way we use them? Actually, we are not using them in the current kernel. So we can leave them as they are and just ignore.\n\nAlternatively, we can remove the block processing in the kernel and process one element per thread? That is what we are doing.\n\nSo the plan:\n\n1. Change the grid to 3 dimensions: (batch, in_channels, out_height * out_width)\n2. In the kernel, compute pid_h and pid_w from pid_hw (the third program_id).\n3. Keep the rest of the kernel the same.\n\nBut note: the kernel also uses BLOCK_SIZE_H and BLOCK_SIZE_W. We are not using them. We can set them to 1? But they are passed as constants. We can set the block sizes to 1 in the launch? Actually, in the launch we have:\n    BLOCK_SIZE_H=1, BLOCK_SIZE_W=64\n\nBut we are not using these in the kernel. So we can ignore.\n\nHowever, the kernel must be adjusted to use the new way of getting pid_h and pid_w.\n\nLet's rewrite the kernel accordingly.\n\nBut note: the constraint says \"NEVER modify PID logic\". However, the current PID logic is broken (using 4 dimensions). We have to fix it.\n\nWe are allowed to change the PID logic to fix the compilation error? Yes, because the current code doesn't compile.\n\nLet me write the fixed kernel:\n\nWe change the kernel to:\n\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n\nThen we use pid_h and pid_w as before.\n\nAlso, we must adjust the grid in the forward function.\n\nWe change the grid to:\n\n    grid = (batch, in_channels, out_height * out_width)\n\nBut note: the kernel expects the output_height and output_width as arguments. We are passing them correctly.\n\nHowever, we must note that the grid dimension for the third axis is `out_height * out_width`, which might be too large? But Triton can handle up to 2^31 in each dimension.\n\nAlternatively, we can use a blocked approach to reduce the grid size, but the problem says to make small changes.\n\nWe are only changing the grid and the way we compute the indices.\n\nLet's do it.\n\nWe change the grid in the forward function of TritonDepthwiseConv2d from:\n    grid = (batch, in_channels, out_height, triton.cdiv(out_width, 64))\nto:\n    grid = (batch, in_channels, out_height * out_width)\n\nAnd remove the block size in the width dimension? Actually, we are not using it.\n\nBut note: the kernel launch also passes BLOCK_SIZE_H and BLOCK_SIZE_W. We can set them to 1 and 1? Because we are processing one element per thread.\n\nBut the kernel does not use these block sizes. We can leave the launch as is? Or we can set them to 1? The problem says not to change the function signature, so we have to pass them.\n\nWe are currently passing:\n    BLOCK_SIZE_H=1, BLOCK_SIZE_W=64\n\nBut in the kernel, we are not using them. So it doesn't matter.\n\nAlternatively, we can remove the block processing parameters? But the constraint says we cannot change the function signature.\n\nSo we leave them.\n\nWe must also adjust the mask for the third dimension: we now have a 1D index for hw, but we must check that pid_hw < (out_height * out_width). We are already doing:\n\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_hw = pid_hw < (output_height * output_width)   # But note: pid_hw is the linear index\n\nBut wait, in the kernel we have:\n\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_h = pid_h < output_height   # This is now computed from pid_hw, but we don't have a direct mask for h and w?\n    mask_w = pid_w < output_width\n\nActually, by computing pid_h = pid_hw // output_width and pid_w = pid_hw % output_width, we are guaranteed that:\n    pid_h is in [0, output_height-1] and pid_w in [0, output_width-1] if pid_hw is in [0, output_height * output_width - 1].\n\nBut we must check that the computed pid_h and pid_w are within bounds? Actually, the computation of pid_h and pid_w from a valid pid_hw (that is less than output_height * output_width) will yield valid coordinates.\n\nSo we only need to check that pid_hw is less than the total number of hw points.\n\nTherefore, we can change the mask to:\n\n    mask = mask_b & mask_c & (pid_hw < (output_height * output_width))\n\nBut note: we are also storing the result with the same mask. The output index is computed with pid_h and pid_w, which are valid.\n\nAlternatively, we can keep the mask as:\n\n    mask = mask_b & mask_c & (pid_hw < (output_height * output_width))\n\nand remove the individual mask_h and mask_w? Because we are guaranteed that if pid_hw is in range, then pid_h and pid_w are valid.\n\nSo let me adjust the kernel:\n\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n\n    # Compute the output indices\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n\n    # Create masks for boundary checks\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_hw = pid_hw < (output_height * output_width)\n    mask = mask_b & mask_c & mask_hw\n\n    # Then the rest is the same.\n\nWe remove the individual mask_h and mask_w because they are always true if mask_hw is true.\n\nBut note: what if output_height * output_width is not divisible by 1? It is, because we are using integer division. So the computed pid_h and pid_w will be in the valid range.\n\nTherefore, we can change the kernel accordingly.\n\nThis should fix the compilation error.\n\nLet's rewrite the kernel accordingly.\n\nWe are modifying about 10 lines.\n\nWe also change the grid in the forward function.\n\nWe note: the kernel is now launched with a grid of (batch, in_channels, out_height * out_width).\n\nWe hope that this will fix the compilation and then we can work on performance.\n\nBut note: the performance might be poor because we are launching one thread per output element. But that is the same as before, except that we are now using a 3D grid.\n\nWe are allowed to optimize later.\n\nLet me write the fixed code.\n\nNote: We are not changing the function signature of the kernel, only the internal logic and the grid configuration.\n\nWe are also not changing the output tensor shape.\n\nWe are going to output the entire code block.\n\nImportant: We are only allowed to change the Triton kernel source within the block and the grid configuration in the forward function of TritonDepthwiseConv2d.\n\nLet's do it.\n</think>\nThe error occurs because Triton's `program_id` only supports axes 0, 1, or 2, but the kernel uses axis 3. To fix this, we need to combine the height and width dimensions into a single program ID dimension. \n\nHere's the solution:\n1. Combine height and width dimensions into a single dimension using `pid_hw = pid // output_width` and `pid_w = pid % output_width`\n2. Update the grid configuration to use 3 dimensions instead of 4\n3. Maintain all other functionality including boundary checks and memory access patterns\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    input_batch, input_channels, input_height, input_width,\n    stride, padding,\n    output_height, output_width,\n    BLOCK_SIZE_H: tl.constexpr, BLOCK_SIZE_W: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_hw = tl.program_id(2)\n    \n    # Calculate output indices from combined dimension\n    pid_h = pid_hw // output_width\n    pid_w = pid_hw % output_width\n    \n    # Create masks for boundary checks\n    mask_b = pid_b < input_batch\n    mask_c = pid_c < input_channels\n    mask_h = pid_h < output_height\n    mask_w = pid_w < output_width\n    mask = mask_b & mask_c & mask_h & mask_w\n    \n    # Calculate input position with stride and padding\n    input_h = pid_h * stride - padding\n    input_w = pid_w * stride - padding\n    \n    # Initialize accumulator\n    acc = 0.0\n    \n    # Loop over 3x3 kernel\n    for kh in range(3):\n        for kw in range(3):\n            h = input_h + kh\n            w = input_w + kw\n            \n            # Check if within input boundaries\n            in_bounds = (h >= 0) & (h < input_height) & (w >= 0) & (w < input_width)\n            \n            if in_bounds:\n                # Calculate input index\n                input_idx = pid_b * input_channels * input_height * input_width + \\\n                           pid_c * input_height * input_width + \\\n                           h * input_width + w\n                input_val = tl.load(input_ptr + input_idx)\n                \n                # Calculate weight index\n                weight_idx = pid_c * 9 + kh * 3 + kw\n                weight_val = tl.load(weight_ptr + weight_idx)\n                \n                acc += input_val * weight_val\n    \n    # Calculate output index\n    output_idx = pid_b * input_channels * output_height * output_width + \\\n                pid_c * output_height * output_width + \\\n                pid_h * output_width + pid_w\n    tl.store(output_ptr + output_idx, acc, mask=mask)\n\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.Tensor(in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.Tensor(in_channels))\n        else:\n            self.bias = None\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / (fan_in**0.5)\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, in_height, in_width = x.shape\n        assert in_channels == self.in_channels\n        \n        out_height = (in_height + 2*self.padding - 3) // self.stride + 1\n        out_width = (in_width + 2*self.padding - 3) // self.stride + 1\n        output = torch.zeros((batch, in_channels, out_height, out_width), device=x.device, dtype=x.dtype)\n        \n        # Updated grid configuration with 3 dimensions\n        grid = (batch, in_channels, out_height * out_width)\n        \n        # Launch Triton kernel\n        depthwise_conv_kernel[grid](\n            x, self.weight, output,\n            batch, in_channels, in_height, in_width,\n            self.stride, self.padding,\n            out_height, out_width,\n            BLOCK_SIZE_H=1, BLOCK_SIZE_W=1\n        )\n        \n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1)\n            \n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.mbconv1 = self._make_mbconv_block(32, 16, 1, 1)\n        self.mbconv2 = self._make_mbconv_block(16, 24, 2, 6)\n        self.mbconv3 = self._make_mbconv_block(24, 40, 2, 6)\n        self.mbconv4 = self._make_mbconv_block(40, 80, 2, 6)\n        self.mbconv5 = self._make_mbconv_block(80, 112, 1, 6)\n        self.mbconv6 = self._make_mbconv_block(112, 192, 2, 6)\n        self.mbconv7 = self._make_mbconv_block(192, 320, 1, 6)\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def _make_mbconv_block(self, in_channels, out_channels, stride, expand_ratio):\n        hidden_dim = round(in_channels * expand_ratio)\n        return nn.Sequential(\n            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            TritonDepthwiseConv2d(hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.mbconv1(x)\n        x = self.mbconv2(x)\n        x = self.mbconv3(x)\n        x = self.mbconv4(x)\n        x = self.mbconv5(x)\n        x = self.mbconv6(x)\n        x = self.mbconv7(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\nbatch_size = 10\ninput_shape = (3, 240, 240)\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}