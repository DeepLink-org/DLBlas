{"id": "76160ef7-a864-4fee-b4e9-5a0f25a21994", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _avg_pool2d_kernel(\n    x_ptr,\n    output_ptr,\n    kernel_size: tl.constexpr,\n    stride,\n    padding,\n    h_in,\n    w_in,\n    h_out,\n    w_out,\n    batch_size,\n    channels,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_output = batch_size * channels * h_out * w_out\n    if pid >= total_output:\n        return\n\n    per_batch = channels * h_out * w_out\n    b = pid // per_batch\n    pid_in_batch = pid % per_batch\n    c = pid_in_batch // (h_out * w_out)\n    pid_in_channel = pid_in_batch % (h_out * w_out)\n    oh = pid_in_channel // w_out\n    ow = pid_in_channel % w_out\n\n    start_h = oh * stride - padding\n    start_w = ow * stride - padding\n    \n    total = 0.0\n    count = 0\n    \n    base_ptr = x_ptr + b * channels * h_in * w_in + c * h_in * w_in\n    \n    for kh in tl.static_range(0, kernel_size):\n        h_index = start_h + kh\n        if h_index >=0 and h_index < h_in:\n            for kw in tl.static_range(0, kernel_size):\n                w_index = start_w + kw\n                if w_index >=0 and w_index < w_in:\n                    ptr = base_ptr + h_index * w_in + w_index\n                    val = tl.load(ptr)\n                    total += val\n                    count += 1\n    \n    if count > 0:\n        total /= count\n    \n    out_index = b * channels * h_out * w_out + c * h_out * w_out + oh * w_out + ow\n    tl.store(output_ptr + out_index, total)\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):\n        super(ModelNew, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.contiguous()\n        h_in, w_in = x.shape[2], x.shape[3]\n        h_out = (h_in + 2 * self.padding - self.kernel_size) // self.stride + 1\n        w_out = (w_in + 2 * self.padding - self.kernel_size) // self.stride + 1\n        \n        output = torch.empty(\n            x.shape[0], x.shape[1], h_out, w_out, \n            dtype=x.dtype, device=x.device\n        )\n        \n        total_elements = output.numel()\n        grid = lambda meta: (total_elements,)\n        _avg_pool2d_kernel[grid](\n            x, output,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            h_in,\n            w_in,\n            h_out,\n            w_out,\n            x.shape[0],\n            x.shape[1],\n            BLOCK_SIZE=1024\n        )\n        return output\n\nbatch_size = 16\nchannels = 64\nheight = 256\nwidth = 256\nkernel_size = 3\n\ndef get_inputs():\n    x = torch.randn(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "4a6e8722-4f8c-45e2-9687-8237649fcff5", "generation": 2, "timestamp": 1754647300.7192965, "iteration_found": 27, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.003, "runtime_ms": 7.66, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.02, "speed_up": 0.003, "custom_timing": 7.66}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 1}, "artifacts_json": null, "artifact_dir": null}