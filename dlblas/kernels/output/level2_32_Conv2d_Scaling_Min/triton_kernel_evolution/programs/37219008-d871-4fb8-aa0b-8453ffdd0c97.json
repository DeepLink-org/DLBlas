{"id": "37219008-d871-4fb8-aa0b-8453ffdd0c97", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _min_reduction_kernel(\n    x_ptr,\n    output_ptr,\n    scale_factor,\n    height,\n    width,\n    stride_batch,\n    stride_channel,\n    stride_height,\n    stride_width,\n    output_stride_batch,\n    output_stride_channel,\n    output_stride_height,\n    output_stride_width,\n    channels: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_h = tl.program_id(1)\n    pid_w = tl.program_id(2)\n    \n    # Check spatial boundaries\n    if pid_h >= height or pid_w >= width:\n        return\n        \n    # Base pointer calculation for input\n    base = pid_batch * stride_batch + pid_h * stride_height + pid_w * stride_width\n    \n    # Load all channels for current spatial position\n    c_offsets = tl.arange(0, channels)\n    ptrs = x_ptr + base + c_offsets * stride_channel\n    vals = tl.load(ptrs, mask=c_offsets < channels, other=float('inf'))\n    \n    # Apply scaling and find minimum value\n    scaled_vals = vals * scale_factor\n    min_val = tl.min(scaled_vals, axis=0)\n    \n    # Store result\n    output_idx = pid_batch * output_stride_batch + pid_h * output_stride_height + pid_w * output_stride_width\n    tl.store(output_ptr + output_idx, min_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        batch_size, channels, height, width = x.shape\n        \n        # Prepare output tensor\n        output = torch.empty(batch_size, 1, height, width, device=x.device, dtype=x.dtype)\n        \n        # Ensure contiguous memory\n        if not x.is_contiguous():\n            x = x.contiguous()\n        output = output.contiguous()\n        \n        # Configure grid - one thread per spatial position\n        grid = (batch_size, height, width)\n        \n        _min_reduction_kernel[grid](\n            x,\n            output,\n            self.scale_factor,\n            height,\n            width,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            channels\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "809c4bf0-495b-4503-9eb4-42dba6d37b69", "generation": 3, "timestamp": 1754568466.7126536, "iteration_found": 15, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.498, "runtime_ms": 0.141, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0702, "speed_up": 0.498, "custom_timing": 0.141}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.638, "runtime_ms": 0.11, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0702, "speed_up": 0.638, "custom_timing": 0.11}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}