{"id": "6d2f4594-1f7c-4e0b-a18c-5b136cb1d23f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 128, 'VECTOR_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 256, 'VECTOR_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 512, 'VECTOR_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 1024, 'VECTOR_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 2048, 'VECTOR_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 4096, 'VECTOR_SIZE': 4}, num_warps=4),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef fused_pointwise_kernel(\n    input_ptr,\n    sum_tensor_ptr,\n    output_ptr,\n    C,  # Number of channels\n    total_spatial,  # D*H*W\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n    VECTOR_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    block_start = pid * BLOCK_SIZE\n    \n    # Process elements in vectors\n    for i in range(0, BLOCK_SIZE, VECTOR_SIZE):\n        current_offset = block_start + i\n        vector_offsets = current_offset + tl.arange(0, VECTOR_SIZE)\n        mask = vector_offsets < n_elements\n        \n        # Vectorized load\n        x_vec = tl.load(input_ptr + vector_offsets, mask=mask, other=0.0)\n        \n        # Compute channel index once per vector\n        channel_idx = (current_offset // total_spatial) % C\n        s_val = tl.load(sum_tensor_ptr + channel_idx)\n        \n        # LeakyReLU (vectorized)\n        x_vec = tl.where(x_vec >= 0, x_vec, 0.2 * x_vec)\n        \n        # Add channel-specific value\n        x_vec = x_vec + s_val\n        \n        # Clamp (vectorized)\n        x_vec = tl.minimum(tl.maximum(x_vec, -1.0), 1.0)\n        \n        # GELU using erf approximation (vectorized)\n        gelu_x = 0.5 * x_vec * (1.0 + tl.erf(x_vec * 0.7071067811865475))\n        \n        # Vectorized store\n        tl.store(output_ptr + vector_offsets, gelu_x, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        # Compute convolution\n        conv_out = self.conv(x)\n        B, C, D, H, W = conv_out.shape\n        total_spatial = D * H * W\n        n_elements = B * C * D * H * W\n        \n        # Prepare output tensor\n        out = torch.empty_like(conv_out)\n        \n        # Flatten sum tensor for efficient access\n        sum_tensor_flat = self.sum_tensor.view(self.out_channels)\n        \n        # Launch kernel with autotune\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        fused_pointwise_kernel[grid](\n            conv_out, \n            sum_tensor_flat, \n            out,\n            C,\n            total_spatial,\n            n_elements,\n        )\n        return out\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "5234ee64-2873-45ec-bbad-669bc0e7de5e", "generation": 3, "timestamp": 1754584143.6787996, "iteration_found": 15, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.057, "runtime_ms": 1.35, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0773, "speed_up": 0.057, "custom_timing": 1.35}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.134, "runtime_ms": 0.576, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0773, "speed_up": 0.134, "custom_timing": 0.576}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}