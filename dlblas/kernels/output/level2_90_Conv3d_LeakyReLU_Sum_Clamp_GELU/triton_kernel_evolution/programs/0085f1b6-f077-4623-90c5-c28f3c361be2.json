{"id": "0085f1b6-f077-4623-90c5-c28f3c361be2", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_CH': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_CH': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_CH': 256}, num_warps=4),\n    ],\n    key=['n_spatial'],\n)\n@triton.jit\ndef fused_pointwise_kernel(\n    conv_ptr,\n    sum_ptr,\n    output_ptr,\n    n_spatial,\n    spatial_size,\n    channels,\n    n_elements,\n    BLOCK_SIZE_CH: tl.constexpr,\n):\n    pid_spatial = tl.program_id(0)\n    pid_channel = tl.program_id(1)\n    \n    if pid_spatial >= n_spatial:\n        return\n        \n    batch_idx = pid_spatial // spatial_size\n    spatial_idx = pid_spatial % spatial_size\n    \n    channel_start = pid_channel * BLOCK_SIZE_CH\n    channel_offsets = channel_start + tl.arange(0, BLOCK_SIZE_CH)\n    channel_mask = channel_offsets < channels\n    \n    base_ptr = batch_idx * channels * spatial_size + spatial_idx\n    x_ptrs = conv_ptr + base_ptr + channel_offsets * spatial_size\n    x = tl.load(x_ptrs, mask=channel_mask, other=0.0)\n    \n    # LeakyReLU\n    x = tl.where(x >= 0, x, x * 0.2)\n    \n    s = tl.load(sum_ptr + channel_offsets, mask=channel_mask, other=0.0)\n    x = x + s\n    \n    # Clamp\n    x = tl.minimum(tl.maximum(x, -1.0), 1.0)\n    \n    # GELU approximation\n    x = 0.5 * x * (1.0 + tl.erf(x * 0.7071067811865475))\n    \n    out_ptrs = output_ptr + base_ptr + channel_offsets * spatial_size\n    tl.store(out_ptrs, x, mask=channel_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, sum_tensor_shape):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.sum_tensor = nn.Parameter(torch.randn(sum_tensor_shape))\n    \n    def forward(self, x):\n        conv_output = self.conv(x)\n        B, C, D, H, W = conv_output.shape\n        spatial_size = D * H * W\n        n_spatial = B * spatial_size\n        n_elements = B * C * D * H * W\n        \n        output = torch.empty_like(conv_output)\n        grid = lambda meta: (\n            n_spatial,\n            triton.cdiv(C, meta['BLOCK_SIZE_CH']),\n        )\n        fused_pointwise_kernel[grid](\n            conv_output, \n            self.sum_tensor.view(-1), \n            output, \n            n_spatial, \n            spatial_size, \n            C,\n            n_elements,\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nsum_tensor_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, sum_tensor_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "3d1ee418-cfe8-4919-8223-b3e8ad70148f", "generation": 2, "timestamp": 1754584922.679603, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.053, "runtime_ms": 1.47, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0773, "speed_up": 0.053, "custom_timing": 1.47}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.135, "runtime_ms": 0.574, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0773, "speed_up": 0.135, "custom_timing": 0.574}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}