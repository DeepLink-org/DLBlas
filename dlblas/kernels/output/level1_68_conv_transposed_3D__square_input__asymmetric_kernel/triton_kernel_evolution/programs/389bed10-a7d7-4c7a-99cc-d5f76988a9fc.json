{"id": "389bed10-a7d7-4c7a-99cc-d5f76988a9fc", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs a transposed 3D convolution with optimized Triton kernel implementation.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (kernel_depth, kernel_width, kernel_height), \n                             where kernel_width == kernel_height.\n        stride (tuple, optional): Stride of the convolution. Defaults to (1, 1, 1).\n        padding (tuple, optional): Padding applied to the input. Defaults to (0, 0, 0).\n        output_padding (tuple, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.output_padding = output_padding\n        self.groups = groups\n        \n        # Initialize weight and bias\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, *kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        # Initialize parameters\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, _, depth, width, height = x.shape\n        kernel_depth, kernel_width, kernel_height = self.kernel_size\n        \n        # Calculate output dimensions\n        depth_out = (depth - 1) * self.stride[0] - 2 * self.padding[0] + kernel_depth + self.output_padding[0]\n        width_out = (width - 1) * self.stride[1] - 2 * self.padding[1] + kernel_width + self.output_padding[1]\n        height_out = (height - 1) * self.stride[2] - 2 * self.padding[2] + kernel_height + self.output_padding[2]\n        \n        output = torch.empty((batch_size, self.out_channels, depth_out, width_out, height_out), \n                            device=x.device, dtype=x.dtype)\n        \n        # Set kernel parameters\n        bias_ptr = self.bias.data_ptr() if self.bias is not None else 0\n        total_elements = batch_size * self.out_channels * depth_out * width_out * height_out\n        \n        # Launch Triton kernel\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        self._conv_transpose3d_kernel[grid](\n            x, output, self.weight,\n            bias_ptr,\n            batch_size, self.in_channels, self.out_channels,\n            depth, width, height,\n            depth_out, width_out, height_out,\n            kernel_depth, kernel_width, kernel_height,\n            *self.stride, *self.padding, self.groups,\n            total_elements,\n            BLOCK_SIZE=128\n        )\n        return output\n\n    @staticmethod\n    @triton.jit\n    def _conv_transpose3d_kernel(\n        x_ptr, out_ptr, weight_ptr,\n        bias_ptr,\n        batch_size, in_channels, out_channels,\n        depth, width, height,\n        depth_out, width_out, height_out,\n        kernel_d, kernel_w, kernel_h,\n        stride_d, stride_w, stride_h,\n        pad_d, pad_w, pad_h,\n        groups,\n        total_elements,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        idx = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = idx < total_elements\n        \n        # Decompose index into b, c_out, d_out, w_out, h_out\n        h_out = idx % height_out\n        idx = idx // height_out\n        w_out = idx % width_out\n        idx = idx // width_out\n        d_out = idx % depth_out\n        idx = idx // depth_out\n        c_out = idx % out_channels\n        b = idx // out_channels\n        \n        # Initialize accumulator\n        acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n        \n        # Compute group boundaries\n        group_id = c_out // (out_channels // groups)\n        c_in_start = group_id * (in_channels // groups)\n        c_in_end = (group_id + 1) * (in_channels // groups)\n        \n        # Compute input position\n        for c_in in range(c_in_start, c_in_end):\n            for kd in range(kernel_d):\n                d_in = d_out - kd + pad_d\n                if d_in < 0 or d_in >= depth * stride_d:\n                    continue\n                if d_in % stride_d != 0:\n                    continue\n                d_in //= stride_d\n                \n                for kw in range(kernel_w):\n                    w_in = w_out - kw + pad_w\n                    if w_in < 0 or w_in >= width * stride_w:\n                        continue\n                    if w_in % stride_w != 0:\n                        continue\n                    w_in //= stride_w\n                    \n                    for kh in range(kernel_h):\n                        h_in = h_out - kh + pad_h\n                        if h_in < 0 or h_in >= height * stride_h:\n                            continue\n                        if h_in % stride_h != 0:\n                            continue\n                        h_in //= stride_h\n                        \n                        # Load input and weight\n                        x_val = tl.load(\n                            x_ptr + b * in_channels * depth * width * height + \n                            c_in * depth * width * height +\n                            d_in * width * height + \n                            w_in * height + \n                            h_in,\n                            mask=(d_in < depth) & (w_in < width) & (h_in < height),\n                            other=0.0\n                        )\n                        \n                        weight_val = tl.load(\n                            weight_ptr + c_out * in_channels * kernel_d * kernel_w * kernel_h + \n                            c_in * kernel_d * kernel_w * kernel_h +\n                            kd * kernel_w * kernel_h + \n                            kw * kernel_h + \n                            kh\n                        )\n                        \n                        acc += x_val * weight_val\n        \n        # Add bias if present\n        if bias_ptr != 0:\n            bias_val = tl.load(bias_ptr + c_out)\n            acc += bias_val\n        \n        # Store result\n        out_offset = b * out_channels * depth_out * width_out * height_out + \\\n                     c_out * depth_out * width_out * height_out + \\\n                     d_out * width_out * height_out + \\\n                     w_out * height_out + \\\n                     h_out\n        tl.store(out_ptr + out_offset, acc, mask=mask)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_depth = 3\nkernel_width = 5\nkernel_height = 5\ndepth = 64\nwidth = 64\nheight = 64\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, depth, width, height)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, (kernel_depth, kernel_width, kernel_height)]  # Provide in_channels, out_channels, kernel_size for initialization\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a2b83c2e-0a70-4869-8b04-989755dba771", "generation": 1, "timestamp": 1754646230.7416174, "iteration_found": 0, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "name 'math' is not defined\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/evaluator.py\", line 173, in _verification_worker\n    result: KernelExecResult = eval_kernel_against_ref(\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 484, in eval_kernel_against_ref\n    custom_model = ModelNew(*init_args, **init_kwargs)\n  File \"/tmp/tmpjwyfpk78.py\", line 40, in __init__\n    self.reset_parameters()\n  File \"/tmp/tmpjwyfpk78.py\", line 43, in reset_parameters\n    nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\nNameError: name 'math' is not defined\n", "exec_log": "[Child] \u7ed1\u5b9a GPU 3, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 7, in <module>\n  File \"<string>\", line 82, in ModelNew\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 844, in jit\n    return decorator(fn)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 832, in decorator\n    return JITFunction(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 635, in __init__\n    self.starting_line_number = inspect.getsourcelines(fn)[1]\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 958, in findsource\n    raise OSError('could not get source code')\nOSError: could not get source code\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 36.9, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.069, "speed_up": 0.002, "custom_timing": 36.9}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}