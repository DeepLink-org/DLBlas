{"id": "0cf294d9-d85b-4064-9834-14e7d434349f", "code": "import torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit(num_warps=8)\ndef group_norm_kernel(\n    x_ptr,\n    gamma_ptr,\n    beta_ptr,\n    y_ptr,\n    N, C, L, num_groups, eps,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    batch_idx = pid // num_groups\n    group_idx = pid % num_groups\n    \n    group_size = C // num_groups\n    start_c = group_idx * group_size\n    M = group_size * L\n    base_ptr = batch_idx * C * L + start_c * L\n\n    # Preload gamma and beta for the entire group\n    gamma_vals = tl.load(gamma_ptr + start_c + tl.arange(0, group_size), \n                         mask=tl.arange(0, group_size) < group_size, other=0.0)\n    beta_vals = tl.load(beta_ptr + start_c + tl.arange(0, group_size), \n                        mask=tl.arange(0, group_size) < group_size, other=0.0)\n\n    # Compute mean\n    mean = 0.0\n    for offset in range(0, M, BLOCK_SIZE):\n        cols = offset + tl.arange(0, BLOCK_SIZE)\n        mask = cols < M\n        x = tl.load(x_ptr + base_ptr + cols, mask=mask, other=0.0)\n        mean += tl.sum(x, axis=0)\n    mean = mean / M\n\n    # Compute variance\n    var = 0.0\n    for offset in range(0, M, BLOCK_SIZE):\n        cols = offset + tl.arange(0, BLOCK_SIZE)\n        mask = cols < M\n        x = tl.load(x_ptr + base_ptr + cols, mask=mask, other=0.0)\n        x_shift = x - mean\n        var += tl.sum(x_shift * x_shift, axis=0)\n    var = var / M\n    rstd = 1.0 / tl.sqrt(var + eps)\n\n    # Normalize and store\n    for offset in range(0, M, BLOCK_SIZE):\n        cols = offset + tl.arange(0, BLOCK_SIZE)\n        mask = cols < M\n        x = tl.load(x_ptr + base_ptr + cols, mask=mask, other=0.0)\n        normalized = (x - mean) * rstd\n        \n        c_idx = (cols // L).to(tl.int32)\n        \n        # Efficient gamma/beta broadcast\n        gamma_val = tl.zeros(BLOCK_SIZE, dtype=tl.float32)\n        beta_val = tl.zeros(BLOCK_SIZE, dtype=tl.float32)\n        for c in range(group_size):\n            mask_c = (c_idx == c)\n            gamma_val = tl.where(mask_c, gamma_vals[c], gamma_val)\n            beta_val = tl.where(mask_c, beta_vals[c], beta_val)\n        \n        y = normalized * gamma_val + beta_val\n        tl.store(y_ptr + base_ptr + cols, y, mask=mask)\n\ndef group_norm_triton(x, num_groups, gamma, beta, eps=1e-5):\n    N, C, D, H, W = x.shape\n    L = D * H * W\n    x_reshaped = x.reshape(N, C, L)\n    y = torch.empty_like(x_reshaped)\n    \n    grid = (N * num_groups,)\n    group_norm_kernel[grid](\n        x_reshaped, gamma, beta, y,\n        N, C, L, num_groups, eps,\n        BLOCK_SIZE=2048\n    )\n    return y.reshape(N, C, D, H, W)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, num_groups):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(num_groups, out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = group_norm_triton(\n            x, \n            self.group_norm.num_groups,\n            self.group_norm.weight,\n            self.group_norm.bias,\n            self.group_norm.eps\n        )\n        x = x.mean(dim=[1, 2, 3, 4])\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nD, H, W = 16, 32, 32\nkernel_size = 3\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, num_groups]", "language": "python", "parent_id": "6eb3993d-23ff-4615-a9e4-7f0d79f44be1", "generation": 3, "timestamp": 1754571761.8000455, "iteration_found": 28, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "", "exec_log": "[Child] \u7ed1\u5b9a GPU 6, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 6, in <module>\nTypeError: jit() got an unexpected keyword argument 'num_warps'\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.142, "runtime_ms": 0.712, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.101, "speed_up": 0.142, "custom_timing": 0.712}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}