{"id": "1bc4bfe9-c231-4f46-bce2-8c1c7216b47b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n@triton.jit\ndef _fused_residual_logsumexp(\n    x_conv_ptr, \n    x_norm_ptr, \n    output_ptr,\n    batch_size, \n    height, \n    width,\n    stride_conv_b, stride_conv_c, stride_conv_h, stride_conv_w,\n    stride_norm_b, stride_norm_c, stride_norm_h, stride_norm_w,\n    stride_out_b, stride_out_c, stride_out_h, stride_out_w,\n    channels: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_spatial = batch_size * height * width\n    base_idx = pid * 2\n    for i in range(2):\n        idx = base_idx + i\n        if idx < total_spatial:\n            hw = height * width\n            pid_batch = idx // hw\n            pid_hw = idx % hw\n            pid_h = pid_hw // width\n            pid_w = pid_hw % width\n            \n            off_base_conv = pid_batch * stride_conv_b + pid_h * stride_conv_h + pid_w * stride_conv_w\n            off_base_norm = pid_batch * stride_norm_b + pid_h * stride_norm_h + pid_w * stride_norm_w\n            \n            c_offsets = tl.arange(0, channels)\n            x_conv_vec = tl.load(x_conv_ptr + off_base_conv + c_offsets * stride_conv_c)\n            x_norm_vec = tl.load(x_norm_ptr + off_base_norm + c_offsets * stride_norm_c)\n            \n            tanh_vec = libdevice.tanh(x_norm_vec)\n            hard_swish_vec = tanh_vec * (tl.minimum(tl.maximum(tanh_vec + 3.0, 0.0), 6.0)) / 6.0\n            residual_vec = x_conv_vec + hard_swish_vec\n            \n            max_val = tl.max(residual_vec, axis=0)\n            exp_vec = tl.exp(residual_vec - max_val)\n            sum_exp = tl.sum(exp_vec, axis=0)\n            log_sum_exp = tl.log(sum_exp) + max_val\n            \n            off_out = pid_batch * stride_out_b + pid_h * stride_out_h + pid_w * stride_out_w\n            tl.store(output_ptr + off_out, log_sum_exp)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.group_norm = nn.GroupNorm(groups, out_channels, eps=eps)\n\n    def forward(self, x):\n        x_conv = self.conv(x)\n        x_norm = self.group_norm(x_conv)\n        \n        batch, channels, height, width = x_conv.shape\n        output = torch.empty(batch, 1, height, width, device=x_conv.device, dtype=x_conv.dtype)\n        \n        if batch * height * width > 0:\n            x_conv = x_conv.contiguous()\n            x_norm = x_norm.contiguous()\n            output = output.contiguous()\n            \n            total_elements = batch * height * width\n            grid = ( (total_elements + 1) // 2, )\n            \n            _fused_residual_logsumexp[grid](\n                x_conv, x_norm, output,\n                batch, height, width,\n                x_conv.stride(0), x_conv.stride(1), x_conv.stride(2), x_conv.stride(3),\n                x_norm.stride(0), x_norm.stride(1), x_norm.stride(2), x_norm.stride(3),\n                output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n                channels\n            )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ngroups = 8\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "62388c3d-033b-4226-80f1-74623662ccd8", "generation": 4, "timestamp": 1754587274.4193306, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.833, "runtime_ms": 0.203, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.169, "speed_up": 0.833, "custom_timing": 0.203}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.849, "runtime_ms": 0.199, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.169, "speed_up": 0.849, "custom_timing": 0.199}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}