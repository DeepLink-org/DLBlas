{"id": "b6c09c92-446a-4ee4-89c3-87491a617991", "code": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _logsumexp_kernel(\n    x_ptr,\n    output_ptr,\n    x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    n_channels, n_height, n_width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_spatial = n_height * n_width\n    batch_id = pid // total_spatial\n    spatial_id = pid % total_spatial\n    h_id = spatial_id // n_width\n    w_id = spatial_id % n_width\n\n    x_batch_ptr = x_ptr + batch_id * x_batch_stride + h_id * x_height_stride + w_id * x_width_stride\n\n    max_val = -float('inf')\n    sum_exp = 0.0\n    num_steps = tl.cdiv(n_channels, BLOCK_SIZE)\n\n    for step in range(num_steps):\n        offset = step * BLOCK_SIZE\n        c_offsets = offset + tl.arange(0, BLOCK_SIZE)\n        mask = c_offsets < n_channels\n        x_ptrs = x_batch_ptr + c_offsets * x_channel_stride\n        chunk = tl.load(x_ptrs, mask=mask, other=-float('inf'))\n        \n        if step == 0:\n            max_val = tl.max(chunk, axis=0)\n        else:\n            chunk_max = tl.max(chunk, axis=0)\n            max_val = tl.maximum(max_val, chunk_max)\n\n    for step in range(num_steps):\n        offset = step * BLOCK_SIZE\n        c_offsets = offset + tl.arange(0, BLOCK_SIZE)\n        mask = c_offsets < n_channels\n        x_ptrs = x_batch_ptr + c_offsets * x_channel_stride\n        chunk = tl.load(x_ptrs, mask=mask, other=0.0)\n        \n        exp_chunk = tl.exp(chunk - max_val)\n        sum_chunk = tl.sum(exp_chunk, axis=0)\n        sum_exp += sum_chunk\n\n    log_sum_exp = tl.log(sum_exp) + max_val\n\n    output_batch_ptr = output_ptr + batch_id * output_batch_stride + 0 * output_channel_stride + h_id * output_height_stride + w_id * output_width_stride\n    tl.store(output_batch_ptr, log_sum_exp)\n\ndef triton_logsumexp(x, dim=1, keepdim=False):\n    assert x.dim() == 4\n    assert dim == 1\n    assert keepdim is True\n\n    n_batch, n_channels, n_height, n_width = x.shape\n    x_cont = x.contiguous()\n    output = torch.empty(n_batch, 1, n_height, n_width, device=x.device, dtype=x.dtype)\n\n    total_elements = n_batch * n_height * n_width\n    BLOCK_SIZE = 128\n\n    x_strides = x_cont.stride()\n    output_strides = output.stride()\n\n    grid = (total_elements,)\n    _logsumexp_kernel[grid](\n        x_cont,\n        output,\n        x_strides[0], x_strides[1], x_strides[2], x_strides[3],\n        output_strides[0], output_strides[1], output_strides[2], output_strides[3],\n        n_channels, n_height, n_width,\n        BLOCK_SIZE=BLOCK_SIZE\n    )\n\n    return output", "language": "python", "parent_id": "eb2486fb-0ee9-4b1e-bced-eff21ab69e9f", "generation": 2, "timestamp": 1754586564.332564, "iteration_found": 12, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.988, "runtime_ms": 0.171, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.169, "speed_up": 0.988, "custom_timing": 0.171}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 34.19999999999999, "speed_up": 1.142, "runtime_ms": 0.148, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.169, "speed_up": 1.142, "custom_timing": 0.148}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}