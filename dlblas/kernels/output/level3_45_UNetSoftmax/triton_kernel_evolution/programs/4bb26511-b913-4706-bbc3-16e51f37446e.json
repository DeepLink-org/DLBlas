{"id": "4bb26511-b913-4706-bbc3-16e51f37446e", "code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef softmax_kernel(\n    output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols, \n    BLOCK_SIZE: tl.constexpr\n):\n    row_idx = tl.program_id(0)\n    row_start = row_idx * input_row_stride\n    row_start_output = row_idx * output_row_stride\n    \n    row_max = tl.full((), -float('inf'), dtype=tl.float32)\n    row_sum = tl.full((), 0.0, dtype=tl.float32)\n    \n    # First pass: online computation of max and sum\n    for col_offset in range(0, n_cols, BLOCK_SIZE):\n        col_offsets = tl.arange(0, BLOCK_SIZE) + col_offset\n        mask = col_offsets < n_cols\n        input_ptrs = input_ptr + row_start + col_offsets\n        chunk = tl.load(input_ptrs, mask=mask, other=-float('inf'))\n        \n        local_max = tl.max(chunk, axis=0)\n        new_max = tl.maximum(row_max, local_max)\n        \n        scale = tl.exp(row_max - new_max)\n        row_sum = row_sum * scale\n        \n        exp_vals = tl.exp(chunk - new_max)\n        chunk_sum = tl.sum(exp_vals, axis=0)\n        row_sum += chunk_sum\n        row_max = new_max\n    \n    # Second pass: compute and store softmax\n    for col_offset in range(0, n_cols, BLOCK_SIZE):\n        col_offsets = tl.arange(0, BLOCK_SIZE) + col_offset\n        mask = col_offsets < n_cols\n        input_ptrs = input_ptr + row_start + col_offsets\n        chunk = tl.load(input_ptrs, mask=mask, other=-float('inf'))\n        \n        exp_vals = tl.exp(chunk - row_max)\n        softmax_output = exp_vals / row_sum\n        output_ptrs = output_ptr + row_start_output + col_offsets\n        tl.store(output_ptrs, softmax_output, mask=mask)\n\nclass TritonSoftmax(nn.Module):\n    def __init__(self):\n        super().__init__()\n    \n    def forward(self, x):\n        x_contig = x.contiguous()\n        original_shape = x_contig.shape\n        \n        if x_contig.dim() > 2:\n            x_2d = x_contig.view(-1, original_shape[-1])\n        else:\n            x_2d = x_contig\n        \n        if x_2d.dim() == 1:\n            x_2d = x_2d.unsqueeze(0)\n        \n        n_rows, n_cols = x_2d.shape\n        output = torch.empty_like(x_2d)\n        \n        BLOCK_SIZE = min(triton.next_power_of_2(n_cols), 4096)\n        grid = (n_rows,)\n        \n        input_row_stride = x_2d.stride(0)\n        output_row_stride = output.stride(0)\n        \n        softmax_kernel[grid](\n            output, x_2d, \n            input_row_stride, output_row_stride, \n            n_cols, \n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output.view(original_shape)", "language": "python", "parent_id": "62c80fdd-f757-4b97-a730-2065a7532466", "generation": 3, "timestamp": 1754595940.0910048, "iteration_found": 17, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.343, "runtime_ms": 5.05, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 1.73, "speed_up": 0.343, "custom_timing": 5.05}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.341, "runtime_ms": 5.07, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 1.73, "speed_up": 0.341, "custom_timing": 5.07}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}