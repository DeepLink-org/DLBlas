{"id": "9c0df9d4-0c9a-4081-bf74-ae513df93c06", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        # Initialize hidden state with proper dtype\n        self.h0 = torch.randn((num_layers, batch_size, hidden_size))\n        self.c0 = torch.randn((num_layers, batch_size, hidden_size))\n        \n        # Use FP16 for LSTM weights\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n                           batch_first=True, dropout=dropout, \n                           bidirectional=False).half()\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # Convert input to FP16\n        x_half = x.half()\n        \n        # Convert states to device and FP16\n        h0 = self.h0.to(x.device).half()\n        c0 = self.c0.to(x.device).half()\n        \n        # Forward propagate LSTM in FP16\n        out, state = self.lstm(x_half, (h0, c0))\n        \n        # Convert output to FP32 for linear layer\n        out_f32 = out[:, -1, :].float()\n        out_f32 = self.fc(out_f32)\n        \n        # Return FP32 cell state\n        return state[1].float()\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "2cafbabc-7a4a-4bb1-95c7-29c207eac400", "generation": 1, "timestamp": 1754591402.7351162, "iteration_found": 5, "metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 26.4, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 25.4, "speed_up": 0.962, "custom_timing": 26.4}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}