{"id": "7d651b2f-ac55-4a6c-b743-b2d09ed758b6", "code": "import math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"BLOCK_SIZE\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask, other=0.0)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    max_val = tl.maximum(max_val, 1e-4)\n    scale = 127.0 / max_val\n    scaled = x * scale\n    clipped = tl.minimum(tl.maximum(scaled, -127.0), 127.0)\n    integer_value = libdevice.llrint(clipped)\n    tl.store(output_ptr + offsets, integer_value.to(tl.int8), mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127.0)\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    row_length = x.shape[1]\n    P2_val = 1 << (row_length - 1).bit_length()\n    grid = (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=row_length, P2=P2_val)\n    return output, output_scale", "language": "python", "parent_id": "8802fe55-ac8c-4284-ba38-79143d61cac4", "generation": 3, "timestamp": 1754595962.3737838, "iteration_found": 10, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.95, "runtime_ms": 4.81, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 4.57, "speed_up": 0.95, "custom_timing": 4.81}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 0}, "artifacts_json": null, "artifact_dir": null}