{"id": "a69a43ce-f103-4f21-b204-53226fda0522", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    h0 = 2 * i\n    w0 = 2 * j\n    \n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        if count > 0:\n            avg = avg / count\n        \n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Replace tensor core dot with element-wise multiplication and sum\n        partial = tl.sum(weight_block * avg[None, :], axis=1)\n        accumulator += partial\n    \n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=64,\n                BLOCK_SIZE_IC=64\n            )\n            return output\n        else:\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "0ca99f27-0b0f-497b-a704-e309333d26d7", "generation": 3, "timestamp": 1754591122.2825196, "iteration_found": 23, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.595, "runtime_ms": 0.506, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.301, "speed_up": 0.595, "custom_timing": 0.506}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.595, "runtime_ms": 0.506, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.301, "speed_up": 0.595, "custom_timing": 0.506}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.5950\n- runtime_ms: 0.5060\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.595, 'custom_timing': 0.506}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: runtime_ms. Consider continuing with similar changes.\n- Metrics showing regression: speed_up. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.5960, runtime_ms: 0.5050, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.596, 'custom_timing': 0.505}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.5970, runtime_ms: 0.5040, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.597, 'custom_timing': 0.504}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.5950, runtime_ms: 0.5060, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.595, 'custom_timing': 0.506}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    h0 = 2 * i\n    w0 = 2 * j\n    \n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        if count > 0:\n            avg = avg / count\n        \n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Use FP16 for tensor core acceleration with FP32 accumulation\n        weight_block_f16 = weight_block.to(tl.float16)\n        avg_f16 = avg.to(tl.float16)\n        partial = tl.dot(weight_block_f16, avg_f16, out_dtype=tl.float32)\n        accumulator += partial\n    \n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=64,\n                BLOCK_SIZE_IC=64\n            )\n            return output\n        else:\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.5950), Performs well on runtime_ms (0.5060), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.595, 'custom_timing': 0.506})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 256, 'BLOCK_SIZE_IC': 64}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    # 2D grid: pid0 = output pixel, pid1 = output channel block\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Calculate output pixel coordinates\n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    # Input window starting positions\n    h0 = 2 * i\n    w0 = 2 * j\n    \n    # Channel block indices\n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    # Initialize accumulator\n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    # Precompute input pointers for the 2x2 window\n    ptrs = tl.zeros((4,), dtype=tl.pointer_type)\n    masks = tl.zeros((4,), dtype=tl.int1)\n    count = 0\n    for di in range(2):\n        for dj in range(2):\n            h = h0 + di\n            w = w0 + dj\n            valid = (h < height) & (w < width)\n            ptrs = tl.where(tl.arange(0, 4) == count, \n                            input_ptr + batch_id * stride_b + h * stride_h + w * stride_w,\n                            ptrs)\n            masks = tl.where(tl.arange(0, 4) == count, valid, masks)\n            count += 1\n    \n    # Process input channels in blocks\n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        # Initialize average vector\n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        valid_count = 0\n        \n        # Load data from the 2x2 window\n        for k in range(4):\n            if tl.program_id(0) == 0 and tl.program_id(1) == 0 and ic_block_start == 0 and k == 0:\n                pass\n            if masks[k]:\n                ptr = ptrs[k] + ic_block_start * stride_c\n                data = tl.load(ptr + tl.arange(0, BLOCK_SIZE_IC), \n                              mask=ic_mask, other=0.0)\n                avg += data\n                valid_count += 1\n        \n        # Compute average if valid pixels found\n        if valid_count > 0:\n            avg = avg / valid_count\n        \n        # Load weight block using vectorized approach\n        weight_ptr_current = conv_weight_ptr + oc_block_start * num_input_features + ic_block_start\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Optimized matrix multiplication\n        partial = tl.sum(weight_block * avg, axis=1)\n        accumulator += partial\n    \n    # Store results\n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        # BatchNorm parameters\n        self.bn = nn.BatchNorm2d(num_input_features)\n        \n        # Convolution weight (1x1 kernel)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            # Apply BatchNorm and ReLU first\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            # Calculate grid dimensions\n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            # Get strides for input tensor\n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            # Launch Triton kernel\n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w\n            )\n            return output\n        else:\n            # Training or CPU fallback\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.5970), Performs well on runtime_ms (0.5040), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.597, 'custom_timing': 0.504})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 32, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 32, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    # 2D grid: pid0 = output pixel, pid1 = output channel block\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Calculate output pixel coordinates\n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    # Input window starting positions\n    h0 = 2 * i\n    w0 = 2 * j\n    \n    # Channel block indices\n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    # Initialize accumulator\n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    # Process input channels in blocks\n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        # Initialize average vector\n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        # Process 2x2 window\n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    # Build pointer and load data\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        # Compute average if valid pixels found\n        if count > 0:\n            avg = avg / count\n        \n        # Load weight block (shape: [BLOCK_SIZE_OC, BLOCK_SIZE_IC])\n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Matrix multiplication\n        partial = tl.sum(avg[None, :] * weight_block, axis=1)\n        accumulator += partial\n    \n    # Store results\n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        # BatchNorm parameters\n        self.bn = nn.BatchNorm2d(num_input_features)\n        \n        # Convolution weight (1x1 kernel)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            # Apply BatchNorm and ReLU first\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            # Calculate grid dimensions\n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 32)\n            )\n            \n            # Get strides for input tensor\n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            # Launch Triton kernel\n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=32,\n                BLOCK_SIZE_IC=32\n            )\n            return output\n        else:\n            # Training or CPU fallback\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.5960), Performs well on runtime_ms (0.5050), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.301, 'speed_up': 0.596, 'custom_timing': 0.505})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    output_ptr,\n    weight_ptr,\n    bias_ptr,\n    num_input_features,\n    H, W,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_output_b, stride_output_k, stride_output_h, stride_output_w,\n    BLOCK_SIZE_C: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_output_features = bias_ptr.shape[0]\n    H_out = H // 2\n    W_out = W // 2\n    total_output_pixels = num_output_features * H_out * W_out\n    \n    b = pid // total_output_pixels\n    pid_in_batch = pid % total_output_pixels\n    k = pid_in_batch // (H_out * W_out)\n    pid_in_channel = pid_in_batch % (H_out * W_out)\n    i = pid_in_channel // W_out\n    j = pid_in_channel % W_out\n\n    bias = tl.load(bias_ptr + k)\n    h0 = 2 * i\n    h1 = 2 * i + 1\n    w0 = 2 * j\n    w1 = 2 * j + 1\n\n    acc = 0.0\n    for c_start in range(0, num_input_features, BLOCK_SIZE_C):\n        c_offsets = c_start + tl.arange(0, BLOCK_SIZE_C)\n        mask = c_offsets < num_input_features\n        \n        w = tl.load(weight_ptr + k * num_input_features + c_offsets, mask=mask, other=0.0)\n        base_ptr = x_ptr + b * stride_xb + c_offsets * stride_xc\n        \n        ptr00 = base_ptr + h0 * stride_xh + w0 * stride_xw\n        v00 = tl.load(ptr00, mask=mask, other=0.0)\n        v00 = tl.maximum(v00, 0.0)\n        \n        ptr01 = base_ptr + h0 * stride_xh + w1 * stride_xw\n        v01 = tl.load(ptr01, mask=mask, other=0.0)\n        v01 = tl.maximum(v01, 0.0)\n        \n        ptr10 = base_ptr + h1 * stride_xh + w0 * stride_xw\n        v10 = tl.load(ptr10, mask=mask, other=0.0)\n        v10 = tl.maximum(v10, 0.0)\n        \n        ptr11 = base_ptr + h1 * stride_xh + w1 * stride_xw\n        v11 = tl.load(ptr11, mask=mask, other=0.0)\n        v11 = tl.maximum(v11, 0.0)\n        \n        v_sum = v00 + v01 + v10 + v11\n        block_acc = tl.sum(w * v_sum, axis=0)\n        acc += block_acc\n\n    acc = acc / 4.0 + bias\n    output_index = b * stride_output_b + k * stride_output_k + i * stride_output_h + j * stride_output_w\n    tl.store(output_ptr + output_index, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n\n    def forward(self, x):\n        device = x.device\n        # Move BN parameters to input device\n        bn_weight = self.bn.weight.to(device)\n        bn_bias = self.bn.bias.to(device)\n        bn_mean = self.bn.running_mean.to(device)\n        bn_var = self.bn.running_var.to(device)\n        \n        bn_scale = bn_weight / torch.sqrt(bn_var + self.bn.eps)\n        folded_weight = self.conv.weight.to(device) * bn_scale[None, :, None, None]\n        folded_bias = bn_bias - bn_mean * bn_scale\n        \n        batch_size, C, H, W = x.shape\n        H_out = H // 2\n        W_out = W // 2\n        output = torch.empty(batch_size, folded_weight.shape[0], H_out, W_out, device=device, dtype=x.dtype)\n        total_output_elements = batch_size * folded_weight.shape[0] * H_out * W_out\n        grid = (total_output_elements,)\n        \n        _forward_kernel[grid](\n            x, output, \n            folded_weight.view(folded_weight.shape[0], folded_weight.shape[1]).contiguous(),\n            folded_bias.contiguous(),\n            C, H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_SIZE_C=32  # Increased block size for better utilization\n        )\n        return output\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    output_ptr,\n    weight_ptr,\n    bias_ptr,\n    num_input_features,\n    H, W,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_output_b, stride_output_k, stride_output_h, stride_output_w,\n    BLOCK_SIZE_C: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_output_features = bias_ptr.shape[0]\n    H_out = H // 2\n    W_out = W // 2\n    total_output_pixels = num_output_features * H_out * W_out\n    \n    b = pid // total_output_pixels\n    pid_in_batch = pid % total_output_pixels\n    k = pid_in_batch // (H_out * W_out)\n    pid_in_channel = pid_in_batch % (H_out * W_out)\n    i = pid_in_channel // W_out\n    j = pid_in_channel % W_out\n\n    bias = tl.load(bias_ptr + k)\n    h0 = 2 * i\n    h1 = 2 * i + 1\n    w0 = 2 * j\n    w1 = 2 * j + 1\n\n    acc = 0.0\n    for c_start in range(0, num_input_features, BLOCK_SIZE_C):\n        c_offsets = c_start + tl.arange(0, BLOCK_SIZE_C)\n        mask = c_offsets < num_input_features\n        \n        w = tl.load(weight_ptr + k * num_input_features + c_offsets, mask=mask, other=0.0)\n        base_ptr = x_ptr + b * stride_xb + c_offsets * stride_xc\n        \n        ptr00 = base_ptr + h0 * stride_xh + w0 * stride_xw\n        v00 = tl.load(ptr00, mask=mask, other=0.0)\n        v00 = tl.maximum(v00, 0.0)\n        \n        ptr01 = base_ptr + h0 * stride_xh + w1 * stride_xw\n        v01 = tl.load(ptr01, mask=mask, other=0.0)\n        v01 = tl.maximum(v01, 0.0)\n        \n        ptr10 = base_ptr + h1 * stride_xh + w0 * stride_xw\n        v10 = tl.load(ptr10, mask=mask, other=0.0)\n        v10 = tl.maximum(v10, 0.0)\n        \n        ptr11 = base_ptr + h1 * stride_xh + w1 * stride_xw\n        v11 = tl.load(ptr11, mask=mask, other=0.0)\n        v11 = tl.maximum(v11, 0.0)\n        \n        v_sum = v00 + v01 + v10 + v11\n        block_acc = tl.sum(w * v_sum, axis=0)\n        acc += block_acc\n\n    acc = acc / 4.0 + bias\n    output_index = b * stride_output_b + k * stride_output_k + i * stride_output_h + j * stride_output_w\n    tl.store(output_ptr + output_index, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n        self.bn_eps = self.bn.eps\n\n    def forward(self, x):\n        x = x.contiguous()\n        device = x.device\n        dtype = x.dtype\n        \n        # Ensure all tensors are on the correct device\n        bn_weight = self.bn.weight.to(device)\n        bn_bias = self.bn.bias.to(device)\n        bn_mean = self.bn.running_mean.to(device)\n        bn_var = self.bn.running_var.to(device)\n        conv_weight = self.conv.weight.to(device)\n        \n        # Compute folded parameters\n        bn_scale = bn_weight / torch.sqrt(bn_var + self.bn_eps)\n        folded_weight = conv_weight * bn_scale[None, :, None, None]\n        folded_bias = bn_bias - bn_mean * bn_scale\n        \n        batch_size, C, H, W = x.shape\n        H_out = H // 2\n        W_out = W // 2\n        output = torch.empty(batch_size, folded_weight.shape[0], H_out, W_out, device=device, dtype=dtype)\n        total_output_elements = batch_size * folded_weight.shape[0] * H_out * W_out\n        grid = (total_output_elements,)\n        \n        # Use larger block size for better memory efficiency\n        block_size_c = 32 if C >= 32 else 16\n        \n        _forward_kernel[grid](\n            x, output, \n            folded_weight.view(folded_weight.shape[0], folded_weight.shape[1]).contiguous(),\n            folded_bias.contiguous(),\n            C, H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_SIZE_C=block_size_c\n        )\n        return output\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 32, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 32, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    # 2D grid: pid0 = output pixel, pid1 = output channel block\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Calculate output pixel coordinates\n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    # Input window starting positions\n    h0 = 2 * i\n    w0 = 2 * j\n    \n    # Channel block indices\n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    # Initialize accumulator\n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    # Process input channels in blocks\n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        # Initialize average vector\n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        # Process 2x2 window\n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    # Build pointer and load data\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        # Compute average if valid pixels found\n        if count > 0:\n            avg = avg / count\n        \n        # Load weight block (shape: [BLOCK_SIZE_OC, BLOCK_SIZE_IC])\n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Matrix multiplication\n        partial = tl.sum(avg[None, :] * weight_block, axis=1)\n        accumulator += partial\n    \n    # Store results\n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        # BatchNorm parameters\n        self.bn = nn.BatchNorm2d(num_input_features)\n        \n        # Convolution weight (1x1 kernel)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            # Apply BatchNorm and ReLU first\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            # Calculate grid dimensions\n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 32)\n            )\n            \n            # Get strides for input tensor\n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            # Launch Triton kernel\n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=32,\n                BLOCK_SIZE_IC=32\n            )\n            return output\n        else:\n            # Training or CPU fallback\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    output_ptr,\n    weight_ptr,\n    bias_ptr,\n    num_input_features,\n    H, W,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_output_b, stride_output_k, stride_output_h, stride_output_w,\n    BLOCK_SIZE_C: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_output_features = bias_ptr.shape[0]\n    H_out = H // 2\n    W_out = W // 2\n    total_output_pixels = num_output_features * H_out * W_out\n    \n    b = pid // total_output_pixels\n    pid_in_batch = pid % total_output_pixels\n    k = pid_in_batch // (H_out * W_out)\n    pid_in_channel = pid_in_batch % (H_out * W_out)\n    i = pid_in_channel // W_out\n    j = pid_in_channel % W_out\n\n    bias = tl.load(bias_ptr + k)\n    h0 = 2 * i\n    h1 = 2 * i + 1\n    w0 = 2 * j\n    w1 = 2 * j + 1\n\n    acc = 0.0\n    for c_start in range(0, num_input_features, BLOCK_SIZE_C):\n        c_offsets = c_start + tl.arange(0, BLOCK_SIZE_C)\n        mask = c_offsets < num_input_features\n        \n        w = tl.load(weight_ptr + k * num_input_features + c_offsets, mask=mask, other=0.0)\n        base_ptr = x_ptr + b * stride_xb + c_offsets * stride_xc\n        \n        ptr00 = base_ptr + h0 * stride_xh + w0 * stride_xw\n        v00 = tl.load(ptr00, mask=mask, other=0.0)\n        v00 = tl.maximum(v00, 0.0)\n        \n        ptr01 = base_ptr + h0 * stride_xh + w1 * stride_xw\n        v01 = tl.load(ptr01, mask=mask, other=0.0)\n        v01 = tl.maximum(v01, 0.0)\n        \n        ptr10 = base_ptr + h1 * stride_xh + w0 * stride_xw\n        v10 = tl.load(ptr10, mask=mask, other=0.0)\n        v10 = tl.maximum(v10, 0.0)\n        \n        ptr11 = base_ptr + h1 * stride_xh + w1 * stride_xw\n        v11 = tl.load(ptr11, mask=mask, other=0.0)\n        v11 = tl.maximum(v11, 0.0)\n        \n        v_sum = v00 + v01 + v10 + v11\n        block_acc = tl.sum(w * v_sum, axis=0)\n        acc += block_acc\n\n    acc = acc / 4.0 + bias\n    output_index = b * stride_output_b + k * stride_output_k + i * stride_output_h + j * stride_output_w\n    tl.store(output_ptr + output_index, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n        self.bn_eps = self.bn.eps\n\n    def forward(self, x):\n        x = x.contiguous()\n        device = x.device\n        dtype = x.dtype\n        \n        # Ensure all tensors are on the correct device\n        bn_weight = self.bn.weight.to(device)\n        bn_bias = self.bn.bias.to(device)\n        bn_mean = self.bn.running_mean.to(device)\n        bn_var = self.bn.running_var.to(device)\n        conv_weight = self.conv.weight.to(device)\n        \n        # Compute folded parameters\n        bn_scale = bn_weight / torch.sqrt(bn_var + self.bn_eps)\n        folded_weight = conv_weight * bn_scale[None, :, None, None]\n        folded_bias = bn_bias - bn_mean * bn_scale\n        \n        batch_size, C, H, W = x.shape\n        H_out = H // 2\n        W_out = W // 2\n        output = torch.empty(batch_size, folded_weight.shape[0], H_out, W_out, device=device, dtype=dtype)\n        total_output_elements = batch_size * folded_weight.shape[0] * H_out * W_out\n        grid = (total_output_elements,)\n        \n        # Use larger block size for better memory efficiency\n        block_size_c = 32 if C >= 32 else 16\n        \n        _forward_kernel[grid](\n            x, output, \n            folded_weight.view(folded_weight.shape[0], folded_weight.shape[1]).contiguous(),\n            folded_bias.contiguous(),\n            C, H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_SIZE_C=block_size_c\n        )\n        return output\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 256, 'BLOCK_SIZE_IC': 64}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    # 2D grid: pid0 = output pixel, pid1 = output channel block\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Calculate output pixel coordinates\n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    # Input window starting positions\n    h0 = 2 * i\n    w0 = 2 * j\n    \n    # Channel block indices\n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    # Initialize accumulator\n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    # Precompute input pointers for the 2x2 window\n    ptrs = tl.zeros((4,), dtype=tl.pointer_type)\n    masks = tl.zeros((4,), dtype=tl.int1)\n    count = 0\n    for di in range(2):\n        for dj in range(2):\n            h = h0 + di\n            w = w0 + dj\n            valid = (h < height) & (w < width)\n            ptrs = tl.where(tl.arange(0, 4) == count, \n                            input_ptr + batch_id * stride_b + h * stride_h + w * stride_w,\n                            ptrs)\n            masks = tl.where(tl.arange(0, 4) == count, valid, masks)\n            count += 1\n    \n    # Process input channels in blocks\n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        # Initialize average vector\n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        valid_count = 0\n        \n        # Load data from the 2x2 window\n        for k in range(4):\n            if tl.program_id(0) == 0 and tl.program_id(1) == 0 and ic_block_start == 0 and k == 0:\n                pass\n            if masks[k]:\n                ptr = ptrs[k] + ic_block_start * stride_c\n                data = tl.load(ptr + tl.arange(0, BLOCK_SIZE_IC), \n                              mask=ic_mask, other=0.0)\n                avg += data\n                valid_count += 1\n        \n        # Compute average if valid pixels found\n        if valid_count > 0:\n            avg = avg / valid_count\n        \n        # Load weight block using vectorized approach\n        weight_ptr_current = conv_weight_ptr + oc_block_start * num_input_features + ic_block_start\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Optimized matrix multiplication\n        partial = tl.sum(weight_block * avg, axis=1)\n        accumulator += partial\n    \n    # Store results\n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        # BatchNorm parameters\n        self.bn = nn.BatchNorm2d(num_input_features)\n        \n        # Convolution weight (1x1 kernel)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            # Apply BatchNorm and ReLU first\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            # Calculate grid dimensions\n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            # Get strides for input tensor\n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            # Launch Triton kernel\n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w\n            )\n            return output\n        else:\n            # Training or CPU fallback\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({\"BLOCK_SIZE\": 128}, num_warps=4),\n        triton.Config({\"BLOCK_SIZE\": 256}, num_warps=4),\n        triton.Config({\"BLOCK_SIZE\": 512}, num_warps=4),\n        triton.Config({\"BLOCK_SIZE\": 1024}, num_warps=4),\n    ],\n    key=[\"num_input_features\", \"num_output_features\", \"height\", \"width\"],\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    bn_mean_ptr,\n    bn_var_ptr,\n    conv_weight_ptr,\n    num_input_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    eps: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_batch = pid // (height * width // 4)\n    pid_spatial = pid % (height * width // 4)\n    pid_h = pid_spatial // (width // 2)\n    pid_w = pid_spatial % (width // 2)\n    \n    # Calculate input window\n    in_h_start = pid_h * 2\n    in_w_start = pid_w * 2\n    \n    # Precompute BN parameters\n    scale = tl.load(bn_weight_ptr) / tl.sqrt(tl.load(bn_var_ptr) + eps)\n    shift = tl.load(bn_bias_ptr) - tl.load(bn_mean_ptr) * scale\n    \n    # Load input window (2x2)\n    input_ptrs = [\n        input_ptr + pid_batch * stride_b + \n        in_h_start * stride_h + \n        in_w_start * stride_w,\n        input_ptr + pid_batch * stride_b + \n        in_h_start * stride_h + \n        (in_w_start + 1) * stride_w,\n        input_ptr + pid_batch * stride_b + \n        (in_h_start + 1) * stride_h + \n        in_w_start * stride_w,\n        input_ptr + pid_batch * stride_b + \n        (in_h_start + 1) * stride_h + \n        (in_w_start + 1) * stride_w,\n    ]\n    \n    # Process each pixel in window\n    output_val = 0.0\n    for i in range(4):\n        pixel_val = tl.load(input_ptrs[i])\n        # Apply BN\n        norm_val = pixel_val * scale + shift\n        # Apply ReLU\n        activated = tl.maximum(norm_val, 0.0)\n        # Accumulate\n        output_val += activated\n    \n    # Average pooling\n    output_val *= 0.25\n    tl.store(output_ptr + pid, output_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n        self.eps = self.bn.eps\n        \n    def forward(self, x):\n        # Precompute BN parameters for inference\n        with torch.no_grad():\n            bn_scale = self.bn.weight / torch.sqrt(self.bn.running_var + self.bn.eps)\n            bn_bias = self.bn.bias - self.bn.running_mean * bn_scale\n        \n        # Reshape and process with Triton kernel\n        batch_size, _, height, width = x.shape\n        output = torch.empty(batch_size, num_output_features, height//2, width//2, \n                             device=x.device, dtype=x.dtype)\n        \n        # Launch kernel\n        grid = (batch_size * (height//2) * (width//2),)\n        transition_kernel[grid](\n            x, output,\n            bn_scale, bn_bias, \n            self.bn.running_mean, self.bn.running_var,\n            self.conv.weight,\n            num_input_features, height, width,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.eps,\n            BLOCK_SIZE=256\n        )\n        return output\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    output_ptr,\n    weight_ptr,\n    bias_ptr,\n    num_input_features,\n    H, W,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_output_b, stride_output_k, stride_output_h, stride_output_w,\n    BLOCK_SIZE_C: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_output_features = bias_ptr.shape[0]\n    H_out = H // 2\n    W_out = W // 2\n    total_output_pixels = num_output_features * H_out * W_out\n    \n    b = pid // total_output_pixels\n    pid_in_batch = pid % total_output_pixels\n    k = pid_in_batch // (H_out * W_out)\n    pid_in_channel = pid_in_batch % (H_out * W_out)\n    i = pid_in_channel // W_out\n    j = pid_in_channel % W_out\n\n    bias = tl.load(bias_ptr + k)\n    h0 = 2 * i\n    h1 = 2 * i + 1\n    w0 = 2 * j\n    w1 = 2 * j + 1\n\n    acc = 0.0\n    for c_start in range(0, num_input_features, BLOCK_SIZE_C):\n        c_offsets = c_start + tl.arange(0, BLOCK_SIZE_C)\n        mask = c_offsets < num_input_features\n        \n        w = tl.load(weight_ptr + k * num_input_features + c_offsets, mask=mask, other=0.0)\n        base_ptr = x_ptr + b * stride_xb + c_offsets * stride_xc\n        \n        ptr00 = base_ptr + h0 * stride_xh + w0 * stride_xw\n        v00 = tl.load(ptr00, mask=mask, other=0.0)\n        v00 = tl.maximum(v00, 0.0)\n        \n        ptr01 = base_ptr + h0 * stride_xh + w1 * stride_xw\n        v01 = tl.load(ptr01, mask=mask, other=0.0)\n        v01 = tl.maximum(v01, 0.0)\n        \n        ptr10 = base_ptr + h1 * stride_xh + w0 * stride_xw\n        v10 = tl.load(ptr10, mask=mask, other=0.0)\n        v10 = tl.maximum(v10, 0.0)\n        \n        ptr11 = base_ptr + h1 * stride_xh + w1 * stride_xw\n        v11 = tl.load(ptr11, mask=mask, other=0.0)\n        v11 = tl.maximum(v11, 0.0)\n        \n        v_sum = v00 + v01 + v10 + v11\n        block_acc = tl.sum(w * v_sum, axis=0)\n        acc += block_acc\n\n    acc = acc / 4.0 + bias\n    output_index = b * stride_output_b + k * stride_output_k + i * stride_output_h + j * stride_output_w\n    tl.store(output_ptr + output_index, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n\n    def forward(self, x):\n        device = x.device\n        # Move BN parameters to input device\n        bn_weight = self.bn.weight.to(device)\n        bn_bias = self.bn.bias.to(device)\n        bn_mean = self.bn.running_mean.to(device)\n        bn_var = self.bn.running_var.to(device)\n        \n        bn_scale = bn_weight / torch.sqrt(bn_var + self.bn.eps)\n        folded_weight = self.conv.weight.to(device) * bn_scale[None, :, None, None]\n        folded_bias = bn_bias - bn_mean * bn_scale\n        \n        batch_size, C, H, W = x.shape\n        H_out = H // 2\n        W_out = W // 2\n        output = torch.empty(batch_size, folded_weight.shape[0], H_out, W_out, device=device, dtype=x.dtype)\n        total_output_elements = batch_size * folded_weight.shape[0] * H_out * W_out\n        grid = (total_output_elements,)\n        \n        _forward_kernel[grid](\n            x, output, \n            folded_weight.view(folded_weight.shape[0], folded_weight.shape[1]).contiguous(),\n            folded_bias.contiguous(),\n            C, H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_SIZE_C=32  # Increased block size for better utilization\n        )\n        return output\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    h0 = 2 * i\n    w0 = 2 * j\n    \n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        if count > 0:\n            avg = avg / count\n        \n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Use FP16 for tensor core acceleration with FP32 accumulation\n        weight_block_f16 = weight_block.to(tl.float16)\n        avg_f16 = avg.to(tl.float16)\n        partial = tl.dot(weight_block_f16, avg_f16, out_dtype=tl.float32)\n        accumulator += partial\n    \n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=64,\n                BLOCK_SIZE_IC=64\n            )\n            return output\n        else:\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that uses Triton for a transition block that does:\n  1. BatchNorm and ReLU\n  2. 1x1 convolution\n  3. Average pooling (by 2x2)\n\nThe current Triton kernel does:\n  - For each output pixel (after pooling) and each block of output channels:\n      * Compute the average over the 2x2 window in the input (after BN and ReLU) for a block of input channels.\n      * Then multiply by the weight matrix (for the 1x1 convolution) for a block of output channels and accumulate.\n\nThe current implementation uses:\n  - A 2D grid: (batch * (H/2) * (W/2), cdiv(num_output_features, BLOCK_SIZE_OC))\n  - For each block of input channels (BLOCK_SIZE_IC), it loads the 2x2 window and computes the average.\n  - Then it loads a block of weights (BLOCK_SIZE_OC x BLOCK_SIZE_IC) and does a matrix multiplication (using tl.dot) by converting to FP16 for tensor cores.\n\nHowever, the performance is currently worse than the reference (speed_up=0.595). We need to improve it.\n\nObservations and potential issues:\n1. The current kernel does the BN and ReLU in the Triton kernel? Actually, no: in the model's forward, we do:\n        x = self.bn(x)\n        x = F.relu(x)\n   and then pass `x` to the Triton kernel. So the Triton kernel is only doing the 1x1 conv and average pooling.\n\n2. The reference (PyTorch) does:\n        x = self.bn(x)\n        x = F.relu(x)\n        weight_4d = self.conv_weight.view(self.num_output_features, self.num_input_features, 1, 1)\n        x = F.conv2d(x, weight_4d, bias=None)\n        return F.avg_pool2d(x, kernel_size=2, stride=2)\n\n3. The Triton kernel is combining the 1x1 conv and average pooling. It does:\n   - For each output pixel (i, j) (which is the average of a 2x2 block in the input) and for each output channel block:\n        accumulator = 0\n        for each input channel block:\n            avg = average of the 2x2 block in the input for the current input channel block\n            partial = dot(weight_block, avg)   # weight_block: [BLOCK_SIZE_OC, BLOCK_SIZE_IC], avg: [BLOCK_SIZE_IC]\n            accumulator += partial\n\n4. The current kernel uses tensor cores by converting the weight and average to FP16. However, note that the input `x` is after BN and ReLU, so it is in FP32. The conversion to FP16 is done on the fly.\n\n5. The problem: the current kernel is slower than the reference. We need to optimize.\n\nPotential optimizations:\na) The current kernel is memory bound. We are loading the same input data multiple times (for each output channel block). We might want to change the order of loops: do output channels in the inner loop? But note: we are tiling the output channels.\n\nb) We are not using shared memory to buffer the input data. The same 2x2 block of input is used for all output channels. We could load the 2x2 block for a block of input channels and then reuse it for multiple output channel blocks? However, the current tiling is over input channels and output channels. The grid is over output pixels and output channel blocks.\n\nc) The current tiling in input channels (BLOCK_SIZE_IC) might be too small. We could increase it to reduce the outer loop.\n\nd) The tensor core operation (tl.dot) is for a vector-matrix multiplication? Actually, it's a matrix-vector multiplication: weight_block (BLOCK_SIZE_OC x BLOCK_SIZE_IC) times avg (BLOCK_SIZE_IC) -> vector of length BLOCK_SIZE_OC. This is a matrix-vector product, which is not the best use of tensor cores (which are optimized for matrix-matrix). We might consider batching multiple output pixels together to form a matrix.\n\ne) Alternatively, we could restructure the kernel to compute multiple output pixels per thread block? Currently, each thread block handles one output pixel and one block of output channels. We could handle a block of output pixels (e.g., a small tile in the output space) to increase data reuse.\n\nGiven the complexity and the fact that we are constrained to not change the grid or the signature, we must work within the current structure.\n\nHowever, note that the current kernel uses:\n    partial = tl.dot(weight_block_f16, avg_f16, out_dtype=tl.float32)\n\nThis is a matrix-vector multiplication. The tensor cores on H100 are optimized for larger matrices. The matrix here is of size (BLOCK_SIZE_OC, BLOCK_SIZE_IC). The current autotune config uses BLOCK_SIZE_OC and BLOCK_SIZE_IC of 64 or 128. A matrix of 128x128 is a good candidate for tensor cores. But note: we are doing a matrix-vector, not matrix-matrix.\n\nActually, the `tl.dot` in Triton can do matrix-vector, but it might not be as efficient as a full matrix-matrix. We are only getting one vector of output per call.\n\nAlternative approach: instead of having the inner loop over input channels and doing a dot product per block, we could accumulate in shared memory and then do a larger matrix multiplication? But that would require restructuring.\n\nAnother idea: we note that the same weight block is used for all output pixels. We are loading the weight block for every output pixel and input channel block. That is a lot of weight loads. We could change the kernel to process multiple output pixels per thread block and reuse the weight block.\n\nBut we are constrained by the grid: the grid is fixed to (batch * (H/2) * (W/2), ...). We cannot change that.\n\nGiven the constraints, let's try to optimize the current code:\n\n1. Precomputation of pointers for the 2x2 window to reduce address calculation overhead.\n\n2. Use of vectorized loads/stores? We are already using tl.load with a mask.\n\n3. Instead of converting the weight and avg to fp16 on the fly, we might try to keep the computation in fp32? But then we don't use tensor cores. However, the matrix-vector product might be memory bound anyway.\n\n4. Alternatively, we can try to increase the block sizes to improve the arithmetic intensity.\n\n5. We note that the current kernel does:\n        avg = tl.zeros(...)\n        for di, dj in 2x2:\n            if valid, then load and add\n        if count>0: avg /= count\n\n   This is efficient.\n\n6. The main issue is the weight load: we are loading a block of weights of size (BLOCK_SIZE_OC, BLOCK_SIZE_IC) for every input channel block and every output pixel. The total number of output pixels is batch * (H/2) * (W/2). The total weight size is (num_output_features, num_input_features). The total number of weight loads is (num_input_features / BLOCK_SIZE_IC) * (batch * (H/2) * (W/2)) * (num_output_features / BLOCK_SIZE_OC). This is a lot and likely the bottleneck.\n\nWe need to reduce the weight loads. How about caching the weights in shared memory? But note: the weight block is different for every output channel block. And the same weight block is used for all output pixels. We could load the entire weight matrix into shared memory? That might not fit.\n\nAlternatively, we could change the kernel to process multiple output pixels per thread block? But the current grid is set by the model.\n\nGiven the constraints, we cannot change the grid. So we must find another way.\n\nIdea: restructure the kernel to have the output channel block as the outer loop? But the grid is fixed: the first dimension is the output pixel, the second is the output channel block.\n\nAlternatively, we might consider a different tiling: instead of having the output channel block in the grid, we could have the input channel block in the grid? But that would require a reduction across input channel blocks, which would require atomic operations? We don't want that.\n\nAnother idea: use the tensor cores more efficiently by batching multiple output pixels together? We could have each thread block process a block of output pixels (say, 4x4) and a block of output channels. Then the dot product becomes a matrix-matrix: weight_block (BLOCK_SIZE_OC, BLOCK_SIZE_IC) * input_block (BLOCK_SIZE_IC, 16) -> (BLOCK_SIZE_OC, 16). This would be a good use of tensor cores.\n\nBut that would require changing the grid and the kernel structure. And we are not allowed to change the grid.\n\nTherefore, we must work within the current grid.\n\nGiven the above, let's try to optimize the memory access patterns:\n\n1. We note that the weight is stored in row-major: (num_output_features, num_input_features). We are loading a block of it by:\n        weight_ptr_current = conv_weight_ptr + oc_block_start * num_input_features + ic_block_start\n        weight_block = tl.load( ... )\n\n   The load is done with:\n        weight_ptr_current + \n        tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n        tl.arange(0, BLOCK_SIZE_IC)[None, :]\n\n   This is a 2D block load. We are loading contiguous in the input channel dimension? Actually, the inner dimension is input channels. So the load for a fixed row (output channel) is contiguous. This is good.\n\n2. The input data for the 2x2 window: we are loading a contiguous block of input channels for each pixel. That is also good.\n\n3. The main issue might be the amount of data movement. We might try to increase the block sizes to improve the ratio of compute to memory.\n\nBut note: the autotuner already tries different block sizes.\n\n4. Another idea: we are doing the conversion to FP16 for the dot product. We might try without it? Because the conversion might add overhead and the tensor cores might not be efficient for small matrix-vector.\n\nWe might try to use FP32 and see if it is faster? But we are on H100, which has fast tensor cores.\n\nAlternatively, we can try to use a larger block size for the tensor core operation? But the block size is already 64 or 128.\n\nLet's look at the current autotune configs: they are for 64 and 128 in both dimensions.\n\nWe might add a config with 256 for the output channels? But note the number of warps is fixed at 4 or 8. A block size of 256 in output channels would require more warps.\n\nBut we are constrained by the grid: the second grid dimension is the number of output channel blocks. We cannot change the grid to have more dimensions.\n\nGiven the complexity, and the fact that the current kernel is slower than the reference, we might try to remove the tensor core usage and do the accumulation in FP32 without conversion. Why?\n  - The matrix-vector product with small matrices might not benefit from tensor cores.\n  - The overhead of converting to FP16 and back might be too high for the small sizes.\n\nLet's try to replace the dot product with a manual loop and accumulate in FP32.\n\nWe change:\n        # Instead of:\n        #   weight_block_f16 = weight_block.to(tl.float16)\n        #   avg_f16 = avg.to(tl.float16)\n        #   partial = tl.dot(weight_block_f16, avg_f16, out_dtype=tl.float32)\n        # Do:\n        partial = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n        for idx in range(BLOCK_SIZE_IC):\n            # We need to check the mask for the input channel?\n            w = weight_block[:, idx]   # vector of length BLOCK_SIZE_OC\n            a = avg[idx]                # scalar\n            partial += w * a\n\nBut note: this loop is over BLOCK_SIZE_IC, which can be 128, and we are doing a vector multiply and add. This might be slow.\n\nAlternatively, we can use `tl.sum(weight_block * avg[None,:], axis=1)`.\n\nLet's try that. We replace the dot product with:\n        partial = tl.sum(weight_block * avg[None, :], axis=1)\n\nBut note: this might not use tensor cores, but it might be more efficient for small sizes? We can try.\n\nWe'll remove the FP16 conversion and do the accumulation in FP32.\n\nSo the plan for the next version:\n  - Remove the FP16 conversion and the dot product.\n  - Replace with: partial = tl.sum(weight_block * avg[None, :], axis=1)\n\nWe hope that this reduces overhead and might be faster.\n\nWe also note that the autotuner might pick a different block size now.\n\nLet's change the kernel accordingly.\n\nWe'll change the following lines in the kernel:\n\n        # Remove:\n        #   weight_block_f16 = weight_block.to(tl.float16)\n        #   avg_f16 = avg.to(tl.float16)\n        #   partial = tl.dot(weight_block_f16, avg_f16, out_dtype=tl.float32)\n        # Replace with:\n        partial = tl.sum(weight_block * avg[None, :], axis=1)\n\nBut note: we must be cautious about the masks? The weight_block and avg are masked, but the multiplication and sum should be safe because the masked-out elements are zero.\n\nWe also note that the weight_block is of shape (BLOCK_SIZE_OC, BLOCK_SIZE_IC) and avg is of shape (BLOCK_SIZE_IC,). We broadcast avg to (1, BLOCK_SIZE_IC) and then multiply. The result is (BLOCK_SIZE_OC, BLOCK_SIZE_IC). Then we sum along axis=1 to get (BLOCK_SIZE_OC,).\n\nThis is mathematically equivalent to the dot product.\n\nWe hope that this might be faster because it avoids the conversion and because the tensor cores were not being used efficiently for matrix-vector.\n\nLet's make this change and see if it improves.\n\nWe are only changing a few lines. We leave the rest of the kernel unchanged.\n\nWe must also update the autotune configs? We are not changing the block sizes. We'll leave them as they are.\n\nWe'll output the entire kernel and the ModelNew class as required.\n\nNote: We must not change the grid or the signature.\n\nWe'll write the new code accordingly.\n\nImportant: The current program uses the tensor core dot product. We are replacing that with a sum of element-wise multiplication.\n\nLet's write the code accordingly.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_OC': 64, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_OC': 128, 'BLOCK_SIZE_IC': 128}, num_warps=8),\n    ],\n    key=['num_input_features', 'num_output_features', 'height', 'width']\n)\n@triton.jit\ndef transition_kernel(\n    input_ptr,\n    output_ptr,\n    conv_weight_ptr,\n    batch_size,\n    num_input_features,\n    num_output_features,\n    height,\n    width,\n    stride_b,\n    stride_c,\n    stride_h,\n    stride_w,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    num_output_pixels = (height // 2) * (width // 2)\n    pixel_id = pid0 % num_output_pixels\n    batch_id = pid0 // num_output_pixels\n    i = pixel_id // (width // 2)\n    j = pixel_id % (width // 2)\n    \n    h0 = 2 * i\n    w0 = 2 * j\n    \n    oc_block_start = pid1 * BLOCK_SIZE_OC\n    oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n    oc_mask = oc_offsets < num_output_features\n    \n    accumulator = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    \n    for ic_block_start in range(0, num_input_features, BLOCK_SIZE_IC):\n        ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < num_input_features\n        \n        avg = tl.zeros((BLOCK_SIZE_IC,), dtype=tl.float32)\n        count = 0\n        \n        for di in range(2):\n            for dj in range(2):\n                h = h0 + di\n                w = w0 + dj\n                if h < height and w < width:\n                    count += 1\n                    input_ptr_current = (\n                        input_ptr + \n                        batch_id * stride_b + \n                        h * stride_h + \n                        w * stride_w + \n                        ic_block_start * stride_c\n                    )\n                    data = tl.load(\n                        input_ptr_current + tl.arange(0, BLOCK_SIZE_IC),\n                        mask=ic_mask,\n                        other=0.0\n                    )\n                    avg += data\n        \n        if count > 0:\n            avg = avg / count\n        \n        weight_ptr_current = (\n            conv_weight_ptr + \n            oc_block_start * num_input_features + \n            ic_block_start\n        )\n        weight_block = tl.load(\n            weight_ptr_current + \n            tl.arange(0, BLOCK_SIZE_OC)[:, None] * num_input_features + \n            tl.arange(0, BLOCK_SIZE_IC)[None, :],\n            mask=oc_mask[:, None] & ic_mask[None, :],\n            other=0.0\n        )\n        \n        # Replace tensor core dot with element-wise multiplication and sum\n        partial = tl.sum(weight_block * avg[None, :], axis=1)\n        accumulator += partial\n    \n    output_ptr_current = (\n        output_ptr + \n        batch_id * num_output_features * (height//2) * (width//2) + \n        i * (width//2) * num_output_features + \n        j * num_output_features + \n        oc_block_start\n    )\n    tl.store(\n        output_ptr_current + tl.arange(0, BLOCK_SIZE_OC),\n        accumulator,\n        mask=oc_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n        \n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv_weight = nn.Parameter(\n            torch.empty(num_output_features, num_input_features)\n        )\n        nn.init.kaiming_uniform_(self.conv_weight, a=math.sqrt(5))\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            x = self.bn(x)\n            x = F.relu(x)\n            \n            batch_size, _, height, width = x.shape\n            output = torch.empty(\n                (batch_size, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            \n            grid = (\n                batch_size * (height//2) * (width//2),\n                triton.cdiv(self.num_output_features, 64)\n            )\n            \n            stride_b = x.stride(0)\n            stride_c = x.stride(1)\n            stride_h = x.stride(2)\n            stride_w = x.stride(3)\n            \n            transition_kernel[grid](\n                x,\n                output,\n                self.conv_weight,\n                batch_size,\n                self.num_input_features,\n                self.num_output_features,\n                height,\n                width,\n                stride_b,\n                stride_c,\n                stride_h,\n                stride_w,\n                BLOCK_SIZE_OC=64,\n                BLOCK_SIZE_IC=64\n            )\n            return output\n        else:\n            x = self.bn(x)\n            x = F.relu(x)\n            weight_4d = self.conv_weight.view(\n                self.num_output_features, self.num_input_features, 1, 1\n            )\n            x = F.conv2d(x, weight_4d, bias=None)\n            return F.avg_pool2d(x, kernel_size=2, stride=2)\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}