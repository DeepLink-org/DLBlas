{"id": "a30bb39b-099f-407a-ba5c-1deac7655588", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_IC': 32, 'BLOCK_SIZE_OC': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_IC': 64, 'BLOCK_SIZE_OC': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_IC': 128, 'BLOCK_SIZE_OC': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_IC': 32, 'BLOCK_SIZE_OC': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_IC': 64, 'BLOCK_SIZE_OC': 256}, num_warps=8),\n    ],\n    key=['in_channels', 'out_channels', 'height', 'width']\n)\n@triton.jit\ndef fused_conv_pool_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    batch, in_channels, height, width, out_channels,\n    stride_b, stride_c, stride_h, stride_w,\n    out_stride_b, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_SIZE_IC: tl.constexpr, BLOCK_SIZE_OC: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_output_pixels = (height // 2) * (width // 2)\n    batch_id = pid // num_output_pixels\n    pixel_id = pid % num_output_pixels\n    \n    h_out = pixel_id // (width // 2)\n    w_out = pixel_id % (width // 2)\n    h_in = h_out * 2\n    w_in = w_out * 2\n\n    output_offset = batch_id * out_stride_b + h_out * out_stride_h + w_out * out_stride_w\n    acc = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n    count = 0.0\n\n    for dh in range(2):\n        for dw in range(2):\n            h = h_in + dh\n            w = w_in + dw\n            if h < height and w < width:\n                count += 1.0\n                for ic_block in range(0, in_channels, BLOCK_SIZE_IC):\n                    ic_offsets = ic_block + tl.arange(0, BLOCK_SIZE_IC)\n                    ic_mask = ic_offsets < in_channels\n                    \n                    input_offset = batch_id * stride_b + h * stride_h + w * stride_w\n                    input_val = tl.load(\n                        input_ptr + input_offset + ic_offsets * stride_c,\n                        mask=ic_mask\n                    )\n                    \n                    for oc_block in range(0, out_channels, BLOCK_SIZE_OC):\n                        oc_offsets = oc_block + tl.arange(0, BLOCK_SIZE_OC)\n                        oc_mask = oc_offsets < out_channels\n                        \n                        weight_offset = oc_offsets[:, None] * in_channels + ic_offsets[None, :]\n                        weight_val = tl.load(\n                            weight_ptr + weight_offset,\n                            mask=oc_mask[:, None] & ic_mask[None, :]\n                        )\n                        \n                        partial = tl.sum(weight_val * input_val[None, :], axis=1)\n                        acc = tl.where(oc_mask, acc + partial, acc)\n    \n    if count > 0:\n        acc /= count\n    \n    for oc_block in range(0, out_channels, BLOCK_SIZE_OC):\n        oc_offsets = oc_block + tl.arange(0, BLOCK_SIZE_OC)\n        oc_mask = oc_offsets < out_channels\n        tl.store(\n            output_ptr + output_offset + oc_offsets * out_stride_c,\n            acc,\n            mask=oc_mask\n        )\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_input_features: int, num_output_features: int):\n        super(ModelNew, self).__init__()\n        self.bn = nn.BatchNorm2d(num_input_features)\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n        self.num_input_features = num_input_features\n        self.num_output_features = num_output_features\n\n    def forward(self, x):\n        if x.is_cuda and not self.training:\n            x = self.bn(x)\n            x = self.relu(x)\n            x = x.contiguous()\n            batch, in_channels, height, width = x.shape\n            output = torch.empty(\n                (batch, self.num_output_features, height//2, width//2),\n                device=x.device, dtype=x.dtype\n            )\n            grid = (batch * (height//2) * (width//2),)\n            fused_conv_pool_kernel[grid](\n                x, self.conv.weight, output,\n                batch, in_channels, height, width, self.num_output_features,\n                x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n                output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n                BLOCK_SIZE_IC=32, BLOCK_SIZE_OC=128\n            )\n            return output\n        else:\n            return self.pool(self.conv(self.relu(self.bn(x))))\n\nbatch_size = 10\nnum_input_features = 32\nnum_output_features = 64\nheight, width = 224, 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, num_output_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "7f0bf327-3817-4e96-bed7-a892426e4483", "generation": 3, "timestamp": 1754589550.2098498, "iteration_found": 15, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.595, "runtime_ms": 0.506, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.301, "speed_up": 0.595, "custom_timing": 0.506}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 2}, "artifacts_json": null, "artifact_dir": null}