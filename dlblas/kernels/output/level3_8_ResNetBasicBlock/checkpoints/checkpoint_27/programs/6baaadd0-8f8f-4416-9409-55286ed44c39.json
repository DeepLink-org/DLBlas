{"id": "6baaadd0-8f8f-4416-9409-55286ed44c39", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass TritonConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.bias = None\n        nn.init.kaiming_uniform_(self.weight)\n\n    @triton.jit\n    def _conv2d_kernel(\n        x_ptr, w_ptr, y_ptr,\n        B, C_in, C_out, H, W, K, S, P,\n        stride_xb, stride_xc, stride_xh, stride_xw,\n        stride_woc, stride_wic, stride_wh, stride_ww,\n        stride_yb, stride_yc, stride_yh, stride_yw,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        # Precompute output dimensions\n        H_out = (H + 2*P - K) // S + 1\n        W_out = (W + 2*P - K) // S + 1\n        total_elements = B * C_out * H_out * W_out\n        \n        pid = tl.program_id(0)\n        num_pid = tl.num_programs(0)\n        start_idx = pid * BLOCK_SIZE\n        offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < total_elements\n        \n        for i in tl.arange(0, BLOCK_SIZE):\n            if mask[i]:\n                idx = offsets[i]\n                b = idx // (C_out * H_out * W_out)\n                rest = idx % (C_out * H_out * W_out)\n                c_out = rest // (H_out * W_out)\n                rest2 = rest % (H_out * W_out)\n                h_out = rest2 // W_out\n                w_out = rest2 % W_out\n                \n                acc = 0.0\n                for c_in in range(C_in):\n                    for kh in range(K):\n                        for kw in range(K):\n                            h_in = h_out * S - P + kh\n                            w_in = w_out * S - P + kw\n                            if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                                x_offset = b*stride_xb + c_in*stride_xc + h_in*stride_xh + w_in*stride_xw\n                                w_offset = c_out*stride_woc + c_in*stride_wic + kh*stride_wh + kw*stride_ww\n                                x_val = tl.load(x_ptr + x_offset)\n                                w_val = tl.load(w_ptr + w_offset)\n                                acc += x_val * w_val\n                \n                y_offset = b*stride_yb + c_out*stride_yc + h_out*stride_yh + w_out*stride_yw\n                tl.store(y_ptr + y_offset, acc)\n\n    def forward(self, x):\n        B, C_in, H, W = x.shape\n        H_out = (H + 2*self.padding - self.kernel_size) // self.stride + 1\n        W_out = (W + 2*self.padding - self.kernel_size) // self.stride + 1\n        y = torch.zeros(B, self.out_channels, H_out, W_out, device=x.device, dtype=x.dtype)\n        \n        total_elements = B * self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        self._conv2d_kernel[grid](\n            x, self.weight, y,\n            B, C_in, self.out_channels, H, W, self.kernel_size, self.stride, self.padding,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), self.weight.stride(3),\n            y.stride(0), y.stride(1), y.stride(2), y.stride(3),\n            BLOCK_SIZE=1024\n        )\n        \n        if self.bias is not None:\n            y += self.bias[None, :, None, None]\n        return y\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = TritonConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = TritonConv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            TritonConv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "313e0ed7-d8fc-4bd6-9bcf-ad1a5a120258", "generation": 3, "timestamp": 1754596791.1610239, "iteration_found": 27, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_8_ResNetBasicBlock", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpe53kdm24.py\", line 108, in forward\n    out = self.conv1(x)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpe53kdm24.py\", line 76, in forward\n    self._conv2d_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 20:4:\n    # Precompute output dimensions\n    H_out = (H + 2*P - K) // S + 1\n    W_out = (W + 2*P - K) // S + 1\n    total_elements = B * C_out * H_out * W_out\n\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    start_idx = pid * BLOCK_SIZE\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < total_elements\n\n    for i in tl.arange(0, BLOCK_SIZE):\n    ^\nRuntimeError('Only `range` and `static_range` iterators are currently supported')\n\n\nThe above exception was the direct cause of the following exception:\n\nRuntimeError: Only `range` and `static_range` iterators are currently supported\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 1.28, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_8_ResNetBasicBlock", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp6gadik0o.py\", line 102, in forward\n    out = self.conv1(x)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp6gadik0o.py\", line 70, in forward\n    self._conv2d_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 16:4:\n    stride_woc, stride_wic, stride_wh, stride_ww,\n    stride_yb, stride_yc, stride_yh, stride_yw,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    elements_per_program = B * C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1)\n    start_idx = pid * BLOCK_SIZE\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < elements_per_program\n\n    for i in tl.range(0, BLOCK_SIZE, mask=mask):\n    ^\nTypeError(\"range.__init__() got an unexpected keyword argument 'mask'\")\n\n\nThe above exception was the direct cause of the following exception:\n\nTypeError: range.__init__() got an unexpected keyword argument 'mask'\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 1.28, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level3_8_ResNetBasicBlock', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp6gadik0o.py\", line 102, in forward\\n    out = self.conv1(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp6gadik0o.py\", line 70, in forward\\n    self._conv2d_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 16:4:\\n    stride_woc, stride_wic, stride_wh, stride_ww,\\n    stride_yb, stride_yc, stride_yh, stride_yw,\\n    BLOCK_SIZE: tl.constexpr,\\n):\\n    pid = tl.program_id(0)\\n    num_pid = tl.num_programs(0)\\n    elements_per_program = B * C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1)\\n    start_idx = pid * BLOCK_SIZE\\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\\n    mask = offsets < elements_per_program\\n\\n    for i in tl.range(0, BLOCK_SIZE, mask=mask):\\n    ^\\nTypeError(\"range.__init__() got an unexpected keyword argument \\'mask\\'\")\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTypeError: range.__init__() got an unexpected keyword argument \\'mask\\'\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 1.28, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level3_8_ResNetBasicBlock', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'max_difference': ['3.534683', '4.035765', '3.738781', '3.744269', '3.689424'], 'avg_difference': ['0.176256', '0.176057', '0.176155', '0.176292', '0.176244'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 1.28, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.0160, runtime_ms: 82.0000, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.28, 'speed_up': 0.016, 'custom_timing': 82.0}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7490, runtime_ms: 1.7100, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.28, 'speed_up': 0.749, 'custom_timing': 1.71}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_bn_relu_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    stride, padding,\n    in_channels, out_channels,\n    H, W,\n    stride_xn, stride_xc, stride_xh, stride_xw,\n    stride_wn, stride_wc, stride_wh, stride_ww,\n    stride_on, stride_oc, stride_oh, stride_ow,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    num_operations = out_channels * H * W\n    operations_per_pid = (num_operations + num_pid - 1) // num_pid\n    \n    start = pid * operations_per_pid\n    end = tl.minimum(start + operations_per_pid, num_operations)\n    \n    BLOCK_CHANNELS = 32  # Vectorization factor for input channels\n    \n    for op_idx in range(start, end):\n        c = op_idx // (H * W)\n        hw = op_idx % (H * W)\n        h = hw // W\n        w = hw % W\n        \n        acc = 0.0\n        # Unroll kernel loops for 3x3 convolution\n        for kh in tl.static_range(0, 3):\n            for kw in tl.static_range(0, 3):\n                h_in = h * stride - padding + kh\n                w_in = w * stride - padding + kw\n                \n                if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                    # Process input channels in vectorized blocks\n                    for ic_block in range(0, in_channels, BLOCK_CHANNELS):\n                        ic_offsets = ic_block + tl.arange(0, BLOCK_CHANNELS)\n                        ic_mask = ic_offsets < in_channels\n                        \n                        # Vectorized load for input channels\n                        x_ptrs = x_ptr + ic_offsets * stride_xc + h_in * stride_xh + w_in * stride_xw\n                        x_vals = tl.load(x_ptrs, mask=ic_mask, other=0.0)\n                        \n                        # Vectorized load for weights\n                        w_ptrs = w_ptr + c * stride_wc + ic_offsets * stride_wn + kh * stride_wh + kw * stride_ww\n                        w_vals = tl.load(w_ptrs, mask=ic_mask, other=0.0)\n                        \n                        # Accumulate vector product\n                        acc += tl.sum(x_vals * w_vals)\n        \n        bias_val = tl.load(b_ptr + c)\n        acc += bias_val\n        acc = tl.maximum(acc, 0.0)\n        out_offset = c * stride_oc + h * stride_oh + w * stride_ow\n        tl.store(output_ptr + out_offset, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n        self.register_buffer('fused_weight', torch.empty_like(self.conv1.weight))\n        self.register_buffer('fused_bias', torch.empty(out_channels))\n\n    def fuse_conv_bn(self):\n        with torch.no_grad():\n            conv_weight = self.conv1.weight\n            bn_weight = self.bn1.weight\n            bn_bias = self.bn1.bias\n            bn_mean = self.bn1.running_mean\n            bn_var = self.bn1.running_var\n            bn_eps = self.bn1.eps\n            \n            scale_factor = bn_weight / torch.sqrt(bn_var + bn_eps)\n            self.fused_weight.copy_(conv_weight * scale_factor[:, None, None, None])\n            self.fused_bias.copy_(bn_bias - bn_mean * scale_factor)\n\n    def forward(self, x):\n        identity = x\n\n        if self.training:\n            out = self.conv1(x)\n            out = self.bn1(out)\n            out = self.relu(out)\n        else:\n            if self.fused_weight is None:\n                self.fuse_conv_bn()\n                \n            B, C, H, W = x.shape\n            output = torch.empty(B, self.conv1.out_channels, H // self.stride, W // self.stride, \n                                device=x.device, dtype=x.dtype)\n            \n            stride_x = x.stride()\n            stride_w = self.fused_weight.stride()\n            stride_o = output.stride()\n            \n            for b in range(B):\n                conv_bn_relu_kernel[(1024,)](x[b], self.fused_weight, self.fused_bias, output[b],\n                    self.stride, 1,\n                    self.conv1.in_channels, self.conv1.out_channels,\n                    output.size(2), output.size(3),\n                    stride_x[1], stride_x[2], stride_x[3],\n                    stride_w[1], stride_w[2], stride_w[3],\n                    stride_o[1], stride_o[2], stride_o[3],\n                    BLOCK_SIZE=128)\n            out = output\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7490), Performs well on runtime_ms (1.7100), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.28, 'speed_up': 0.749, 'custom_timing': 1.71})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef conv2d_kernel(\n    x_ptr, weight_ptr, output_ptr,\n    in_c, in_h, in_w, out_c, out_h, out_w,\n    k_h, k_w, stride_h, stride_w, pad_h, pad_w,\n    BLOCK_C: tl.constexpr\n):\n    pid = tl.program_id(0)\n    total_ops = out_h * out_w * tl.cdiv(out_c, BLOCK_C)\n    op_idx = pid % total_ops\n    pid_batch = pid // total_ops\n\n    # Decompose operation index\n    pid_spatial = op_idx // tl.cdiv(out_c, BLOCK_C)\n    pid_channel_block = op_idx % tl.cdiv(out_c, BLOCK_C)\n\n    # Get spatial indices\n    oh = pid_spatial // out_w\n    ow = pid_spatial % out_w\n\n    # Get channel block indices\n    c_start = pid_channel_block * BLOCK_C\n    c_end = tl.minimum(c_start + BLOCK_C, out_c)\n    channel_indices = c_start + tl.arange(0, BLOCK_C)\n\n    # Input window\n    ih_start = oh * stride_h - pad_h\n    iw_start = ow * stride_w - pad_w\n\n    # Accumulator\n    acc = tl.zeros((BLOCK_C,), dtype=tl.float32)\n\n    # Convolution computation\n    for kh in range(k_h):\n        for kw in range(k_w):\n            ih = ih_start + kh\n            iw = iw_start + kw\n            \n            if ih >= 0 and ih < in_h and iw >= 0 and iw < in_w:\n                # Load input block\n                x_offset = pid_batch * (in_c * in_h * in_w) + ih * in_w + iw\n                for ic in range(0, in_c):\n                    # Load input value\n                    x_val = tl.load(x_ptr + x_offset)\n                    \n                    # Load weights\n                    w_offset = (channel_indices * in_c * k_h * k_w + \n                                ic * k_h * k_w + \n                                kh * k_w + kw)\n                    w_val = tl.load(weight_ptr + w_offset, \n                                   mask=channel_indices < c_end, \n                                   other=0.0)\n                    \n                    # Accumulate\n                    acc += x_val * w_val\n                    \n                    # Move to next input channel\n                    x_offset += in_h * in_w\n\n    # Store result\n    out_offset = (pid_batch * out_c * out_h * out_w + \n                  channel_indices * out_h * out_w + \n                  oh * out_w + ow)\n    tl.store(output_ptr + out_offset, acc, mask=channel_indices < c_end)\n\nclass TritonConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        \n        self.weight = nn.Parameter(\n            torch.empty(out_channels, in_channels, kernel_size, kernel_size)\n        )\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        \n    def forward(self, x):\n        batch, in_c, in_h, in_w = x.shape\n        out_h = (in_h + 2*self.padding - self.kernel_size) // self.stride + 1\n        out_w = (in_w + 2*self.padding - self.kernel_size) // self.stride + 1\n        \n        output = torch.empty(\n            (batch, self.out_channels, out_h, out_w),\n            device=x.device, dtype=x.dtype\n        )\n        \n        total_blocks = batch * out_h * out_w * triton.cdiv(self.out_channels, 128)\n        grid = (total_blocks,)\n        conv2d_kernel[grid](\n            x, self.weight, output,\n            in_c, in_h, in_w, self.out_channels, out_h, out_w,\n            self.kernel_size, self.kernel_size,\n            self.stride, self.stride,\n            self.padding, self.padding,\n            BLOCK_C=128\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = TritonConv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = TritonConv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.downsample = None\n        if stride != 1 or in_channels != out_channels * self.expansion:\n            self.downsample = nn.Sequential(\n                TritonConv2d(in_channels, out_channels * self.expansion, 1, stride, 0, bias=False),\n                nn.BatchNorm2d(out_channels * self.expansion)\n            )\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.0160), Performs well on runtime_ms (82.0000), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 1.28, 'speed_up': 0.016, 'custom_timing': 82.0})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    n_elements = out_channels * height_out * width_out\n    elements_per_block = tl.cdiv(n_elements, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, n_elements)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        if b_ptr is not None:\n            bias = tl.load(b_ptr + c_out)\n            acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        H_out = H // self.stride\n        W_out = W // self.stride\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        n_elements = self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            downsample_kernel[grid](\n                x[b].contiguous(), \n                self.downsample_fused_weight.view(self.out_channels, -1).contiguous(),\n                self.downsample_fused_bias,\n                identity_down[b].contiguous(),\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level3_8_ResNetBasicBlock', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'max_difference': ['3.534683', '4.035765', '3.738781', '3.744269', '3.689424'], 'avg_difference': ['0.176256', '0.176057', '0.176155', '0.176292', '0.176244'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 1.28, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    elements_per_block = tl.cdiv(out_channels * height_out * width_out, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, out_channels * height_out * width_out)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        bias = tl.load(b_ptr + c_out)\n        acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        H_out = H // self.stride\n        W_out = W // self.stride\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        n_elements = B * self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            downsample_kernel[grid](\n                x[b], \n                self.downsample_fused_weight, \n                self.downsample_fused_bias,\n                identity_down[b],\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    elements_per_block = tl.cdiv(out_channels * height_out * width_out, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, out_channels * height_out * width_out)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        bias = tl.load(b_ptr + c_out)\n        acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        # Correct output size calculation\n        H_out = (H + 2*0 - 1) // self.stride + 1\n        W_out = (W + 2*0 - 1) // self.stride + 1\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        # Prepare contiguous tensors\n        weight_2d = self.downsample_fused_weight.view(self.out_channels, self.in_channels).contiguous()\n        bias_1d = self.downsample_fused_bias.contiguous()\n        \n        # Calculate grid per batch element\n        n_elements_batch = self.out_channels * H_out * W_out\n        grid_batch = lambda meta: (triton.cdiv(n_elements_batch, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            # Ensure contiguous input\n            x_b = x[b].contiguous()\n            downsample_kernel[grid_batch](\n                x_b, \n                weight_2d, \n                bias_1d,\n                identity_down[b],\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef conv2d_kernel(\n    x_ptr, weight_ptr, output_ptr,\n    in_c, in_h, in_w, out_c, out_h, out_w,\n    k_h, k_w, stride_h, stride_w, pad_h, pad_w,\n    BLOCK_C: tl.constexpr\n):\n    pid = tl.program_id(0)\n    total_ops = out_h * out_w * tl.cdiv(out_c, BLOCK_C)\n    op_idx = pid % total_ops\n    pid_batch = pid // total_ops\n\n    # Decompose operation index\n    pid_spatial = op_idx // tl.cdiv(out_c, BLOCK_C)\n    pid_channel_block = op_idx % tl.cdiv(out_c, BLOCK_C)\n\n    # Get spatial indices\n    oh = pid_spatial // out_w\n    ow = pid_spatial % out_w\n\n    # Get channel block indices\n    c_start = pid_channel_block * BLOCK_C\n    c_end = tl.minimum(c_start + BLOCK_C, out_c)\n    channel_indices = c_start + tl.arange(0, BLOCK_C)\n\n    # Input window\n    ih_start = oh * stride_h - pad_h\n    iw_start = ow * stride_w - pad_w\n\n    # Accumulator\n    acc = tl.zeros((BLOCK_C,), dtype=tl.float32)\n\n    # Convolution computation\n    for kh in range(k_h):\n        for kw in range(k_w):\n            ih = ih_start + kh\n            iw = iw_start + kw\n            \n            if ih >= 0 and ih < in_h and iw >= 0 and iw < in_w:\n                # Load input block\n                x_offset = pid_batch * (in_c * in_h * in_w) + ih * in_w + iw\n                for ic in range(0, in_c):\n                    # Load input value\n                    x_val = tl.load(x_ptr + x_offset)\n                    \n                    # Load weights\n                    w_offset = (channel_indices * in_c * k_h * k_w + \n                                ic * k_h * k_w + \n                                kh * k_w + kw)\n                    w_val = tl.load(weight_ptr + w_offset, \n                                   mask=channel_indices < c_end, \n                                   other=0.0)\n                    \n                    # Accumulate\n                    acc += x_val * w_val\n                    \n                    # Move to next input channel\n                    x_offset += in_h * in_w\n\n    # Store result\n    out_offset = (pid_batch * out_c * out_h * out_w + \n                  channel_indices * out_h * out_w + \n                  oh * out_w + ow)\n    tl.store(output_ptr + out_offset, acc, mask=channel_indices < c_end)\n\nclass TritonConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        \n        self.weight = nn.Parameter(\n            torch.empty(out_channels, in_channels, kernel_size, kernel_size)\n        )\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        \n    def forward(self, x):\n        batch, in_c, in_h, in_w = x.shape\n        out_h = (in_h + 2*self.padding - self.kernel_size) // self.stride + 1\n        out_w = (in_w + 2*self.padding - self.kernel_size) // self.stride + 1\n        \n        output = torch.empty(\n            (batch, self.out_channels, out_h, out_w),\n            device=x.device, dtype=x.dtype\n        )\n        \n        total_blocks = batch * out_h * out_w * triton.cdiv(self.out_channels, 128)\n        grid = (total_blocks,)\n        conv2d_kernel[grid](\n            x, self.weight, output,\n            in_c, in_h, in_w, self.out_channels, out_h, out_w,\n            self.kernel_size, self.kernel_size,\n            self.stride, self.stride,\n            self.padding, self.padding,\n            BLOCK_C=128\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = TritonConv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = TritonConv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.downsample = None\n        if stride != 1 or in_channels != out_channels * self.expansion:\n            self.downsample = nn.Sequential(\n                TritonConv2d(in_channels, out_channels * self.expansion, 1, stride, 0, bias=False),\n                nn.BatchNorm2d(out_channels * self.expansion)\n            )\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_bn_relu_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    stride, padding,\n    in_channels, out_channels,\n    H, W,\n    stride_xn, stride_xc, stride_xh, stride_xw,\n    stride_wn, stride_wc, stride_wh, stride_ww,\n    stride_on, stride_oc, stride_oh, stride_ow,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    num_operations = out_channels * H * W\n    operations_per_pid = (num_operations + num_pid - 1) // num_pid\n    \n    start = pid * operations_per_pid\n    end = tl.minimum(start + operations_per_pid, num_operations)\n    \n    BLOCK_CHANNELS = 32  # Vectorization factor for input channels\n    \n    for op_idx in range(start, end):\n        c = op_idx // (H * W)\n        hw = op_idx % (H * W)\n        h = hw // W\n        w = hw % W\n        \n        acc = 0.0\n        # Unroll kernel loops for 3x3 convolution\n        for kh in tl.static_range(0, 3):\n            for kw in tl.static_range(0, 3):\n                h_in = h * stride - padding + kh\n                w_in = w * stride - padding + kw\n                \n                if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                    # Process input channels in vectorized blocks\n                    for ic_block in range(0, in_channels, BLOCK_CHANNELS):\n                        ic_offsets = ic_block + tl.arange(0, BLOCK_CHANNELS)\n                        ic_mask = ic_offsets < in_channels\n                        \n                        # Vectorized load for input channels\n                        x_ptrs = x_ptr + ic_offsets * stride_xc + h_in * stride_xh + w_in * stride_xw\n                        x_vals = tl.load(x_ptrs, mask=ic_mask, other=0.0)\n                        \n                        # Vectorized load for weights\n                        w_ptrs = w_ptr + c * stride_wc + ic_offsets * stride_wn + kh * stride_wh + kw * stride_ww\n                        w_vals = tl.load(w_ptrs, mask=ic_mask, other=0.0)\n                        \n                        # Accumulate vector product\n                        acc += tl.sum(x_vals * w_vals)\n        \n        bias_val = tl.load(b_ptr + c)\n        acc += bias_val\n        acc = tl.maximum(acc, 0.0)\n        out_offset = c * stride_oc + h * stride_oh + w * stride_ow\n        tl.store(output_ptr + out_offset, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n        self.register_buffer('fused_weight', torch.empty_like(self.conv1.weight))\n        self.register_buffer('fused_bias', torch.empty(out_channels))\n\n    def fuse_conv_bn(self):\n        with torch.no_grad():\n            conv_weight = self.conv1.weight\n            bn_weight = self.bn1.weight\n            bn_bias = self.bn1.bias\n            bn_mean = self.bn1.running_mean\n            bn_var = self.bn1.running_var\n            bn_eps = self.bn1.eps\n            \n            scale_factor = bn_weight / torch.sqrt(bn_var + bn_eps)\n            self.fused_weight.copy_(conv_weight * scale_factor[:, None, None, None])\n            self.fused_bias.copy_(bn_bias - bn_mean * scale_factor)\n\n    def forward(self, x):\n        identity = x\n\n        if self.training:\n            out = self.conv1(x)\n            out = self.bn1(out)\n            out = self.relu(out)\n        else:\n            if self.fused_weight is None:\n                self.fuse_conv_bn()\n                \n            B, C, H, W = x.shape\n            output = torch.empty(B, self.conv1.out_channels, H // self.stride, W // self.stride, \n                                device=x.device, dtype=x.dtype)\n            \n            stride_x = x.stride()\n            stride_w = self.fused_weight.stride()\n            stride_o = output.stride()\n            \n            for b in range(B):\n                conv_bn_relu_kernel[(1024,)](x[b], self.fused_weight, self.fused_bias, output[b],\n                    self.stride, 1,\n                    self.conv1.in_channels, self.conv1.out_channels,\n                    output.size(2), output.size(3),\n                    stride_x[1], stride_x[2], stride_x[3],\n                    stride_w[1], stride_w[2], stride_w[3],\n                    stride_o[1], stride_o[2], stride_o[3],\n                    BLOCK_SIZE=128)\n            out = output\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    elements_per_block = tl.cdiv(out_channels * height_out * width_out, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, out_channels * height_out * width_out)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        bias = tl.load(b_ptr + c_out)\n        acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        H_out = H // self.stride\n        W_out = W // self.stride\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        n_elements = B * self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            downsample_kernel[grid](\n                x[b], \n                self.downsample_fused_weight, \n                self.downsample_fused_bias,\n                identity_down[b],\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    n_elements = out_channels * height_out * width_out\n    elements_per_block = tl.cdiv(n_elements, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, n_elements)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        if b_ptr is not None:\n            bias = tl.load(b_ptr + c_out)\n            acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        H_out = H // self.stride\n        W_out = W // self.stride\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        n_elements = self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            downsample_kernel[grid](\n                x[b].contiguous(), \n                self.downsample_fused_weight.view(self.out_channels, -1).contiguous(),\n                self.downsample_fused_bias,\n                identity_down[b].contiguous(),\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef downsample_kernel(\n    x_ptr, \n    w_ptr, \n    b_ptr,\n    output_ptr,\n    in_channels, out_channels, stride,\n    height, width, height_out, width_out,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_blocks = tl.num_programs(0)\n    elements_per_block = tl.cdiv(out_channels * height_out * width_out, num_blocks)\n    start_idx = pid * elements_per_block\n    end_idx = min(start_idx + elements_per_block, out_channels * height_out * width_out)\n    \n    for idx in range(start_idx, end_idx):\n        c_out = idx // (height_out * width_out)\n        spatial_idx = idx % (height_out * width_out)\n        h_out = spatial_idx // width_out\n        w_out = spatial_idx % width_out\n        \n        h_in = h_out * stride\n        w_in = w_out * stride\n        \n        acc = 0.0\n        for c_in in range(0, in_channels, BLOCK_SIZE):\n            c_mask = c_in + tl.arange(0, BLOCK_SIZE) < in_channels\n            x_off = h_in * width + w_in\n            x_val = tl.load(x_ptr + (c_in + tl.arange(0, BLOCK_SIZE)) * (height * width) + x_off, mask=c_mask, other=0.0)\n            w_val = tl.load(w_ptr + c_out * in_channels + c_in + tl.arange(0, BLOCK_SIZE), mask=c_mask, other=0.0)\n            acc += tl.sum(x_val * w_val, axis=0)\n        \n        bias = tl.load(b_ptr + c_out)\n        acc += bias\n        tl.store(output_ptr + c_out * (height_out * width_out) + h_out * width_out + w_out, acc)\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Replace downsample with fused parameters\n        self.downsample_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n        self.downsample_bn = nn.BatchNorm2d(out_channels)\n        self.downsample_fused_weight = nn.Parameter(torch.empty(out_channels, in_channels, 1, 1))\n        self.downsample_fused_bias = nn.Parameter(torch.empty(out_channels))\n        \n        self.stride = stride\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Fuse downsample parameters\n        with torch.no_grad():\n            gamma = self.downsample_bn.weight\n            beta = self.downsample_bn.bias\n            mean = self.downsample_bn.running_mean\n            var = self.downsample_bn.running_var\n            eps = 1e-5\n            \n            w = self.downsample_conv.weight\n            w_fused = w * (gamma / torch.sqrt(var + eps)).view(-1, 1, 1, 1)\n            b_fused = beta - gamma * mean / torch.sqrt(var + eps)\n            \n            self.downsample_fused_weight.copy_(w_fused)\n            self.downsample_fused_bias.copy_(b_fused)\n        \n        # Compute downsample with Triton kernel\n        B, C, H, W = x.shape\n        # Correct output size calculation\n        H_out = (H + 2*0 - 1) // self.stride + 1\n        W_out = (W + 2*0 - 1) // self.stride + 1\n        identity_down = torch.empty((B, self.out_channels, H_out, W_out), \n                                   device=x.device, dtype=x.dtype)\n        \n        # Prepare contiguous tensors\n        weight_2d = self.downsample_fused_weight.view(self.out_channels, self.in_channels).contiguous()\n        bias_1d = self.downsample_fused_bias.contiguous()\n        \n        # Calculate grid per batch element\n        n_elements_batch = self.out_channels * H_out * W_out\n        grid_batch = lambda meta: (triton.cdiv(n_elements_batch, meta['BLOCK_SIZE']),)\n        \n        for b in range(B):\n            # Ensure contiguous input\n            x_b = x[b].contiguous()\n            downsample_kernel[grid_batch](\n                x_b, \n                weight_2d, \n                bias_1d,\n                identity_down[b],\n                self.in_channels, self.out_channels, self.stride,\n                H, W, H_out, W_out,\n                BLOCK_SIZE=16\n            )\n        \n        out += identity_down\n        out = self.relu(out)\n        return out\n    \n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass TritonConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.bias = None\n        nn.init.kaiming_uniform_(self.weight)\n\n    @triton.jit\n    def _conv2d_kernel(\n        x_ptr, w_ptr, y_ptr,\n        B, C_in, C_out, H, W, K, S, P,\n        stride_xb, stride_xc, stride_xh, stride_xw,\n        stride_woc, stride_wic, stride_wh, stride_ww,\n        stride_yb, stride_yc, stride_yh, stride_yw,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        num_pid = tl.num_programs(0)\n        elements_per_program = B * C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1)\n        start_idx = pid * BLOCK_SIZE\n        offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < elements_per_program\n        \n        for i in tl.range(0, BLOCK_SIZE, mask=mask):\n            idx = offsets[i]\n            b = idx // (C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1))\n            rest = idx % (C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1))\n            c_out = rest // (((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1))\n            rest = rest % (((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1))\n            h_out = rest // ((W + 2*P - K)//S + 1)\n            w_out = rest % ((W + 2*P - K)//S + 1)\n            \n            acc = 0.0\n            for c_in in range(C_in):\n                for kh in range(K):\n                    for kw in range(K):\n                        h_in = h_out * S - P + kh\n                        w_in = w_out * S - P + kw\n                        if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                            x_offset = b*stride_xb + c_in*stride_xc + h_in*stride_xh + w_in*stride_xw\n                            w_offset = c_out*stride_woc + c_in*stride_wic + kh*stride_wh + kw*stride_ww\n                            x_val = tl.load(x_ptr + x_offset)\n                            w_val = tl.load(w_ptr + w_offset)\n                            acc += x_val * w_val\n            \n            y_offset = b*stride_yb + c_out*stride_yc + h_out*stride_yh + w_out*stride_yw\n            tl.store(y_ptr + y_offset, acc, mask=mask)\n\n    def forward(self, x):\n        B, C_in, H, W = x.shape\n        H_out = (H + 2*self.padding - self.kernel_size) // self.stride + 1\n        W_out = (W + 2*self.padding - self.kernel_size) // self.stride + 1\n        y = torch.zeros(B, self.out_channels, H_out, W_out, device=x.device, dtype=x.dtype)\n        \n        grid = lambda meta: (triton.cdiv(B * self.out_channels * H_out * W_out, meta['BLOCK_SIZE']),)\n        self._conv2d_kernel[grid](\n            x, self.weight, y,\n            B, C_in, self.out_channels, H, W, self.kernel_size, self.stride, self.padding,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), self.weight.stride(3),\n            y.stride(0), y.stride(1), y.stride(2), y.stride(3),\n            BLOCK_SIZE=1024\n        )\n        \n        if self.bias is not None:\n            y += self.bias[None, :, None, None]\n        return y\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = TritonConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = TritonConv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            TritonConv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that has a compilation error in the Triton kernel.\n The error is: \n   TypeError: range.__init__() got an unexpected keyword argument 'mask'\n\n The issue is in the line:\n   for i in tl.range(0, BLOCK_SIZE, mask=mask):\n\n In Triton, the `tl.range` function does not accept a `mask` argument. Instead, we should use a conditional inside the loop.\n\n We are going to change the loop to a standard for-loop and use the mask for conditional loading.\n\n Additionally, note that the current kernel is doing a naive convolution with nested loops and might be slow.\n However, the immediate goal is to fix the compilation error and then we can work on performance.\n\n Steps for the kernel:\n 1. Remove the mask from the `tl.range` call.\n 2. Instead, we can loop over `i` from 0 to BLOCK_SIZE and check the mask for each element.\n\n However, note that the current kernel uses a single program per element? Actually, it uses a grid of programs that each process BLOCK_SIZE elements.\n\n Alternatively, we can restructure the kernel to use a more efficient approach, but for now, we fix the compilation.\n\n Proposed fix for the kernel:\n\n   pid = tl.program_id(0)\n   num_pid = tl.num_programs(0)\n   elements_per_program = B * C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1)\n   start_idx = pid * BLOCK_SIZE\n   offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n   mask = offsets < elements_per_program\n\n   for i in range(BLOCK_SIZE):\n        if mask[i]:\n            idx = offsets[i]\n            ... (rest of the code)\n\n But note: using a loop with conditionals in Triton might not be efficient. However, for correctness and compilation, we do this.\n\n However, we note that the kernel is very naive and will be slow. But let's first fix the compilation and correctness.\n\n Alternatively, we can change the kernel to use a more standard approach by having each program handle one output element?\n But the current structure is that each program handles a block of BLOCK_SIZE output elements.\n\n We are going to change the inner loop to:\n\n   for i in tl.range(0, BLOCK_SIZE):\n        if mask[i]:\n            ... \n\n But note: `tl.range` does not support conditionals inside? Actually, we can use an `if` statement.\n\n However, the problem is that the original `tl.range` was called with `mask` which is not allowed.\n\n Let's change the loop to:\n\n   for i in range(0, BLOCK_SIZE):\n        if mask[i]:\n            ... \n\n But note: we are in a Triton kernel and we cannot use Python's `range` because it is not compiled. We must use `tl.range` without mask.\n\n We can do:\n\n   for i in tl.arange(0, BLOCK_SIZE):\n        if mask[i]:\n            ... \n\n So the corrected code for the kernel loop:\n\n   for i in tl.arange(0, BLOCK_SIZE):\n        if mask[i]:\n            idx = offsets[i]\n            ... \n\n However, we must be cautious because `mask[i]` is a scalar condition in Triton.\n\n Alternatively, we can use `tl.where` but that is not for control flow.\n\n We can use `tl.range` and then conditionally skip using an if statement.\n\n But note: the entire kernel must be compiled to the GPU, and we can use conditionals.\n\n Let's restructure the kernel accordingly.\n\n But note: the original kernel design is inefficient. We are going to fix the compilation error first.\n\n We change the loop from:\n\n   for i in tl.range(0, BLOCK_SIZE, mask=mask):\n\n to:\n\n   for i in tl.arange(0, BLOCK_SIZE):\n        if mask[i]:\n            ... \n\n However, we note that `mask` is a vector of length BLOCK_SIZE, and we are indexing it with `i`. This should be valid.\n\n But note: the original `mask` is defined as `mask = offsets < elements_per_program`, which is a vector of booleans of length BLOCK_SIZE.\n\n So we can do:\n\n   for i in tl.arange(0, BLOCK_SIZE):\n        if mask[i]:\n            idx = offsets[i]\n            ... (the rest)\n\n We also note that the kernel uses a triple nested loop for the convolution (over c_in, kh, kw). This is going to be very slow for large channels and kernel sizes, but we are only dealing with 3x3.\n\n However, the current problem is compilation.\n\n Let's rewrite the kernel accordingly.\n\n Also note: the kernel uses a lot of integer divisions and mod operations. We might want to precompute the output dimensions to avoid recalculating.\n\n We can precompute:\n   H_out = (H + 2*P - K) // S + 1\n   W_out = (W + 2*P - K) // S + 1\n\n But note: the kernel already has these expressions in the calculation of `elements_per_program`. We can compute them once at the beginning.\n\n However, to avoid recalculating, we can compute them once and then use.\n\n But for now, we focus on fixing the compilation.\n\n We are going to change the kernel as follows:\n\n   H_out = (H + 2*P - K) // S + 1\n   W_out = (W + 2*P - K) // S + 1\n   elements_per_program = B * C_out * H_out * W_out\n\n   ... then the same ...\n\n   for i in tl.arange(0, BLOCK_SIZE):\n        if mask[i]:\n            idx = offsets[i]\n            # Then compute b, c_out, h_out, w_out from idx\n            b = idx // (C_out * H_out * W_out)\n            rest = idx % (C_out * H_out * W_out)\n            c_out = rest // (H_out * W_out)\n            rest2 = rest % (H_out * W_out)\n            h_out = rest2 // W_out\n            w_out = rest2 % W_out\n\n            ... then the inner loops ...\n\n We also note that the original kernel uses `//` which is integer division. In Triton, we can use `//` for integers.\n\n Let's implement these changes.\n\n Additionally, we note that the kernel does not handle the case when the output dimensions are not integers? But the problem says they are.\n\n We are going to rewrite the kernel accordingly.\n\n Since we are changing the kernel, we must also adjust the grid in the forward function.\n\n But note: the grid is set as:\n   grid = lambda meta: (triton.cdiv(B * self.out_channels * H_out * W_out, meta['BLOCK_SIZE']),)\n\n This matches the number of programs.\n\n We are going to change the kernel to precompute H_out and W_out and then use them.\n\n We also note: the original kernel had a loop over `i` that was masked. We are replacing it with a loop that iterates over all indices in the block and conditionally processes the element.\n\n This change should fix the compilation error.\n\n However, note that the kernel might still be slow. We are only fixing the compilation and correctness in this step.\n\n We will output the entire ModelNew class with the fixed kernel.\n\n Let's write the fixed kernel code.\n\n IMPORTANT: We are not allowed to change the function signature or the parameters.\n\n We change the kernel inside the TritonConv2d class.\n\n Also note: the kernel is defined as a static method? Actually, it is defined inside the class but with the decorator at the method level. However, in Triton, we cannot have a kernel inside a class because of the way compilation works. But the current code does it.\n\n Alternatively, we can move the kernel outside, but the problem says we cannot change the structure outside the EVOLVE-BLOCK.\n\n But note: the current program is entirely within the EVOLVE-BLOCK. We are allowed to change only the Triton kernel source.\n\n However, we note that the kernel is defined as:\n\n   @triton.jit\n   def _conv2d_kernel(...)\n\n and then called in the forward.\n\n We are going to change the body of _conv2d_kernel.\n\n We'll rewrite the kernel as:\n\n   @triton.jit\n   def _conv2d_kernel(...):\n        # Precompute output dimensions\n        H_out = (H + 2*P - K) // S + 1\n        W_out = (W + 2*P - K) // S + 1\n        total_elements = B * C_out * H_out * W_out\n\n        pid = tl.program_id(0)\n        num_pid = tl.num_programs(0)\n        elements_per_program = total_elements\n        start_idx = pid * BLOCK_SIZE\n        offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < total_elements\n\n        for i in tl.arange(0, BLOCK_SIZE):\n            if mask[i]:\n                idx = offsets[i]\n                b = idx // (C_out * H_out * W_out)\n                rest = idx % (C_out * H_out * W_out)\n                c_out = rest // (H_out * W_out)\n                rest2 = rest % (H_out * W_out)\n                h_out = rest2 // W_out\n                w_out = rest2 % W_out\n\n                acc = 0.0\n                for c_in in range(C_in):\n                    for kh in range(K):\n                        for kw in range(K):\n                            h_in = h_out * S - P + kh\n                            w_in = w_out * S - P + kw\n                            if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                                x_offset = b*stride_xb + c_in*stride_xc + h_in*stride_xh + w_in*stride_xw\n                                w_offset = c_out*stride_woc + c_in*stride_wic + kh*stride_wh + kw*stride_ww\n                                x_val = tl.load(x_ptr + x_offset)\n                                w_val = tl.load(w_ptr + w_offset)\n                                acc += x_val * w_val\n\n                y_offset = b*stride_yb + c_out*stride_yc + h_out*stride_yh + w_out*stride_yw\n                tl.store(y_ptr + y_offset, acc)\n\n However, note: the original kernel did not precompute H_out and W_out, but we are doing it now.\n\n Also note: the original kernel had a variable `elements_per_program` that was the same as `total_elements`? Actually, we are now setting `elements_per_program` to `total_elements` and then the mask is over the entire tensor. But the grid is set to cover the entire tensor in blocks.\n\n But note: the grid function is: `triton.cdiv(total_elements, BLOCK_SIZE)`\n\n This is correct.\n\n Let's write the fixed code.\n\n We are also going to change the variable `elements_per_program` to `total_elements` and remove the redundant calculation.\n\n However, note that the original code had:\n   elements_per_program = B * C_out * ((H + 2*P - K)//S + 1) * ((W + 2*P - K)//S + 1)\n\n We are replacing that with:\n   H_out = (H + 2*P - K) // S + 1\n   W_out = (W + 2*P - K) // S + 1\n   total_elements = B * C_out * H_out * W_out\n\n This is the same.\n\n We are going to output the entire ModelNew class with the fixed kernel.\n\n But note: we are only allowed to output the code within the EVOLVE-BLOCK.\n\n We are going to replace the current kernel with the fixed version.\n\n Also note: the kernel uses integer division for H_out and W_out. This is correct because the output dimensions are integers.\n\n Let's write the code accordingly.\n\n IMPORTANT: We are not allowed to change the class name (ModelNew) or the test code at the bottom.\n\n We are only changing the body of the `_conv2d_kernel` function.\n\n We hope this will fix the compilation error.\n\n After that, we can work on performance in the next steps.\n</think>\nThe compilation error occurred due to an incorrect usage of `tl.range` with a mask parameter. The kernel has been fixed by:\n1. Replacing the masked range loop with a standard range loop and explicit mask checking\n2. Precomputing output dimensions (H_out, W_out) for efficiency\n3. Maintaining all other functionality including boundary checks\n\nHere's the corrected implementation:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass TritonConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.bias = None\n        nn.init.kaiming_uniform_(self.weight)\n\n    @triton.jit\n    def _conv2d_kernel(\n        x_ptr, w_ptr, y_ptr,\n        B, C_in, C_out, H, W, K, S, P,\n        stride_xb, stride_xc, stride_xh, stride_xw,\n        stride_woc, stride_wic, stride_wh, stride_ww,\n        stride_yb, stride_yc, stride_yh, stride_yw,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        # Precompute output dimensions\n        H_out = (H + 2*P - K) // S + 1\n        W_out = (W + 2*P - K) // S + 1\n        total_elements = B * C_out * H_out * W_out\n        \n        pid = tl.program_id(0)\n        num_pid = tl.num_programs(0)\n        start_idx = pid * BLOCK_SIZE\n        offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < total_elements\n        \n        for i in tl.arange(0, BLOCK_SIZE):\n            if mask[i]:\n                idx = offsets[i]\n                b = idx // (C_out * H_out * W_out)\n                rest = idx % (C_out * H_out * W_out)\n                c_out = rest // (H_out * W_out)\n                rest2 = rest % (H_out * W_out)\n                h_out = rest2 // W_out\n                w_out = rest2 % W_out\n                \n                acc = 0.0\n                for c_in in range(C_in):\n                    for kh in range(K):\n                        for kw in range(K):\n                            h_in = h_out * S - P + kh\n                            w_in = w_out * S - P + kw\n                            if h_in >= 0 and h_in < H and w_in >= 0 and w_in < W:\n                                x_offset = b*stride_xb + c_in*stride_xc + h_in*stride_xh + w_in*stride_xw\n                                w_offset = c_out*stride_woc + c_in*stride_wic + kh*stride_wh + kw*stride_ww\n                                x_val = tl.load(x_ptr + x_offset)\n                                w_val = tl.load(w_ptr + w_offset)\n                                acc += x_val * w_val\n                \n                y_offset = b*stride_yb + c_out*stride_yc + h_out*stride_yh + w_out*stride_yw\n                tl.store(y_ptr + y_offset, acc)\n\n    def forward(self, x):\n        B, C_in, H, W = x.shape\n        H_out = (H + 2*self.padding - self.kernel_size) // self.stride + 1\n        W_out = (W + 2*self.padding - self.kernel_size) // self.stride + 1\n        y = torch.zeros(B, self.out_channels, H_out, W_out, device=x.device, dtype=x.dtype)\n        \n        total_elements = B * self.out_channels * H_out * W_out\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        self._conv2d_kernel[grid](\n            x, self.weight, y,\n            B, C_in, self.out_channels, H, W, self.kernel_size, self.stride, self.padding,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), self.weight.stride(3),\n            y.stride(0), y.stride(1), y.stride(2), y.stride(3),\n            BLOCK_SIZE=1024\n        )\n        \n        if self.bias is not None:\n            y += self.bias[None, :, None, None]\n        return y\n\nclass ModelNew(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ModelNew, self).__init__()\n        self.conv1 = TritonConv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = TritonConv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = nn.Sequential(\n            TritonConv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(out_channels * self.expansion),\n        )\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n# Test code\nin_channels = 3\nout_channels = 64\nstride = 1\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, 224, 224)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, stride]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}