{"id": "be788781-d6e8-429a-a71e-9fc0d7678348", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to float16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Use tensor core optimized dot product\n        partial = tl.dot(w_vals_f16, x_vals_f16, out_dtype=tl.float32)\n        acc += partial\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with autotuned block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0)\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "7ab2762a-7acb-441a-b4af-f54e4000202f", "generation": 2, "timestamp": 1754578514.9756196, "iteration_found": 28, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_39_Gemm_Scale_BatchNorm", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "runtime_error": "Traceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1497, in dot\n    assert lhs_rank == rhs_rank == 2 or lhs_rank == rhs_rank == 3, f\"Both inputs must be either 2D or 3D; (lhs: {lhs.shape} vs rhs: {rhs.shape})\"\nAssertionError: Both inputs must be either 2D or 3D; (lhs: ['constexpr[64]', 'constexpr[64]'] vs rhs: ['constexpr[64]'])\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp8so4tj_k.py\", line 106, in forward\n    x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n  File \"/tmp/tmp8so4tj_k.py\", line 89, in fused_linear_scale\n    fused_linear_scale_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\n    fn()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\n    self.fn.run(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 40:18:\n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n\n        # Convert to float16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n\n        # Use tensor core optimized dot product\n        partial = tl.dot(w_vals_f16, x_vals_f16, out_dtype=tl.float32)\n                  ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1497, in dot\n    assert lhs_rank == rhs_rank == 2 or lhs_rank == rhs_rank == 3, f\"Both inputs must be either 2D or 3D; (lhs: {lhs.shape} vs rhs: {rhs.shape})\"\nAssertionError: Both inputs must be either 2D or 3D; (lhs: ['constexpr[64]', 'constexpr[64]'] vs rhs: ['constexpr[64]'])\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 0.0935, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.926, "runtime_ms": 0.101, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0935, "speed_up": 0.926, "custom_timing": 0.101}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.9260\n- runtime_ms: 0.1010\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0935, 'speed_up': 0.926, 'custom_timing': 0.101}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_39_Gemm_Scale_BatchNorm', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpfcadeu8g.py\", line 98, in forward\\n    x = fused_linear_scale(\\n  File \"/tmp/tmpfcadeu8g.py\", line 79, in fused_linear_scale\\n    fused_linear_scale_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\\n    fn()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\\n    self.fn.run(\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\\n    dependencies_finder.visit(self.parse())\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 229, in visit_For\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\\n    self.visit(value)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\\n    self.visit(value)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\\n    ret = getattr(lhs, node.attr)\\nAttributeError: module \\'triton.language\\' has no attribute \\'transpose\\'\\n', 'runtime_error_name': 'builtins.AttributeError', 'reference_timing_ms': 0.0935, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.9260, runtime_ms: 0.1010, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0935, 'speed_up': 0.926, 'custom_timing': 0.101}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8060, runtime_ms: 0.1160, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0935, 'speed_up': 0.806, 'custom_timing': 0.116}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to float16 for computation\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Compute partial dot product using element-wise operations\n        partial = tl.sum(w_vals_f16 * x_vals_f16[None, :], axis=1)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with autotuned block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0)\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8060), Performs well on runtime_ms (0.1160), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0935, 'speed_up': 0.806, 'custom_timing': 0.116})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Compute partial dot product\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        partial = tl.sum(x_vals_f16[None, :] * w_vals_f16, axis=1)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.9260), Performs well on runtime_ms (0.1010), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0935, 'speed_up': 0.926, 'custom_timing': 0.101})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32, 'BLOCK_K': 256}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_bn,\n    stride_sn,\n    stride_outm, stride_outn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(K, BLOCK_K)):\n        k_remaining = K - k * BLOCK_K\n        k_mask = offs_k < k_remaining\n        x = tl.load(x_ptrs, mask=k_mask[None, :] & (offs_m[:, None] < M), other=0.0)\n        w = tl.load(w_ptrs, mask=k_mask[None, :] & (offs_n[:, None] < N), other=0.0)\n        w = tl.transpose(w)\n        acc += tl.dot(x, w, allow_tf32=True)\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    if b_ptr is not None:\n        b_ptrs = b_ptr + offs_n\n        b = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n        acc += b[None, :]\n    \n    s_ptrs = s_ptr + offs_n\n    scale = tl.load(s_ptrs, mask=offs_n < N, other=0.0)\n    acc *= scale[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_outm + offs_n[None, :] * stride_outn\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\ndef fused_linear_scale(x, weight, bias, scale):\n    M, K = x.shape\n    N, _ = weight.shape\n    x = x.contiguous()\n    weight = weight.contiguous()\n    bias = bias.contiguous() if bias is not None else None\n    scale = scale.contiguous()\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    grid = lambda META: (\n        triton.cdiv(M, META['BLOCK_M']),\n        triton.cdiv(N, META['BLOCK_N'])\n    )\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        bias.stride(0) if bias is not None else 0,\n        scale.stride(0),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        x = fused_linear_scale(\n            x, \n            self.gemm.weight, \n            self.gemm.bias, \n            self.scale\n        )\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_39_Gemm_Scale_BatchNorm', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpfcadeu8g.py\", line 98, in forward\\n    x = fused_linear_scale(\\n  File \"/tmp/tmpfcadeu8g.py\", line 79, in fused_linear_scale\\n    fused_linear_scale_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\\n    fn()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\\n    self.fn.run(\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\\n    dependencies_finder.visit(self.parse())\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 229, in visit_For\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\\n    self.visit(item)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\\n    self.generic_visit(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\\n    self.visit(value)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\\n    self.visit(value)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\\n    return visitor(node)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\\n    ret = getattr(lhs, node.attr)\\nAttributeError: module \\'triton.language\\' has no attribute \\'transpose\\'\\n', 'runtime_error_name': 'builtins.AttributeError', 'reference_timing_ms': 0.0935, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features with tensor core operations\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to fp16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Tensor core optimized matrix multiplication\n        partial = tl.dot(w_vals_f16, x_vals_f16)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes for tensor cores\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features with tensor core operations\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to fp16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Tensor core optimized matrix multiplication\n        partial = tl.dot(x_vals_f16, w_vals_f16, trans_b=True, allow_tf32=False)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes and tensor cores\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=256, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to float16 for computation\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Compute partial dot product using element-wise operations\n        partial = tl.sum(w_vals_f16 * x_vals_f16[None, :], axis=1)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with autotuned block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0)\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, weight_ptr, bias_ptr, scale_ptr, output_ptr,\n    in_features, out_features,\n    stride_x_batch, stride_x_feature,\n    stride_weight_out, stride_weight_in,\n    stride_output_batch, stride_output_feature,\n    BLOCK_SIZE: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_block = tl.program_id(1)\n    \n    feature_offset = pid_block * BLOCK_SIZE\n    feature_idx = feature_offset + tl.arange(0, BLOCK_SIZE)\n    feature_mask = feature_idx < out_features\n    \n    x_row_ptr = x_ptr + pid_batch * stride_x_batch\n    output_row_ptr = output_ptr + pid_batch * stride_output_batch + feature_offset\n    \n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_K):\n        k_idx = k + tl.arange(0, BLOCK_K)\n        k_mask = k_idx < in_features\n        \n        x_val = tl.load(x_row_ptr + k_idx, mask=k_mask, other=0.0)\n        \n        weight_ptr_block = weight_ptr + feature_idx[:, None] * stride_weight_out + k_idx[None, :]\n        weight_vals = tl.load(weight_ptr_block, mask=feature_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        acc += tl.sum(weight_vals * x_val[None, :], axis=1)\n    \n    bias_vals = tl.load(bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    scale_vals = tl.load(scale_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    result = (acc + bias_vals) * scale_vals\n    tl.store(output_row_ptr + tl.arange(0, BLOCK_SIZE), result, mask=feature_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.zeros(out_features))\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        x = x.contiguous()\n        batch_size, _ = x.shape\n        output = torch.empty((batch_size, out_features), device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size, triton.cdiv(out_features, 128))\n        fused_linear_scale_kernel[grid](\n            x, self.weight, self.bias, self.scale, output,\n            in_features, out_features,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=128\n        )\n        \n        output = self.bn(output)\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features with tensor core operations\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to fp16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Tensor core optimized matrix multiplication\n        partial = tl.dot(w_vals_f16, x_vals_f16)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes for tensor cores\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features with tensor core operations\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to fp16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Tensor core optimized matrix multiplication\n        partial = tl.dot(x_vals_f16, w_vals_f16, trans_b=True, allow_tf32=False)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes and tensor cores\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=256, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32, 'BLOCK_K': 256}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_bn,\n    stride_sn,\n    stride_outm, stride_outn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[:, None] * stride_wn + offs_k[None, :] * stride_wk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(K, BLOCK_K)):\n        k_remaining = K - k * BLOCK_K\n        k_mask = offs_k < k_remaining\n        x = tl.load(x_ptrs, mask=k_mask[None, :] & (offs_m[:, None] < M), other=0.0)\n        w = tl.load(w_ptrs, mask=k_mask[None, :] & (offs_n[:, None] < N), other=0.0)\n        w = tl.transpose(w)\n        acc += tl.dot(x, w, allow_tf32=True)\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    if b_ptr is not None:\n        b_ptrs = b_ptr + offs_n\n        b = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n        acc += b[None, :]\n    \n    s_ptrs = s_ptr + offs_n\n    scale = tl.load(s_ptrs, mask=offs_n < N, other=0.0)\n    acc *= scale[None, :]\n    \n    out_ptrs = out_ptr + offs_m[:, None] * stride_outm + offs_n[None, :] * stride_outn\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\ndef fused_linear_scale(x, weight, bias, scale):\n    M, K = x.shape\n    N, _ = weight.shape\n    x = x.contiguous()\n    weight = weight.contiguous()\n    bias = bias.contiguous() if bias is not None else None\n    scale = scale.contiguous()\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    grid = lambda META: (\n        triton.cdiv(M, META['BLOCK_M']),\n        triton.cdiv(N, META['BLOCK_N'])\n    )\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        bias.stride(0) if bias is not None else 0,\n        scale.stride(0),\n        output.stride(0), output.stride(1),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        x = fused_linear_scale(\n            x, \n            self.gemm.weight, \n            self.gemm.bias, \n            self.scale\n        )\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Compute partial dot product\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        partial = tl.sum(x_vals_f16[None, :] * w_vals_f16, axis=1)\n        acc += partial.to(tl.float32)\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with optimized block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0),\n        BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program and the history of attempts. The current program has a speedup of 0.926 (which is less than 1, meaning it's slower than the reference). We need to improve the performance.\n\nThe current kernel uses a loop over the input features (K dimension) and for each block, it loads a block of input data (x_vals) and a block of weights (w_vals). Then it converts them to float16 and does an element-wise multiplication followed by a sum along the K dimension.\n\nOne major issue is that the current kernel does not use tensor cores. The element-wise multiplication and sum is not as efficient as using the tensor core operations (tl.dot) for matrix multiplication.\n\nLooking at the hardware (NVIDIA H100/H800 with FP16 Tensor Core 32x16x16), we can leverage tensor cores by restructuring the kernel to use the dot product operation.\n\nIn the inspiration programs, we see attempts to use tl.dot. However, note that the current kernel is structured such that:\n  - Each program in the grid computes a block of the output of size (1, BLOCK_SIZE_N) for one batch and a contiguous block of output features.\n\nTo use tensor cores, we need to have two-dimensional blocks. However, note that the current kernel uses a 1D block for the output features (BLOCK_SIZE_N) and loops over K. We can restructure to use 2D blocks (BLOCK_SIZE_M for the batch dimension and BLOCK_SIZE_N for the output features) but that would require a different grid.\n\nAlternatively, we can note that for each batch element and each block of output features, we are effectively doing a vector-matrix product (the input vector of length in_features and a matrix of weight of size (BLOCK_SIZE_N, in_features)). This can be seen as a matrix multiplication of a 1xK matrix (the input row) and a KxN matrix (the weight block). However, tensor cores are designed for larger matrices.\n\nGiven the constraints (we cannot change the grid configuration, output tensor shapes, or PID logic), we must keep the current grid: (batch_size, triton.cdiv(out_features, BLOCK_SIZE_N)).\n\nBut note: the current kernel does not use tensor cores because the inner product is done by hand with element-wise operations. We can try to use the tl.dot operation by restructuring the inner loop to accumulate in a way that uses tensor cores.\n\nHowever, the tl.dot operation in Triton requires two 2D matrices. In our case, we have:\n  - x_vals: a vector of size [1, BLOCK_SIZE_K] (for the current k block)\n  - w_vals: a matrix of size [BLOCK_SIZE_N, BLOCK_SIZE_K]\n\nWe can do a matrix multiplication of w_vals (which is [BLOCK_SIZE_N, BLOCK_SIZE_K]) and x_vals (which is [BLOCK_SIZE_K, 1]) to get a vector of size [BLOCK_SIZE_N, 1]. This is a matrix-vector product, but note that tensor cores are optimized for larger matrices.\n\nAlternatively, we can accumulate multiple k-blocks together to form a larger matrix for the tensor core. However, the current kernel structure does not allow that because we are looping over k.\n\nAnother idea: restructure the kernel to have a 2D block in the output (batch and feature) and then use tensor cores for a block matrix multiplication. But note the constraint: we cannot change the grid configuration.\n\nTherefore, we must stick to the current grid. But we can try to change the inner loop to use a more efficient tensor core operation for the matrix-vector product? Actually, the tensor core operation in Triton (tl.dot) can be used for matrix-vector products, but it may not be efficient.\n\nLooking at the inspiration programs, we see that some tried to use tl.dot but with transposed weights. We can try:\n\n    partial = tl.dot(w_vals_f16, x_vals_f16, allow_tf32=False)\n\nThis would compute a vector of size [BLOCK_SIZE_N] (since w_vals_f16 is [BLOCK_SIZE_N, BLOCK_SIZE_K] and x_vals_f16 is [BLOCK_SIZE_K]), and the result is a vector of size [BLOCK_SIZE_N]. This is exactly the same as our current manual sum.\n\nBut note: the tl.dot operation might be optimized to use tensor cores when the sizes are appropriate. The requirement for tensor cores is that the dimensions are multiples of 16 (for FP16). Our BLOCK_SIZE_N and BLOCK_SIZE_K might be set to 128 and 64, which are multiples of 16 and 64 respectively, so it might use tensor cores.\n\nLet's change the inner computation to use tl.dot.\n\nReplace:\n    partial = tl.sum(x_vals_f16[None, :] * w_vals_f16, axis=1)\nwith:\n    partial = tl.dot(w_vals_f16, x_vals_f16)\n\nBut note: the tl.dot operation for a matrix and a vector:\n    A: [M, K]  (w_vals_f16)\n    B: [K]     (x_vals_f16) -> will be treated as [K, 1]\n    Result: [M] (partial)\n\nThis is equivalent to the sum along axis=1 of (w_vals_f16 * x_vals_f16[None, :]).\n\nSo we can replace the manual dot product with a call to tl.dot.\n\nAdditionally, we can allow the use of tensor cores by setting the allow_tf32 flag to False (because we are using FP16) and ensuring that the block sizes are multiples of 16.\n\nWe also note that the current kernel uses fixed block sizes (BLOCK_SIZE_N=128, BLOCK_SIZE_K=64). We might want to autotune these block sizes to find the best configuration.\n\nHowever, the task says: modify only the Triton kernel source within the block. We are allowed to change the kernel and the launch parameters.\n\nBut note: the constraint says we cannot change the grid configuration. The grid is still (batch_size, triton.cdiv(out_features, BLOCK_SIZE_N)). So if we change BLOCK_SIZE_N, we must adjust the grid accordingly. But the grid is defined as a lambda that uses meta['BLOCK_SIZE_N'] and we are currently hardcoding the block sizes in the kernel launch. We see that the kernel launch currently uses:\n    BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n\nWe can change the kernel to use autotuning by adding the @triton.autotune decorator and then launching with the meta parameters.\n\nBut the current program does not use autotune. We can introduce autotuning to select the best block sizes.\n\nHowever, note that the constraint says: \"NEVER change @triton.jit function signatures or parameter names\". We can change the kernel and add autotune without changing the signature? Actually, the autotune decorator is added above the jit decorator and the function signature remains the same.\n\nBut the kernel launch in the function `fused_linear_scale` currently uses fixed block sizes. We should change that to use the autotuned parameters.\n\nBut note: the constraint also says: \"NEVER modify grid configuration, output tensor shapes, or PID logic\". The grid is defined as:\n    grid = lambda meta: (batch_size, triton.cdiv(out_features, meta['BLOCK_SIZE_N']))\n\nThis grid is acceptable because it uses the meta parameter for the block size.\n\nSo let's do the following:\n\n1. Add the autotune decorator to the kernel with several configurations that are multiples of 16 (for tensor cores) and try to cover different block sizes.\n\n2. Change the inner loop to use tl.dot for the matrix-vector product.\n\n3. Remove the manual sum and replace it with tl.dot.\n\n4. We must also note that the tl.dot operation returns a vector of size BLOCK_SIZE_N in float32? Actually, the accumulation is in float32, but we are converting the partial result to float32 anyway. The tl.dot operation with FP16 inputs will accumulate in float32 by default? Actually, the tl.dot function returns a tensor of the same dtype as the inputs? But we are doing FP16, and the result might be in FP16. We want to accumulate in FP32. So we can do:\n\n    partial = tl.dot(w_vals_f16, x_vals_f16).to(tl.float32)\n\nBut note: the tl.dot operation might not support FP16 output? Actually, we can let it return FP16 and then convert to FP32. Alternatively, we can specify the output type? The documentation says we can use the `out_dtype` argument.\n\nWe can do:\n    partial = tl.dot(w_vals_f16, x_vals_f16, out_dtype=tl.float32)\n\nBut note: the tl.dot operation for FP16 on tensor cores will accumulate in FP32 internally? It's better to accumulate in FP32 to avoid precision loss.\n\nSo we change the inner loop to:\n\n    x_vals_f16 = x_vals.to(tl.float16)\n    w_vals_f16 = w_vals.to(tl.float16)\n    partial = tl.dot(w_vals_f16, x_vals_f16, out_dtype=tl.float32)\n\nThen we can remove the conversion of partial to float32.\n\nBut note: the accumulation variable `acc` is in float32, so we are safe.\n\nLet's write the new kernel with autotune and tl.dot.\n\nWe must be cautious: the autotune decorator must come before the jit decorator.\n\nWe are going to define several configurations. Since the tensor core requires block sizes that are multiples of 16, we choose:\n\n    BLOCK_SIZE_N: [64, 128, 256]   (must be multiple of 16, and these are)\n    BLOCK_SIZE_K: [64, 128]         (multiple of 16)\n\nWe also vary the number of warps.\n\nWe also note that the current kernel uses two program ids (batch and output feature block). The inner loop is over K.\n\nWe will try to set:\n\n    configs = [\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ]\n\nAnd the key for autotune can be ['in_features', 'out_features'].\n\nWe also note that the kernel launch in `fused_linear_scale` must not hardcode the block sizes. Instead, we pass the meta parameters:\n\n    fused_linear_scale_kernel[grid](\n        ...,\n        BLOCK_SIZE_N=meta['BLOCK_SIZE_N'],\n        BLOCK_SIZE_K=meta['BLOCK_SIZE_K']\n    )\n\nBut wait, the kernel parameters are named BLOCK_SIZE_N and BLOCK_SIZE_K, and we are passing them as keyword arguments. We can use the meta dictionary to provide these values.\n\nHowever, note that the grid function also uses meta['BLOCK_SIZE_N'] to compute the grid. This is acceptable because the autotuner will set these values.\n\nLet's restructure the code:\n\nWe'll add the autotune decorator and change the inner loop to use tl.dot.\n\nWe must also note: the current kernel uses the same variable names for the block sizes. So the kernel parameters are already BLOCK_SIZE_N and BLOCK_SIZE_K.\n\nNow, the new kernel code:\n\nSteps:\n\n1. Add autotune decorator.\n2. Change the inner computation to use tl.dot with out_dtype=tl.float32.\n3. In the fused_linear_scale function, remove the hardcoded block sizes and use the meta parameters.\n\nBut note: the kernel launch currently uses:\n\n    BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n\nWe change it to:\n\n    BLOCK_SIZE_N=meta['BLOCK_SIZE_N'],\n    BLOCK_SIZE_K=meta['BLOCK_SIZE_K']\n\nBut note: the meta dictionary in the grid function is the same as the one passed to the kernel. We can use the same meta for both.\n\nHowever, we must be cautious: the grid function uses meta['BLOCK_SIZE_N'] to compute the number of blocks in the feature dimension. This is correct.\n\nLet's write the new code.\n\nBut note: the constraint says \"NEVER change @triton.jit function signatures or parameter names\". We are not changing the parameter names, but we are adding an autotune decorator. This is allowed because the function signature remains the same.\n\nWe are also changing the inner implementation (which is allowed).\n\nWe must test for correctness and performance.\n\nWe hope that using tensor cores will improve the performance.\n\nWe also note that the current program has a speedup of 0.926. We hope to get above 1.0.\n\nLet's write the code accordingly.\n\nWe must also note: the current kernel has the following parameters in the kernel launch:\n\n    x, weight, bias, scale, output,\n    in_features, out_features,\n    x.stride(0), weight.stride(0), \n    bias.stride(0), scale.stride(0), output.stride(0),\n    BLOCK_SIZE_N=128, BLOCK_SIZE_K=64\n\nWe change the last two to use meta.\n\nBut note: the kernel launch is inside the function `fused_linear_scale`. We are passing the block sizes as keyword arguments. We change them to:\n\n    BLOCK_SIZE_N=meta['BLOCK_SIZE_N'],\n    BLOCK_SIZE_K=meta['BLOCK_SIZE_K']\n\nBut wait, the kernel expects these as tl.constexpr. The autotuner will set the meta dictionary accordingly.\n\nNow, the complete code:\n\nWe are going to output the entire EVOLVE-BLOCK.\n\nNote: We are not allowed to change anything outside the EVOLVE-BLOCK.\n\nWe are going to replace the kernel and the kernel launch in the fused_linear_scale function.\n\nWe are also going to add the autotune decorator.\n\nLet's write the new code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_scale_kernel(\n    x_ptr, w_ptr, b_ptr, s_ptr, out_ptr,\n    in_features, out_features,\n    stride_x, stride_w, stride_b, stride_s, stride_out,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)  # Batch index\n    pid1 = tl.program_id(1)  # Output feature block index\n    \n    # Create ranges for current block\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Create masks for boundaries\n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    # Loop over input features\n    for k in range(0, in_features, BLOCK_SIZE_K):\n        # Load block of input data\n        x_vals = tl.load(\n            x_ptr + pid0 * stride_x + k + offs_k, \n            mask=mask_k, other=0.0\n        )\n        \n        # Load block of weights\n        w_vals = tl.load(\n            w_ptr + (offs_n[:, None]) * stride_w + (k + offs_k[None, :]), \n            mask=mask_n[:, None] & mask_k[None, :], other=0.0\n        )\n        \n        # Convert to float16 for tensor core acceleration\n        x_vals_f16 = x_vals.to(tl.float16)\n        w_vals_f16 = w_vals.to(tl.float16)\n        \n        # Use tensor core optimized dot product\n        partial = tl.dot(w_vals_f16, x_vals_f16, out_dtype=tl.float32)\n        acc += partial\n    \n    # Load bias and scale\n    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n    s_vals = tl.load(s_ptr + offs_n, mask=mask_n, other=0.0)\n    \n    # Apply bias and scale\n    output = (acc + b_vals) * s_vals\n    \n    # Store result\n    tl.store(\n        out_ptr + pid0 * stride_out + offs_n, \n        output, mask=mask_n\n    )\n\ndef fused_linear_scale(x, weight, bias, scale):\n    batch_size, in_features = x.shape\n    out_features = weight.shape[0]\n    \n    # Preallocate output tensor\n    output = torch.empty((batch_size, out_features), \n                         device=x.device, dtype=torch.float32)\n    \n    # Calculate grid dimensions\n    grid = lambda meta: (\n        batch_size, \n        triton.cdiv(out_features, meta['BLOCK_SIZE_N'])\n    )\n    \n    # Launch kernel with autotuned block sizes\n    fused_linear_scale_kernel[grid](\n        x, weight, bias, scale, output,\n        in_features, out_features,\n        x.stride(0), weight.stride(0), \n        bias.stride(0), scale.stride(0), output.stride(0)\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x):\n        # Fused linear layer + scaling\n        x = fused_linear_scale(x, self.gemm.weight, self.gemm.bias, self.scale)\n        x = self.bn(x)\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}