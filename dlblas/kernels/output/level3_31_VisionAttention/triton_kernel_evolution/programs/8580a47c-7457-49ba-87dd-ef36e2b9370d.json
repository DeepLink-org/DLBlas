{"id": "8580a47c-7457-49ba-87dd-ef36e2b9370d", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _attn_kernel(\n    Q, K, V, Out,\n    stride_qb, stride_qh, stride_qm, stride_qk,\n    stride_kb, stride_kh, stride_kn, stride_kk,\n    stride_vb, stride_vh, stride_vn, stride_vk,\n    stride_ob, stride_oh, stride_om, stride_ok,\n    B, H, M, N, K_dim,\n    scale: tl.constexpr,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_h = tl.program_id(1)\n    pid_m = tl.program_id(2)\n    \n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    # Load Q block once (masked)\n    q_ptr = Q + pid_b * stride_qb + pid_h * stride_qh + (offs_m[:, None] * stride_qm + offs_k[None, :] * stride_qk)\n    q_mask = (offs_m[:, None] < M) & (offs_k[None, :] < K_dim)\n    q = tl.load(q_ptr, mask=q_mask, other=0.0).to(tl.float32)\n    \n    # Initialize accumulators and stats\n    acc = tl.zeros((BLOCK_M, BLOCK_K), dtype=tl.float32)\n    m_i = tl.full((BLOCK_M,), float('-inf'), dtype=tl.float32)\n    l_i = tl.zeros((BLOCK_M,), dtype=tl.float32)\n    \n    # Loop over K/V blocks\n    for block_n in range(0, tl.cdiv(N, BLOCK_N)):\n        offs_n_current = block_n * BLOCK_N + offs_n\n        \n        # Load K block (transposed: [head_dim, BLOCK_N])\n        k_ptr = K + pid_b * stride_kb + pid_h * stride_kh + (offs_n_current[None, :] * stride_kn + offs_k[:, None] * stride_kk)\n        k_mask = (offs_n_current[None, :] < N) & (offs_k[:, None] < K_dim)\n        k = tl.load(k_ptr, mask=k_mask, other=0.0).to(tl.float32)\n        \n        # Load V block ([BLOCK_N, head_dim])\n        v_ptr = V + pid_b * stride_vb + pid_h * stride_vh + (offs_n_current[:, None] * stride_vn + offs_k[None, :] * stride_vk)\n        v_mask = (offs_n_current[:, None] < N) & (offs_k[None, :] < K_dim)\n        v = tl.load(v_ptr, mask=v_mask, other=0.0).to(tl.float32)\n        \n        # Compute attention scores\n        S = tl.dot(q, k) * scale\n        \n        # Apply combined mask\n        mask = (offs_m[:, None] < M) & (offs_n_current[None, :] < N)\n        S = tl.where(mask, S, float('-inf'))\n        \n        # Online softmax updates\n        m_ij = tl.max(S, axis=1)\n        m_i_new = tl.maximum(m_i, m_ij)\n        alpha = tl.exp(m_i - m_i_new)\n        \n        # Rescale previous accumulators\n        acc = acc * alpha[:, None]\n        l_i = l_i * alpha\n        \n        # Compute current block contributions\n        p = tl.exp(S - m_i_new[:, None])\n        p = tl.where(mask, p, 0.0)\n        l_ij = tl.sum(p, axis=1)\n        \n        # Update accumulators\n        pv = tl.dot(p, v)\n        acc = acc + pv\n        l_i = l_i + l_ij\n        m_i = m_i_new\n    \n    # Final normalization\n    acc = acc / l_i[:, None]\n    acc = acc.to(Q.dtype.element_ty)\n    \n    # Store output\n    out_ptr = Out + pid_b * stride_ob + pid_h * stride_oh + (offs_m[:, None] * stride_om + offs_k[None, :] * stride_ok)\n    tl.store(out_ptr, acc, mask=q_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        self.q_proj = nn.Linear(embed_dim, embed_dim)\n        self.k_proj = nn.Linear(embed_dim, embed_dim)\n        self.v_proj = nn.Linear(embed_dim, embed_dim)\n        self.out_proj = nn.Linear(embed_dim, embed_dim)\n        self.norm = nn.LayerNorm(embed_dim)\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        M = H * W\n        x_flat = x.view(B, C, M).permute(2, 0, 1)\n        \n        # Project inputs\n        q = self.q_proj(x_flat)\n        k = self.k_proj(x_flat)\n        v = self.v_proj(x_flat)\n        \n        # Reshape for multi-head\n        q = q.permute(1, 0, 2).reshape(B, M, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        k = k.permute(1, 0, 2).reshape(B, M, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        v = v.permute(1, 0, 2).reshape(B, M, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        \n        out = torch.empty_like(q)\n        scale = 1.0 / math.sqrt(self.head_dim)\n        \n        # Optimized block sizes\n        BLOCK_M = 64\n        BLOCK_N = 32\n        BLOCK_K = self.head_dim\n        \n        grid = (B, self.num_heads, triton.cdiv(M, BLOCK_M))\n        _attn_kernel[grid](\n            q, k, v, out,\n            q.stride(0), q.stride(1), q.stride(2), q.stride(3),\n            k.stride(0), k.stride(1), k.stride(2), k.stride(3),\n            v.stride(0), v.stride(1), v.stride(2), v.stride(3),\n            out.stride(0), out.stride(1), out.stride(2), out.stride(3),\n            B, self.num_heads, M, M, self.head_dim,\n            scale,\n            BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K\n        )\n        \n        # Combine heads and project\n        out = out.permute(0, 2, 1, 3).reshape(B, M, C)\n        out = self.out_proj(out)\n        \n        # Residual and norm\n        out = self.norm(out + x_flat.permute(1, 0, 2))\n        out = out.permute(0, 2, 1).reshape(B, C, H, W)\n        return out\n\nembed_dim = 128\nnum_heads = 4\nbatch_size = 2\nnum_channels = embed_dim\nimage_height = 128\nimage_width = 128\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_channels, image_height, image_width)]\n\ndef get_init_inputs():\n    return [embed_dim, num_heads]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "84650fb9-934c-420e-a859-c671c42808b9", "generation": 2, "timestamp": 1754598304.8969758, "iteration_found": 28, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_31_VisionAttention", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "max_difference": ["0.238592", "0.247373", "0.242119", "0.270904", "0.239257"], "avg_difference": ["0.056394", "0.056733", "0.056066", "0.056213", "0.055577"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.335, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_31_VisionAttention", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "max_difference": ["0.341329", "0.281027", "0.323904", "0.325999", "0.298916"], "avg_difference": ["0.064148", "0.062220", "0.066247", "0.062522", "0.064222"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.335, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}