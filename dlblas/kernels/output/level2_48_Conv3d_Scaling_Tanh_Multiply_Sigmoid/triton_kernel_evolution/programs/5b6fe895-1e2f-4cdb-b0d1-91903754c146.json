{"id": "5b6fe895-1e2f-4cdb-b0d1-91903754c146", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _pointwise_fusion(\n    input_ptr,\n    scaling_factor_ptr,\n    bias_ptr,\n    output_ptr,\n    total_elements,\n    out_channels,\n    channel_stride,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    mask = offs < total_elements\n    \n    # Precompute channel indices using vectorized operations\n    channel_idx = tl.minimum((offs // channel_stride) % out_channels, out_channels - 1)\n    \n    # Vectorized loads for input and parameters\n    x = tl.load(input_ptr + offs, mask=mask)\n    s = tl.load(scaling_factor_ptr + channel_idx, mask=mask, cache_modifier=\".cg\")\n    b = tl.load(bias_ptr + channel_idx, mask=mask, cache_modifier=\".cg\")\n    \n    # Optimized fused operations\n    x = x * s\n    # Efficient tanh approximation (2 ops) with better numerical stability\n    exp_2x = tl.exp(-2.0 * tl.abs(x))\n    tanh_x = tl.where(x >= 0, 1 - exp_2x, exp_2x - 1) / (1 + exp_2x)\n    x = tanh_x * b\n    # Optimized sigmoid (1 exp op)\n    x = 1.0 / (1.0 + tl.exp(-x))\n    \n    tl.store(output_ptr + offs, x, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.scaling_factor = nn.Parameter(torch.randn(bias_shape))\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n    \n    def forward(self, x):\n        x = self.conv(x)\n        \n        # Prepare parameters and tensors\n        scaling_factor_flat = self.scaling_factor.view(-1)\n        bias_flat = self.bias.view(-1)\n        channel_stride = x.shape[2] * x.shape[3] * x.shape[4]\n        total_elements = x.numel()\n        output = torch.empty_like(x)\n        \n        # Launch Triton kernel with optimized block size\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        _pointwise_fusion[grid](\n            x.view(-1),\n            scaling_factor_flat,\n            bias_flat,\n            output.view(-1),\n            total_elements,\n            x.shape[1],\n            channel_stride,\n            BLOCK_SIZE=1024\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nscaling_factor = 2\nbias_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, scaling_factor, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "4cf6d898-dd6d-4e31-8a75-046bb41971fb", "generation": 3, "timestamp": 1754574058.8046303, "iteration_found": 16, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.07, "runtime_ms": 1.04, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0731, "speed_up": 0.07, "custom_timing": 1.04}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.126, "runtime_ms": 0.581, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0731, "speed_up": 0.126, "custom_timing": 0.581}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}