{"id": "d3cb5a95-621c-4ac7-bdef-a136bfd3bd77", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block in transposed layout\n        w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n        w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication with transposed weight layout\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "8861a68c-485d-4475-af40-c295e8db9273", "generation": 3, "timestamp": 1754574277.4480958, "iteration_found": 16, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 29.499999999999996, "speed_up": 1.095, "runtime_ms": 0.0613, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0671, "speed_up": 1.095, "custom_timing": 0.0613}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_40_Matmul_Scaling_ResidualAdd", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "runtime_error": "Traceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1498, in dot\n    assert lhs.shape[-1].value == rhs.shape[\nAssertionError: First input shape (['constexpr[16]', 'constexpr[32]']) and second input shape ['constexpr[64]', 'constexpr[32]'] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (64)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpcprzi6d2.py\", line 80, in forward\n    _fused_matmul_scale_kernel[(grid_b, grid_o)](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 33:15:\n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n\n        # Load weight block\n        w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n        w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n\n        # Matrix multiplication\n        acc += tl.dot(x_block, w_block)\n               ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1498, in dot\n    assert lhs.shape[-1].value == rhs.shape[\nAssertionError: First input shape (['constexpr[16]', 'constexpr[32]']) and second input shape ['constexpr[64]', 'constexpr[32]'] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (64)\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 0.0671, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level2_40_Matmul_Scaling_ResidualAdd', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1498, in dot\\n    assert lhs.shape[-1].value == rhs.shape[\\nAssertionError: First input shape ([\\'constexpr[16]\\', \\'constexpr[32]\\']) and second input shape [\\'constexpr[64]\\', \\'constexpr[32]\\'] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (64)\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpcprzi6d2.py\", line 80, in forward\\n    _fused_matmul_scale_kernel[(grid_b, grid_o)](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 33:15:\\n        # Load input block\\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\\n\\n        # Load weight block\\n        w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\\n        w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\\n\\n        # Matrix multiplication\\n        acc += tl.dot(x_block, w_block)\\n               ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1498, in dot\\n    assert lhs.shape[-1].value == rhs.shape[\\nAssertionError: First input shape ([\\'constexpr[16]\\', \\'constexpr[32]\\']) and second input shape [\\'constexpr[64]\\', \\'constexpr[32]\\'] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (64)\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 0.0671, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: -1.0000, runtime_ms: -1.0000, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'error_during_performance': 'save_for_backward can only save variables, but argument 0 is of type float', 'reference_timing_ms': 0.0671, 'speed_up': -1.0, 'custom_timing': -1.0}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 24.2000, speed_up: 1.0420, runtime_ms: 0.0644, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0671, 'speed_up': 1.042, 'custom_timing': 0.0644}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 28.1000, speed_up: 1.0810, runtime_ms: 0.0621, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0671, 'speed_up': 1.081, 'custom_timing': 0.0621}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 28.1000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block in transposed layout\n        w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n        w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication with transposed weight layout\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (28.1000), Performs well on speed_up (1.0810), Performs well on runtime_ms (0.0621), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0671, 'speed_up': 1.081, 'custom_timing': 0.0621})\n\n\n### Program 2 (Score: 24.2000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    scaling_factor,\n    batch_size, in_features, out_features,\n    stride_x_batch, stride_x_feat,\n    stride_w_out, stride_w_feat,\n    stride_b_out,\n    stride_out_batch, stride_out_feat,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_j = tl.program_id(1)\n    \n    if pid_b >= batch_size or pid_j >= out_features:\n        return\n    \n    idx = tl.arange(0, BLOCK_SIZE)\n    mask = idx < in_features\n    \n    x_row_ptr = x_ptr + pid_b * stride_x_batch + idx * stride_x_feat\n    w_row_ptr = w_ptr + pid_j * stride_w_out + idx * stride_w_feat\n    \n    x_row = tl.load(x_row_ptr, mask=mask, other=0.0)\n    w_row = tl.load(w_row_ptr, mask=mask, other=0.0)\n    \n    dot = tl.sum(x_row * w_row)\n    bias = tl.load(b_ptr + pid_j * stride_b_out)\n    result = (dot + bias) * scaling_factor\n    \n    output_ptr_val = output_ptr + pid_b * stride_out_batch + pid_j * stride_out_feat\n    tl.store(output_ptr_val, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.scaling_factor = scaling_factor\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        \n    def forward(self, x):\n        batch_size, in_feat = x.shape\n        out_feat = self.weight.shape[0]\n        output = torch.empty((batch_size, out_feat), device=x.device, dtype=torch.float32)\n        \n        if not x.is_contiguous():\n            x = x.contiguous()\n        if not self.weight.is_contiguous():\n            self.weight = self.weight.contiguous()\n        if not self.bias.is_contiguous():\n            self.bias = self.bias.contiguous()\n            \n        scale_val = 1.0 + self.scaling_factor\n        grid = (batch_size, out_feat)\n        BLOCK_SIZE = triton.next_power_of_2(in_feat)\n        \n        _forward_kernel[grid](\n            x, self.weight, self.bias, output,\n            scale_val,\n            batch_size, in_feat, out_feat,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (24.2000), Performs well on speed_up (1.0420), Performs well on runtime_ms (0.0644), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0671, 'speed_up': 1.042, 'custom_timing': 0.0644})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_scale_residual_kernel(\n    y_ptr,\n    output_ptr,\n    scaling_factor,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    \n    y = tl.load(y_ptr + offsets, mask=mask)\n    scaled = y * scaling_factor\n    output = scaled + y\n    tl.store(output_ptr + offsets, output, mask=mask)\n\nclass ScaledResidual(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, y, scaling_factor):\n        ctx.save_for_backward(scaling_factor)\n        output = torch.empty_like(y)\n        n_elements = y.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        fused_scale_residual_kernel[grid](\n            y, output, scaling_factor, n_elements, \n            BLOCK_SIZE=1024\n        )\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        scaling_factor, = ctx.saved_tensors\n        return grad_output * scaling_factor, None\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        return ScaledResidual.apply(x, self.scaling_factor)\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (-1.0000), Performs well on runtime_ms (-1.0000), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'error_during_performance': 'save_for_backward can only save variables, but argument 0 is of type float', 'reference_timing_ms': 0.0671, 'speed_up': -1.0, 'custom_timing': -1.0})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n        w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 28.1000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block in transposed layout\n        w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n        w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication with transposed weight layout\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: -100.0000, Type: Exploratory)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        # Use detach() instead of clone().detach() to avoid unnecessary memory copy\n        original_x = x.detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Alternative compiled approach, Alternative correctness approach\n\n\n### Inspiration 3 (Score: 24.2000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    scaling_factor,\n    batch_size, in_features, out_features,\n    stride_x_batch, stride_x_feat,\n    stride_w_out, stride_w_feat,\n    stride_b_out,\n    stride_out_batch, stride_out_feat,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_j = tl.program_id(1)\n    \n    if pid_b >= batch_size or pid_j >= out_features:\n        return\n    \n    idx = tl.arange(0, BLOCK_SIZE)\n    mask = idx < in_features\n    \n    x_row_ptr = x_ptr + pid_b * stride_x_batch + idx * stride_x_feat\n    w_row_ptr = w_ptr + pid_j * stride_w_out + idx * stride_w_feat\n    \n    x_row = tl.load(x_row_ptr, mask=mask, other=0.0)\n    w_row = tl.load(w_row_ptr, mask=mask, other=0.0)\n    \n    dot = tl.sum(x_row * w_row)\n    bias = tl.load(b_ptr + pid_j * stride_b_out)\n    result = (dot + bias) * scaling_factor\n    \n    output_ptr_val = output_ptr + pid_b * stride_out_batch + pid_j * stride_out_feat\n    tl.store(output_ptr_val, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.scaling_factor = scaling_factor\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        \n    def forward(self, x):\n        batch_size, in_feat = x.shape\n        out_feat = self.weight.shape[0]\n        output = torch.empty((batch_size, out_feat), device=x.device, dtype=torch.float32)\n        \n        if not x.is_contiguous():\n            x = x.contiguous()\n        if not self.weight.is_contiguous():\n            self.weight = self.weight.contiguous()\n        if not self.bias.is_contiguous():\n            self.bias = self.bias.contiguous()\n            \n        scale_val = 1.0 + self.scaling_factor\n        grid = (batch_size, out_feat)\n        BLOCK_SIZE = triton.next_power_of_2(in_feat)\n        \n        _forward_kernel[grid](\n            x, self.weight, self.bias, output,\n            scale_val,\n            batch_size, in_feat, out_feat,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 4 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_scale_residual_kernel(\n    y_ptr,\n    output_ptr,\n    scaling_factor,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    \n    y = tl.load(y_ptr + offsets, mask=mask)\n    scaled = y * scaling_factor\n    output = scaled + y\n    tl.store(output_ptr + offsets, output, mask=mask)\n\nclass ScaledResidual(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, y, scaling_factor):\n        ctx.save_for_backward(scaling_factor)\n        output = torch.empty_like(y)\n        n_elements = y.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        fused_scale_residual_kernel[grid](\n            y, output, scaling_factor, n_elements, \n            BLOCK_SIZE=1024\n        )\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        scaling_factor, = ctx.saved_tensors\n        return grad_output * scaling_factor, None\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        return ScaledResidual.apply(x, self.scaling_factor)\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 5 (Score: 0.0000, Type: Exploratory)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    A model that performs a matrix multiplication, scaling, and residual addition.\n\n    Args:\n        in_features (int): Number of input features.\n        out_features (int): Number of output features.\n        scaling_factor (float): Scaling factor to apply after matrix multiplication.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_features).\n        \"\"\"\n        x = self.matmul(x)\n        original_x = x.clone().detach()\n        x = x * self.scaling_factor\n        x = x + original_x\n        return x\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nUnique approach: Excellent compiled (1.000), Excellent correctness (1.000), Alternative passed approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n        w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that has a compilation error due to an incompatible matrix multiplication in the Triton kernel.\n The error message states:\n   First input shape (['constexpr[16]', 'constexpr[32]']) and second input shape ['constexpr[64]', 'constexpr[32]'] are not compatible for matmul \n   (second index of first shape (32) must be equal to first index of second shape (64)\n\n In the current kernel, we are doing:\n   x_block: shape [BLOCK_SIZE_B, BLOCK_SIZE_K] (which is [16, 32] in this case)\n   w_block: shape [BLOCK_SIZE_O, BLOCK_SIZE_K] (which is [64, 32] in this case)\n\n But for a matrix multiplication (dot product) we require the inner dimensions to match. Specifically, if we do:\n   x_block (shape [M, K]) @ w_block (shape [N, K])   -> this is not directly possible because the inner dimensions are both K but we need the second of the first to be the same as the first of the second? \n Actually, note: the Triton `tl.dot` operation expects the second argument to be transposed? Or is it?\n\n Let me clarify: The Triton `tl.dot` operation does:\n   dot(input, other) = input @ other.T\n\n So the operation we are doing is:\n   x_block (shape [16, 32]) @ (w_block (shape [64, 32])).T   -> which would be [16,32] @ [32,64] -> [16,64]\n\n But note: the w_block is stored in row-major for the weight matrix. However, in the kernel we are loading a block of the weight matrix that is contiguous in memory as [BLOCK_SIZE_O, BLOCK_SIZE_K]. But the weight matrix is stored as [out_features, in_features]. So when we load a block of size [BLOCK_SIZE_O, BLOCK_SIZE_K], it is a contiguous block of the weight matrix.\n\n However, the matrix multiplication in the kernel is written as:\n   acc += tl.dot(x_block, w_block)\n\n This operation requires that the last dimension of `x_block` (which is BLOCK_SIZE_K) equals the last dimension of `w_block` (which is BLOCK_SIZE_K) because the dot product does:\n   (BLOCK_SIZE_B, BLOCK_SIZE_K) @ (BLOCK_SIZE_O, BLOCK_SIZE_K) -> This is not standard.\n\n Actually, the Triton dot operation requires the second argument to have the same inner dimension as the first. But note: the Triton dot operation does not transpose the second argument. Instead, the operation is:\n   tl.dot(a, b) = a @ b.T   if a and b are both 2D.\n\n Therefore, we are effectively doing:\n   x_block (16x32) @ (w_block (64x32)).T = (16x32) @ (32x64) = (16x64)\n\n But the problem is that the Triton `tl.dot` function expects the second argument to be of shape [K, N] if the first is [M, K]. However, our w_block is [64,32] (N=64, K=32) and we want to do x_block (M=16, K=32) @ w_block (K=32, N=64) -> [16,64]. But to do that we would have to pass the transpose of w_block? \n\n Alternatively, we can note that the weight matrix in the reference PyTorch code is stored as [out_features, in_features]. In the PyTorch matmul, we do: x @ weight.T. Therefore, to match, we should have the weight block transposed.\n\n In the top-performing Program 1 (score 28.1), they loaded the weight in a transposed layout by using:\n   w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n   w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n   w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n\n And then they did:\n   acc += tl.dot(x_block, w_block)\n\n But note: the way they set up the pointers, the w_block is of shape [BLOCK_SIZE_K, BLOCK_SIZE_O] (because the offsets are [k_offsets (size K) in the first dimension and out_offsets (size O) in the second]). Then the dot product of x_block (shape [B, K]) and w_block (shape [K, O]) gives [B, O] as desired.\n\n In the current program, we are loading w_block as [BLOCK_SIZE_O, BLOCK_SIZE_K]. Then we try to do a dot product of [B, K] and [O, K] -> which is not compatible.\n\n Therefore, to fix the compilation error, we have two options:\n\n Option 1: Transpose the weight block after loading? But that would be expensive.\n\n Option 2: Change the way we load the weight block so that it is [BLOCK_SIZE_K, BLOCK_SIZE_O] (i.e., transposed in the block layout). This is what the top-performing program did.\n\n Let's change the weight loading to be transposed:\n\n Original for weight:\n   w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n   w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n   w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n\n We want to load a block of the weight matrix that is of shape [BLOCK_SIZE_K, BLOCK_SIZE_O]. So we should have:\n\n   w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n   w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n\n But note: the weight matrix is stored in row-major: [out_features, in_features]. So to get a block of [BLOCK_SIZE_K, BLOCK_SIZE_O] we are effectively taking a contiguous block in memory? Actually, no: we are taking a block that is non-contiguous because we are transposing the dimensions.\n\n However, we are using the strides correctly. The weight matrix has:\n   stride(0) = in_features (if it's row-major for out_features as rows) -> actually, the weight is of shape [out_features, in_features]. Then:\n   w_out_stride = self.weight.stride(0) = in_features? Actually, in PyTorch, for a tensor of shape [M, N], the stride(0) is N and stride(1) is 1.\n\n But note: the kernel arguments for the weight are:\n   w_out_stride, w_in_stride\n\n We are passing:\n   self.weight.stride(0) -> which is the stride for the output feature dimension (which is in_features, because to move one row we skip in_features elements) and stride(1) is 1.\n\n In the original weight loading, we did:\n   w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n   -> This gives a block of [BLOCK_SIZE_O, BLOCK_SIZE_K] because the offsets are [O, 1] and [1, K] -> so the result is a grid of [O, K] points.\n\n Now, we want a block of [BLOCK_SIZE_K, BLOCK_SIZE_O]. We can do:\n   w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n\n But note: the mask must also be adjusted accordingly.\n\n Let me write the new weight loading:\n\n   w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n   w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n\n Then w_block will be of shape [BLOCK_SIZE_K, BLOCK_SIZE_O].\n\n Now, the dot product: \n   x_block: [BLOCK_SIZE_B, BLOCK_SIZE_K]\n   w_block: [BLOCK_SIZE_K, BLOCK_SIZE_O]\n   -> tl.dot(x_block, w_block) gives [BLOCK_SIZE_B, BLOCK_SIZE_O] as desired.\n\n This matches the top-performing Program 1.\n\n Therefore, we change the weight loading to the transposed layout.\n\n Additionally, we note that the top-performing program also used this transposed layout.\n\n Let's update the kernel accordingly.\n\n We also note that the current program had the following for the weight block:\n   w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n   w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n\n We change it to:\n   w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n   w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n\n This should fix the shape issue.\n\n We leave the rest of the kernel unchanged.\n\n We also note that the current program sets the block sizes as:\n   BLOCK_SIZE_B = 16\n   BLOCK_SIZE_O = 64\n   BLOCK_SIZE_K = 32\n\n These are the same as in the top-performing program.\n\n Therefore, we make the minimal change to the weight loading.\n\n Let's write the updated kernel in the EVOLVE-BLOCK.\n\n IMPORTANT: We must not change the function signature or the grid configuration.\n\n We only change the two lines for the weight mask and the weight pointers.\n\n Also note: the current program is stored in the EVOLVE-BLOCK. We are to output the entire block with the change.\n\n We are going to output the entire code for the EVOLVE-BLOCK, but with the two lines for weight loading fixed.\n\n Let me copy the current program and change the two lines.\n\n Note: The current program has the following for the weight block:\n\n        # Load weight block\n        w_mask = (out_offsets[:, None] < out_features) & (k_offsets[None, :] < in_features)\n        w_ptrs = w_ptr + out_offsets[:, None] * w_out_stride + k_offsets[None, :] * w_in_stride\n\n We change these two lines to:\n\n        # Load weight block in transposed layout\n        w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n        w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n\n And then we do the same load: w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n\n We also change the comment to indicate we are loading in transposed layout.\n\n We leave the rest unchanged.\n\n We hope this will fix the compilation error and then we can get correctness and performance.\n\n However, note that the top-performing program had a comment about \"transposed weight layout\", so we add that.\n\n Let's write the updated code.\n</think>\nI'll modify the Triton kernel to fix the matrix multiplication shape mismatch error by correctly loading the weight block in transposed layout. The issue was with the weight matrix dimensions in the dot product operation. Here's the corrected implementation:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_matmul_scale_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    x_batch_stride, x_feature_stride,\n    w_out_stride, w_in_stride,\n    b_stride,\n    output_batch_stride, output_feature_stride,\n    batch, in_features, out_features,\n    scaling_factor,\n    BLOCK_SIZE_B: tl.constexpr, BLOCK_SIZE_O: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_o = tl.program_id(1)\n    \n    batch_offsets = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)\n    out_offsets = pid_o * BLOCK_SIZE_O + tl.arange(0, BLOCK_SIZE_O)\n    \n    acc = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_O), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block\n        x_mask = (batch_offsets[:, None] < batch) & (k_offsets[None, :] < in_features)\n        x_ptrs = x_ptr + batch_offsets[:, None] * x_batch_stride + k_offsets[None, :] * x_feature_stride\n        x_block = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block in transposed layout\n        w_mask = (out_offsets[None, :] < out_features) & (k_offsets[:, None] < in_features)\n        w_ptrs = w_ptr + out_offsets[None, :] * w_out_stride + k_offsets[:, None] * w_in_stride\n        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Matrix multiplication with transposed weight layout\n        acc += tl.dot(x_block, w_block)\n    \n    # Load bias block\n    b_ptrs = b_ptr + out_offsets * b_stride\n    b_mask = out_offsets < out_features\n    b_block = tl.load(b_ptrs, mask=b_mask, other=0.0)\n    \n    # Scale and add residual\n    acc = acc * (scaling_factor + 1.0) + b_block[None, :] * (scaling_factor + 1.0)\n    \n    # Store results\n    out_ptrs = output_ptr + batch_offsets[:, None] * output_batch_stride + out_offsets[None, :] * output_feature_stride\n    out_mask = (batch_offsets[:, None] < batch) & (out_offsets[None, :] < out_features)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch, _ = x.shape\n        out = torch.empty((batch, self.out_features), device=x.device, dtype=x.dtype)\n        \n        BLOCK_SIZE_B = 16\n        BLOCK_SIZE_O = 64\n        BLOCK_SIZE_K = 32\n        \n        grid_b = triton.cdiv(batch, BLOCK_SIZE_B)\n        grid_o = triton.cdiv(self.out_features, BLOCK_SIZE_O)\n        \n        _fused_matmul_scale_kernel[(grid_b, grid_o)](\n            x, self.weight, self.bias, out,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            out.stride(0), out.stride(1),\n            batch, self.in_features, self.out_features,\n            self.scaling_factor,\n            BLOCK_SIZE_B=BLOCK_SIZE_B, BLOCK_SIZE_O=BLOCK_SIZE_O, BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        return out\n\nbatch_size = 128\nin_features = 64\nout_features = 128\nscaling_factor = 0.5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\nThe key changes are:\n1. Fixed weight block loading to use transposed layout by adjusting the offsets and mask\n2. Updated the weight block pointer calculation to match the transposed layout\n3. Added comments to clarify the transposed weight layout\n4. Maintained all other parameters and block sizes for optimal performance\n\nThis should resolve the matrix shape compatibility issue while maintaining the same functionality and performance characteristics as the top-performing version."]}}}