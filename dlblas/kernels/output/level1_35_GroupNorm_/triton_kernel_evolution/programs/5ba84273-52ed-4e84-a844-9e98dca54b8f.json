{"id": "5ba84273-52ed-4e84-a844-9e98dca54b8f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({\"BLOCK_SIZE\": 1024}, num_warps=8),\n        triton.Config({\"BLOCK_SIZE\": 2048}, num_warps=8),\n        triton.Config({\"BLOCK_SIZE\": 4096}, num_warps=8),\n        triton.Config({\"BLOCK_SIZE\": 8192}, num_warps=8),\n        triton.Config({\"BLOCK_SIZE\": 1024}, num_warps=16),\n        triton.Config({\"BLOCK_SIZE\": 2048}, num_warps=16),\n        triton.Config({\"BLOCK_SIZE\": 4096}, num_warps=16),\n    ],\n    key=[\"n_channels\", \"H\", \"W\", \"n_groups\"],\n)\n@triton.jit\ndef group_norm_forward_kernel(\n    x_ptr,\n    y_ptr,\n    gamma_ptr,\n    beta_ptr,\n    n_groups,\n    n_channels,\n    H,\n    W,\n    eps,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    group_idx = pid % n_groups\n    sample_idx = pid // n_groups\n\n    channels_per_group = n_channels // n_groups\n    spatial_size = H * W\n    group_size = channels_per_group * spatial_size\n    base_offset = sample_idx * n_channels * spatial_size + group_idx * channels_per_group * spatial_size\n\n    # Precompute pointers and sizes\n    spatial_mask = tl.arange(0, BLOCK_SIZE) < spatial_size\n    spatial_offsets = tl.arange(0, BLOCK_SIZE)\n\n    # First pass: Compute mean and variance with vectorized loads\n    sum_val = 0.0\n    sum_sq_val = 0.0\n    for offset in range(0, group_size, BLOCK_SIZE):\n        offs = offset + tl.arange(0, BLOCK_SIZE)\n        mask = offs < group_size\n        data = tl.load(x_ptr + base_offset + offs, mask=mask, other=0.0)\n        sum_val += tl.sum(data, axis=0)\n        sum_sq_val += tl.sum(data * data, axis=0)\n    \n    mean = sum_val / group_size\n    variance = (sum_sq_val / group_size) - (mean * mean)\n    rstd = 1.0 / tl.sqrt(variance + eps)\n\n    # Second pass: Vectorized normalization and affine transform\n    for offset in range(0, group_size, BLOCK_SIZE):\n        offs = offset + tl.arange(0, BLOCK_SIZE)\n        mask = offs < group_size\n        data = tl.load(x_ptr + base_offset + offs, mask=mask, other=0.0)\n        \n        # Normalize\n        normalized = (data - mean) * rstd\n        \n        # Compute channel index using vectorized operations\n        channel_in_group = offs // spatial_size\n        global_channel_idx = group_idx * channels_per_group + channel_in_group\n        \n        # Vectorized gamma/beta loading\n        gamma = tl.load(gamma_ptr + global_channel_idx, mask=spatial_mask)\n        beta = tl.load(beta_ptr + global_channel_idx, mask=spatial_mask)\n        \n        # Apply affine transformation\n        out = normalized * gamma + beta\n        \n        # Vectorized store\n        tl.store(y_ptr + base_offset + offs, out, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_features: int, num_groups: int):\n        super(ModelNew, self).__init__()\n        self.num_features = num_features\n        self.num_groups = num_groups\n        self.weight = nn.Parameter(torch.ones(num_features))\n        self.bias = nn.Parameter(torch.zeros(num_features))\n        self.eps = 1e-5\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        n, c, h, w = x.shape\n        y = torch.empty_like(x)\n        grid = (n * self.num_groups,)\n        \n        group_norm_forward_kernel[grid](\n            x_ptr=x,\n            y_ptr=y,\n            gamma_ptr=self.weight,\n            beta_ptr=self.bias,\n            n_groups=self.num_groups,\n            n_channels=c,\n            H=h,\n            W=w,\n            eps=self.eps\n        )\n        return y\n\nbatch_size = 16\nfeatures = 64\nnum_groups = 8\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features, num_groups]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "9c09e214-98a7-4c0d-99df-b3ebea419fbc", "generation": 4, "timestamp": 1754639365.6968794, "iteration_found": 22, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.134, "runtime_ms": 0.37, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0497, "speed_up": 0.134, "custom_timing": 0.37}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.064, "runtime_ms": 0.781, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0497, "speed_up": 0.064, "custom_timing": 0.781}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}