{"id": "8fdf835e-a426-4573-a305-3b78524aa7b0", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, dilation: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.dilation = dilation\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n        \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n            \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, _, length = x.shape\n        output_length = (length - self.dilation * (self.kernel_size - 1) - 1) // self.stride + 1\n        \n        if output_length <= 0:\n            return torch.empty(batch_size, self.out_channels, 0, device=x.device)\n            \n        y = torch.empty(batch_size, self.out_channels, output_length, device=x.device, dtype=x.dtype)\n        \n        if self.bias is not None:\n            bias_data = self.bias\n        else:\n            bias_data = None\n            \n        grid = lambda meta: (batch_size * output_length * triton.cdiv(self.out_channels, meta['BLOCK_CHANNEL']),)\n        \n        _conv1d_kernel[grid](\n            x, y, self.weight, bias_data,\n            x.stride(0), x.stride(1), x.stride(2),\n            y.stride(0), y.stride(1), y.stride(2),\n            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2),\n            length, self.in_channels, self.out_channels,\n            self.kernel_size, self.stride, self.dilation, output_length,\n            bias_data is not None,\n            BLOCK_CHANNEL=128\n        )\n        return y\n\n@triton.jit\ndef _conv1d_kernel(\n    x_ptr, y_ptr, weight_ptr, bias_ptr,\n    x_batch_stride, x_channel_stride, x_length_stride,\n    y_batch_stride, y_channel_stride, y_length_stride,\n    w_out_stride, w_in_stride, w_k_stride,\n    L, C_in, C_out, K, S, D, output_length,\n    has_bias: tl.constexpr,\n    BLOCK_CHANNEL: tl.constexpr\n):\n    pid = tl.program_id(0)\n    total_programs = tl.num_programs(0)\n    \n    pid_batch_output = pid // tl.cdiv(C_out, BLOCK_CHANNEL)\n    pid_channel_block = pid % tl.cdiv(C_out, BLOCK_CHANNEL)\n    \n    batch_id = pid_batch_output // output_length\n    output_idx = pid_batch_output % output_length\n    input_start_idx = output_idx * S\n    \n    channel_start = pid_channel_block * BLOCK_CHANNEL\n    channel_offsets = channel_start + tl.arange(0, BLOCK_CHANNEL)\n    channel_mask = channel_offsets < C_out\n    \n    acc = tl.zeros((BLOCK_CHANNEL,), dtype=tl.float32)\n    \n    for k in range(K):\n        input_idx = input_start_idx + k * D\n        if input_idx < 0 or input_idx >= L:\n            continue\n            \n        for in_block_start in range(0, C_in, 32):\n            in_offsets = in_block_start + tl.arange(0, 32)\n            in_mask = in_offsets < C_in\n            \n            x_ptr_block = x_ptr + batch_id * x_batch_stride + input_idx * x_length_stride + in_block_start * x_channel_stride\n            w_ptr_block = weight_ptr + channel_start * w_out_stride + in_block_start * w_in_stride + k * w_k_stride\n            \n            x_vals = tl.load(x_ptr_block + in_offsets * x_channel_stride, mask=in_mask, other=0.0)\n            w_vals = tl.load(w_ptr_block + channel_offsets[:, None] * w_out_stride + in_offsets[None, :] * w_in_stride, \n                            mask=channel_mask[:, None] & in_mask[None, :], other=0.0)\n            \n            acc += tl.sum(x_vals[None, :] * w_vals, axis=1)\n    \n    if has_bias:\n        bias_vals = tl.load(bias_ptr + channel_offsets, mask=channel_mask, other=0.0)\n        acc += bias_vals\n    \n    y_ptr_out = y_ptr + batch_id * y_batch_stride + channel_offsets * y_channel_stride + output_idx * y_length_stride\n    tl.store(y_ptr_out, acc, mask=channel_mask)\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nlength = 256\nstride = 3\ndilation = 4\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, length)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "3d96afa1-257f-4245-aa50-9756cd6e08af", "generation": 1, "timestamp": 1754646288.2567363, "iteration_found": 3, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "name 'math' is not defined\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/evaluator.py\", line 173, in _verification_worker\n    result: KernelExecResult = eval_kernel_against_ref(\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 484, in eval_kernel_against_ref\n    custom_model = ModelNew(*init_args, **init_kwargs)\n  File \"/tmp/tmpyy75wcmq.py\", line 20, in __init__\n    self.reset_parameters()\n  File \"/tmp/tmpyy75wcmq.py\", line 23, in reset_parameters\n    nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\nNameError: name 'math' is not defined\n", "exec_log": "[Child] \u7ed1\u5b9a GPU 2, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 58, in <module>\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 844, in jit\n    return decorator(fn)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 832, in decorator\n    return JITFunction(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 635, in __init__\n    self.starting_line_number = inspect.getsourcelines(fn)[1]\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 958, in findsource\n    raise OSError('could not get source code')\nOSError: could not get source code\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0309, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0348, "speed_up": 1.126, "custom_timing": 0.0309}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}