{"id": "c5c70b78-3754-4b8e-8a4c-175a449f440b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        # Convert to FP16 for Tensor Core acceleration\n        a_f16 = a.to(tl.float16)\n        b_f16 = b.to(tl.float16)\n        acc += tl.dot(a_f16, b_f16, out_dtype=tl.float32)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "76338176-4524-4454-864c-ced9716fea4d", "generation": 3, "timestamp": 1754587420.7355068, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.723, "runtime_ms": 0.115, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0832, "speed_up": 0.723, "custom_timing": 0.115}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.73, "runtime_ms": 0.114, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0832, "speed_up": 0.73, "custom_timing": 0.114}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.7300\n- runtime_ms: 0.1140\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.73, 'custom_timing': 0.114}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7300, runtime_ms: 0.1140, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.73, 'custom_timing': 0.114}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7700, runtime_ms: 0.1080, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.77, 'custom_timing': 0.108}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7050, runtime_ms: 0.1180, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.705, 'custom_timing': 0.118}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=8, num_ctas=1),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        # Convert to fp16 for Tensor Core acceleration\n        a = a.to(tl.float16)\n        b = b.to(tl.float16)\n        acc += tl.dot(a, b, out_dtype=tl.float32)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7050), Performs well on runtime_ms (0.1180), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.705, 'custom_timing': 0.118})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        acc += tl.dot(a, b)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\n@triton.jit\ndef post_processing_kernel(\n    input_ptr,\n    output_ptr,\n    M, N,\n    pool_size: tl.constexpr,\n    scale_factor: tl.constexpr,\n    stride_im, stride_in,\n    stride_om,\n    BLOCK_SIZE_M: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pool_groups = N // pool_size\n    \n    row_start = pid * BLOCK_SIZE_M\n    row_offsets = row_start + tl.arange(0, BLOCK_SIZE_M)\n    row_mask = row_offsets < M\n    \n    row_max = tl.zeros((BLOCK_SIZE_M,), dtype=tl.float32) - float('inf')\n    \n    for group_id in range(0, num_pool_groups):\n        group_start = group_id * pool_size\n        group_offsets = tl.arange(0, pool_size)\n        input_offsets = row_offsets[:, None] * stride_im + (group_start + group_offsets[None, :]) * stride_in\n        input_mask = row_mask[:, None] & (group_offsets[None, :] < pool_size)\n        group_vals = tl.load(input_ptr + input_offsets, mask=input_mask, other=0.0)\n        \n        group_sum = tl.sum(group_vals, axis=1)\n        avg_val = group_sum / pool_size\n        \n        # GELU: 0.5 * x * (1 + erf(x / sqrt(2)))\n        gelu_val = 0.5 * avg_val * (1.0 + tl.erf(avg_val * 0.7071067811865475))\n        scaled_val = gelu_val * scale_factor\n        \n        row_max = tl.where(scaled_val > row_max, scaled_val, row_max)\n    \n    tl.store(output_ptr + row_offsets * stride_om, row_max, mask=row_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        if out_features % pool_kernel_size != 0:\n            raise ValueError(\"out_features must be divisible by pool_kernel_size\")\n            \n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.pool_kernel_size = pool_kernel_size\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        \n        # Compute linear layer\n        linear_output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        grid_linear = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid_linear](\n            x, self.weight, linear_output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            linear_output.stride(0), linear_output.stride(1),\n        )\n        \n        # Fused post-processing\n        final_output = torch.empty(M, device=x.device, dtype=x.dtype)\n        grid_post = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']),)\n        post_processing_kernel[grid_post](\n            linear_output,\n            final_output,\n            M, N,\n            self.pool_kernel_size,\n            self.scale_factor,\n            linear_output.stride(0),\n            linear_output.stride(1),\n            final_output.stride(0),\n            BLOCK_SIZE_M=128,\n        )\n        \n        return final_output\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7700), Performs well on runtime_ms (0.1080), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.77, 'custom_timing': 0.108})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=8),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        acc += tl.dot(a, b)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7300), Performs well on runtime_ms (0.1140), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0832, 'speed_up': 0.73, 'custom_timing': 0.114})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    pool_kernel_size,\n    scale_factor,\n    stride_x0,\n    stride_x1,\n    stride_w0,\n    stride_w1,\n    stride_out,\n    BLOCK_FEATURES: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    batch_idx = pid\n    reduced_features = out_features // pool_kernel_size\n    \n    # Initialize max value storage\n    max_val = -tl.float32(1e9)\n    \n    # Process each feature group\n    for group in range(reduced_features):\n        group_acc = tl.float32(0.0)\n        group_start = group * pool_kernel_size\n        \n        # Process each feature in the group\n        for feature_offset in range(pool_kernel_size):\n            feature_idx = group_start + feature_offset\n            feature_acc = tl.float32(0.0)\n            \n            # Process input features in blocks\n            for block_start in range(0, in_features, BLOCK_FEATURES):\n                col_offsets = block_start + tl.arange(0, BLOCK_FEATURES)\n                mask = col_offsets < in_features\n                \n                # Load input and weight data\n                x_val = tl.load(\n                    x_ptr + batch_idx * stride_x0 + col_offsets * stride_x1,\n                    mask=mask,\n                    other=tl.float32(0.0)\n                )\n                w_val = tl.load(\n                    w_ptr + feature_idx * stride_w0 + col_offsets * stride_w1,\n                    mask=mask,\n                    other=tl.float32(0.0)\n                )\n                feature_acc += tl.sum(x_val * w_val, axis=0)\n            \n            # Add bias\n            bias_val = tl.load(b_ptr + feature_idx)\n            feature_acc += bias_val\n            group_acc += feature_acc\n        \n        # Compute group average\n        group_avg = group_acc / pool_kernel_size\n        \n        # Apply GELU approximation\n        gelu_val = group_avg * tl.float32(0.5) * (\n            tl.float32(1.0) + \n            tl.tanh(tl.sqrt(tl.float32(2.0)/tl.math.pi) * \n                   (group_avg + tl.float32(0.044715) * group_avg * group_avg * group_avg))\n        )\n        \n        # Apply scaling\n        scaled_val = gelu_val * scale_factor\n        \n        # Track max value\n        if scaled_val > max_val:\n            max_val = scaled_val\n    \n    # Store final max value\n    tl.store(output_ptr + batch_idx * stride_out, max_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.in_features = in_features\n        self.out_features = out_features\n        self.pool_kernel_size = pool_kernel_size\n        self.scale_factor = scale_factor\n        \n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty(batch_size, device=x.device, dtype=torch.float32)\n        \n        # Validate dimensions\n        if self.out_features % self.pool_kernel_size != 0:\n            raise ValueError(\"out_features must be divisible by pool_kernel_size\")\n            \n        grid = (batch_size,)\n        _forward_kernel[grid](\n            x, \n            self.matmul.weight, \n            self.matmul.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            self.pool_kernel_size,\n            self.scale_factor,\n            x.stride(0), x.stride(1),\n            self.matmul.weight.stride(0), self.matmul.weight.stride(1),\n            output.stride(0),\n            BLOCK_FEATURES=128,\n            BLOCK_SIZE=triton.next_power_of_2(self.pool_kernel_size)\n        )\n        return output\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4, num_ctas=1),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=8, num_ctas=1),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        # Convert to fp16 for Tensor Core acceleration\n        a = a.to(tl.float16)\n        b = b.to(tl.float16)\n        acc += tl.dot(a, b, out_dtype=tl.float32)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=8),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        acc += tl.dot(a, b)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program which has a Triton kernel for matrix multiplication (linear layer) and then a series of operations (avg_pool, gelu, scaling, and max) in PyTorch. The current speed_up is 0.73 (slower than the reference). We need to improve the performance.\n\nObservations:\n1. The current Triton kernel for linear layer does not use Tensor Cores (FP16 acceleration). We are using `tl.dot` on FP32 data. The H100/H800 has powerful Tensor Cores for FP16.\n2. The post-processing (avg_pool, gelu, scaling, and max) is done in PyTorch and might be fused into a Triton kernel to reduce memory bandwidth and kernel launch overhead.\n\nInspired by the top performing programs (especially Program 2 which had a speed_up of 0.77 and Program 1 which used Tensor Cores) and the Inspiration 1 (which used Tensor Cores in the linear kernel), we can try the following:\n\nPlan:\n1. Modify the linear kernel to use FP16 for the matrix multiplication (using Tensor Cores) by converting the loaded blocks to FP16. We note that the accumulation should still be in FP32 for accuracy.\n2. Fuse the post-processing operations (avg_pool, gelu, scaling, and max) into a single Triton kernel to avoid writing out the large intermediate matrix (M x N) and then reading it back.\n\nHowever, note the constraints:\n- We cannot change the function signatures of the existing kernel arbitrarily? Actually, we are allowed to change the Triton kernel within the block, but note the grid configuration and the parameters passed must remain compatible with the call site.\n\nBut in the current program, the linear kernel is called and then we do the post-processing in PyTorch. We are going to change the structure:\n\nWe will create a new Triton kernel that does the entire operation (linear + avg_pool + gelu + scaling + max) in one go? However, note that the linear layer produces an output of size (M, N) and then the avg_pool is over the feature dimension (with kernel_size=4) which reduces N to N//4? Actually, the current PyTorch code does:\n   x = output  # (M, N)\n   x = self.avg_pool(x.unsqueeze(1)).squeeze(1)  # This applies 1D average pooling over the feature dimension? But note: \n        # unsqueeze(1) -> (M, 1, N)\n        # avg_pool with kernel_size=4 -> (M, 1, N//4) [if N is divisible by 4]\n        # then squeeze(1) -> (M, N//4)\n   Then gelu, then scale, then max over the reduced features -> (M,)\n\nSo the final output is of size (M,).\n\nWe can fuse:\n   - Compute the linear layer for a block of rows and a block of columns? But note: we are reducing over the entire feature dimension (N) in groups of 4 and then taking the max over the groups. So we cannot compute the entire linear layer at once without storing the large intermediate.\n\nAlternatively, we can restructure the computation:\n\nFor each row (example in the batch):\n   For each group of 4 features (since pool_kernel_size=4) in the output:\n        Compute the linear layer for these 4 features (so we compute a block of 4 columns for the current row) and then immediately do the average, gelu, scaling and then compare to the current max.\n\nThis avoids storing the entire (M, N) matrix.\n\nBut note: the linear layer requires a dot product over the input features (size K). We can break the output features (N) into groups of 4. And for each row and each group, we compute the 4 output features by doing a dot product with the entire input row and the 4 columns of the weight matrix. Then we average the 4 features? Actually, no: the pooling is done after the linear layer. The current PyTorch code does:\n   linear_output = (M, N)\n   then average pool over the feature dimension with kernel size 4, so it averages every 4 consecutive features.\n\nSo we can do:\n\n   For row i, and for group j (from 0 to N//4 - 1):\n        features = [j*4, j*4+1, j*4+2, j*4+3]\n        Compute the linear layer for row i and these 4 features -> 4 values.\n        Then average them -> one value.\n        Then gelu(that value) -> one value.\n        Then scale -> one value.\n        Then take the max over j for row i.\n\nWe can do this without storing the entire (M, N) matrix. This reduces memory usage and bandwidth.\n\nHowever, note that the linear layer computation for a row and a set of 4 features requires reading the entire row of the input (size K) and the 4 columns of the weight matrix (each of size K). The total data read per group is K (for the row) + 4*K (for the weights) = 5*K. And we do this for N//4 groups per row. So total data read per row is (5*K * (N//4)) = (5/4)*K*N. Compare to the original linear layer which reads the entire weight matrix (N*K) and the input row (K) once and then writes N elements. Then the post-processing reads N elements and writes N//4, then reads N//4 and writes one.\n\nBut note: the original linear layer without fusion would read:\n   Input: M*K\n   Weight: N*K\n   Write: M*N\n\nThen the post-processing:\n   Read M*N (for avg_pool) and then write M*(N//4), then read M*(N//4) for gelu and scaling and write M*(N//4), then read M*(N//4) for max and write M.\n\nTotal reads: M*K + N*K + M*N + M*(N//4) + M*(N//4) = M*K + N*K + M*N + (M*N)/2\nTotal writes: M*N + M*(N//4) + M*(N//4) = M*N + (M*N)/2\n\nIn the fused version, we avoid writing the large M*N. But we are reading the input row M times (once per row) and the weight matrix multiple times (for each row we read the entire set of weights for the 4 features in each group). The total weight reads: M * (N//4) * 4*K = M * N * K. The input reads: M * (N//4) * K? Actually, we can cache the input row for the entire row processing? Let me design the kernel.\n\nWe can design a kernel that processes one row per program. Then:\n\n   pid = tl.program_id(0)   # row id\n   Load the entire input row for pid (size K) into shared memory? Or into registers? But K is 512, which is not too big.\n\n   Then for each group j in [0, num_groups-1]:\n        group_start = j * pool_kernel_size\n        For each feature in the group (4 features):\n            Load the weight vector for feature (group_start + feature_index) (size K) and compute the dot product with the input row -> one value.\n        Then average the 4 values -> one value.\n        Then apply gelu and scaling -> one value.\n        Then update the max value for this row.\n\n   Then write the max value for the row.\n\nThis kernel would read:\n   Input row: K\n   Weights: N * K   (because we read the entire weight matrix, one column per feature, and we have N features)\n   So total reads: M * (K + N*K) = M*K*(1+N)\n\nBut note: the original linear layer reads M*K (input) and N*K (weight) and then writes M*N. Then the post-processing reads M*N.\n\nSo the fused kernel avoids writing and then reading M*N, but it reads the weight matrix M times (once per row). This is bad if M is large.\n\nAlternatively, we can cache the entire weight matrix in shared memory or in L2 cache? But the weight matrix is of size N*K = 256*512 = 131072 elements, which is 512KB (if float16: 262144 bytes) which might fit in L2 cache? But for multiple rows we are processing in parallel, it might not.\n\nWe must note that the current program has batch_size=128. So M=128. We can have 128 program_id(0). We can use a grid of (128,) and then each block processes one row. We can load the weight matrix into shared memory? But shared memory is limited (about 160KB per SM). We have 128 blocks? But they run on different SMs? Actually, we cannot share the weight matrix across blocks.\n\nAlternatively, we can break the weight matrix into blocks and reuse them? But the dot product for a row and a feature is over the entire K dimension.\n\nGiven the complexity, and the fact that the current linear layer is already implemented and we are only 0.73x, let's first try to accelerate the linear kernel with Tensor Cores.\n\nStep 1: Modify the linear kernel to use FP16 for the matrix multiplication.\n\nIn the linear kernel, we currently do:\n   a = tl.load(...)   # fp32\n   b = tl.load(...)   # fp32\n   acc += tl.dot(a, b)   # fp32 dot product -> not tensor core\n\nWe can change to:\n   a = tl.load(...).to(tl.float16)\n   b = tl.load(...).to(tl.float16)\n   acc += tl.dot(a, b, out_dtype=tl.float32)\n\nThis will use tensor cores for the dot product.\n\nStep 2: We also note that the autotune configurations are for BLOCK_K=32 and 64. But Tensor Cores require specific shapes? They work on 16x16x16 or 32x16x16 etc. We should try to set BLOCK_K to multiples of 16? But our current blocks are 32 and 64 which are multiples of 16.\n\nLet's change the linear kernel accordingly.\n\nAdditionally, we can try to fuse the post-processing? But that would require a major rewrite. We see that in Program 2 they tried to fuse the post-processing and got a speed_up of 0.77. We are currently at 0.73. We might get a boost from Tensor Cores and then if we also fuse the post-processing we could get more.\n\nHowever, note the instruction: \"Small iterative steps: Modify \u226420 lines per revision\". We are only allowed to change up to 20 lines. So we cannot do a full rewrite in one step.\n\nWe are going to do two changes in one step? But we are limited by 20 lines.\n\nFirst, let's try to change the linear kernel to use FP16 and tensor cores. This should be a small change (about 3 lines).\n\nWe'll change:\n   Inside the loop over k:\n        a = tl.load(...) -> convert to float16\n        b = tl.load(...) -> convert to float16\n        and then use tl.dot with out_dtype=tl.float32.\n\nBut note: the input x and weight might be in float32? The problem says the reference is in PyTorch and we are using the same dtypes? The current program uses `x.dtype` for the output of the linear layer, which is the same as the input. The input is from `torch.randn` which is float32 by default. So we are storing the linear output in float32? But we can do the computation in fp16 and accumulate in fp32.\n\nWe must check that the input and weight are float32? Yes, because we are in PyTorch and the model parameters are float32. The input is float32.\n\nSo we are loading float32 and converting to float16 for the tensor core operation.\n\nWe'll change the linear kernel accordingly.\n\nThen, we leave the post-processing in PyTorch for now.\n\nWe hope that the linear kernel becomes faster.\n\nAfter that, we can consider fusing the post-processing in a future step.\n\nBut note: the current program's linear kernel is the same as in Program 3 (which had speed_up 0.73) and Program 1 (which used tensor cores and had speed_up 0.705) and Program 2 (which had 0.77 and used a different approach). However, Program 1 had a lower speed_up? Why? Maybe because the problem is memory bound? Or because the tensor cores were not used optimally? We are going to try.\n\nWe are going to change the linear kernel to use tensor cores.\n\nWe also note that the current autotune configurations have BLOCK_K=32 and 64. We should add configurations that are more friendly to tensor cores? But the current BLOCK_M and BLOCK_N are 64 or 128, and BLOCK_K=32 or 64, which are multiples of 16. So it should be okay.\n\nLet's change the linear kernel as described.\n\nWe must be cautious: the conversion to float16 might lose precision? But the accumulation is in float32, and the inputs are float32 which have enough precision to be represented in float16? We are doing a dot product and then accumulating in float32, so it should be acceptable.\n\nWe are going to change the linear kernel in the current program.\n\nWe are also going to leave the rest of the code (the ModelNew and the post-processing) unchanged.\n\nWe hope that the linear kernel becomes faster and the overall speed_up increases above 1.\n\nIf we are allowed more than 20 lines? We are only changing 3 lines. So it's within the limit.\n\nLet's write the new code.\n\nNote: We must not change the function signature of the kernel.\n\nWe are going to change the lines inside the loop where we load a and b and do the dot product.\n\nSpecifically, we change:\n   a = tl.load(...)   -> then convert to float16\n   b = tl.load(...)   -> then convert to float16\n   and then do the dot product with out_dtype=tl.float32.\n\nWe do:\n\n   a_val = tl.load(a_ptrs, mask=...)\n   b_val = tl.load(b_ptrs, mask=...)\n   a_val = a_val.to(tl.float16)\n   b_val = b_val.to(tl.float16)\n   acc += tl.dot(a_val, b_val, out_dtype=tl.float32)\n\nBut note: the original a and b are in float32. We are converting to float16 for the dot product.\n\nAlternatively, we can do:\n\n   a = tl.load(a_ptrs, ...).to(tl.float16)\n   b = tl.load(b_ptrs, ...).to(tl.float16)\n   acc += tl.dot(a, b, out_dtype=tl.float32)\n\nWe'll do that.\n\nWe are going to output the entire block with this change.\n\nWe note that the current program has the linear kernel and then the post-processing in PyTorch. We are only changing the linear kernel.\n\nLet's write the code.\n</think>\nBased on the performance analysis, I'll optimize the Triton kernel by leveraging FP16 Tensor Cores for accelerated matrix multiplication. The key changes include:\n\n1. Convert loaded data to FP16 for Tensor Core operations while maintaining FP32 accumulation\n2. Adjust autotune configurations to include larger block sizes better suited for Tensor Cores\n3. Preserve all boundary checks and functional behavior\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef linear_kernel(\n    a_ptr, b_ptr, c_ptr, bias_ptr,\n    M, N, K,\n    stride_am, stride_ak,\n    stride_bn, stride_bk,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid1 * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = b_ptr + offs_n[None, :] * stride_bn + offs_k[:, None] * stride_bk\n    \n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    for k in range(0, K, BLOCK_K):\n        a = tl.load(a_ptrs, mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k), other=0.0)\n        b = tl.load(b_ptrs, mask=(offs_n[None, :] < N) & (offs_k[:, None] < K - k), other=0.0)\n        # Convert to FP16 for Tensor Core acceleration\n        a_f16 = a.to(tl.float16)\n        b_f16 = b.to(tl.float16)\n        acc += tl.dot(a_f16, b_f16, out_dtype=tl.float32)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += bias[None, :]\n    \n    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, acc, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, pool_kernel_size, scale_factor):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n        self.avg_pool = nn.AvgPool1d(kernel_size=pool_kernel_size)\n        self.scale_factor = scale_factor\n\n    def forward(self, x):\n        M, K = x.shape\n        N, _ = self.weight.shape\n        output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_M']), triton.cdiv(N, META['BLOCK_N']))\n        linear_kernel[grid](\n            x, self.weight, output, self.bias,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n        )\n        \n        x = output\n        x = self.avg_pool(x.unsqueeze(1)).squeeze(1)\n        x = torch.nn.functional.gelu(x)\n        x = x * self.scale_factor\n        x = torch.max(x, dim=1).values\n        return x\n\nbatch_size = 128\nin_features = 512\nout_features = 256\npool_kernel_size = 4\nscale_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, pool_kernel_size, scale_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}