{"id": "5092794b-55d3-42db-bdae-6d6e05c20435", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n# Triton kernel for 1x1 convolution\n@triton.jit\ndef conv1x1_kernel(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    in_channels, out_channels, stride_x_b, stride_x_h, stride_x_w, stride_x_c,\n    stride_out_b, stride_out_h, stride_out_w, stride_out_c,\n    stride_weight_oc, stride_weight_ic,\n    height, width, batch_size,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_IC: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pixels = batch_size * height * width\n    if pid >= num_pixels:\n        return\n\n    # Calculate spatial indices\n    b_idx = pid // (height * width)\n    hw = pid % (height * width)\n    i_idx = hw // width\n    j_idx = hw % width\n\n    # Compute base pointers for current pixel\n    base_x = x_ptr + b_idx * stride_x_b + i_idx * stride_x_h + j_idx * stride_x_w\n    base_output = output_ptr + b_idx * stride_out_b + i_idx * stride_out_h + j_idx * stride_out_w\n\n    # Process output channels in blocks\n    for oc_block_start in range(0, out_channels, BLOCK_SIZE_OC):\n        oc_offsets = oc_block_start + tl.arange(0, BLOCK_SIZE_OC)\n        oc_mask = oc_offsets < out_channels\n        acc = tl.zeros((BLOCK_SIZE_OC,), dtype=tl.float32)\n\n        # Process input channels in blocks\n        for ic_block_start in range(0, in_channels, BLOCK_SIZE_IC):\n            ic_offsets = ic_block_start + tl.arange(0, BLOCK_SIZE_IC)\n            ic_mask = ic_offsets < in_channels\n\n            # Load input block\n            x_vals = tl.load(base_x + ic_offsets * stride_x_c, mask=ic_mask, other=0.0)\n            \n            # Load weight block\n            weight_ptrs = weight_ptr + oc_offsets[:, None] * stride_weight_oc + ic_offsets[None, :] * stride_weight_ic\n            w_block = tl.load(weight_ptrs, mask=oc_mask[:, None] & ic_mask[None, :], other=0.0)\n            \n            # Compute partial dot product\n            acc += tl.sum(x_vals[None, :] * w_block, axis=1)\n\n        # Load bias and store results\n        bias_vals = tl.load(bias_ptr + oc_offsets, mask=oc_mask, other=0.0)\n        output_vals = acc + bias_vals\n        tl.store(base_output + oc_offsets * stride_out_c, output_vals, mask=oc_mask)\n\ndef conv1x1_triton(x, weight, bias):\n    batch, in_channels, height, width = x.shape\n    out_channels = weight.shape[0]\n    output = torch.empty((batch, out_channels, height, width), device=x.device, dtype=x.dtype)\n    \n    # Ensure contiguous tensors\n    x = x.contiguous()\n    weight = weight.contiguous()\n    bias = bias.contiguous()\n    \n    # Launch kernel\n    num_pixels = batch * height * width\n    grid = (num_pixels,)\n    conv1x1_kernel[grid](\n        x, weight, bias, output,\n        in_channels, out_channels,\n        x.stride(0), x.stride(2), x.stride(3), x.stride(1),\n        output.stride(0), output.stride(2), output.stride(3), output.stride(1),\n        weight.stride(0), weight.stride(1),\n        height, width, batch,\n        BLOCK_SIZE_OC=128,\n        BLOCK_SIZE_IC=32\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj):\n        super(ModelNew, self).__init__()\n        \n        # 1x1 convolution branch - replaced with Triton implementation\n        self.weight_1x1 = nn.Parameter(torch.Tensor(out_1x1, in_channels, 1, 1))\n        self.bias_1x1 = nn.Parameter(torch.Tensor(out_1x1))\n        nn.init.kaiming_uniform_(self.weight_1x1, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight_1x1)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias_1x1, -bound, bound)\n        \n        # 3x3 convolution branch\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_3x3, kernel_size=1),\n            nn.Conv2d(reduce_3x3, out_3x3, kernel_size=3, padding=1)\n        )\n        \n        # 5x5 convolution branch\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, reduce_5x5, kernel_size=1),\n            nn.Conv2d(reduce_5x5, out_5x5, kernel_size=5, padding=2)\n        )\n        \n        # Max pooling branch\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n        )\n    \n    def forward(self, x):\n        branch1x1 = conv1x1_triton(x, self.weight_1x1.squeeze(-1).squeeze(-1), self.bias_1x1)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        \n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n# Test code\nin_channels = 480\nout_1x1 = 192\nreduce_3x3 = 96\nout_3x3 = 208\nreduce_5x5 = 16\nout_5x5 = 48\npool_proj = 64\nbatch_size = 10\nheight = 224\nwidth = 224\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_1x1, reduce_3x3, out_3x3, reduce_5x5, out_5x5, pool_proj]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b6dcfbf5-4684-4ec2-92c1-da7ff60fc74b", "generation": 1, "timestamp": 1754593440.9246402, "iteration_found": 0, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.01, "runtime_ms": 28.8, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.301, "speed_up": 0.01, "custom_timing": 28.8}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 8.76, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.301, "speed_up": 0.034, "custom_timing": 8.76}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}