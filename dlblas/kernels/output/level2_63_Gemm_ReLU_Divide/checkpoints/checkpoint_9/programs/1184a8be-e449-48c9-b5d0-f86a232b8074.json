{"id": "1184a8be-e449-48c9-b5d0-f86a232b8074", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_relu_div(\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    divisor,\n    stride_input0, stride_weight0, stride_weight1, stride_output0,\n    in_features, out_features,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_col_block = tl.program_id(1)\n    \n    col_offsets = pid_col_block * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    col_mask = col_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_offsets = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        k_mask = k_offsets < in_features\n        \n        input_ptr_row = input_ptr + pid_batch * stride_input0 + k_offsets\n        input_chunk = tl.load(input_ptr_row, mask=k_mask, other=0.0)\n        \n        weight_ptr_block = weight_ptr + col_offsets[:, None] * stride_weight0 + k_offsets[None, :] * stride_weight1\n        weight_chunk = tl.load(weight_ptr_block, mask=col_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        acc += tl.sum(input_chunk[None, :] * weight_chunk, axis=1)\n    \n    if bias_ptr is not None:\n        bias_vals = tl.load(bias_ptr + col_offsets, mask=col_mask, other=0.0)\n        acc += bias_vals\n    \n    acc = tl.maximum(acc, 0.0)\n    acc = acc / divisor\n    \n    output_ptr_row = output_ptr + pid_batch * stride_output0 + col_offsets\n    tl.store(output_ptr_row, acc, mask=col_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, divisor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.divisor = divisor\n        \n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        grid = (x.size(0), triton.cdiv(self.out_features, 256))\n        \n        fused_linear_relu_div[grid](\n            x, self.weight, self.bias, output,\n            self.divisor,\n            x.stride(0), self.weight.stride(0), self.weight.stride(1), output.stride(0),\n            self.in_features, self.out_features\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "84f00626-3928-4355-aa12-d486d2922126", "generation": 1, "timestamp": 1754573180.2337177, "iteration_found": 3, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_63_Gemm_ReLU_Divide", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "max_difference": ["1.228441", "1.178561", "1.217971", "1.217971"], "avg_difference": ["0.122449", "0.122603", "0.122586", "0.122596"], "correctness_issue": "Output mismatch", "correctness_trials": "(1 / 5)", "reference_timing_ms": 0.0548, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0602, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0548, "speed_up": 0.91, "custom_timing": 0.0602}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.0602\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0548, 'speed_up': 0.91, 'custom_timing': 0.0602}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.0602, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0548, 'speed_up': 0.91, 'custom_timing': 0.0602}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.0602), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0548, 'speed_up': 0.91, 'custom_timing': 0.0602})\n\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies ReLU, and divides by a constant.\n    \"\"\"\n    def __init__(self, in_features, out_features, divisor):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.divisor = divisor\n\n    def forward(self, x):\n        x = self.linear(x)\n        x = torch.relu(x)\n        x = x / self.divisor\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a simple model that does:\n   x = linear(x)\n   x = relu(x)\n   x = x / divisor\n\nThe current implementation uses a standard nn.Linear and then element-wise operations.\n\nHowever, note that the current performance shows a speed_up of 0.91 (which is less than 1) meaning our custom implementation is slower than the reference.\n\nWe are to rewrite the program to improve performance, specifically by using Triton for the linear layer and the subsequent operations.\n\nConstraints:\n- We cannot change the function signatures (the forward method, the class name, the get_inputs, get_init_inputs)\n- We must maintain the same inputs and outputs.\n\nApproach:\n1. We will replace the nn.Linear with a Triton kernel that does the matrix multiplication, then applies ReLU and division by divisor in the same kernel to avoid multiple kernel launches and to fuse the operations.\n\n2. We note that the current implementation uses a single kernel for the entire operation, which can be more efficient.\n\n3. We design a Triton kernel for the fused operation: matmul + relu + division.\n\n4. We must handle the parameters (weight and bias) appropriately.\n\nSteps for the Triton kernel:\n   - The kernel will take the input tensor, weight matrix, bias vector (if exists), and the divisor.\n   - We will compute the matrix multiplication in blocks.\n   - Then we apply ReLU and division by divisor.\n\nHowever, note that the original nn.Linear has a bias. We must account for that.\n\nWe can break down the operation as:\n   output = relu( (input @ weight.t()) + bias ) / divisor\n\nWe can do:\n   - Load a block of input and weight.\n   - Compute the dot product for a block of the output.\n   - Add the bias (if present) for that row.\n   - Apply ReLU and then divide by divisor.\n\nBut note: the current model does not have a bias in the nn.Linear? Actually, by default nn.Linear has bias=True. However, in our model we did not specify, so it uses the default.\n\nWe must initialize the linear layer with bias? The current code does. So we have to handle bias.\n\nWe will write a Triton kernel that does:\n   For each row of input:\n      For each column of output (or each element in the output row):\n          acc = 0\n          for k in range(K): # K is in_features\n             acc += input[i, k] * weight[j, k]   # but note: weight in nn.Linear is stored as [out_features, in_features] and we do input @ weight.t()\n          Then add bias[j] to acc.\n          Then relu(acc) and then divide by divisor.\n\nWe can do this with a block-oriented approach.\n\nAlternatively, we can use a kernel that does the entire row of output for a given input row.\n\nWe note that the output has shape [batch_size, out_features]. We can assign each row of the output to a program id, and then within the row, we can split the columns into blocks.\n\nBut note: we want to use multiple warps and blocks to parallelize over both rows and columns? However, the batch_size is 128 and out_features is 512. We can do:\n   - Let each block handle a set of rows? Or each block handles a row and then splits the columns? Or we can do 2D grid.\n\nGiven the sizes, we can do:\n   - Grid: (batch_size, ceil(out_features / BLOCK_SIZE))\n   - Each block computes a contiguous block of the row (BLOCK_SIZE elements).\n\nBut note: we are going to have to load the same input row for multiple blocks (for the same row index but different columns). So we can load the input row once in shared memory? However, Triton doesn't have shared memory. We can use registers and reuse.\n\nAlternatively, we can assign one row to one program id (so grid of (batch_size,)) and then have the kernel compute the entire row. But then we are limited by the number of columns we can process in one kernel (we can use multiple blocks? Actually, we can use a 1D grid and then have a loop over blocks of columns).\n\nGiven that out_features is 512, we can process the entire row in one kernel if we use a block size of 512? But 512 is within the limit (1024 per block). However, we might want to use multiple warps.\n\nAlternatively, we can use a 1D grid of size (batch_size * ceil(out_features / BLOCK_SIZE)) and then each program id computes one element? That would be too many and not efficient.\n\nWe choose:\n   - 1D grid over batch_size. Each program id (pid) is a row index in the batch.\n   - Then we split the columns (out_features) into blocks. We'll have a loop over blocks of columns.\n\nSteps for the kernel:\n\n   pid = tl.program_id(0)   # row index in [0, batch_size)\n   # We have to compute the entire row of output: from column 0 to out_features-1.\n\n   # We'll break the columns into blocks of size BLOCK_SIZE_N.\n   for j_block in range(0, out_features, BLOCK_SIZE_N):\n        j = j_block + tl.arange(0, BLOCK_SIZE_N)\n        mask = j < out_features\n\n        # Load the weight block: [BLOCK_SIZE_N, in_features]\n        # But note: weight is stored as [out_features, in_features]. We are loading a block of rows (each row is a feature vector for one output neuron).\n        weight_block_ptr = weight_ptr + j[:, None] * stride_weight_0 + tl.arange(0, in_features)[None, :] * stride_weight_1\n        weight_block = tl.load(weight_block_ptr, mask=mask[:, None], other=0.0)\n\n        # Initialize the accumulator for this block of the row.\n        acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n        # Loop over the input row in chunks to reduce memory pressure.\n        for i_block in range(0, in_features, BLOCK_SIZE_K):\n            i = i_block + tl.arange(0, BLOCK_SIZE_K)\n            mask_k = i < in_features\n\n            # Load the input chunk: [1, BLOCK_SIZE_K]\n            input_ptr_chunk = input_ptr + pid * stride_input_0 + i\n            input_chunk = tl.load(input_ptr_chunk, mask=mask_k, other=0.0)   # [BLOCK_SIZE_K]\n\n            # Load the weight chunk for this block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n            weight_chunk_ptr = weight_block_ptr + i[None, :] * stride_weight_1\n            weight_chunk = tl.load(weight_chunk_ptr, mask=mask[:, None] & mask_k[None, :], other=0.0)\n\n            # Compute the dot product for this chunk.\n            acc += tl.sum(input_chunk[None, :] * weight_chunk, axis=1)\n\n        # Now add bias for this block of columns.\n        if bias_ptr is not None:\n            bias_block_ptr = bias_ptr + j\n            bias_block = tl.load(bias_block_ptr, mask=mask, other=0.0)\n            acc += bias_block\n\n        # Apply ReLU: max(0, acc)\n        acc = tl.maximum(acc, 0.0)\n\n        # Divide by divisor\n        acc = acc / divisor\n\n        # Write the output block: [BLOCK_SIZE_N]\n        output_ptr_block = output_ptr + pid * out_features + j\n        tl.store(output_ptr_block, acc, mask=mask)\n\nBut note: the above kernel does the entire row in one program, but we are looping over the columns in blocks? Actually, we are looping over the input features (K dimension) and then over the output features in blocks? Actually, we are processing a block of output features at a time and within that block we are looping over the input features.\n\nAlternatively, we can do a single loop over K and accumulate the entire row? That would require storing a row of out_features in registers. Since out_features=512, we can do that. But we must be cautious about the number of registers.\n\nWe can do:\n\n   pid = tl.program_id(0)   # row index\n   # We are going to compute the entire row of output (out_features elements)\n\n   # We need to allocate a buffer of size out_features for the accumulator? But we don't know out_features at compile time. We can break the row into blocks? Or we can use a loop over the columns? Actually, we can break the row into fixed-size blocks.\n\n   # Instead, we can use a 2D grid: (batch_size, num_blocks) where num_blocks = ceil(out_features / BLOCK_SIZE_N)\n\n   pid_batch = tl.program_id(0)\n   pid_col_block = tl.program_id(1)\n\n   j = pid_col_block * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n   mask = j < out_features\n\n   # Now we want to compute the entire block of the row for the columns in j.\n\n   # We'll accumulate in a vector of size BLOCK_SIZE_N.\n   acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n   # Loop over K (in_features) in blocks.\n   for k_block in range(0, in_features, BLOCK_SIZE_K):\n        k = k_block + tl.arange(0, BLOCK_SIZE_K)\n        mask_k = k < in_features\n\n        # Load input: [BLOCK_SIZE_K]\n        input_ptr_chunk = input_ptr + pid_batch * stride_input_0 + k\n        input_chunk = tl.load(input_ptr_chunk, mask=mask_k, other=0.0)\n\n        # Load weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n        weight_block_ptr = weight_ptr + j[:, None] * stride_weight_0 + k[None, :] * stride_weight_1\n        weight_block = tl.load(weight_block_ptr, mask=mask[:, None] & mask_k[None, :], other=0.0)\n\n        # Compute: input_chunk[1, :] * weight_block [BLOCK_SIZE_N, BLOCK_SIZE_K] -> then sum over the last dimension.\n        acc += tl.sum(input_chunk[None, :] * weight_block, axis=1)\n\n   # Add bias for this block of columns.\n   if bias_ptr is not None:\n        bias_ptr_block = bias_ptr + j\n        bias_block = tl.load(bias_ptr_block, mask=mask, other=0.0)\n        acc += bias_block\n\n   # ReLU and divide by divisor.\n   acc = tl.maximum(acc, 0.0)\n   acc = acc / divisor\n\n   # Write output: [BLOCK_SIZE_N]\n   output_ptr_block = output_ptr + pid_batch * out_features + j\n   tl.store(output_ptr_block, acc, mask=mask)\n\nThis 2D grid approach might be better for parallelism.\n\nWe choose the 2D grid because we have two dimensions: batch and output features. We can use a grid of (batch_size, num_blocks) where num_blocks = ceil(out_features / BLOCK_SIZE_N).\n\nWe must note: the weight matrix is stored as [out_features, in_features]. We are loading a block of rows (each row of weight corresponds to one output feature) and a block of columns (which are the input features).\n\nWe'll use BLOCK_SIZE_N for the output feature block and BLOCK_SIZE_K for the input feature block.\n\nWe need to set the grid accordingly.\n\nWe will write the kernel and then replace the forward method to use this kernel.\n\nWe must also note: the original model has parameters (weight and bias) that are learnable. We will store them in the model. We cannot use nn.Linear because we are replacing it.\n\nSo we will:\n   - Remove the nn.Linear and replace it with our own parameters.\n   - In __init__: we create weight and bias as nn.Parameter.\n\nWe must initialize the weight and bias as in nn.Linear.\n\nWe'll use the same initialization as nn.Linear? Actually, we are not changing the initialization, we are just replacing the operation.\n\nSteps for the model:\n\n   class ModelNew(nn.Module):\n        def __init__(self, in_features, out_features, divisor):\n            super().__init__()\n            self.in_features = in_features\n            self.out_features = out_features\n            self.divisor = divisor\n\n            # Initialize weight and bias\n            self.weight = nn.Parameter(torch.empty(out_features, in_features))\n            self.bias = nn.Parameter(torch.empty(out_features))\n\n            # We must initialize as in nn.Linear\n            nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n            if self.bias is not None:\n                fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n                bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n                nn.init.uniform_(self.bias, -bound, bound)\n\n        def forward(self, x):\n            # We are going to call our Triton kernel\n            # x shape: [batch_size, in_features]\n            # output shape: [batch_size, out_features]\n            output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n\n            # We must check the dimensions\n            batch_size = x.size(0)\n\n            # We need to set the grid and kernel\n            # Grid: (batch_size, ceil(self.out_features / BLOCK_SIZE_N))\n            grid = (batch_size, triton.cdiv(self.out_features, BLOCK_SIZE_N))\n\n            # We call the kernel\n            fused_linear_relu_div_kernel[grid](\n                x, self.weight, self.bias, output,\n                self.divisor,\n                x.stride(0), self.weight.stride(0), self.weight.stride(1), output.stride(0),\n                self.in_features, self.out_features,\n                BLOCK_SIZE_N=BLOCK_SIZE_N, BLOCK_SIZE_K=BLOCK_SIZE_K\n            )\n\n            return output\n\nWe must choose BLOCK_SIZE_N and BLOCK_SIZE_K. We can set them as constants or use autotune.\n\nBut note: the problem says we can use adaptive tuning. We can set them as triton.constexpr and then autotune.\n\nWe'll define the kernel with autotune.\n\nHowever, note the constraints: we cannot change the grid configuration. But we are setting the grid based on the block sizes? Actually, the grid is determined by the problem size and the block sizes. We are allowed to change the block sizes.\n\nWe'll define the kernel with configs for BLOCK_SIZE_N and BLOCK_SIZE_K.\n\nBut note: the kernel above uses two block sizes. We can set them independently.\n\nWe'll try to set BLOCK_SIZE_N=128 and BLOCK_SIZE_K=32 and then autotune.\n\nAlternatively, we can use a list of configs.\n\nWe'll write the kernel with autotune.\n\nBut note: the current program does not have a Triton kernel. We are adding one.\n\nWe must be cautious: the current program is a pure PyTorch model. We are replacing it with a Triton kernel.\n\nWe are going to write the entire model again.\n\nLet's write the code accordingly.\n\nWe'll write:\n\n   import triton\n   import triton.language as tl\n\n   @triton.autotune(...)\n   @triton.jit\n   def fused_linear_relu_div_kernel(...):\n        ... as above ...\n\nThen the model class.\n\nWe must note: the kernel must handle the case when bias is None. But in our model, we have bias. So we can always pass bias. However, to be safe, we can check in the kernel if bias_ptr is not null.\n\nBut note: in Triton, we can pass a pointer that might be None. We can condition on the value of the pointer? Actually, we cannot. Instead, we can pass a boolean flag? Or we can pass a dummy pointer? But the kernel uses tl.load on bias_ptr. If the pointer is None, that would be invalid.\n\nWe can pass a boolean has_bias.\n\nAlternatively, we can pass a dummy tensor? But the model always has a bias. So we don't need to worry.\n\nBut note: the model might change? We are not removing the bias. So we can assume bias is always present.\n\nWe'll pass the bias tensor.\n\nWe must be cautious: the kernel uses 2D grid. We set the grid as (batch_size, num_blocks).\n\nWe'll set BLOCK_SIZE_N and BLOCK_SIZE_K as configurable.\n\nWe'll write the kernel with two block sizes.\n\nLet's code accordingly.\n\nBut note: the example above for the kernel is for a 2D grid. We must set the program indices accordingly.\n\nWe'll write:\n\n   pid_batch = tl.program_id(0)\n   pid_col_block = tl.program_id(1)\n\n   # ... rest of the kernel ...\n\nWe'll now write the entire EVOLVE-BLOCK.\n\nImportant: We must not change the get_inputs and get_init_inputs. They return the same as before.\n\nWe are going to replace the entire ModelNew class and the functions? Actually, we are going to replace the entire block.\n\nBut note: the batch_size, in_features, out_features, divisor are defined at the bottom? We are going to keep them.\n\nWe'll write:\n\n   import ... (we need to import triton, etc.)\n\n   class ModelNew(nn.Module):\n        ... with the parameters and the kernel call ...\n\n   batch_size = ... (same as before)\n   ... and the get_inputs and get_init_inputs.\n\nWe must import math for the initialization.\n\nLet's write the code.\n\nNote: We are going to use autotune for the kernel. We'll define a few configs.\n\nWe'll try:\n\n   configs = [\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n   ]\n\nWe'll let Triton choose the best.\n\nWe must also note: the kernel uses the strides. We are passing the strides of the tensors.\n\nWe are going to write the kernel in the same file.\n\nBut note: the EVOLVE-BLOCK must contain everything? Yes.\n\nWe are going to write a long block. We hope it compiles.\n\nWe must also note: the kernel must be compiled for the specific device. We are using the same device as the input.\n\nLet's write the code.\n\nWe must be cautious: the kernel uses tl.arange and then masks. We are doing bounds checking.\n\nWe hope that with this fused kernel we get a speedup.\n\nLet's write the entire code block.\n</think>\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_relu_div(\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    divisor,\n    stride_input0, stride_weight0, stride_weight1, stride_output0,\n    in_features, out_features,\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_col_block = tl.program_id(1)\n    \n    col_offsets = pid_col_block * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    col_mask = col_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(in_features, BLOCK_SIZE_K)):\n        k_offsets = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        k_mask = k_offsets < in_features\n        \n        input_ptr_row = input_ptr + pid_batch * stride_input0 + k_offsets\n        input_chunk = tl.load(input_ptr_row, mask=k_mask, other=0.0)\n        \n        weight_ptr_block = weight_ptr + col_offsets[:, None] * stride_weight0 + k_offsets[None, :] * stride_weight1\n        weight_chunk = tl.load(weight_ptr_block, mask=col_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        acc += tl.sum(input_chunk[None, :] * weight_chunk, axis=1)\n    \n    if bias_ptr is not None:\n        bias_vals = tl.load(bias_ptr + col_offsets, mask=col_mask, other=0.0)\n        acc += bias_vals\n    \n    acc = tl.maximum(acc, 0.0)\n    acc = acc / divisor\n    \n    output_ptr_row = output_ptr + pid_batch * stride_output0 + col_offsets\n    tl.store(output_ptr_row, acc, mask=col_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, divisor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.divisor = divisor\n        \n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        grid = (x.size(0), triton.cdiv(self.out_features, 256))\n        \n        fused_linear_relu_div[grid](\n            x, self.weight, self.bias, output,\n            self.divisor,\n            x.stride(0), self.weight.stride(0), self.weight.stride(1), output.stride(0),\n            self.in_features, self.out_features\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\ndivisor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, divisor]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}