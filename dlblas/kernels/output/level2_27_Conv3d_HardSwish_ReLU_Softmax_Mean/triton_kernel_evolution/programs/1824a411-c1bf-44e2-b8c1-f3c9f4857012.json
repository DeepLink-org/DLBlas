{"id": "1824a411-c1bf-44e2-b8c1-f3c9f4857012", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef softmax_kernel(\n    input_ptr,\n    temp_softmax_ptr,\n    n_spatial,\n    n_channels,\n    BLOCK_SIZE_C: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_spatial = tl.program_id(1)\n    \n    base_ptr = pid_batch * n_spatial * n_channels + pid_spatial * n_channels\n    offsets = base_ptr + tl.arange(0, BLOCK_SIZE_C)\n    mask = tl.arange(0, BLOCK_SIZE_C) < n_channels\n    \n    data = tl.load(input_ptr + offsets, mask=mask, other=0.0)\n    \n    shifted = data + 3.0\n    clipped = tl.minimum(tl.maximum(shifted, 0.0), 6.0)\n    activated = data * clipped / 6.0\n    activated = tl.maximum(activated, 0.0)\n    \n    max_val = tl.max(activated, axis=0)\n    exp_vals = tl.exp(activated - max_val)\n    sum_exp = tl.sum(exp_vals, axis=0)\n    softmax_vals = exp_vals / sum_exp\n    \n    output_base = pid_batch * n_channels * n_spatial + pid_spatial\n    output_offsets = output_base + tl.arange(0, BLOCK_SIZE_C) * n_spatial\n    tl.store(temp_softmax_ptr + output_offsets, softmax_vals, mask=mask)\n\n@triton.jit\ndef mean_kernel(\n    temp_softmax_ptr,\n    output_ptr,\n    n_spatial,\n    n_channels,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_block = tl.program_id(1)\n    pid_channel = tl.program_id(2)\n    \n    base_ptr = pid_batch * n_channels * n_spatial + pid_channel * n_spatial\n    start_idx = pid_block * BLOCK_SIZE\n    offsets = base_ptr + start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = (start_idx + tl.arange(0, BLOCK_SIZE)) < n_spatial\n    \n    vals = tl.load(temp_softmax_ptr + offsets, mask=mask, other=0.0)\n    block_sum = tl.sum(vals, axis=0)\n    \n    output_offset = pid_batch * n_channels + pid_channel\n    tl.atomic_add(output_ptr + output_offset, block_sum)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias=True):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, bias=bias)\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, D, H, W = x.shape\n        n_spatial = D * H * W\n        \n        x = x.permute(0, 2, 3, 4, 1).contiguous()\n        x = x.view(B, n_spatial, C)\n        \n        temp_softmax = torch.empty((B, C, n_spatial), device=x.device, dtype=x.dtype)\n        \n        grid_softmax = (B, n_spatial)\n        BLOCK_SIZE_C = triton.next_power_of_2(C)\n        softmax_kernel[grid_softmax](\n            x, temp_softmax, n_spatial, C, BLOCK_SIZE_C=BLOCK_SIZE_C\n        )\n        \n        output = torch.zeros((B, C), device=x.device, dtype=x.dtype)\n        BLOCK_SIZE_SPATIAL = 1024\n        num_blocks = (n_spatial + BLOCK_SIZE_SPATIAL - 1) // BLOCK_SIZE_SPATIAL\n        grid_mean = (B, num_blocks, C)\n        \n        mean_kernel[grid_mean](\n            temp_softmax, output, n_spatial, C, BLOCK_SIZE=BLOCK_SIZE_SPATIAL\n        )\n        \n        return output / n_spatial\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "ceb2ab2d-62b5-4606-acbf-ed480f4348e9", "generation": 3, "timestamp": 1754571594.4222257, "iteration_found": 25, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.048, "runtime_ms": 1.62, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0784, "speed_up": 0.048, "custom_timing": 1.62}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.049, "runtime_ms": 1.61, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0784, "speed_up": 0.049, "custom_timing": 1.61}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}