{"id": "39a608d5-614f-46a2-8ad1-6b5d0a0bee0b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_transpose3d_kernel(\n    input_ptr,\n    weight_ptr,\n    output_ptr,\n    batch_size,\n    in_channels,\n    depth,\n    height,\n    width,\n    out_channels,\n    kernel_size,\n    stride,\n    padding,\n    dilation,\n    output_depth,\n    output_height,\n    output_width,\n    input_batch_stride,\n    input_channel_stride,\n    input_depth_stride,\n    input_height_stride,\n    input_width_stride,\n    weight_outc_stride,\n    weight_inc_stride,\n    weight_d_stride,\n    weight_h_stride,\n    weight_w_stride,\n    output_batch_stride,\n    output_channel_stride,\n    output_depth_stride,\n    output_height_stride,\n    output_width_stride,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_d = tl.cdiv(output_depth, BLOCK_SIZE)\n    num_pid_h = tl.cdiv(output_height, BLOCK_SIZE)\n    num_pid_w = tl.cdiv(output_width, BLOCK_SIZE)\n    \n    pid_batch = pid // (num_pid_d * num_pid_h * num_pid_w * out_channels)\n    pid_oc = (pid // (num_pid_d * num_pid_h * num_pid_w)) % out_channels\n    pid_w = (pid // (num_pid_d * num_pid_h)) % num_pid_w\n    pid_h = (pid // num_pid_d) % num_pid_h\n    pid_d = pid % num_pid_d\n\n    d_start = pid_d * BLOCK_SIZE\n    h_start = pid_h * BLOCK_SIZE\n    w_start = pid_w * BLOCK_SIZE\n\n    d_offsets = d_start + tl.arange(0, BLOCK_SIZE)\n    h_offsets = h_start + tl.arange(0, BLOCK_SIZE)\n    w_offsets = w_start + tl.arange(0, BLOCK_SIZE)\n\n    output_block = tl.zeros((BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE), dtype=tl.float32)\n    \n    # Iterate over kernel dimensions and input channels\n    for kd in range(kernel_size):\n        for kh in range(kernel_size):\n            for kw in range(kernel_size):\n                for ic in range(in_channels):\n                    # Calculate input indices with dilation\n                    d_in = (d_offsets - (kd * dilation - padding)) // stride\n                    h_in = (h_offsets - (kh * dilation - padding)) // stride\n                    w_in = (w_offsets - (kw * dilation - padding)) // stride\n                    \n                    # Create masks for valid input positions\n                    d_mask = (d_offsets - (kd * dilation - padding)) % stride == 0\n                    h_mask = (h_offsets - (kh * dilation - padding)) % stride == 0\n                    w_mask = (w_offsets - (kw * dilation - padding)) % stride == 0\n                    valid_mask = d_mask[:, None, None] & h_mask[None, :, None] & w_mask[None, None, :]\n                    \n                    # Check input bounds\n                    d_in_bounds = (d_in >= 0) & (d_in < depth)\n                    h_in_bounds = (h_in >= 0) & (h_in < height)\n                    w_in_bounds = (w_in >= 0) & (w_in < width)\n                    in_bounds = d_in_bounds[:, None, None] & h_in_bounds[None, :, None] & w_in_bounds[None, None, :]\n                    \n                    # Combined mask\n                    mask = valid_mask & in_bounds\n                    \n                    # Load input value\n                    input_offset = (\n                        pid_batch * input_batch_stride +\n                        ic * input_channel_stride +\n                        d_in * input_depth_stride +\n                        h_in * input_height_stride +\n                        w_in * input_width_stride\n                    )\n                    input_val = tl.load(input_ptr + input_offset, mask=mask, other=0.0)\n                    \n                    # Load weight value\n                    weight_offset = (\n                        pid_oc * weight_outc_stride +\n                        ic * weight_inc_stride +\n                        kd * weight_d_stride +\n                        kh * weight_h_stride +\n                        kw * weight_w_stride\n                    )\n                    weight_val = tl.load(weight_ptr + weight_offset)\n                    \n                    # Accumulate\n                    output_block += input_val * weight_val\n    \n    # Store output block\n    for d_idx in range(BLOCK_SIZE):\n        for h_idx in range(BLOCK_SIZE):\n            for w_idx in range(BLOCK_SIZE):\n                if (d_start + d_idx < output_depth and \n                    h_start + h_idx < output_height and \n                    w_start + w_idx < output_width):\n                    output_offset = (\n                        pid_batch * output_batch_stride +\n                        pid_oc * output_channel_stride +\n                        (d_start + d_idx) * output_depth_stride +\n                        (h_start + h_idx) * output_height_stride +\n                        (w_start + w_idx) * output_width_stride\n                    )\n                    tl.store(output_ptr + output_offset, output_block[d_idx, h_idx, w_idx])\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        \n        # Calculate output dimensions\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        # Initialize parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, depth, height, width = x.shape\n        out_channels = self.out_channels\n        \n        # Calculate output dimensions\n        output_depth = (depth - 1) * self.stride - 2 * self.padding + self.dilation * (self.kernel_size - 1) + 1\n        output_height = (height - 1) * self.stride - 2 * self.padding + self.dilation * (self.kernel_size - 1) + 1\n        output_width = (width - 1) * self.stride - 2 * self.padding + self.dilation * (self.kernel_size - 1) + 1\n        \n        # Create output tensor\n        output = torch.zeros(\n            batch_size, \n            out_channels, \n            output_depth, \n            output_height, \n            output_width, \n            device=x.device, \n            dtype=x.dtype\n        )\n        \n        # Compute grid and launch kernel\n        BLOCK_SIZE = 8\n        grid = (batch_size * out_channels * \n                triton.cdiv(output_depth, BLOCK_SIZE) * \n                triton.cdiv(output_height, BLOCK_SIZE) * \n                triton.cdiv(output_width, BLOCK_SIZE))\n        \n        # Get strides\n        x_strides = [x.stride(i) for i in range(5)]\n        w_strides = [self.weight.stride(i) for i in range(5)]\n        out_strides = [output.stride(i) for i in range(5)]\n        \n        conv_transpose3d_kernel[grid](\n            x,\n            self.weight,\n            output,\n            batch_size,\n            in_channels,\n            depth,\n            height,\n            width,\n            out_channels,\n            self.kernel_size,\n            self.stride,\n            self.padding,\n            self.dilation,\n            output_depth,\n            output_height,\n            output_width,\n            x_strides[0], x_strides[1], x_strides[2], x_strides[3], x_strides[4],\n            w_strides[0], w_strides[1], w_strides[2], w_strides[3], w_strides[4],\n            out_strides[0], out_strides[1], out_strides[2], out_strides[3], out_strides[4],\n            BLOCK_SIZE\n        )\n        \n        # Add bias if needed\n        if self.bias is not None:\n            output += self.bias.view(1, -1, 1, 1, 1)\n            \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\ndepth = 16\nheight = 32\nwidth = 32\nstride = 2\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "286bc68c-7587-4950-b33a-1780313ab139", "generation": 1, "timestamp": 1754645071.3719294, "iteration_found": 3, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "name 'math' is not defined\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/evaluator.py\", line 173, in _verification_worker\n    result: KernelExecResult = eval_kernel_against_ref(\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 484, in eval_kernel_against_ref\n    custom_model = ModelNew(*init_args, **init_kwargs)\n  File \"/tmp/tmpnhxhaik1.py\", line 145, in __init__\n    nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\nNameError: name 'math' is not defined\n", "exec_log": "[Child] \u7ed1\u5b9a GPU 0, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 8, in <module>\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 844, in jit\n    return decorator(fn)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 832, in decorator\n    return JITFunction(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 635, in __init__\n    self.starting_line_number = inspect.getsourcelines(fn)[1]\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 958, in findsource\n    raise OSError('could not get source code')\nOSError: could not get source code\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 1.97, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0534, "speed_up": 0.027, "custom_timing": 1.97}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}