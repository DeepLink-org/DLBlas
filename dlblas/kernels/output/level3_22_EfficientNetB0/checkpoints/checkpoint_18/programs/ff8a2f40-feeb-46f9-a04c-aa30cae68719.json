{"id": "ff8a2f40-feeb-46f9-a04c-aa30cae68719", "code": "=\u67810, bias=False)\n        self.b", "language": "python", "parent_id": "259ba7a0-bca5-47fa-a0ae-899037174b78", "generation": 1, "timestamp": 1754590057.2109802, "iteration_found": 14, "metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 2.83, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 2.47, "speed_up": 0.873, "custom_timing": 2.83}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 2.8300\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.47, 'speed_up': 0.873, 'custom_timing': 2.83}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: speed_up. Consider continuing with similar changes.\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level3_22_EfficientNetB0', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1479, in dot\\n    assert lhs.dtype == rhs.dtype, f\"Both operands must be same dtype. Got {lhs.dtype} and {rhs.dtype}\"\\nAssertionError: Both operands must be same dtype. Got fp16 and fp32\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 96, in forward\\n    x = self.blocks(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\\n    input = module(input)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 132, in forward\\n    x = self.expand_conv(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\\n    input = module(input)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 56, in forward\\n    pointwise_conv_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 24:23:\\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\\n    offs_k = tl.arange(0, BLOCK_K)\\n\\n    a_ptrs = input_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\\n    b_ptrs = weight_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn\\n\\n    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\\n    for k in range(0, tl.cdiv(in_channels, BLOCK_K)):\\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < in_channels - k * BLOCK_K, other=0.0)\\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < in_channels - k * BLOCK_K, other=0.0)\\n        accumulator += tl.dot(a, b)\\n                       ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1479, in dot\\n    assert lhs.dtype == rhs.dtype, f\"Both operands must be same dtype. Got {lhs.dtype} and {rhs.dtype}\"\\nAssertionError: Both operands must be same dtype. Got fp16 and fp32\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 2.47, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7240, runtime_ms: 3.4100, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.47, 'speed_up': 0.724, 'custom_timing': 3.41}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.6320, runtime_ms: 3.9100, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.47, 'speed_up': 0.632, 'custom_timing': 3.91}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 4}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 8}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 2048, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 4096, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 16}, num_warps=8),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    num_vectors = tl.cdiv(n_elements, VEC_SIZE)\n    block_start = pid * BLOCK_SIZE\n    vector_indices = block_start + tl.arange(0, BLOCK_SIZE)\n    mask_vectors = vector_indices < num_vectors\n    \n    vector_offsets = vector_indices * VEC_SIZE\n    element_offsets = vector_offsets[:, None] + tl.arange(0, VEC_SIZE)[None, :]\n    mask_elements = (element_offsets < n_elements) & mask_vectors[:, None]\n    \n    x_vectors = tl.load(x_ptr + element_offsets, mask=mask_elements, other=0.0)\n    x_vectors = tl.where(x_vectors < 0, 0, x_vectors)\n    x_vectors = tl.where(x_vectors > 6, 6, x_vectors)\n    \n    tl.store(output_ptr + element_offsets, x_vectors, mask=mask_elements)\n\ndef relu6_triton(x):\n    output = torch.empty_like(x)\n    n_elements = output.numel()\n    grid = lambda meta: (triton.cdiv(triton.cdiv(n_elements, meta['VEC_SIZE']), meta['BLOCK_SIZE']),)\n    relu6_kernel[grid](x, output, n_elements)\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n            x = relu6_triton(x)\n        \n        x = self.depthwise_conv(x)\n        x = relu6_triton(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.6320), Performs well on runtime_ms (3.9100), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.47, 'speed_up': 0.632, 'custom_timing': 3.91})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.where(x < 0, 0, x)\n    x = tl.where(x > 6, 6, x)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\ndef relu6_triton(x):\n    output = torch.empty_like(x)\n    n_elements = output.numel()\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n    relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n            x = relu6_triton(x)\n        \n        x = self.depthwise_conv(x)\n        x = relu6_triton(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7240), Performs well on runtime_ms (3.4100), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 2.47, 'speed_up': 0.724, 'custom_timing': 3.41})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef pointwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    batch_size, in_channels, out_channels, height, width,\n    stride_am, stride_ak, stride_bk, stride_bn,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_m = tl.cdiv(batch_size * height * width, BLOCK_M)\n    pid_m = pid // num_pid_m\n    pid_n = pid % num_pid_m\n    \n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = input_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = weight_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn\n    \n    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(in_channels, BLOCK_K)):\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < in_channels - k * BLOCK_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < in_channels - k * BLOCK_K, other=0.0)\n        accumulator += tl.dot(a, b)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    c_ptrs = output_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, accumulator.to(tl.float16))\n\nclass TritonPointwiseConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels))\n        nn.init.kaiming_uniform_(self.weight)\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        batch, _, height, width = x.shape\n        x_flat = x.permute(0, 2, 3, 1).contiguous().view(-1, self.in_channels)\n        output = torch.empty((batch * height * width, self.out_channels), \n                            device=x.device, dtype=torch.float16)\n        \n        grid = lambda meta: (triton.cdiv(batch * height * width, meta['BLOCK_M']) * \n                            triton.cdiv(self.out_channels, meta['BLOCK_N']),)\n        \n        pointwise_conv_kernel[grid](\n            x_flat, self.weight, output,\n            batch, self.in_channels, self.out_channels, height, width,\n            x_flat.stride(0), x_flat.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_M=64, BLOCK_N=128, BLOCK_K=32\n        )\n        \n        output = output.view(batch, height, width, self.out_channels)\n        return output.permute(0, 3, 1, 2)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                TritonPointwiseConv(in_channels, hidden_dim),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, \n                     padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            TritonPointwiseConv(hidden_dim, out_channels),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        \n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level3_22_EfficientNetB0', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1479, in dot\\n    assert lhs.dtype == rhs.dtype, f\"Both operands must be same dtype. Got {lhs.dtype} and {rhs.dtype}\"\\nAssertionError: Both operands must be same dtype. Got fp16 and fp32\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 96, in forward\\n    x = self.blocks(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\\n    input = module(input)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 132, in forward\\n    x = self.expand_conv(x)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 244, in forward\\n    input = module(input)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmpsqofe7b3.py\", line 56, in forward\\n    pointwise_conv_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 24:23:\\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\\n    offs_k = tl.arange(0, BLOCK_K)\\n\\n    a_ptrs = input_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\\n    b_ptrs = weight_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn\\n\\n    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\\n    for k in range(0, tl.cdiv(in_channels, BLOCK_K)):\\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < in_channels - k * BLOCK_K, other=0.0)\\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < in_channels - k * BLOCK_K, other=0.0)\\n        accumulator += tl.dot(a, b)\\n                       ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1479, in dot\\n    assert lhs.dtype == rhs.dtype, f\"Both operands must be same dtype. Got {lhs.dtype} and {rhs.dtype}\"\\nAssertionError: Both operands must be same dtype. Got fp16 and fp32\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 2.47, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n# Triton kernel for 3x3 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_3x3_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    w00 = tl.load(weight_ptr_c + 0*weight_stride_kh + 0*weight_stride_kw)\n    w01 = tl.load(weight_ptr_c + 0*weight_stride_kh + 1*weight_stride_kw)\n    w02 = tl.load(weight_ptr_c + 0*weight_stride_kh + 2*weight_stride_kw)\n    w10 = tl.load(weight_ptr_c + 1*weight_stride_kh + 0*weight_stride_kw)\n    w11 = tl.load(weight_ptr_c + 1*weight_stride_kh + 1*weight_stride_kw)\n    w12 = tl.load(weight_ptr_c + 1*weight_stride_kh + 2*weight_stride_kw)\n    w20 = tl.load(weight_ptr_c + 2*weight_stride_kh + 0*weight_stride_kw)\n    w21 = tl.load(weight_ptr_c + 2*weight_stride_kh + 1*weight_stride_kw)\n    w22 = tl.load(weight_ptr_c + 2*weight_stride_kh + 2*weight_stride_kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 2)\n    i_w = tl.arange(0, BLOCK_W + 2)\n    input_h = start_h - 1 + i_h\n    input_w = start_w - 1 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    output_block += input_block[0:BLOCK_H, 0:BLOCK_W] * w00\n    output_block += input_block[0:BLOCK_H, 1:BLOCK_W+1] * w01\n    output_block += input_block[0:BLOCK_H, 2:BLOCK_W+2] * w02\n    output_block += input_block[1:BLOCK_H+1, 0:BLOCK_W] * w10\n    output_block += input_block[1:BLOCK_H+1, 1:BLOCK_W+1] * w11\n    output_block += input_block[1:BLOCK_H+1, 2:BLOCK_W+2] * w12\n    output_block += input_block[2:BLOCK_H+2, 0:BLOCK_W] * w20\n    output_block += input_block[2:BLOCK_H+2, 1:BLOCK_W+1] * w21\n    output_block += input_block[2:BLOCK_H+2, 2:BLOCK_W+2] * w22\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton kernel for 5x5 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_5x5_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    weights = tl.zeros((5, 5), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            weights = tl.where(True, weights, tl.load(weight_ptr_c + kh*weight_stride_kh + kw*weight_stride_kw), kh, kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 4)\n    i_w = tl.arange(0, BLOCK_W + 4)\n    input_h = start_h - 2 + i_h\n    input_w = start_w - 2 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            output_block += input_block[kh:kh+BLOCK_H, kw:kw+BLOCK_W] * weights[kh, kw]\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton depthwise convolution module\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, 1, kernel_size, kernel_size))\n    \n    def forward(self, x):\n        if self.kernel_size == 3 and self.stride == 1 and self.padding == 1:\n            return self._triton_conv(x, 3)\n        elif self.kernel_size == 5 and self.stride == 1 and self.padding == 2:\n            return self._triton_conv(x, 5)\n        else:\n            return F.conv2d(x, self.weight, stride=self.stride, padding=self.padding, groups=self.in_channels)\n    \n    def _triton_conv(self, x, kernel_size):\n        batch, in_channels, in_h, in_w = x.shape\n        out_h = (in_h + 2 * self.padding - kernel_size) // self.stride + 1\n        out_w = (in_w + 2 * self.padding - kernel_size) // self.stride + 1\n        output = torch.empty((batch, in_channels, out_h, out_w), device=x.device, dtype=x.dtype)\n        \n        BLOCK_H, BLOCK_W = (32, 32) if kernel_size == 3 else (16, 16)\n        num_blocks_h = (out_h + BLOCK_H - 1) // BLOCK_H\n        num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n        grid = (batch, in_channels, num_blocks_h * num_blocks_w)\n        \n        in_stride_n, in_stride_c, in_stride_h, in_stride_w = x.stride()\n        weight_stride_c, _, weight_stride_kh, weight_stride_kw = self.weight.stride()\n        out_stride_n, out_stride_c, out_stride_h, out_stride_w = output.stride()\n        \n        kernel = _depthwise_conv2d_3x3_kernel if kernel_size == 3 else _depthwise_conv2d_5x5_kernel\n        kernel[grid](\n            x, self.weight, output,\n            in_h, in_w, out_h, out_w,\n            in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n            weight_stride_c, weight_stride_kh, weight_stride_kw,\n            out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n            BLOCK_H, BLOCK_W\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        padding = (kernel_size - 1) // 2\n        self.depthwise_conv = nn.Sequential(\n            TritonDepthwiseConv2d(hidden_dim, kernel_size, stride, padding),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        if self.use_residual:\n            x += identity\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 1.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n# Triton kernel for 3x3 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_3x3_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_str\u6781c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    w00 = tl.load(weight_ptr_c + 0*weight_stride_kh + 0*weight_stride_kw)\n    w01 = tl.load(weight_ptr_c + 0*weight_stride_kh + 1*weight_stride_kw)\n    w02 = tl.load(weight_ptr_c + 0*weight_stride_kh + 2*weight_stride_kw)\n    w10 = tl.load(weight_ptr_c + 1*weight_stride_kh + 0*weight_stride_kw)\n    w11 = tl.load(weight_ptr_c + 1*weight_stride_k\u6781 + 1*weight_stride_kw)\n    w12 = tl.load(weight_ptr_c + 1*weight_stride_kh + 2*weight_stride_kw)\n    w20 = tl.load(weight_ptr_c + 2*weight_stride_kh + 0*weight_stride_kw)\n    w21 = tl.load(weight_ptr_c + 2*weight_stride_kh + 1*weight_stride_kw)\n    w22 = tl.load(weight_ptr_c + 2*weight_stride_kh + 2*weight_stride_kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 2)\n    i_w = tl.arange(0, BLOCK_W + 2)\n    input_h = start_h - 1 + i_h\n    input_w = start_w - 1 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    output_block += input_block[0:BLOCK_H, 0:BLOCK_W] * w00\n    output_block += input_block[0:BLOCK_H, 1:BLOCK_W+1] * w01\n    output_block += input_block[0:BLOCK_H, 2:BLOCK_W+2] * w02\n    output_block += input_block[1:BLOCK_H+1, 0:BLOCK_W] * w10\n    output_block += input_block[1:BLOCK_H+1, 1:BLOCK_W+1] * w11\n    output_block += input_block[1:BLOCK_H+1, 2:BLOCK_W+2] * w12\n    output_block += input_block[2:BLOCK_H+2, 0:BLOCK_W] * w20\n    output_block += input_block[2:BLOCK_H+2, 1:BLOCK_W+1] * w21\n    output_block += input_block[2:BLOCK_H+2, 2:BLOCK_W+2] * w22\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton kernel for 5x5 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_5x5_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    weights = tl.zeros((5, 5), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            weights = tl.where(True, weights, tl.load(weight_ptr_c + kh*weight_stride_kh + kw*weight_stride_kw), kh, kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 4)\n    i_w = tl.arange(0, BLOCK_W + 4)\n    input_h = start_h - 2 + i_h\n    input_w = start_w - 2 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            output_block += input_block[kh:kh+BLOCK_H, kw:kw+BLOCK_W] * weights[kh, kw]\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton depthwise convolution module\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, 1, kernel_size, kernel_size))\n    \n    def forward(self, x):\n        if self.kernel_size == 3 and self.stride == 1 and self.padding == 1:\n            return self._triton_conv(x, 3)\n        elif self.kernel_size == 5 and self.stride == 1 and self.padding == 2:\n            return self._triton_conv(x, 5)\n        else:\n            return F.conv2d(x, self.weight, stride=self.stride, padding=self.padding, groups=self.in_channels)\n    \n    def _triton_conv(self, x, kernel_size):\n        batch, in_channels, in_h, in_w = x.shape\n        out_h = (in_h + 2 * self.padding - kernel_size) // self.stride + 1\n        out_w = (in_w + 2 * self.padding - kernel_size) // self.stride + 1\n        output = torch.empty((batch, in_channels, out_h, out_w), device=x.device, dtype=x.dtype)\n        \n        # Changed block sizes to make input dimensions powers of two\n        BLOCK_H, BLOCK_W = (30, 30) if kernel_size == 3 else (12, 12)\n        num_blocks_h = (out_h + BLOCK_H - 1) // BLOCK_H\n        num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n        grid = (batch, in_channels, num_blocks_h * num_blocks_w)\n        \n        in_stride_n, in_stride_c, in_stride_h, in_stride_w = x.stride()\n        weight_stride_c, _, weight_stride_kh, weight_stride_kw = self.weight.stride()\n        out_stride_n, out_stride_c, out_stride_h, out_stride_w = output.stride()\n        \n        kernel = _depthwise_conv2d_3x3_kernel if kernel_size == 3 else _depthwise_conv2d_5x5_kernel\n        kernel[grid](\n            x, self.weight, output,\n            in_h, in_w, out_h, out_w,\n            in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n            weight_stride_c, weight_stride_kh, weight_stride_kw,\n            out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n            BLOCK_H, BLOCK_W\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32\u6781 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        padding = (kernel_size - 1) // 2\n        self.depthwise_conv = nn.Sequential(\n            TritonDepthwiseConv2d(hidden_dim, kernel_size, stride, padding),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        if self.use_residual:\n            x += identity\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    x = tl.where(x < 0, 0, x)\n    x = tl.where(x > 6, 6, x)\n    tl.store(output_ptr + offsets, x, mask=mask)\n\ndef relu6_triton(x):\n    output = torch.empty_like(x)\n    n_elements = output.numel()\n    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n    relu6_kernel[grid](x, output, n_elements, BLOCK_SIZE=1024)\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n            x = relu6_triton(x)\n        \n        x = self.depthwise_conv(x)\n        x = relu6_triton(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=1),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 4}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 4}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 8}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 2048, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 4096, 'VEC_SIZE': 8}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024, 'VEC_SIZE': 16}, num_warps=8),\n    ],\n    key=['n_elements'],\n)\n@triton.jit\ndef relu6_kernel(\n    x_ptr,\n    output_ptr,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    num_vectors = tl.cdiv(n_elements, VEC_SIZE)\n    block_start = pid * BLOCK_SIZE\n    vector_indices = block_start + tl.arange(0, BLOCK_SIZE)\n    mask_vectors = vector_indices < num_vectors\n    \n    vector_offsets = vector_indices * VEC_SIZE\n    element_offsets = vector_offsets[:, None] + tl.arange(0, VEC_SIZE)[None, :]\n    mask_elements = (element_offsets < n_elements) & mask_vectors[:, None]\n    \n    x_vectors = tl.load(x_ptr + element_offsets, mask=mask_elements, other=0.0)\n    x_vectors = tl.where(x_vectors < 0, 0, x_vectors)\n    x_vectors = tl.where(x_vectors > 6, 6, x_vectors)\n    \n    tl.store(output_ptr + element_offsets, x_vectors, mask=mask_elements)\n\ndef relu6_triton(x):\n    output = torch.empty_like(x)\n    n_elements = output.numel()\n    grid = lambda meta: (triton.cdiv(triton.cdiv(n_elements, meta['VEC_SIZE']), meta['BLOCK_SIZE']),)\n    relu6_kernel[grid](x, output, n_elements)\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n            x = relu6_triton(x)\n        \n        x = self.depthwise_conv(x)\n        x = relu6_triton(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n# Triton kernel for 3x3 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_3x3_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    w00 = tl.load(weight_ptr_c + 0*weight_stride_kh + 0*weight_stride_kw)\n    w01 = tl.load(weight_ptr_c + 0*weight_stride_kh + 1*weight_stride_kw)\n    w02 = tl.load(weight_ptr_c + 0*weight_stride_kh + 2*weight_stride_kw)\n    w10 = tl.load(weight_ptr_c + 1*weight_stride_kh + 0*weight_stride_kw)\n    w11 = tl.load(weight_ptr_c + 1*weight_stride_kh + 1*weight_stride_kw)\n    w12 = tl.load(weight_ptr_c + 1*weight_stride_kh + 2*weight_stride_kw)\n    w20 = tl.load(weight_ptr_c + 2*weight_stride_kh + 0*weight_stride_kw)\n    w21 = tl.load(weight_ptr_c + 2*weight_stride_kh + 1*weight_stride_kw)\n    w22 = tl.load(weight_ptr_c + 2*weight_stride_kh + 2*weight_stride_kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 2)\n    i_w = tl.arange(0, BLOCK_W + 2)\n    input_h = start_h - 1 + i_h\n    input_w = start_w - 1 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    output_block += input_block[0:BLOCK_H, 0:BLOCK_W] * w00\n    output_block += input_block[0:BLOCK_H, 1:BLOCK_W+1] * w01\n    output_block += input_block[0:BLOCK_H, 2:BLOCK_W+2] * w02\n    output_block += input_block[1:BLOCK_H+1, 0:BLOCK_W] * w10\n    output_block += input_block[1:BLOCK_H+1, 1:BLOCK_W+1] * w11\n    output_block += input_block[1:BLOCK_H+1, 2:BLOCK_W+2] * w12\n    output_block += input_block[2:BLOCK_H+2, 0:BLOCK_W] * w20\n    output_block += input_block[2:BLOCK_H+2, 1:BLOCK_W+1] * w21\n    output_block += input_block[2:BLOCK_H+2, 2:BLOCK_W+2] * w22\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton kernel for 5x5 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_5x5_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    weights = tl.zeros((5, 5), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            weights = tl.where(True, weights, tl.load(weight_ptr_c + kh*weight_stride_kh + kw*weight_stride_kw), kh, kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 4)\n    i_w = tl.arange(0, BLOCK_W + 4)\n    input_h = start_h - 2 + i_h\n    input_w = start_w - 2 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            output_block += input_block[kh:kh+BLOCK_H, kw:kw+BLOCK_W] * weights[kh, kw]\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton depthwise convolution module\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, 1, kernel_size, kernel_size))\n    \n    def forward(self, x):\n        if self.kernel_size == 3 and self.stride == 1 and self.padding == 1:\n            return self._triton_conv(x, 3)\n        elif self.kernel_size == 5 and self.stride == 1 and self.padding == 2:\n            return self._triton_conv(x, 5)\n        else:\n            return F.conv2d(x, self.weight, stride=self.stride, padding=self.padding, groups=self.in_channels)\n    \n    def _triton_conv(self, x, kernel_size):\n        batch, in_channels, in_h, in_w = x.shape\n        out_h = (in_h + 2 * self.padding - kernel_size) // self.stride + 1\n        out_w = (in_w + 2 * self.padding - kernel_size) // self.stride + 1\n        output = torch.empty((batch, in_channels, out_h, out_w), device=x.device, dtype=x.dtype)\n        \n        BLOCK_H, BLOCK_W = (32, 32) if kernel_size == 3 else (16, 16)\n        num_blocks_h = (out_h + BLOCK_H - 1) // BLOCK_H\n        num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n        grid = (batch, in_channels, num_blocks_h * num_blocks_w)\n        \n        in_stride_n, in_stride_c, in_stride_h, in_stride_w = x.stride()\n        weight_stride_c, _, weight_stride_kh, weight_stride_kw = self.weight.stride()\n        out_stride_n, out_stride_c, out_stride_h, out_stride_w = output.stride()\n        \n        kernel = _depthwise_conv2d_3x3_kernel if kernel_size == 3 else _depthwise_conv2d_5x5_kernel\n        kernel[grid](\n            x, self.weight, output,\n            in_h, in_w, out_h, out_w,\n            in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n            weight_stride_c, weight_stride_kh, weight_stride_kw,\n            out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n            BLOCK_H, BLOCK_W\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        padding = (kernel_size - 1) // 2\n        self.depthwise_conv = nn.Sequential(\n            TritonDepthwiseConv2d(hidden_dim, kernel_size, stride, padding),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        if self.use_residual:\n            x += identity\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef pointwise_conv_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    batch_size, in_channels, out_channels, height, width,\n    stride_am, stride_ak, stride_bk, stride_bn,\n    stride_cm, stride_cn,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_m = tl.cdiv(batch_size * height * width, BLOCK_M)\n    pid_m = pid // num_pid_m\n    pid_n = pid % num_pid_m\n    \n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    a_ptrs = input_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = weight_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn\n    \n    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(in_channels, BLOCK_K)):\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < in_channels - k * BLOCK_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < in_channels - k * BLOCK_K, other=0.0)\n        accumulator += tl.dot(a, b)\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    c_ptrs = output_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn\n    tl.store(c_ptrs, accumulator.to(tl.float16))\n\nclass TritonPointwiseConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels))\n        nn.init.kaiming_uniform_(self.weight)\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        batch, _, height, width = x.shape\n        x_flat = x.permute(0, 2, 3, 1).contiguous().view(-1, self.in_channels)\n        output = torch.empty((batch * height * width, self.out_channels), \n                            device=x.device, dtype=torch.float16)\n        \n        grid = lambda meta: (triton.cdiv(batch * height * width, meta['BLOCK_M']) * \n                            triton.cdiv(self.out_channels, meta['BLOCK_N']),)\n        \n        pointwise_conv_kernel[grid](\n            x_flat, self.weight, output,\n            batch, self.in_channels, self.out_channels, height, width,\n            x_flat.stride(0), x_flat.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_M=64, BLOCK_N=128, BLOCK_K=32\n        )\n        \n        output = output.view(batch, height, width, self.out_channels)\n        return output.permute(0, 3, 1, 2)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                TritonPointwiseConv(in_channels, hidden_dim),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, \n                     padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            TritonPointwiseConv(hidden_dim, out_channels),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        \n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 1.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nimport math\n\n# Triton kernel for 3x3 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_3x3_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_str\u6781c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    w00 = tl.load(weight_ptr_c + 0*weight_stride_kh + 0*weight_stride_kw)\n    w01 = tl.load(weight_ptr_c + 0*weight_stride_kh + 1*weight_stride_kw)\n    w02 = tl.load(weight_ptr_c + 0*weight_stride_kh + 2*weight_stride_kw)\n    w10 = tl.load(weight_ptr_c + 1*weight_stride_kh + 0*weight_stride_kw)\n    w11 = tl.load(weight_ptr_c + 1*weight_stride_k\u6781 + 1*weight_stride_kw)\n    w12 = tl.load(weight_ptr_c + 1*weight_stride_kh + 2*weight_stride_kw)\n    w20 = tl.load(weight_ptr_c + 2*weight_stride_kh + 0*weight_stride_kw)\n    w21 = tl.load(weight_ptr_c + 2*weight_stride_kh + 1*weight_stride_kw)\n    w22 = tl.load(weight_ptr_c + 2*weight_stride_kh + 2*weight_stride_kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 2)\n    i_w = tl.arange(0, BLOCK_W + 2)\n    input_h = start_h - 1 + i_h\n    input_w = start_w - 1 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    output_block += input_block[0:BLOCK_H, 0:BLOCK_W] * w00\n    output_block += input_block[0:BLOCK_H, 1:BLOCK_W+1] * w01\n    output_block += input_block[0:BLOCK_H, 2:BLOCK_W+2] * w02\n    output_block += input_block[1:BLOCK_H+1, 0:BLOCK_W] * w10\n    output_block += input_block[1:BLOCK_H+1, 1:BLOCK_W+1] * w11\n    output_block += input_block[1:BLOCK_H+1, 2:BLOCK_W+2] * w12\n    output_block += input_block[2:BLOCK_H+2, 0:BLOCK_W] * w20\n    output_block += input_block[2:BLOCK_H+2, 1:BLOCK_W+1] * w21\n    output_block += input_block[2:BLOCK_H+2, 2:BLOCK_W+2] * w22\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton kernel for 5x5 depthwise convolution\n@triton.jit\ndef _depthwise_conv2d_5x5_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_h, in_w, out_h, out_w,\n    in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n    weight_stride_c, weight_stride_kh, weight_stride_kw,\n    out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_n = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n    pid_hb = pid_block // num_blocks_w\n    pid_wb = pid_block % num_blocks_w\n    start_h = pid_hb * BLOCK_H\n    start_w = pid_wb * BLOCK_W\n    \n    # Load weights for this channel\n    weight_ptr_c = weight_ptr + pid_c * weight_stride_c\n    weights = tl.zeros((5, 5), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            weights = tl.where(True, weights, tl.load(weight_ptr_c + kh*weight_stride_kh + kw*weight_stride_kw), kh, kw)\n    \n    # Prepare input block\n    input_ptr_nc = input_ptr + pid_n * in_stride_n + pid_c * in_stride_c\n    i_h = tl.arange(0, BLOCK_H + 4)\n    i_w = tl.arange(0, BLOCK_W + 4)\n    input_h = start_h - 2 + i_h\n    input_w = start_w - 2 + i_w\n    \n    # Boundary checks\n    mask_h = (input_h >= 0) & (input_h < in_h)\n    mask_w = (input_w >= 0) & (input_w < in_w)\n    mask = mask_h[:, None] & mask_w[None, :]\n    \n    # Load input block\n    input_ptrs = input_ptr_nc + input_h[:, None] * in_stride_h + input_w[None, :] * in_stride_w\n    input_block = tl.load(input_ptrs, mask=mask, other=0.0)\n    \n    # Compute output block\n    output_block = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    for kh in range(5):\n        for kw in range(5):\n            output_block += input_block[kh:kh+BLOCK_H, kw:kw+BLOCK_W] * weights[kh, kw]\n    \n    # Store output block\n    output_ptr_nc = output_ptr + pid_n * out_stride_n + pid_c * out_stride_c\n    output_h = start_h + tl.arange(0, BLOCK_H)\n    output_w = start_w + tl.arange(0, BLOCK_W)\n    mask_out = (output_h < out_h)[:, None] & (output_w < out_w)[None, :]\n    output_ptrs = output_ptr_nc + output_h[:, None] * out_stride_h + output_w[None, :] * out_stride_w\n    tl.store(output_ptrs, output_block, mask=mask_out)\n\n# Triton depthwise convolution module\nclass TritonDepthwiseConv2d(nn.Module):\n    def __init__(self, in_channels, kernel_size, stride, padding, bias=False):\n        super().__init__()\n        self.in_channels = in_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, 1, kernel_size, kernel_size))\n    \n    def forward(self, x):\n        if self.kernel_size == 3 and self.stride == 1 and self.padding == 1:\n            return self._triton_conv(x, 3)\n        elif self.kernel_size == 5 and self.stride == 1 and self.padding == 2:\n            return self._triton_conv(x, 5)\n        else:\n            return F.conv2d(x, self.weight, stride=self.stride, padding=self.padding, groups=self.in_channels)\n    \n    def _triton_conv(self, x, kernel_size):\n        batch, in_channels, in_h, in_w = x.shape\n        out_h = (in_h + 2 * self.padding - kernel_size) // self.stride + 1\n        out_w = (in_w + 2 * self.padding - kernel_size) // self.stride + 1\n        output = torch.empty((batch, in_channels, out_h, out_w), device=x.device, dtype=x.dtype)\n        \n        # Changed block sizes to make input dimensions powers of two\n        BLOCK_H, BLOCK_W = (30, 30) if kernel_size == 3 else (12, 12)\n        num_blocks_h = (out_h + BLOCK_H - 1) // BLOCK_H\n        num_blocks_w = (out_w + BLOCK_W - 1) // BLOCK_W\n        grid = (batch, in_channels, num_blocks_h * num_blocks_w)\n        \n        in_stride_n, in_stride_c, in_stride_h, in_stride_w = x.stride()\n        weight_stride_c, _, weight_stride_kh, weight_stride_kw = self.weight.stride()\n        out_stride_n, out_stride_c, out_stride_h, out_stride_w = output.stride()\n        \n        kernel = _depthwise_conv2d_3x3_kernel if kernel_size == 3 else _depthwise_conv2d_5x5_kernel\n        kernel[grid](\n            x, self.weight, output,\n            in_h, in_w, out_h, out_w,\n            in_stride_n, in_stride_c, in_stride_h, in_stride_w,\n            weight_stride_c, weight_stride_kh, weight_stride_kw,\n            out_stride_n, out_stride_c, out_stride_h, out_stride_w,\n            BLOCK_H, BLOCK_W\n        )\n        return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ModelNew, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        self.blocks = nn.Sequential(\n            MBConv(32\u6781 16, kernel_size=3, stride=1, expand_ratio=1),\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        super(MBConv, self).__init__()\n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        padding = (kernel_size - 1) // 2\n        self.depthwise_conv = nn.Sequential(\n            TritonDepthwiseConv2d(hidden_dim, kernel_size, stride, padding),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        identity = x\n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        if self.use_residual:\n            x += identity\n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Alternative compiled approach, Alternative correctness approach\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_classes=1000):\n        \"\"\"\n        EfficientNetB0 architecture implementation in PyTorch.\n\n        :param num_classes: The number of output classes (default is 1000 for ImageNet).\n        \"\"\"\n        super(ModelNew, self).__init__()\n        \n        # Initial convolutional layer\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        \n        # MBConv blocks\n        self.blocks = nn.Sequential(\n            # MBConv1 (32, 16, 1, 1)\n            MBConv(32, 16, kernel_size=3, stride=1, expand_ratio=1),\n            # MBConv6 (16, 24, 2, 6)\n            MBConv(16, 24, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (24, 24, 1, 6)\n            MBConv(24, 24, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (24, 40, 2, 6)\n            MBConv(24, 40, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (40, 40, 1, 6)\n            MBConv(40, 40, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (40, 80, 2, 6)\n            MBConv(40, 80, kernel_size=3, stride=2, expand_ratio=6),\n            # MBConv6 (80, 80, 1, 6)\n            MBConv(80, 80, kernel_size=3, stride=1, expand_ratio=6),\n            # MBConv6 (80, 112, 1, 6)\n            MBConv(80, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 112, 1, 6)\n            MBConv(112, 112, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (112, 192, 2, 6)\n            MBConv(112, 192, kernel_size=5, stride=2, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 192, 1, 6)\n            MBConv(192, 192, kernel_size=5, stride=1, expand_ratio=6),\n            # MBConv6 (192, 320, 1, 6)\n            MBConv(192, 320, kernel_size=3, stride=1, expand_ratio=6)\n        )\n        \n        # Final convolutional layer\n        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(1280)\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1280, num_classes)\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the EfficientNetB0 model.\n\n        :param x: The input tensor, shape (batch_size, 3, 224, 224)\n        :return: The output tensor, shape (batch_size, num_classes)\n        \"\"\"\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.blocks(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):\n        \"\"\"\n        MBConv block implementation.\n\n        :param in_channels: Number of input channels.\n        :param out_channels: Number of output channels.\n        :param kernel_size: Kernel size for the depthwise convolution.\n        :param stride: Stride for the depthwise convolution.\n        :param expand_ratio: Expansion ratio for the intermediate channels.\n        \"\"\"\n        super(MBConv, self).__init__()\n        \n        self.use_residual = (stride == 1 and in_channels == out_channels)\n        hidden_dim = in_channels * expand_ratio\n        \n        if expand_ratio != 1:\n            self.expand_conv = nn.Sequential(\n                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU6(inplace=True)\n            )\n        \n        self.depthwise_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, groups=hidden_dim, bias=False),\n            nn.BatchNorm2d(hidden_dim),\n            nn.ReLU6(inplace=True)\n        )\n        \n        self.project_conv = nn.Sequential(\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Forward pass of the MBConv block.\n\n        :param x: The input tensor, shape (batch_size, in_channels, H, W)\n        :return: The output tensor, shape (batch_size, out_channels, H', W')\n        \"\"\"\n        identity = x\n        \n        if hasattr(self, 'expand_conv'):\n            x = self.expand_conv(x)\n        \n        x = self.depthwise_conv(x)\n        x = self.project_conv(x)\n        \n        if self.use_residual:\n            x += identity\n        \n        return x\n\n# Test code\nbatch_size = 10\nnum_classes = 1000\n\ndef get_inputs():\n    return [torch.randn(batch_size, 3, 224, 224)]\n\ndef get_init_inputs():\n    return [num_classes]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["=\u67810, bias=False)\n        self.b"]}}}