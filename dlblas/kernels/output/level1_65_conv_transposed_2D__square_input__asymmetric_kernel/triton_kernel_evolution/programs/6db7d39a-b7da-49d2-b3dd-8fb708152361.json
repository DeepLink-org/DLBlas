{"id": "6db7d39a-b7da-49d2-b3dd-8fb708152361", "code": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_transpose2d_kernel(\n    # Pointers to tensors\n    x_ptr, w_ptr, bias_ptr, output_ptr,\n    # Tensor dimensions\n    B, C_in, H_in, W_in,\n    C_out, H_out, W_out,\n    # Strides and paddings\n    stride_h, stride_w,\n    padding_h, padding_w,\n    kernel_h, kernel_w,\n    groups,\n    # Meta-parameters\n    BLOCK_SIZE: tl.constexpr,\n):\n    # We use a 3D grid: (batch, output channel, spatial_block)\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    pid_block = tl.program_id(2)  # which block of the spatial dimension\n\n    # Calculate the spatial block start and offsets\n    block_start = pid_block * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    spatial_mask = offsets < (H_out * W_out)\n\n    # Decompose the spatial offset into height and width indices\n    offs_h = offsets // W_out\n    offs_w = offsets % W_out\n\n    # Group processing\n    out_channels_per_group = C_out // groups\n    in_channels_per_group = C_in // groups\n    group_id = pid_oc // out_channels_per_group\n    oc_in_group = pid_oc % out_channels_per_group\n    ic_start = group_id * in_channels_per_group\n\n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n\n    # Iterate over kernel and input channels\n    for kh in range(kernel_h):\n        for kw in range(kernel_w):\n            for ic in range(in_channels_per_group):\n                # Calculate the input element indices\n                input_h = (offs_h * stride_h) + kh - padding_h\n                input_w = (offs_w * stride_w) + kw - padding_w\n\n                # Check if the input indices are within bounds\n                in_bounds = (input_h >= 0) & (input_h < H_in) & (input_w >= 0) & (input_w < W_in) & spatial_mask\n                input_idx = ic_start + ic\n\n                # Compute the input pointer offsets\n                input_offsets = pid_b * (C_in * H_in * W_in) + input_idx * (H_in * W_in) + input_h * W_in + input_w\n\n                # Load input values with masking\n                input_val = tl.load(x_ptr + input_offsets, mask=in_bounds, other=0.0)\n\n                # Weight offset: [input_channel, output_channel_in_group, kernel_h, kernel_w]\n                weight_offset = (ic_start + ic) * (out_channels_per_group * kernel_h * kernel_w) + \\\n                               oc_in_group * (kernel_h * kernel_w) + \\\n                               kh * kernel_w + kw\n\n                weight_val = tl.load(w_ptr + weight_offset)\n\n                # Accumulate\n                acc += input_val * weight_val\n\n    # Add bias if provided\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + pid_oc)\n        acc += bias_val\n\n    # Compute output offsets: [batch, output_channel, height, width]\n    output_offsets = pid_b * (C_out * H_out * W_out) + pid_oc * (H_out * W_out) + offsets\n    tl.store(output_ptr + output_offsets, acc, mask=spatial_mask)", "language": "python", "parent_id": "20432a5a-dffe-4831-b9dc-3bff0c8b346d", "generation": 6, "timestamp": 1754984163.910269, "iteration_found": 9, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.258, "runtime_ms": 0.204, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0526, "speed_up": 0.258, "custom_timing": 0.204}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 2}, "artifacts_json": null, "artifact_dir": null}