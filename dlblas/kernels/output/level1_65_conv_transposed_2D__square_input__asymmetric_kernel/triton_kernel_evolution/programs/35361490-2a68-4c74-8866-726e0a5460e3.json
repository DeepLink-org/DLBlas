{"id": "35361490-2a68-4c74-8866-726e0a5460e3", "code": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_transpose2d_kernel(\n    # Pointers to tensors\n    x_ptr, w_ptr, bias_ptr, output_ptr,\n    # Tensor dimensions\n    B, C_in, H_in, W_in,\n    C_out, H_out, W_out,\n    # Strides and paddings\n    stride_h, stride_w,\n    padding_h, padding_w,\n    kernel_h, kernel_w,\n    groups,\n    # Meta-parameters\n    BLOCK_SIZE: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    # 3D grid: (batch, output channel, spatial_block)\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    pid_block = tl.program_id(2)\n\n    # Group processing\n    out_channels_per_group = C_out // groups\n    in_channels_per_group = C_in // groups\n    group_id = pid_oc // out_channels_per_group\n    oc_in_group = pid_oc % out_channels_per_group\n    ic_start = group_id * in_channels_per_group\n\n    # Compute spatial block start and offsets\n    block_start = pid_block * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    spatial_mask = offsets < (H_out * W_out)\n    \n    # Decompose spatial offset into height and width\n    offs_h = offsets // W_out\n    offs_w = offsets % W_out\n\n    # Initialize accumulator with vectorization\n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n    \n    # Preload all weights for this output channel\n    weight_cache = tl.zeros((in_channels_per_group, kernel_h, kernel_w), dtype=tl.float32)\n    for ic in range(in_channels_per_group):\n        input_idx = ic_start + ic\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                weight_offset = (input_idx * out_channels_per_group * kernel_h * kernel_w + \n                                oc_in_group * kernel_h * kernel_w + \n                                kh * kernel_w + kw)\n                weight_cache[ic, kh, kw] = tl.load(w_ptr + weight_offset)\n\n    # Process input in vectorized chunks\n    for vec_start in range(0, BLOCK_SIZE, VEC_SIZE):\n        vec_offsets = vec_start + tl.arange(0, VEC_SIZE)\n        vec_mask = vec_offsets < BLOCK_SIZE\n        active_mask = vec_mask & spatial_mask[vec_offsets]\n        \n        if tl.reduce(active_mask, 0) > 0:\n            vec_offs_h = tl.load(offs_h + vec_offsets, mask=active_mask)\n            vec_offs_w = tl.load(offs_w + vec_offsets, mask=active_mask)\n            \n            # Vectorized accumulation\n            for ic in range(in_channels_per_group):\n                input_idx = ic_start + ic\n                base_offset = pid_b * (C_in * H_in * W_in) + input_idx * (H_in * W_in)\n                \n                for kh in tl.static(range(kernel_h)):\n                    for kw in tl.static(range(kernel_w)):\n                        input_h = vec_offs_h * stride_h + kh - padding_h\n                        input_w = vec_offs_w * stride_w + kw - padding_w\n                        \n                        # Boundary checks\n                        in_bounds = (input_h >= 0) & (input_h < H_in) & \\\n                                    (input_w >= 0) & (input_w < W_in) & \\\n                                    active_mask\n                        \n                        # Compute input pointer offsets\n                        input_offsets = base_offset + input_h * W_in + input_w\n                        \n                        # Vectorized load\n                        input_val = tl.load(\n                            x_ptr + input_offsets, \n                            mask=in_bounds, \n                            other=0.0\n                        )\n                        \n                        # Accumulate with preloaded weights\n                        weight_val = weight_cache[ic, kh, kw]\n                        acc_vec = tl.load(acc + vec_offsets, mask=active_mask)\n                        acc_vec += input_val * weight_val\n                        tl.store(acc + vec_offsets, acc_vec, mask=active_mask)\n\n    # Add bias if provided\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + pid_oc)\n        acc += bias_val\n\n    # Compute output offsets and store\n    output_offsets = pid_b * (C_out * H_out * W_out) + \\\n                     pid_oc * (H_out * W_out) + offsets\n    tl.store(output_ptr + output_offsets, acc, mask=spatial_mask)", "language": "python", "parent_id": "3656816e-4606-4aad-855d-1cf785ce50bd", "generation": 8, "timestamp": 1754987873.1035385, "iteration_found": 26, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.259, "runtime_ms": 0.203, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0526, "speed_up": 0.259, "custom_timing": 0.203}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.254, "runtime_ms": 0.207, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0526, "speed_up": 0.254, "custom_timing": 0.207}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}