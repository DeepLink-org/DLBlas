{"id": "4158acd5-c01a-4518-b1d3-0233e7f747cb", "code": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_transpose2d_kernel(\n    # Pointers to tensors\n    x_ptr, w_ptr, bias_ptr, output_ptr,\n    # Tensor dimensions\n    B, C_in, H_in, W_in,\n    C_out, H_out, W_out,\n    # Strides and paddings\n    stride_h, stride_w,\n    padding_h, padding_w,\n    kernel_h, kernel_w,\n    groups,\n    # Meta-parameters\n    BLOCK_SIZE: tl.constexpr,\n):\n    # We use a 3D grid: (batch, output channel, spatial_block)\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    pid_block = tl.program_id(2)  # which block of the spatial dimension\n\n    # Calculate the spatial block start and offsets\n    block_start = pid_block * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    spatial_mask = offsets < (H_out * W_out)\n\n    # Decompose the spatial offset into height and width indices\n    offs_h = offsets // W_out\n    offs_w = offsets % W_out\n\n    # Group processing\n    out_channels_per_group = C_out // groups\n    in_channels_per_group = C_in // groups\n    group_id = pid_oc // out_channels_per_group\n    oc_in_group = pid_oc % out_channels_per_group\n    ic_start = group_id * in_channels_per_group\n\n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n\n    # Vectorization parameters\n    VECTOR_WIDTH = 8\n    num_vectors = tl.cdiv(in_channels_per_group, VECTOR_WIDTH)\n\n    # Iterate over kernel positions\n    for kh in range(kernel_h):\n        for kw in range(kernel_w):\n            # Calculate input positions for all spatial elements in block\n            input_h = (offs_h * stride_h) + kh - padding_h\n            input_w = (offs_w * stride_w) + kw - padding_w\n            \n            # Check input bounds for all spatial positions\n            in_bounds = (input_h >= 0) & (input_h < H_in) & (input_w >= 0) & (input_w < W_in) & spatial_mask\n            \n            # Vectorized loop over input channels\n            for vec_idx in range(num_vectors):\n                ic = vec_idx * VECTOR_WIDTH\n                ic_vec = tl.arange(0, VECTOR_WIDTH)\n                channel_mask = (ic + ic_vec) < in_channels_per_group\n                input_idx = ic_start + ic + ic_vec\n                \n                # Compute input pointer offsets [BLOCK_SIZE, VECTOR_WIDTH]\n                input_offsets = (\n                    pid_b * (C_in * H_in * W_in) + \n                    input_idx[None, :] * (H_in * W_in) + \n                    input_h[:, None] * W_in + \n                    input_w[:, None]\n                )\n                \n                # Load input values with vectorization\n                input_vals = tl.load(\n                    x_ptr + input_offsets,\n                    mask=in_bounds[:, None] & channel_mask[None, :],\n                    other=0.0\n                )\n                \n                # Weight offset: [VECTOR_WIDTH]\n                weight_offset = (\n                    input_idx * (out_channels_per_group * kernel_h * kernel_w) +\n                    oc_in_group * (kernel_h * kernel_w) +\n                    kh * kernel_w + kw\n                )\n                weight_vals = tl.load(\n                    w_ptr + weight_offset,\n                    mask=channel_mask,\n                    other=0.0\n                )\n                \n                # Vectorized accumulation\n                acc += tl.sum(input_vals * weight_vals[None, :], axis=1)\n\n    # Add bias if provided\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + pid_oc)\n        acc += bias_val\n\n    # Compute output offsets: [batch, output_channel, height, width]\n    output_offsets = pid_b * (C_out * H_out * W_out) + pid_oc * (H_out * W_out) + offsets\n    tl.store(output_ptr + output_offsets, acc, mask=spatial_mask)", "language": "python", "parent_id": "6db7d39a-b7da-49d2-b3dd-8fb708152361", "generation": 7, "timestamp": 1754985498.7337556, "iteration_found": 15, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.26, "runtime_ms": 0.202, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0526, "speed_up": 0.26, "custom_timing": 0.202}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.258, "runtime_ms": 0.204, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0526, "speed_up": 0.258, "custom_timing": 0.204}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}