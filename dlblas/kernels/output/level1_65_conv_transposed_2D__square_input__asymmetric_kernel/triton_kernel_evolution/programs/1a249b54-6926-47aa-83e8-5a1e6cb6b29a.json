{"id": "1a249b54-6926-47aa-83e8-5a1e6cb6b29a", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef conv_transpose2d_kernel(\n    input_ptr, weight_ptr, output_ptr,\n    in_channels, out_channels, kH, kW,\n    groups, stride_h, stride_w, padding_h, padding_w,\n    H_in, W_in, H_out, W_out,\n    input_bs, input_cs, input_hs, input_ws,\n    weight_ics, weight_ocs, weight_hs, weight_ws,\n    output_bs, output_cs, output_hs, output_ws,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_bc = tl.program_id(0)\n    pid_h = tl.program_id(1)\n    pid_w = tl.program_id(2)\n    \n    pid_b = pid_bc // out_channels\n    pid_c = pid_bc % out_channels\n    \n    # Compute output block positions\n    oh = pid_h * BLOCK_H + tl.arange(0, BLOCK_H)\n    ow = pid_w * BLOCK_W + tl.arange(0, BLOCK_W)\n    \n    # Calculate group parameters\n    channels_per_group = out_channels // groups\n    group_id = pid_c // channels_per_group\n    local_c_out = pid_c % channels_per_group\n    \n    # Create masks for boundary checks\n    oh_mask = oh < H_out\n    ow_mask = ow < W_out\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    # Iterate over kernel positions\n    for kh in range(kH):\n        for kw in range(kW):\n            # Compute input positions\n            ih = (oh - padding_h + kh) // stride_h\n            iw = (ow - padding_w + kw) // stride_w\n            \n            # Check divisibility and boundaries\n            rem_h = (oh - padding_h + kh) % stride_h\n            rem_w = (ow - padding_w + kw) % stride_w\n            valid_h = (ih >= 0) & (ih < H_in) & (rem_h == 0)\n            valid_w = (iw >= 0) & (iw < W_in) & (rem_w == 0)\n            \n            # Create 2D masks\n            valid_mask = valid_h[:, None] & valid_w[None, :]\n            bounds_mask = oh_mask[:, None] & ow_mask[None, :] & valid_mask\n            \n            # Iterate over input channels in group\n            for c_in in range(group_id * (in_channels // groups), (group_id + 1) * (in_channels // groups)):\n                # Load input values\n                input_vals = tl.load(\n                    input_ptr + pid_b * input_bs + c_in * input_cs + ih[:, None] * input_hs + iw[None, :] * input_ws,\n                    mask=bounds_mask,\n                    other=0.0\n                )\n                \n                # Load weight value\n                weight_val = tl.load(\n                    weight_ptr + c_in * weight_ics + local_c_out * weight_ocs + kh * weight_hs + kw * weight_ws\n                )\n                \n                # Accumulate\n                acc += input_vals * weight_val\n    \n    # Create output mask\n    output_mask = oh_mask[:, None] & ow_mask[None, :]\n    \n    # Compute output pointer offsets\n    output_offsets = (\n        pid_b * output_bs + \n        pid_c * output_cs + \n        oh[:, None] * output_hs + \n        ow[None, :] * output_ws\n    )\n    \n    # Store results\n    tl.store(output_ptr + output_offsets, acc, mask=output_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, \n                 stride: int = 1, padding: int = 0, output_padding: int = 0, \n                 groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.output_padding = output_padding\n        self.groups = groups\n        \n        # Correct weight shape for grouped convolution\n        self.weight = nn.Parameter(\n            torch.empty(in_channels, out_channels // groups, kernel_size[0], kernel_size[1])\n        )\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n            \n        # Initialize parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch, in_channels, H_in, W_in = x.shape\n        kH, kW = self.kernel_size\n        H_out = (H_in - 1) * self.stride - 2 * self.padding + kH + self.output_padding\n        W_out = (W_in - 1) * self.stride - 2 * self.padding + kW + self.output_padding\n        \n        output = torch.empty(\n            (batch, self.out_channels, H_out, W_out), \n            device=x.device, \n            dtype=x.dtype\n        )\n        \n        grid = lambda meta: (\n            batch * self.out_channels,\n            triton.cdiv(H_out, meta['BLOCK_H']),\n            triton.cdiv(W_out, meta['BLOCK_W']),\n        )\n        \n        conv_transpose2d_kernel[grid](\n            x, self.weight, output,\n            in_channels, self.out_channels, kH, kW,\n            self.groups, self.stride, self.stride, self.padding, self.padding,\n            H_in, W_in, H_out, W_out,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.weight.stride(0), self.weight.stride(1), \n            self.weight.stride(2), self.weight.stride(3),\n            output.stride(0), output.stride(1), \n            output.stride(2), output.stride(3),\n            BLOCK_H=16, BLOCK_W=16\n        )\n        \n        if self.bias is not None:\n            output += self.bias[None, :, None, None]\n            \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nwidth = 128\nheight = 128\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "81330ee2-a1f4-47ae-92ac-e89f0f054835", "generation": 4, "timestamp": 1754985213.142003, "iteration_found": 14, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_65_conv_transposed_2D__square_input__asymmetric_kernel", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "max_difference": ["2.985656", "3.380133", "3.100494", "2.989229", "3.169021"], "avg_difference": ["0.430041", "0.430071", "0.429963", "0.429983", "0.430066"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0526, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_65_conv_transposed_2D__square_input__asymmetric_kernel", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "max_difference": ["1.785323", "1.682542", "1.667400", "1.709230", "1.695624"], "avg_difference": ["0.016985", "0.016994", "0.016998", "0.017029", "0.017001"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0526, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}