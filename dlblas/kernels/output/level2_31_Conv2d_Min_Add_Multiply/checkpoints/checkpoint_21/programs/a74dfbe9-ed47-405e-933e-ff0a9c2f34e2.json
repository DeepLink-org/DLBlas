{"id": "a74dfbe9-ed47-405e-933e-ff0a9c2f34e2", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1, num_stages=1),\n        triton.Config({}, num_warps=2, num_stages=1),\n        triton.Config({}, num_warps=4, num_stages=1),\n        triton.Config({}, num_warps=8, num_stages=1),\n        triton.Config({}, num_warps=16, num_stages=1),\n        triton.Config({}, num_warps=32, num_stages=1),\n        triton.Config({}, num_warps=32, num_stages=2),\n        triton.Config({}, num_warps=32, num_stages=4),\n    ],\n    key=['B', 'C', 'H', 'W'],\n)\n@triton.jit\ndef fused_pointwise_kernel(\n    x_ptr,\n    bias_ptr,\n    output_ptr,\n    constant_value,\n    scaling_factor,\n    B, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_idx = pid0 // C\n    channel_idx = pid0 % C\n    row_start = pid1 * BLOCK_SIZE\n    row_size = H * W\n    \n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < row_size\n    \n    x_vals = tl.load(\n        x_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        mask=mask,\n        other=0.0\n    )\n    \n    bias_val = tl.load(bias_ptr + channel_idx)\n    result = tl.minimum(x_vals, constant_value)\n    result = result + bias_val\n    result = result * scaling_factor\n    \n    tl.store(\n        output_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        result,\n        mask=mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        output = torch.empty_like(x)\n        bias_1d = self.bias.view(-1)\n        \n        n_rows = B * C\n        n_blocks_per_row = triton.cdiv(H * W, 1024)\n        grid = (n_rows, n_blocks_per_row)\n        \n        fused_pointwise_kernel[grid](\n            x, \n            bias_1d, \n            output,\n            self.constant_value,\n            self.scaling_factor,\n            B, C, H, W,\n            BLOCK_SIZE=1024\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "17124703-9aa1-4f7b-bed5-09bf026e623d", "generation": 2, "timestamp": 1754567078.8691883, "iteration_found": 7, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.741, "runtime_ms": 0.0994, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0737, "speed_up": 0.741, "custom_timing": 0.0994}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.844, "runtime_ms": 0.0873, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0737, "speed_up": 0.844, "custom_timing": 0.0873}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.8440\n- runtime_ms: 0.0873\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.844, 'custom_timing': 0.0873}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.0751, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.981, 'custom_timing': 0.0751}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8440, runtime_ms: 0.0873, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.844, 'custom_timing': 0.0873}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.7980, runtime_ms: 0.0923, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.798, 'custom_timing': 0.0923}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise(\n    x_ptr,\n    output_ptr,\n    bias_ptr,\n    constant_value,\n    scaling_factor,\n    N, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    \n    total_elements = N * C * H * W\n    elements_per_program = (total_elements + num_pid - 1) // num_pid\n    start_idx = pid * elements_per_program\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < total_elements\n    \n    n = offsets // (C * H * W)\n    c = (offsets % (C * H * W)) // (H * W)\n    hw = offsets % (H * W)\n    \n    x = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    bias_val = tl.load(bias_ptr + c, mask=mask, other=0.0)\n    \n    x = tl.minimum(x, constant_value)\n    x = x + bias_val\n    x = x * scaling_factor\n    \n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        N, C, H, W = x.shape\n        \n        output = torch.empty_like(x)\n        total_elements = N * C * H * W\n        BLOCK_SIZE = 1024\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        \n        fused_pointwise[grid](\n            x, output, self.bias.view(C),\n            self.constant_value, self.scaling_factor,\n            N, C, H, W,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.7980), Performs well on runtime_ms (0.0923), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.798, 'custom_timing': 0.0923})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise_kernel(\n    x_ptr,\n    bias_ptr,\n    output_ptr,\n    constant_value,\n    scaling_factor,\n    B, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_idx = pid0 // C\n    channel_idx = pid0 % C\n    row_start = pid1 * BLOCK_SIZE\n    row_size = H * W\n    \n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < row_size\n    \n    x_vals = tl.load(\n        x_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        mask=mask,\n        other=0.0\n    )\n    \n    bias_val = tl.load(bias_ptr + channel_idx)\n    result = tl.minimum(x_vals, constant_value)\n    result = result + bias_val\n    result = result * scaling_factor\n    \n    tl.store(\n        output_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        result,\n        mask=mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        output = torch.empty_like(x)\n        bias_1d = self.bias.view(-1)\n        \n        n_rows = B * C\n        n_blocks_per_row = triton.cdiv(H * W, 1024)\n        grid = (n_rows, n_blocks_per_row)\n        \n        fused_pointwise_kernel[grid](\n            x, \n            bias_1d, \n            output,\n            self.constant_value,\n            self.scaling_factor,\n            B, C, H, W,\n            BLOCK_SIZE=1024\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8440), Performs well on runtime_ms (0.0873), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.844, 'custom_timing': 0.0873})\n\n\n### Program 3 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = torch.min(x, torch.tensor(self.constant_value))\n        x = x + self.bias\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.0751), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0737, 'speed_up': 0.981, 'custom_timing': 0.0751})\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise(\n    x_ptr,\n    output_ptr,\n    bias_ptr,\n    constant_value,\n    scaling_factor,\n    N, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    \n    total_elements = N * C * H * W\n    elements_per_program = (total_elements + num_pid - 1) // num_pid\n    start_idx = pid * elements_per_program\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < total_elements\n    \n    n = offsets // (C * H * W)\n    c = (offsets % (C * H * W)) // (H * W)\n    hw = offsets % (H * W)\n    \n    x = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    bias_val = tl.load(bias_ptr + c, mask=mask, other=0.0)\n    \n    x = tl.minimum(x, constant_value)\n    x = x + bias_val\n    x = x * scaling_factor\n    \n    tl.store(output_ptr + offsets, x, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        N, C, H, W = x.shape\n        \n        output = torch.empty_like(x)\n        total_elements = N * C * H * W\n        BLOCK_SIZE = 1024\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        \n        fused_pointwise[grid](\n            x, output, self.bias.view(C),\n            self.constant_value, self.scaling_factor,\n            N, C, H, W,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise_kernel(\n    x_ptr,\n    bias_ptr,\n    output_ptr,\n    constant_value,\n    scaling_factor,\n    B, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_idx = pid0 // C\n    channel_idx = pid0 % C\n    row_start = pid1 * BLOCK_SIZE\n    row_size = H * W\n    \n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < row_size\n    \n    x_vals = tl.load(\n        x_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        mask=mask,\n        other=0.0\n    )\n    \n    bias_val = tl.load(bias_ptr + channel_idx)\n    result = tl.minimum(x_vals, constant_value)\n    result = result + bias_val\n    result = result * scaling_factor\n    \n    tl.store(\n        output_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        result,\n        mask=mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        output = torch.empty_like(x)\n        bias_1d = self.bias.view(-1)\n        \n        n_rows = B * C\n        n_blocks_per_row = triton.cdiv(H * W, 1024)\n        grid = (n_rows, n_blocks_per_row)\n        \n        fused_pointwise_kernel[grid](\n            x, \n            bias_1d, \n            output,\n            self.constant_value,\n            self.scaling_factor,\n            B, C, H, W,\n            BLOCK_SIZE=1024\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a Triton kernel that performs a fused pointwise operation: min(x, constant) + bias, then scaled.\n The current implementation uses a 2D grid: \n   - pid0: over batch and channel (B*C)\n   - pid1: over blocks of H*W (each block of size BLOCK_SIZE)\n\n The current performance (speed_up=0.844) is worse than the reference (0.844x means slower).\n\n We note that the kernel is doing:\n   result = (min(x, constant_value) + bias) * scaling_factor\n\n The current kernel loads one element per thread? Actually, it loads a block of BLOCK_SIZE elements per thread block.\n\n However, the memory access pattern might not be optimal.\n\n Let's analyze the access pattern for the input tensor (x_ptr) and output tensor (output_ptr):\n   The tensor has shape [B, C, H, W]. The kernel is launched with grid (B*C, n_blocks_per_row) and each block processes BLOCK_SIZE (1024) contiguous elements in the H*W dimension.\n\n This means that within a block, the elements are contiguous in the H*W dimension. Since the tensor is stored in contiguous memory in the order of (B, C, H, W), the contiguous H*W dimension is the innermost. Therefore, the accesses are contiguous and should be coalesced.\n\n However, note that we are storing the result in the same layout. So the memory accesses should be efficient.\n\n Why then is the Triton version slower?\n\n Possible reasons:\n  1. The kernel is doing very little computation per element (only min, add, multiply) and therefore is memory-bound.\n  2. The current grid launch might have too many blocks, and the overhead of launching many small blocks might be high.\n\n Another possibility: the current implementation uses a 2D grid. The reference (PyTorch) code is:\n      x = self.conv(x)\n      x = torch.min(x, torch.tensor(self.constant_value))\n      x = x + self.bias\n      x = x * self.scaling_factor\n\n The PyTorch operations are likely fused and optimized by the CUDA backend. Our Triton kernel must be very efficient to beat that.\n\n We note that the current kernel loads the bias for every element (via `bias_val = tl.load(bias_ptr + channel_idx)`). However, this is a scalar per channel and could be reused.\n\n How can we improve?\n  - We are already reusing the bias per channel within a block? Actually, each block processes a contiguous segment of one channel. So the bias is the same for the entire block. We can load it once per block.\n\n  But note: the current code already loads the bias once per block? Because the bias is loaded with `channel_idx` which is fixed for the entire block.\n\n  However, the current code does:\n      bias_val = tl.load(bias_ptr + channel_idx)\n\n  This is a single load per block. So that should be fine.\n\n  Another idea: the current kernel uses a 2D grid. We might try a 1D grid and use a larger block size to improve memory coalescing and reduce overhead.\n\n  Alternatively, we can try to increase the block size beyond 1024? But note that the block size is currently 1024, and the H*W dimension is 32*32=1024. So each row is exactly one block. Therefore, the grid is (B*C, 1). That is, we have one block per channel per batch.\n\n  Actually, the current code uses:\n        n_blocks_per_row = triton.cdiv(H * W, 1024)\n\n  Since H*W=1024, then n_blocks_per_row=1. So the grid is (B*C, 1). That is one block per channel per batch.\n\n  Therefore, each block processes 1024 elements (exactly one row). \n\n  This should be efficient because:\n    - The block processes contiguous memory.\n    - The bias is loaded once per block.\n\n  Why is it slower then?\n\n  We must consider the overhead of launching a kernel and the fact that the computation is very light.\n\n  The reference PyTorch code might be doing the entire operation in one optimized kernel (like the one we are writing) but with a more efficient implementation?\n\n  Alternatively, we might try to fuse the entire operation including the convolution? But the problem does not allow that because the convolution is done by PyTorch and then we get the output of the convolution.\n\n  Another idea: use vectorized loads and stores. Currently, we are loading and storing element by element? Actually, we are using a contiguous block of 1024. But note: the Triton `tl.load` and `tl.store` can be vectorized if we use the `tl.dot` option? But we don't have a dot product. However, we can load multiple elements at once by using a vector of pointers? Actually, we are already loading a contiguous block with one instruction? \n\n  But note: the current code uses:\n        x_vals = tl.load(x_ptr + ... + offsets, mask=mask, other=0.0)\n\n  This is a contiguous block load? Actually, it is a contiguous block if the offsets are contiguous? They are: `tl.arange(0, BLOCK_SIZE)`. So the load is contiguous and should be coalesced.\n\n  However, the block size of 1024 might be too large? Or too small? \n\n  We note that the H100 has 128KB shared memory per SM. Each block uses:\n        - One float32 for the bias: 4 bytes.\n        - The block of data: 1024 * sizeof(float32) = 4096 bytes.\n        - Plus some indices: negligible.\n\n  So about 4100 bytes per block. That is within the shared memory limit? But we are not using shared memory at all! The data is loaded directly from global memory and stored back.\n\n  We might consider using shared memory to reduce global memory traffic? But the operation is element-wise and each element is read once and written once. Using shared memory would not reduce the global memory traffic. It might even increase it because we would have to load into shared memory and then store from shared memory to global.\n\n  Therefore, shared memory is not beneficial.\n\n  What else?\n\n  We note that the kernel is launched with a grid of (B*C, 1). For B=128, C=16, that is 2048 blocks. The H100 has 132 SMs. This might be enough to fill the GPU? But 2048 blocks is more than 132, so it should be fine.\n\n  Another idea: the current kernel uses a block size of 1024. The H100 has a warp of 32 threads. So 1024/32=32 warps per block. The maximum warps per SM is 64 (for H100). So we are using 32 warps per block. Each SM can run 2 blocks? Because 64 warps per SM, so 2 blocks (each 32 warps) would be 64 warps. That is acceptable.\n\n  However, the occupancy might be limited by the number of blocks we can run concurrently? We have 2048 blocks and 132 SMs, so each SM would run about 15-16 blocks? But the maximum blocks per SM is 32 (for H100). So we are within the limit.\n\n  Why is the Triton kernel slower? \n\n  We might try to increase the block size? But the row is only 1024 elements. So we cannot process more than 1024 in one block without having multiple rows? But we are processing one row per block.\n\n  Alternatively, we can process multiple rows per block? But note: the tensor has dimensions [B, C, H, W]. The rows (H*W) are 1024. We cannot change that.\n\n  Another possibility: the kernel is compiled without optimizations? We can try to add the `num_warps` and `num_stages` parameters? The autotune example we saw earlier had multiple configurations.\n\n  We can try to autotune the kernel for different configurations (number of warps and stages) to see if we can get better performance.\n\n  Let's add an autotune decorator with a few configurations.\n\n  We note that the current kernel does not have any autotune. We can try:\n\n      configs = [\n          triton.Config({}, num_warps=1),\n          triton.Config({}, num_warps=2),\n          triton.Config({}, num_warps=4),\n          triton.Config({}, num_warps=8),\n          triton.Config({}, num_warps=16),\n          triton.Config({}, num_warps=32),\n      ]\n\n  Since the block has 1024 elements, and a warp has 32 threads, then:\n        num_warps = 1024 / 32 = 32 warps per block.\n\n  So we are currently using 32 warps? Actually, the kernel does not specify the number of warps. The default might be 4? We must check the Triton documentation.\n\n  In the current kernel, we are not setting the number of warps. The default is 4? That would be 4 * 32 = 128 threads per block, but we have 1024 elements. So each thread would process 1024/128=8 elements.\n\n  But in the current kernel, we are using:\n\n        offsets = row_start + tl.arange(0, BLOCK_SIZE)\n\n  And then we load and store in a vectorized way? Actually, the `tl.arange(0, BLOCK_SIZE)` creates a vector of 1024 elements. This is handled by the compiler by splitting the work among the threads.\n\n  How does Triton assign work? It uses the number of warps to determine the number of threads. The default number of warps is 4? Then we have 128 threads. Each thread would then process 1024/128=8 elements.\n\n  But we are not using a loop? The current kernel does:\n\n        x_vals = tl.load(...)   # This loads 8 elements per thread? \n\n  Actually, the Triton compiler will automatically vectorize the load and store if the indices are contiguous? And then each thread will process multiple elements.\n\n  We can try to increase the number of warps? Because 4 warps (128 threads) might be too few for a block of 1024 elements. The H100 SM can run up to 2048 threads (64 warps). We are only using 128 threads per block. We could use 32 warps (1024 threads) to have one element per thread? That might be faster.\n\n  Let's try to set the number of warps to 32 (which is 1024 threads) for the block of 1024 elements.\n\n  We can do that by adding an autotune decorator that tries different numbers of warps and also different numbers of stages.\n\n  Also, note that the kernel is very memory bound. We might want to use the `num_stages` parameter to control the pipeline stages? More stages can hide memory latency.\n\n  We'll try:\n\n      configs = [\n          triton.Config({}, num_warps=1, num_stages=1),\n          triton.Config({}, num_warps=1, num_stages=2),\n          triton.Config({}, num_warps=1, num_stages=4),\n          triton.Config({}, num_warps=2, num_stages=1),\n          ... # but we want to cover the 32 warps and also try stages.\n\n      ]\n\n  But note: the maximum number of warps per block is 32 for 1024 threads? Actually, 32 warps * 32 threads = 1024 threads. That is the maximum for our block size.\n\n  We can try:\n\n      triton.Config({}, num_warps=32, num_stages=1),\n      triton.Config({}, num_warps=32, num_stages=2),\n      triton.Config({}, num_warps=32, num_stages=4),\n\n  And also try fewer warps? But we want to cover the case of one element per thread.\n\n  Alternatively, we can note that the H100 has Tensor Cores? But we are doing element-wise operations, so we don't use Tensor Cores.\n\n  Let's add an autotune decorator with a few configurations, especially the one with 32 warps.\n\n  We also note that the block size is fixed to 1024? But what if the H*W is not 1024? The problem says the input is 32x32=1024. So it is fixed.\n\n  However, to make it general, we keep the BLOCK_SIZE.\n\n  We'll change the kernel to:\n\n      @triton.autotune(\n          configs=[\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=1, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=2, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=4, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=8, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=16, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=32, num_stages=1),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=32, num_stages=2),\n              triton.Config({'BLOCK_SIZE': 1024}, num_warps=32, num_stages=4),\n          ],\n          key=['B', 'C', 'H', 'W'],\n      )\n      @triton.jit\n      def fused_pointwise_kernel(...):\n          ... same as before ...\n\n  We also note that the kernel uses BLOCK_SIZE as a constant. We are setting it to 1024 in the autotune configs? But note that the kernel also uses BLOCK_SIZE as an argument. We must remove the argument and use it as a constant from the config? Actually, the autotune will override the BLOCK_SIZE provided in the kernel call? \n\n  Alternatively, we can let the autotune set the BLOCK_SIZE? But in our case, the block size must be 1024 because the row is 1024. We are not processing more than one row per block? \n\n  Actually, the kernel is designed to process a row in multiple blocks? But we are setting the grid to have n_blocks_per_row = triton.cdiv(H*W, BLOCK_SIZE). So if we change BLOCK_SIZE, the grid would change accordingly.\n\n  However, the problem is that the row is 1024, and we want to process it in one block? Because if we break it into multiple blocks, we might have to do multiple blocks per row? But that would require more blocks and more overhead.\n\n  Since we are trying to improve performance, we can try to keep the block size 1024 and use the autotune for the number of warps and stages.\n\n  But note: the kernel must be general for any H and W? The problem says the input is 32x32, but we are writing a general model.\n\n  We are given the input in the problem: height, width = 32,32. So we can assume that H*W is 1024? But the kernel should work for any H and W.\n\n  We can leave the kernel as is and only autotune the number of warps and stages.\n\n  However, we must change the way we launch the kernel? Currently, we set BLOCK_SIZE=1024 in the forward function. We should instead let the autotune choose the BLOCK_SIZE? But note: the autotune configs we are writing are for BLOCK_SIZE=1024. We are not changing the block size.\n\n  Alternatively, we can remove the BLOCK_SIZE from the kernel argument and make it a constant from the config? But then we cannot change it per launch.\n\n  We decide: we will keep the BLOCK_SIZE as an argument to the kernel, but in the autotune we fix it to 1024? But what if the row is not 1024? We can set the BLOCK_SIZE to the minimum of 1024 and the row size? Actually, we are already computing the grid with triton.cdiv.\n\n  We can try to autotune for different block sizes? But the problem says the tensor is 32x32, so we focus on that.\n\n  Since we are in a competition and the input is fixed, we can optimize for 1024.\n\n  We'll try to set the number of warps to 32 and num_stages to 4? That might be the best.\n\n  But we'll let the autotune decide.\n\n  Steps:\n\n  1. Add the autotune decorator with the configs above.\n  2. Remove the BLOCK_SIZE from the kernel arguments? No, because we use it to compute the offsets. We will keep it as an argument, and in the autotune configs we set it to 1024? But note: the autotune configs can override the value of BLOCK_SIZE that is passed? Actually, the autotune will override the value provided in the kernel call with the value in the config? We must be cautious.\n\n  The autotune documentation: the configs are dictionaries that set the values of the `tl.constexpr` arguments. So if we have a `tl.constexpr` argument named `BLOCK_SIZE`, then we can set it in the config.\n\n  But note: we are passing BLOCK_SIZE from the forward function. We want to autotune the number of warps and stages, but we don't want to change the block size? Then we don't set BLOCK_SIZE in the config. We only set num_warps and num_stages.\n\n  So we change the autotune configs to not include BLOCK_SIZE? We leave it as:\n\n        configs = [\n            triton.Config({}, num_warps=1, num_stages=1),\n            triton.Config({}, num_warps=1, num_stages=2),\n            triton.Config({}, num_warps=1, num_stages=4),\n            ... # and so on\n        ]\n\n  Then the BLOCK_SIZE will be taken from the kernel call.\n\n  3. We must also note that the kernel uses BLOCK_SIZE as a `tl.constexpr`. That is already the case.\n\n  Let's write the autotune.\n\n  We also note that the kernel has other parameters (B, C, H, W) that we use in the key? But we are using the same kernel for different tensor sizes? The problem says the input is fixed (batch_size=128, in_channels=3, ...). So we don't need to worry about different sizes? But we set the key to the sizes.\n\n  We'll set the key to ['B','C','H','W'] so that the autotune will cache the best config for a given tensor shape.\n\n  We'll also note that the kernel has an argument `constant_value` and `scaling_factor` which are scalars. We don't include them in the key.\n\n  Implementation:\n\n      @triton.autotune(\n          configs=[\n              triton.Config({}, num_warps=1, num_stages=1),\n              triton.Config({}, num_warps=2, num_stages=1),\n              triton.Config({}, num_warps=4, num_stages=1),\n              triton.Config({}, num_warps=8, num_stages=1),\n              triton.Config({}, num_warps=16, num_stages=1),\n              triton.Config({}, num_warps=32, num_stages=1),\n              triton.Config({}, num_warps=32, num_stages=2),\n              triton.Config({}, num_warps=32, num_stages=4),\n          ],\n          key=['B', 'C', 'H', 'W'],\n      )\n      @triton.jit\n      def fused_pointwise_kernel(...):\n          ... same as before ...\n\n  And then in the forward function, we remove the BLOCK_SIZE from the kernel call? No, we still pass it. The autotune will override the num_warps and num_stages, but the BLOCK_SIZE is passed as an argument.\n\n  But note: the autotune configs do not set BLOCK_SIZE, so they use the value we pass.\n\n  We are passing BLOCK_SIZE=1024. So it's fixed.\n\n  We hope that the autotune will choose a configuration with 32 warps and 4 stages, which might be faster.\n\n  We also note that the kernel is very memory bound. We might try to use vectorized loads and stores? The current code uses scalar loads and stores? Actually, the Triton compiler might automatically vectorize. But we can try to do explicit vectorization.\n\n  How? We can change the kernel to process multiple elements per thread? But the current kernel already processes a contiguous block. The Triton compiler should be able to generate vectorized loads.\n\n  Alternatively, we can use the `tl.make_block_ptr` and `tl.advance` to get a pointer to a block and then load a block? But that might be more efficient? \n\n  We can try that in a separate version if this doesn't work.\n\n  Let's try the autotune first because it is a small change.\n\n  We'll change the kernel by adding the autotune decorator and hope that it improves performance.\n\n  Also, note: the current kernel does:\n\n        result = tl.minimum(x_vals, constant_value)\n        result = result + bias_val\n        result = result * scaling_factor\n\n  We can fuse these into one line? That might help the compiler to optimize the intermediate registers? But it is already simple.\n\n  We'll leave it as is.\n\n  We also note that the current kernel does:\n\n        bias_val = tl.load(bias_ptr + channel_idx)\n\n  This is a broadcasted load? And it is outside the loop? So it should be efficient.\n\n  We are optimistic that with 32 warps (so 1024 threads) each thread processing one element, we can get better performance.\n\n  We'll write the kernel with autotune.\n\n  IMPORTANT: We must not change the function signature or the grid configuration. We are keeping the same grid: (B*C, n_blocks_per_row) and the same BLOCK_SIZE=1024.\n\n  We'll also note that when the row is not a multiple of BLOCK_SIZE, the mask is handled correctly.\n\n  Let's write the code.\n\n  Note: We are not allowed to change the grid configuration. So we keep the grid as:\n\n        n_rows = B * C\n        n_blocks_per_row = triton.cdiv(H * W, BLOCK_SIZE)   # which is 1 for 32x32\n        grid = (n_rows, n_blocks_per_row)\n\n  We are using BLOCK_SIZE=1024.\n\n  We hope that the autotune will improve performance.\n\n  If not, we might try a different approach (like 1D grid) in a future iteration.\n\n  Let's code accordingly.\n\n  We'll also note that the kernel might be memory bound and the H100 has high memory bandwidth. We are processing 128*16*32*32 = 128*16*1024 = 2.1e6 elements. Each element is 4 bytes (float32). So total data read and written is 2 * 2.1e6 * 4 = 16.8 MB. The H100 has 3 TB/s = 3000 GB/s. So the minimum time is 16.8e-3 GB / 3000 GB/s = 5.6e-6 seconds = 0.0056 ms. But the kernel takes 0.08 ms? That is 14 times slower. So there is room for improvement? But note that the kernel launch overhead and the fact that we are doing multiple small operations might be the issue.\n\n  We are hopeful that the autotune will help.\n\n  We'll now write the code.\n\n  IMPORTANT: We must not break the correctness. We are only changing the kernel decorator and adding autotune. The kernel body remains the same.\n\n  We'll also note that the kernel must be compiled for the specific GPU. The autotune will run the first time and then cache the best config.\n\n  We'll run the code and hope for a speedup.\n\n  Since we cannot run it, we rely on the autotune to pick the best config.\n\n  We'll output the code with the autotune decorator.\n\n  Also, note: the kernel uses `row_size = H * W` and `row_start = pid1 * BLOCK_SIZE`. We are not changing that.\n\n  We are changing the kernel to:\n\n      @triton.autotune(\n          configs=[\n              triton.Config({}, num_warps=1, num_stages=1),\n              triton.Config({}, num_warps=2, num_stages=1),\n              triton.Config({}, num_warps=4, num_stages=1),\n              triton.Config({}, num_warps=8, num_stages=1),\n              triton.Config({}, num_warps=16, num_stages=1),\n              triton.Config({}, num_warps=32, num_stages=1),\n              triton.Config({}, num_warps=32, num_stages=2),\n              triton.Config({}, num_warps=32, num_stages=4),\n          ],\n          key=['B', 'C', 'H', 'W'],\n      )\n      @triton.jit\n      def fused_pointwise_kernel(...):\n          ... same body ...\n\n  We'll also note that the kernel uses the `constant_value` and `scaling_factor` as scalar arguments. That is fine.\n\n  We hope this will improve performance.\n\n  If it doesn't, we might have to try a different approach (like a 1D grid) in the next iteration.\n\n  Let's output the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1, num_stages=1),\n        triton.Config({}, num_warps=2, num_stages=1),\n        triton.Config({}, num_warps=4, num_stages=1),\n        triton.Config({}, num_warps=8, num_stages=1),\n        triton.Config({}, num_warps=16, num_stages=1),\n        triton.Config({}, num_warps=32, num_stages=1),\n        triton.Config({}, num_warps=32, num_stages=2),\n        triton.Config({}, num_warps=32, num_stages=4),\n    ],\n    key=['B', 'C', 'H', 'W'],\n)\n@triton.jit\ndef fused_pointwise_kernel(\n    x_ptr,\n    bias_ptr,\n    output_ptr,\n    constant_value,\n    scaling_factor,\n    B, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_idx = pid0 // C\n    channel_idx = pid0 % C\n    row_start = pid1 * BLOCK_SIZE\n    row_size = H * W\n    \n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < row_size\n    \n    x_vals = tl.load(\n        x_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        mask=mask,\n        other=0.0\n    )\n    \n    bias_val = tl.load(bias_ptr + channel_idx)\n    result = tl.minimum(x_vals, constant_value)\n    result = result + bias_val\n    result = result * scaling_factor\n    \n    tl.store(\n        output_ptr + batch_idx * C * H * W + channel_idx * H * W + offsets,\n        result,\n        mask=mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        output = torch.empty_like(x)\n        bias_1d = self.bias.view(-1)\n        \n        n_rows = B * C\n        n_blocks_per_row = triton.cdiv(H * W, 1024)\n        grid = (n_rows, n_blocks_per_row)\n        \n        fused_pointwise_kernel[grid](\n            x, \n            bias_1d, \n            output,\n            self.constant_value,\n            self.scaling_factor,\n            B, C, H, W,\n            BLOCK_SIZE=1024\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}