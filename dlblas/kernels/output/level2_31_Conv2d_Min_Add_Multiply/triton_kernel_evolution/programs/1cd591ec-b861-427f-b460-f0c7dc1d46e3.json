{"id": "1cd591ec-b861-427f-b460-f0c7dc1d46e3", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise(\n    x_ptr,\n    output_ptr,\n    bias_ptr,\n    constant_value,\n    scaling_factor,\n    N, C, H, W,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_elements = N * C * H * W\n    start_idx = pid * BLOCK_SIZE\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < total_elements\n    \n    # Load input values\n    x_vals = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    \n    # Compute channel indices for bias\n    channel_idx = (offsets // (H * W)) % C\n    \n    # Load bias values\n    bias_vals = tl.load(bias_ptr + channel_idx, mask=mask, other=0.0)\n    \n    # Fused operations: min, add, scale\n    clipped = tl.minimum(x_vals, constant_value)\n    biased = clipped + bias_vals\n    result = biased * scaling_factor\n    \n    # Store results\n    tl.store(output_ptr + offsets, result, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.constant_value = constant_value\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.conv(x)\n        N, C, H, W = x.shape\n        \n        # Prepare output tensor\n        output = torch.empty_like(x)\n        total_elements = N * C * H * W\n        \n        # Launch kernel with optimized block size\n        BLOCK_SIZE = 2048\n        grid = (triton.cdiv(total_elements, BLOCK_SIZE),)\n        \n        fused_pointwise[grid](\n            x.contiguous().view(-1),\n            output.view(-1),\n            self.bias.view(-1),\n            self.constant_value,\n            self.scaling_factor,\n            N, C, H, W,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nconstant_value = 0.5\nbias_shape = (out_channels, 1, 1)\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "96a4e605-bd77-4312-b1e6-69c6dc209ed5", "generation": 3, "timestamp": 1754568604.0458286, "iteration_found": 15, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.821, "runtime_ms": 0.0898, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0737, "speed_up": 0.821, "custom_timing": 0.0898}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 1}, "artifacts_json": null, "artifact_dir": null}