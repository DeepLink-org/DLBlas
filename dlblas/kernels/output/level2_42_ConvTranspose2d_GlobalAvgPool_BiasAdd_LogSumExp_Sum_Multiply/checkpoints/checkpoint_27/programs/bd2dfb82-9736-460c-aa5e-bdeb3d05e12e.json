{"id": "bd2dfb82-9736-460c-aa5e-bdeb3d05e12e", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_kernel(\n    input_ptr,\n    bias_ptr,\n    output_ptr,\n    batch_size,\n    height,\n    width,\n    stride_b, stride_c, stride_h, stride_w,\n    BLOCK_SIZE: tl.constexpr,\n    channels: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    spatial_size = height * width\n    batch_offset = pid * stride_b\n    channel_vals = tl.zeros((channels,), dtype=tl.float32)\n\n    for c in tl.static_range(channels):\n        accum = 0.0\n        for i in range(0, spatial_size, BLOCK_SIZE):\n            offsets = i + tl.arange(0, BLOCK_SIZE)\n            mask = offsets < spatial_size\n            h = offsets // width\n            w = offsets % width\n            ptr = input_ptr + batch_offset + c * stride_c + h * stride_h + w * stride_w\n            data = tl.load(ptr, mask=mask, other=0.0)\n            accum += tl.sum(data, axis=0)\n        \n        channel_avg = accum / spatial_size\n        bias_val = tl.load(bias_ptr + c)\n        channel_vals += tl.where(tl.arange(0, channels) == c, channel_avg + bias_val, 0.0)\n\n    max_val = tl.max(channel_vals, axis=0)\n    exp_vals = tl.exp(channel_vals - max_val)\n    exp_sum = tl.sum(exp_vals, axis=0)\n    result = max_val + tl.log(exp_sum)\n    tl.store(output_ptr + pid, result * 10.0)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        B, C, H, W = x.shape\n        x = x.contiguous()\n        output = torch.empty(B, device=x.device, dtype=torch.float32)\n        \n        grid = (B,)\n        fused_kernel[grid](\n            x, \n            self.bias.view(-1), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "50a5ec96-d713-4e1a-a2dc-9529f03feb1e", "generation": 2, "timestamp": 1754577269.5854933, "iteration_found": 17, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 27.499999999999996, "speed_up": 1.075, "runtime_ms": 0.161, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.173, "speed_up": 1.075, "custom_timing": 0.161}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "max_difference": ["1.694868", "1.916801", "1.591812", "1.789497", "1.647457"], "avg_difference": ["0.859683", "0.934681", "0.894299", "0.856587", "0.864364"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.173, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'max_difference': ['1.694868', '1.916801', '1.591812', '1.789497', '1.647457'], 'avg_difference': ['0.859683', '0.934681', '0.894299', '0.856587', '0.864364'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.173, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'max_difference': ['0.349226', '0.322727'], 'avg_difference': ['0.089094', '0.092143'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(3 / 5)', 'reference_timing_ms': 0.173, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'max_difference': ['1.694868', '1.916801', '1.591812', '1.789497', '1.647457'], 'avg_difference': ['0.859683', '0.934681', '0.894299', '0.856587', '0.864364'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.173, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 24.8000, speed_up: 1.0480, runtime_ms: 0.1650, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.173, 'speed_up': 1.048, 'custom_timing': 0.165}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 24.8000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super().__init__()\n        self.conv_transpose = torch.nn.ConvTranspose2d(\n            in_channels, out_channels, kernel_size)\n        self.bias = torch.nn.Parameter(torch.randn(bias_shape))\n        self.out_channels = out_channels\n\n    @triton.jit\n    def _fused_kernel(\n        input_ptr,\n        bias_ptr,\n        output_ptr,\n        batch_size,\n        height,\n        width,\n        stride_b, stride_c, stride_h, stride_w,\n        BLOCK_SIZE: tl.constexpr,\n        channels: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        if pid >= batch_size:\n            return\n        \n        spatial_size = height * width\n        batch_offset = pid * stride_b\n        channel_vals = tl.zeros((channels,), dtype=tl.float32)\n\n        # Process each channel sequentially\n        for c in tl.static_range(channels):\n            accum = 0.0\n            # Block processing of spatial dimensions\n            for i in range(0, spatial_size, BLOCK_SIZE):\n                offsets = i + tl.arange(0, BLOCK_SIZE)\n                mask = offsets < spatial_size\n                h = offsets // width\n                w = offsets % width\n                ptr = input_ptr + batch_offset + c * stride_c + h * stride_h + w * stride_w\n                data = tl.load(ptr, mask=mask, other=0.0)\n                accum += tl.sum(data, axis=0)\n            \n            channel_avg = accum / spatial_size\n            bias_val = tl.load(bias_ptr + c)\n            channel_vals += tl.where(tl.arange(0, channels) == c, channel_avg + bias_val, 0.0)\n\n        # Log-sum-exp with numerical stability\n        max_val = tl.max(channel_vals, axis=0)\n        exp_vals = tl.exp(channel_vals - max_val)\n        exp_sum = tl.sum(exp_vals, axis=0)\n        result = max_val + tl.log(exp_sum)\n        tl.store(output_ptr + pid, result * 10.0)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        B, C, H, W = x.shape\n        x = x.contiguous()\n        output = torch.empty(B, device=x.device, dtype=torch.float32)\n        \n        grid = (B,)\n        self._fused_kernel[grid](\n            x, \n            self.bias.reshape(-1), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (24.8000), Performs well on speed_up (1.0480), Performs well on runtime_ms (0.1650), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.173, 'speed_up': 1.048, 'custom_timing': 0.165})\n\n\n### Program 2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _post_conv(\n    x_ptr, \n    bias_ptr,\n    output_ptr,\n    H: tl.constexpr,\n    W: tl.constexpr,\n    out_channels: tl.constexpr,\n    batch_size: tl.constexpr,\n    x_stride_batch: tl.constexpr,\n    x_stride_channel: tl.constexpr,\n    x_stride_height: tl.constexpr,\n    x_stride_width: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n\n    total = tl.zeros((out_channels,), dtype=tl.float32)\n    for j in range(out_channels):\n        for h in range(H):\n            for w in range(W):\n                offset = pid * x_stride_batch + j * x_stride_channel + h * x_stride_height + w * x_stride_width\n                total += tl.load(x_ptr + offset)\n    \n    mean = total / (H * W)\n    bias_vals = tl.load(bias_ptr + tl.arange(0, out_channels))\n    t_vals = mean + bias_vals\n    \n    max_val = tl.max(t_vals, axis=0)\n    exp_vals = tl.exp(t_vals - max_val)\n    exp_sum = tl.sum(exp_vals, axis=0)\n    log_sum_exp = max_val + tl.log(exp_sum)\n    result = 10.0 * log_sum_exp\n    \n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n    \n    def forward(self, x):\n        x = self.conv_transpose(x)\n        batch, out_channels, H, W = x.shape\n        output = torch.empty(batch, 1, device=x.device, dtype=x.dtype)\n        \n        if not x.is_contiguous():\n            x = x.contiguous()\n        bias_1d = self.bias.view(-1).contiguous()\n        \n        grid = (batch,)\n        _post_conv[grid](\n            x, \n            bias_1d, \n            output,\n            H, \n            W, \n            out_channels, \n            batch,\n            x.stride(0),\n            x.stride(1),\n            x.stride(2),\n            x.stride(3)\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'max_difference': ['1.694868', '1.916801', '1.591812', '1.789497', '1.647457'], 'avg_difference': ['0.859683', '0.934681', '0.894299', '0.856587', '0.864364'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 0.173, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_operations_kernel(\n    input_ptr,\n    bias_ptr,\n    output_ptr,\n    in_channels,\n    in_height,\n    in_width,\n    stride_batch,\n    stride_channel,\n    stride_height,\n    stride_width,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr\n):\n    pid = tl.program_id(0)\n    offsets = tl.arange(0, BLOCK_SIZE)\n    mask = offsets < in_channels\n    \n    # Initialize accumulation variables\n    channel_sum = tl.zeros([BLOCK_SIZE], dtype=tl.float32)\n    channel_max = tl.full([BLOCK_SIZE], float('-inf'), dtype=tl.float32)\n    \n    # Reduce spatial dimensions\n    for h in range(in_height):\n        for w in range(in_width):\n            spatial_offset = pid * stride_batch + h * stride_height + w * stride_width\n            channel_vals = tl.load(input_ptr + spatial_offset + offsets * stride_channel, mask=mask, other=0.0)\n            channel_sum += channel_vals\n            channel_max = tl.maximum(channel_max, channel_vals)\n    \n    # Compute mean and add bias\n    spatial_elements = in_height * in_width\n    channel_mean = channel_sum / spatial_elements\n    bias_vals = tl.load(bias_ptr + offsets, mask=mask, other=0.0)\n    biased_vals = channel_mean + bias_vals\n    \n    # Log-sum-exp reduction\n    global_max = tl.max(channel_max, axis=0)\n    exp_sum = tl.sum(tl.exp(biased_vals - global_max), axis=0)\n    log_sum_exp = tl.log(exp_sum) + global_max\n    \n    # Final scaling and store\n    result = log_sum_exp * 10.0\n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape).squeeze())\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        batch_size, _, h, w = x.shape\n        \n        # Prepare inputs for Triton kernel\n        x_flat = x.contiguous().view(batch_size, self.out_channels, -1)\n        output = torch.empty(batch_size, device=x.device, dtype=torch.float32)\n        \n        # Launch kernel\n        grid = (batch_size,)\n        fused_operations_kernel[grid](\n            x_flat,\n            self.bias,\n            output,\n            self.out_channels,\n            h,\n            w,\n            x_flat.stride(0),\n            x_flat.stride(1),\n            x_flat.stride(2),\n            1,  # stride_width\n            BLOCK_SIZE=triton.next_power_of_2(self.out_channels),\n            P2=0  # Unused but required for signature\n        )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_42_ConvTranspose2d_GlobalAvgPool_BiasAdd_LogSumExp_Sum_Multiply', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'max_difference': ['0.349226', '0.322727'], 'avg_difference': ['0.089094', '0.092143'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(3 / 5)', 'reference_timing_ms': 0.173, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -100.0000)\n```python\nglobal_max = tl.max(channel_max, axis=0)\n    exp_sum = tl.sum(tl.exp(biased_vals - global_max), axis=0)\n    log_sum_exp = tl.log(exp_sum) + global_max\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 24.8000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super().__init__()\n        self.conv_transpose = torch.nn.ConvTranspose2d(\n            in_channels, out_channels, kernel_size)\n        self.bias = torch.nn.Parameter(torch.randn(bias_shape))\n        self.out_channels = out_channels\n\n    @triton.jit\n    def _fused_kernel(\n        input_ptr,\n        bias_ptr,\n        output_ptr,\n        batch_size,\n        height,\n        width,\n        stride_b, stride_c, stride_h, stride_w,\n        BLOCK_SIZE: tl.constexpr,\n        channels: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        if pid >= batch_size:\n            return\n        \n        spatial_size = height * width\n        batch_offset = pid * stride_b\n        channel_vals = tl.zeros((channels,), dtype=tl.float32)\n\n        # Process each channel sequentially\n        for c in tl.static_range(channels):\n            accum = 0.0\n            # Block processing of spatial dimensions\n            for i in range(0, spatial_size, BLOCK_SIZE):\n                offsets = i + tl.arange(0, BLOCK_SIZE)\n                mask = offsets < spatial_size\n                h = offsets // width\n                w = offsets % width\n                ptr = input_ptr + batch_offset + c * stride_c + h * stride_h + w * stride_w\n                data = tl.load(ptr, mask=mask, other=0.0)\n                accum += tl.sum(data, axis=0)\n            \n            channel_avg = accum / spatial_size\n            bias_val = tl.load(bias_ptr + c)\n            channel_vals += tl.where(tl.arange(0, channels) == c, channel_avg + bias_val, 0.0)\n\n        # Log-sum-exp with numerical stability\n        max_val = tl.max(channel_vals, axis=0)\n        exp_vals = tl.exp(channel_vals - max_val)\n        exp_sum = tl.sum(exp_vals, axis=0)\n        result = max_val + tl.log(exp_sum)\n        tl.store(output_ptr + pid, result * 10.0)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        B, C, H, W = x.shape\n        x = x.contiguous()\n        output = torch.empty(B, device=x.device, dtype=torch.float32)\n        \n        grid = (B,)\n        self._fused_kernel[grid](\n            x, \n            self.bias.reshape(-1), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _post_conv(\n    x_ptr, \n    bias_ptr,\n    output_ptr,\n    H: tl.constexpr,\n    W: tl.constexpr,\n    out_channels: tl.constexpr,\n    batch_size: tl.constexpr,\n    x_stride_batch: tl.constexpr,\n    x_stride_channel: tl.constexpr,\n    x_stride_height: tl.constexpr,\n    x_stride_width: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n\n    total = tl.zeros((out_channels,), dtype=tl.float32)\n    for j in range(out_channels):\n        for h in range(H):\n            for w in range(W):\n                offset = pid * x_stride_batch + j * x_stride_channel + h * x_stride_height + w * x_stride_width\n                total += tl.load(x_ptr + offset)\n    \n    mean = total / (H * W)\n    bias_vals = tl.load(bias_ptr + tl.arange(0, out_channels))\n    t_vals = mean + bias_vals\n    \n    max_val = tl.max(t_vals, axis=0)\n    exp_vals = tl.exp(t_vals - max_val)\n    exp_sum = tl.sum(exp_vals, axis=0)\n    log_sum_exp = max_val + tl.log(exp_sum)\n    result = 10.0 * log_sum_exp\n    \n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n    \n    def forward(self, x):\n        x = self.conv_transpose(x)\n        batch, out_channels, H, W = x.shape\n        output = torch.empty(batch, 1, device=x.device, dtype=x.dtype)\n        \n        if not x.is_contiguous():\n            x = x.contiguous()\n        bias_1d = self.bias.view(-1).contiguous()\n        \n        grid = (batch,)\n        _post_conv[grid](\n            x, \n            bias_1d, \n            output,\n            H, \n            W, \n            out_channels, \n            batch,\n            x.stride(0),\n            x.stride(1),\n            x.stride(2),\n            x.stride(3)\n        )\n        \n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a program that currently has a correctness issue (output mismatch) and we are to fix it while also aiming for performance.\n The current program (which is the same as \"Program 2\" in the history) has:\n   - compiled: True\n   - correctness: False (output mismatch)\n\n The top performer (Program 1) has both compiled and correctness passing, and also a speedup of 1.048.\n We note that the current program (Program 2) uses nested loops over channels and spatial dimensions in the Triton kernel, which is likely inefficient and might also be the source of the correctness issue.\n\n Let's analyze the current Triton kernel in the provided program:\n\n The kernel `_post_conv` does:\n   - For each batch element (pid from 0 to batch_size-1):\n        total = zeros(out_channels)\n        for j in range(out_channels):\n            for h in range(H):\n                for w in range(W):\n                    offset = ... (using strides)\n                    total[j] += x[offset]\n\n        mean = total / (H*W)\n        t_vals = mean + bias (a vector of length out_channels)\n        log_sum_exp = max(t_vals) + log(sum(exp(t_vals - max(t_vals))))\n        result = 10.0 * log_sum_exp\n        store result at output[pid]\n\n The correctness issue might be due to:\n   - The bias is loaded for the entire channel vector at once: `bias_vals = tl.load(bias_ptr + tl.arange(0, out_channels))`\n     This is correct because the bias is of length `out_channels` and we are adding it to `mean` (which is also of length `out_channels`).\n\n However, the way we compute the mean per channel might be incorrect because the input tensor `x` is of shape [batch, out_channels, H, W]. \n The inner loops are over j (channel index), then h and w. For each channel j, we are summing over h and w.\n\n But note: the offset computation:\n   offset = pid * x_stride_batch + j * x_stride_channel + h * x_stride_height + w * x_stride_width\n\n This is the correct offset for the element at (pid, j, h, w).\n\n So why the output mismatch?\n\n One possibility is that the Triton kernel is not using the contiguous memory in the way we expect. However, the code in the model's forward function does:\n   if not x.is_contiguous(): x = x.contiguous()\n\n Another possibility is that the log-sum-exp operation is not being computed correctly. We are computing:\n   max_val = tl.max(t_vals, axis=0)   # scalar for the entire vector\n   exp_vals = tl.exp(t_vals - max_val) # vector\n   exp_sum = tl.sum(exp_vals, axis=0)  # scalar\n   log_sum_exp = max_val + tl.log(exp_sum)\n\n This is the standard log-sum-exp and should be correct.\n\n However, note that the kernel does not have any tiling or blocking for the spatial dimensions. It is iterating over every single element in the spatial dimensions for each channel and batch. This is very inefficient and might also be causing numerical issues due to the order of operations? (But that seems unlikely.)\n\n Alternatively, let's look at the top performer (Program 1) which uses a different approach:\n\n   - It processes each channel sequentially and uses a block-wise reduction for the spatial dimensions.\n   - Then it builds a vector `channel_vals` (of length `channels`) which is the per-channel average plus the bias for that channel.\n   - Then it does log-sum-exp over the entire vector.\n\n The main difference in the computation is that in the top performer, the per-channel average is computed by summing over the spatial dimensions and then dividing by the number of elements. This is the same as the current program.\n\n Why then does the current program (Program 2) fail correctness?\n\n Let me check the data types and the way we are accumulating:\n\n   total = tl.zeros((out_channels,), dtype=tl.float32)\n\n   Then for each j (channel index), we are accumulating over h and w. This is a per-channel sum.\n\n   Then we compute the mean by dividing by (H*W). Then we add the bias.\n\n This should be the same as the top performer.\n\n However, note that in the top performer, the kernel uses:\n\n   channel_vals = tl.zeros((channels,), dtype=tl.float32)\n   for c in tl.static_range(channels):\n        ... compute accum for channel c ...\n        channel_avg = accum / spatial_size\n        bias_val = tl.load(bias_ptr + c)\n        channel_vals += tl.where(tl.arange(0, channels) == c, channel_avg + bias_val, 0.0)\n\n This is a scatter operation that sets the c-th element to (channel_avg + bias_val). The current program does the same by having a vector `total` that is indexed by j.\n\n So what is the difference?\n\n Another possibility: the current program might be suffering from a race condition? But note that each batch element is independent and the kernel is launched with one program per batch. There is no parallelism within a batch element.\n\n However, the top performer uses a block-wise reduction for the spatial dimensions (with a block size of 128) and then does a loop over channels. The current program does a naive triple loop.\n\n I suspect the issue might be with the way we are loading the bias. In the top performer, the bias is loaded per channel (inside the channel loop) and then added to the channel average. In the current program, we load the entire bias vector at once and then add it to the mean vector. This should be equivalent.\n\n But note: the top performer's kernel has a parameter `channels` (the number of channels) and the current program has `out_channels` (same meaning). The top performer uses `tl.static_range(channels)` which unrolls the loop. The current program uses a dynamic loop `for j in range(out_channels)`. This is acceptable in Triton, but might be less efficient.\n\n However, the current program is failing correctness. Let me check the verification payload:\n\n   In the current program's verification, we see:\n        max_difference: ['1.694868', ...] and avg_difference: ['0.859683', ...]  (for one device)\n        and in another attempt: max_difference: ['0.349226', ...] and avg_difference: ['0.089094', ...]\n\n This indicates that the output is not matching the reference.\n\n We need to fix the correctness first.\n\n Let me compare the two kernels more carefully:\n\n   Top performer (Program 1):\n        channel_vals = zeros(channels)\n        for c in static_range(channels):\n            accum = 0.0\n            for i in range(0, spatial_size, BLOCK_SIZE):\n                ... load a block of data for channel c and add to accum\n            channel_avg = accum / spatial_size\n            bias_val = load(bias_ptr + c)\n            # Then: set the c-th element of channel_vals to channel_avg + bias_val\n\n        Then log-sum-exp on channel_vals.\n\n   Current program (Program 2):\n        total = zeros(out_channels)   # per-channel total\n        for j in range(out_channels):\n            for h in range(H):\n                for w in range(W):\n                    offset = ... (for j, h, w)\n                    total[j] += load(x_ptr + offset)\n        mean = total / (H*W)\n        bias_vals = load(bias_ptr + [0:out_channels])   # entire bias vector\n        t_vals = mean + bias_vals\n\n        Then log-sum-exp on t_vals.\n\n The operations are mathematically equivalent. However, the order of accumulation might cause floating point differences? But that should be within tolerance.\n\n Another possibility: the current program does not handle non-contiguous tensors? But the model's forward function makes the input contiguous.\n\n How about the bias? The current program does:\n        bias_1d = self.bias.view(-1).contiguous()\n\n And then in the kernel, we load the entire bias vector at once. This should be safe.\n\n However, note that the top performer uses:\n        self.bias.reshape(-1)   (which is the same as view(-1))\n\n So what is the problem?\n\n I suspect the issue might be in the offset calculation. Let me check the strides:\n\n   The kernel is called with:\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3)\n\n   And the offset is computed as:\n        offset = pid * x_stride_batch + j * x_stride_channel + h * x_stride_height + w * x_stride_width\n\n   This is the correct formula for a 4D tensor.\n\n   But note: the tensor might have been transposed or have non-standard strides? However, we made it contiguous.\n\n   Also, the top performer uses the same strides.\n\n Why then the difference?\n\n Another possibility: the top performer uses a different kernel structure and does the reduction in a block-wise manner. The current program does a naive triple loop which might be more prone to floating point rounding? But the differences reported are large (max_difference of 1.69) so that is unlikely.\n\n I notice that in the top performer, the kernel is defined as a method of the module and uses `@triton.jit` without the `autotune` decorator. But that shouldn't affect correctness.\n\n After re-examining the top performer's kernel:\n\n        # Process each channel sequentially\n        for c in tl.static_range(channels):\n            accum = 0.0\n            # Block processing of spatial dimensions\n            for i in range(0, spatial_size, BLOCK_SIZE):\n                offsets = i + tl.arange(0, BLOCK_SIZE)\n                mask = offsets < spatial_size\n                h = offsets // width\n                w = offsets % width\n                ptr = input_ptr + batch_offset + c * stride_c + h * stride_h + w * stride_w\n                data = tl.load(ptr, mask=mask, other=0.0)\n                accum += tl.sum(data, axis=0)\n\n        ... and then sets the c-th element of channel_vals to (accum / spatial_size) + bias_val.\n\n The current program does:\n\n        for j in range(out_channels):\n            for h in range(H):\n                for w in range(W):\n                    offset = ... \n                    total[j] += tl.load(x_ptr + offset)\n\n The top performer uses a vectorized load and sum for a block of spatial elements. The current program loads one element at a time.\n\n The two methods should produce the same sum, but the order of addition might be different and lead to different rounding. However, the differences should be small. The verification reports large differences.\n\n Another possibility: the current program does not mask the load for the last block? Actually, it doesn't need to because we are iterating exactly over H and W. But note: the inner loop is over h in [0, H) and w in [0, W). We are not going out of bounds. So the load is safe.\n\n What if the tensor is not in the expected layout? We made it contiguous, so the strides should be standard: \n   stride_batch = C*H*W, stride_channel = H*W, stride_height = W, stride_width = 1.\n\n But the current program uses the provided strides. The top performer also uses the provided strides.\n\n I suspect the issue might be with the log-sum-exp computation in the current program. Let me check:\n\n        max_val = tl.max(t_vals, axis=0)   # This is a scalar\n        exp_vals = tl.exp(t_vals - max_val) # This is a vector\n        exp_sum = tl.sum(exp_vals, axis=0)  # This is a scalar\n        log_sum_exp = max_val + tl.log(exp_sum)\n\n This is correct.\n\n However, note that the top performer does:\n\n        max_val = tl.max(channel_vals, axis=0)\n        exp_vals = tl.exp(channel_vals - max_val)\n        exp_sum = tl.sum(exp_vals, axis=0)\n        result = max_val + tl.log(exp_sum)\n\n Same.\n\n What if the current program is not initializing `total` properly? It is initialized to zeros.\n\n What if the current program has an indexing issue? We are using `j` to index the channel in the inner loops. And then we use `tl.arange(0, out_channels)` for the bias. The vector `t_vals` is of length `out_channels`.\n\n The only difference I see is that the top performer's kernel uses a `tl.static_range` (which unrolls the channel loop) and the current program uses a dynamic loop. This might cause code generation differences? But Triton should handle it.\n\n Given the time, I propose to rewrite the current program to use the top performer's approach. Since the top performer has been verified to be correct and also has a speedup, we can adopt its kernel.\n\n Steps:\n\n  1. Replace the current Triton kernel with the one from the top performer (Program 1).\n  2. Adjust the kernel call to match the top performer's signature.\n\n However, note that the top performer's kernel is defined as a method of the class. We can define it as a standalone function if we wish, but the top performer defined it as a method.\n\n But the current program defines the kernel as a standalone function. We can change it to be a method or leave it as a function. Let's leave it as a function for consistency with the current program.\n\n Let me write the kernel function as:\n\n   @triton.jit\n   def _fused_kernel(\n        input_ptr,\n        bias_ptr,\n        output_ptr,\n        batch_size,\n        height,\n        width,\n        stride_b, stride_c, stride_h, stride_w,\n        BLOCK_SIZE: tl.constexpr,\n        channels: tl.constexpr,\n   ):\n\n        ... same as in the top performer ...\n\n   Then in the forward function, we call this kernel.\n\n   Note: the top performer's kernel uses `tl.static_range(channels)`. The number of channels must be known at compile time? Actually, `tl.static_range` is for unrolling. We can change it to a dynamic loop if the number of channels is not too large? But the top performer uses static_range.\n\n   However, the current program has `out_channels` which is 16. This is small and safe to unroll.\n\n   We'll keep the static_range.\n\n   Also, note the top performer uses `channels` as a kernel argument and then as a constant. We must pass the number of channels (which is `out_channels`).\n\n 3. In the forward function, we must set the grid and call the kernel with the same parameters as the top performer.\n\n    The top performer does:\n\n        grid = (B,)\n        self._fused_kernel[grid](\n            x, \n            self.bias.reshape(-1), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n\n    In the current program, we have:\n\n        batch, out_channels, H, W = x.shape\n\n        ... and then we call:\n\n        grid = (batch,)\n        _fused_kernel[grid](\n            x, \n            bias_1d, \n            output,   # note: in the current program, output is of shape [batch, 1] but in the top performer it's [batch] and then unsqueezed later.\n            batch,    # batch_size\n            H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=out_channels\n        )\n\n    And then we return output.unsqueeze(1) to make it [batch, 1]. But note: in the current program, we are creating `output` as [batch, 1] but the kernel writes to a 1D tensor of length batch. We should change that.\n\n    In the top performer, the output tensor is created as:\n\n        output = torch.empty(B, device=x.device, dtype=torch.float32)\n\n    Then after the kernel, they do:\n\n        return output.unsqueeze(1)\n\n    So we can do the same.\n\n 4. We must change the ModelNew.forward function accordingly.\n\n Let me write the new program:\n\n   - We'll define the kernel as a standalone function (like the current program) but with the top performer's kernel code.\n   - We'll adjust the forward function to create a 1D output tensor and then unsqueeze.\n\n However, note that the current program's forward function already returns a tensor of shape [batch, 1]. So we are consistent.\n\n Implementation:\n\n   We'll replace the kernel function and adjust the forward function to use the new kernel.\n\n   We note that the top performer uses a block size of 128 for the spatial reduction. We'll keep that.\n\n   We also note that the top performer's kernel uses a loop over channels and then a block-wise reduction over the spatial dimensions. This should be efficient and correct.\n\n Let's write the code accordingly.\n\n We hope this will fix the correctness and also give a speedup.\n\n Note: The top performer achieved a speedup of 1.048. We hope to at least match that.\n\n However, note that the top performer's kernel uses a block size of 128 for the spatial dimension. The spatial dimension is H*W. We are using a for-loop over the spatial dimension in blocks. This is more efficient than the triple nested loop in the current program.\n\n We are going to write:\n\n   @triton.jit\n   def _fused_kernel(\n        input_ptr,\n        bias_ptr,\n        output_ptr,\n        batch_size,\n        height,\n        width,\n        stride_b, stride_c, stride_h, stride_w,\n        BLOCK_SIZE: tl.constexpr,\n        channels: tl.constexpr,\n   ):\n        ... same as the top performer ...\n\n   And then in the forward function:\n\n        x = self.conv_transpose(x)\n        B, C, H, W = x.shape\n        x = x.contiguous()\n        output = torch.empty(B, device=x.device, dtype=torch.float32)   # 1D tensor of length B\n\n        grid = (B,)\n        _fused_kernel[grid](\n            x, \n            self.bias.view(-1).contiguous(), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n\n        return output.unsqueeze(1)\n\n We are not changing the class structure otherwise.\n\n Let's generate the code accordingly.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_kernel(\n    input_ptr,\n    bias_ptr,\n    output_ptr,\n    batch_size,\n    height,\n    width,\n    stride_b, stride_c, stride_h, stride_w,\n    BLOCK_SIZE: tl.constexpr,\n    channels: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    spatial_size = height * width\n    batch_offset = pid * stride_b\n    channel_vals = tl.zeros((channels,), dtype=tl.float32)\n\n    for c in tl.static_range(channels):\n        accum = 0.0\n        for i in range(0, spatial_size, BLOCK_SIZE):\n            offsets = i + tl.arange(0, BLOCK_SIZE)\n            mask = offsets < spatial_size\n            h = offsets // width\n            w = offsets % width\n            ptr = input_ptr + batch_offset + c * stride_c + h * stride_h + w * stride_w\n            data = tl.load(ptr, mask=mask, other=0.0)\n            accum += tl.sum(data, axis=0)\n        \n        channel_avg = accum / spatial_size\n        bias_val = tl.load(bias_ptr + c)\n        channel_vals += tl.where(tl.arange(0, channels) == c, channel_avg + bias_val, 0.0)\n\n    max_val = tl.max(channel_vals, axis=0)\n    exp_vals = tl.exp(channel_vals - max_val)\n    exp_sum = tl.sum(exp_vals, axis=0)\n    result = max_val + tl.log(exp_sum)\n    tl.store(output_ptr + pid, result * 10.0)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, bias_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        B, C, H, W = x.shape\n        x = x.contiguous()\n        output = torch.empty(B, device=x.device, dtype=torch.float32)\n        \n        grid = (B,)\n        fused_kernel[grid](\n            x, \n            self.bias.view(-1), \n            output,\n            B,\n            H, \n            W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_SIZE=128,\n            channels=C\n        )\n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nbias_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, bias_shape]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}