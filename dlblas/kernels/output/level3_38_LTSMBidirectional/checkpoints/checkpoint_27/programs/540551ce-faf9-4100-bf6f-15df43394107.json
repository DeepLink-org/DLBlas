{"id": "540551ce-faf9-4100-bf6f-15df43394107", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_forward_kernel(\n    x_ptr, output_ptr, h_ptr, c_ptr,\n    weight_ih_ptr, weight_hh_ptr, bias_ih_ptr, bias_hh_ptr,\n    input_size: tl.constexpr, hidden_size: tl.constexpr,\n    seq_length: tl.constexpr, batch_size: tl.constexpr\n):\n    pid = tl.program_id(0)\n    \n    # Initialize state for this sequence\n    h_prev = tl.zeros((hidden_size,), dtype=tl.float32)\n    c_prev = tl.zeros((hidden_size,), dtype=tl.float32)\n    \n    # Iterate over sequence steps\n    for step in range(seq_length):\n        # Load input for current timestep\n        x_offset = pid * seq_length * input_size + step * input_size\n        x_t = tl.load(x_ptr + x_offset + tl.arange(0, input_size))\n        \n        # Compute gates\n        gates = tl.zeros((4 * hidden_size,), dtype=tl.float32)\n        \n        # Input-hidden transformation\n        for j in range(4 * hidden_size):\n            w_ih_row = tl.load(weight_ih_ptr + j * input_size + tl.arange(0, input_size))\n            gates = tl.store(gates, j, tl.sum(w_ih_row * x_t))\n            gates = tl.store(gates, j, gates[j] + tl.load(bias_ih_ptr + j))\n            \n        # Hidden-hidden transformation\n        for j in range(4 * hidden_size):\n            w_hh_row = tl.load(weight_hh_ptr + j * hidden_size + tl.arange(0, hidden_size))\n            gates = tl.store(gates, j, gates[j] + tl.sum(w_hh_row * h_prev))\n            gates = tl.store(gates, j, gates[j] + tl.load(bias_hh_ptr + j))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0:hidden_size])\n        f_gate = tl.sigmoid(gates[hidden_size:2*hidden_size])\n        g_gate = tl.tanh(gates[2*hidden_size:3*hidden_size])\n        o_gate = tl.sigmoid(gates[3*hidden_size:4*hidden_size])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_prev + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        out_offset = pid * seq_length * hidden_size + step * hidden_size\n        tl.store(output_ptr + out_offset + tl.arange(0, hidden_size), h_cur)\n        \n        # Update state for next timestep\n        h_prev = h_cur\n        c_prev = c_cur\n    \n    # Store final state\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, hidden_size), h_cur)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, hidden_size), c_cur)\n\ndef bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, \n                              h0_forward, c0_forward, h0_backward, c0_backward):\n    batch_size, seq_length, input_size = x.shape\n    hidden_size = weight_ih.shape[0] // 4\n    \n    # Process forward direction\n    output_forward = torch.empty((batch_size, seq_length, hidden_size), \n                                device=x.device, dtype=x.dtype)\n    grid = (batch_size,)\n    lstm_forward_kernel[grid](\n        x.contiguous().view(-1), output_forward.view(-1), \n        h0_forward, c0_forward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size\n    )\n    \n    # Process backward direction\n    x_reversed = torch.flip(x, [1])\n    output_backward = torch.empty((batch_size, seq_length, hidden_size), \n                                 device=x.device, dtype=x.dtype)\n    lstm_forward_kernel[grid](\n        x_reversed.contiguous().view(-1), output_backward.view(-1), \n        h0_backward, c0_backward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size\n    )\n    output_backward = torch.flip(output_backward, [1])\n    \n    # Combine directions\n    output = torch.cat([output_forward, output_backward], dim=-1)\n    hn = torch.stack([h0_forward, h0_backward], dim=0)\n    cn = torch.stack([c0_forward, c0_backward], dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n        \n        # Create parameters for all layers\n        self.weights_ih = nn.ParameterList()\n        self.weights_hh = nn.ParameterList()\n        self.biases_ih = nn.ParameterList()\n        self.biases_hh = nn.ParameterList()\n        \n        for i in range(num_layers):\n            # Forward layer weights\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, \n                                                           input_size if i == 0 else hidden_size * 2)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            \n            # Backward layer weights\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, \n                                                           input_size if i == 0 else hidden_size * 2)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n        \n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_length, _ = x.shape\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process through all layers\n        for layer in range(self.num_layers):\n            # Get initial states for this layer\n            h0_forward = h0[layer * 2]\n            c0_forward = c0[layer * 2]\n            h0_backward = h0[layer * 2 + 1]\n            c0_backward = c0[layer * 2 + 1]\n            \n            # Get weights for this layer\n            weight_idx = layer * 2\n            out, (hn, cn) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0_forward, c0_forward, h0_backward, c0_backward\n            )\n            \n            # Update input for next layer\n            x = out\n            \n            # Store final states for next layer\n            if layer < self.num_layers - 1:\n                h0[(layer + 1) * 2] = hn[0]\n                h0[(layer + 1) * 2 + 1] = hn[1]\n                c0[(layer + 1) * 2] = cn[0]\n                c0[(layer + 1) * 2 + 1] = cn[1]\n        \n        # Final output\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "901736b0-7002-4f28-83a0-80d37f86e4f9", "generation": 3, "timestamp": 1754594254.2959735, "iteration_found": 25, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_38_LTSMBidirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmphrnko4tw.py\", line 145, in forward\n    out, (hn, cn) = bidirectional_lstm_triton(\n  File \"/tmp/tmphrnko4tw.py\", line 72, in bidirectional_lstm_triton\n    lstm_forward_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 229, in visit_For\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language' has no attribute 'tanh'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 42.6, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_38_LTSMBidirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "max_difference": ["0.286796", "0.302321", "0.286816", "0.302320", "0.287174"], "avg_difference": ["0.078024", "0.078617", "0.077893", "0.078659", "0.077975"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 42.6, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 0.0000\n- score: 10.0000\n- stage: wrong_answer\n- verify_payload: {'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'max_difference': ['0.286796', '0.302321', '0.286816', '0.302320', '0.287174'], 'avg_difference': ['0.078024', '0.078617', '0.077893', '0.078659', '0.077975'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'max_difference': ['0.291248', '0.291834', '0.291467', '0.291834', '0.291268'], 'avg_difference': ['0.079197', '0.079147', '0.079152', '0.079223', '0.079194'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'max_difference': ['0.286796', '0.302321', '0.286816', '0.302320', '0.287174'], 'avg_difference': ['0.078024', '0.078617', '0.077893', '0.078659', '0.077975'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'max_difference': ['0.289905', '0.289961', '0.289797', '0.289905', '0.289464'], 'avg_difference': ['0.079079', '0.079012', '0.079034', '0.079094', '0.079034'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_forward_kernel(\n    x_ptr, w_ptr, b_ptr, y_ptr,\n    n, m, k,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_y0, stride_y1,\n    BLOCK_M: tl.constexpr, BLOCK_K: tl.constexpr, BLOCK_N: tl.constexpr\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Create block pointers\n    x_block_ptr = tl.make_block_ptr(\n        base=x_ptr,\n        shape=(n, k),\n        strides=(stride_x0, stride_x1),\n        offsets=(pid0 * BLOCK_M, 0),\n        block_shape=(BLOCK_M, BLOCK_K),\n        order=(1, 0)\n    )\n    \n    w_block_ptr = tl.make_block_ptr(\n        base=w_ptr,\n        shape=(m, k),\n        strides=(stride_w0, stride_w1),\n        offsets=(pid1 * BLOCK_N, 0),\n        block_shape=(BLOCK_N, BLOCK_K),\n        order=(1, 0)\n    )\n    \n    y_block_ptr = tl.make_block_ptr(\n        base=y_ptr,\n        shape=(n, m),\n        strides=(stride_y0, stride_y1),\n        offsets=(pid0 * BLOCK_M, pid1 * BLOCK_N),\n        block_shape=(BLOCK_M, BLOCK_N),\n        order=(1, 0)\n    )\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Blocked matrix multiplication\n    for i in range(0, tl.cdiv(k, BLOCK_K)):\n        x_block = tl.load(x_block_ptr, boundary_check=(0, 1))\n        w_block = tl.load(w_block_ptr, boundary_check=(0, 1))\n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        # Update pointers\n        x_block_ptr = tl.advance(x_block_ptr, (0, BLOCK_K))\n        w_block_ptr = tl.advance(w_block_ptr, (0, BLOCK_K))\n    \n    # Add bias\n    if b_ptr is not None:\n        bias = tl.load(b_ptr + tl.arange(0, BLOCK_N) + pid1 * BLOCK_N, \n                      mask=(tl.arange(0, BLOCK_N) + pid1 * BLOCK_N) < m, other=0.0)\n        acc += bias[None, :]\n    \n    # Store result\n    tl.store(y_block_ptr, acc.to(y_ptr.dtype.element_ty), boundary_check=(0, 1))\n\nclass TritonLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        y = torch.empty(x.shape[0], self.out_features, device=x.device, dtype=x.dtype)\n        n, k = x.shape\n        m = self.out_features\n        \n        # Tune block sizes for H100 architecture\n        BLOCK_M = 64\n        BLOCK_N = 64\n        BLOCK_K = 64\n        \n        grid = (\n            triton.cdiv(n, BLOCK_M),\n            triton.cdiv(m, BLOCK_N)\n        )\n        \n        linear_forward_kernel[grid](\n            x, self.weight, self.bias, y,\n            n, m, k,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            y.stride(0), y.stride(1),\n            BLOCK_M=BLOCK_M, BLOCK_K=BLOCK_K, BLOCK_N=BLOCK_N\n        )\n        return y\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers, \n            batch_first=True, dropout=dropout, bidirectional=True\n        )\n        self.fc = TritonLinear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'max_difference': ['0.289905', '0.289961', '0.289797', '0.289905', '0.289464'], 'avg_difference': ['0.079079', '0.079012', '0.079034', '0.079094', '0.079034'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n### Program 2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr, output_ptr, hidden_ptr, cell_ptr,\n    weight_ih_ptr, weight_hh_ptr, bias_ih_ptr, bias_hh_ptr,\n    input_size: tl.constexpr, hidden_size: tl.constexpr,\n    seq_length: tl.constexpr, batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    offsets = pid * seq_length * hidden_size + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < batch_size * seq_length * hidden_size\n    x_val = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    tl.store(output_ptr + offsets, x_val, mask=mask)\n    \n    if pid < batch_size:\n        state_offsets = pid * hidden_size + tl.arange(0, BLOCK_SIZE)\n        state_mask = state_offsets < batch_size * hidden_size\n        tl.store(hidden_ptr + state_offsets, 0.0, mask=state_mask)\n        tl.store(cell_ptr + state_offsets, 0.0, mask=state_mask)\n\ndef bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, h0, c0):\n    batch_size, seq_length, input_size = x.shape\n    hidden_size = weight_ih.shape[0] // 4\n    \n    # Process forward direction\n    output_forward = torch.empty((batch_size, seq_length, hidden_size), \n                                device=x.device, dtype=x.dtype)\n    hn_forward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_forward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    n_elements = batch_size\n    grid = (n_elements,)\n    lstm_kernel[grid](\n        x.contiguous().view(-1), output_forward.view(-1), \n        hn_forward, cn_forward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size,\n        hidden_size\n    )\n    \n    # Process backward direction\n    x_reversed = torch.flip(x, [1])\n    output_backward = torch.empty((batch_size, seq_length, hidden_size), \n                                 device=x.device, dtype=x.dtype)\n    hn_backward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_backward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    lstm_kernel[grid](\n        x_reversed.contiguous().view(-1), output_backward.view(-1), \n        hn_backward, cn_backward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size,\n        hidden_size\n    )\n    output_backward = torch.flip(output_backward, [1])\n    \n    # Combine directions\n    output = torch.cat([output_forward, output_backward], dim=-1)\n    hn = torch.stack([hn_forward, hn_backward], dim=0)\n    cn = torch.stack([cn_forward, cn_backward], dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n        \n        # Create parameters for all layers\n        self.weights_ih = nn.ParameterList()\n        self.weights_hh = nn.ParameterList()\n        self.biases_ih = nn.ParameterList()\n        self.biases_hh = nn.ParameterList()\n        \n        for _ in range(num_layers * 2):  # *2 for bidirectional\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, input_size)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            input_size = hidden_size * 2  # For subsequent layers\n        \n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_length, _ = x.shape\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process through all layers\n        for layer in range(self.num_layers):\n            weight_idx = layer * 2\n            out, (hn, cn) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0[0], c0[0]\n            )\n            x = out  # Input for next layer\n        \n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'max_difference': ['0.286796', '0.302321', '0.286816', '0.302320', '0.287174'], 'avg_difference': ['0.078024', '0.078617', '0.077893', '0.078659', '0.077975'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n### Program 3 (Score: 10.0000)\n```python\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    batch_size,\n    stride_x,       # stride for batch dimension in x\n    stride_weight,  # stride for output feature dimension in weight\n    stride_bias,    # not used for bias (1D tensor)\n    stride_output,  # stride for batch dimension in output\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    if pid_batch >= batch_size or pid_feature >= out_features:\n        return\n        \n    x_ptr += pid_batch * stride_x\n    weight_ptr_j = weight_ptr + pid_feature * stride_weight\n    output_ptr += pid_batch * stride_output + pid_feature\n\n    acc = 0.0\n    for k in range(0, in_features, BLOCK_SIZE):\n        offs = k + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_val = tl.load(x_ptr + offs, mask=mask, other=0.0)\n        w_val = tl.load(weight_ptr_j + offs, mask=mask, other=0.0)\n        acc += tl.sum(x_val * w_val)\n    \n    if bias_ptr is not None:\n        b = tl.load(bias_ptr + pid_feature)\n        acc += b\n\n    tl.store(output_ptr, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers,\n            batch_first=True, dropout=dropout, bidirectional=True\n        )\n        in_features = hidden_size * 2\n        self.in_features = in_features\n        self.out_features = output_size\n        self.weight = nn.Parameter(torch.Tensor(output_size, in_features))\n        self.bias = nn.Parameter(torch.Tensor(output_size))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n\n        out, _ = self.lstm(x, (h0, c0))\n        last_output = out[:, -1, :].contiguous()\n\n        output = torch.empty((batch_size, self.out_features), device=last_output.device, dtype=last_output.dtype)\n        grid = (batch_size, self.out_features)\n        \n        linear_kernel[grid](\n            last_output, \n            self.weight, \n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            batch_size,\n            last_output.stride(0),\n            self.weight.stride(0),\n            0,  # bias stride (unused)\n            output.stride(0),\n            BLOCK_SIZE=128,\n        )\n        return output\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level3_38_LTSMBidirectional', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'max_difference': ['0.291248', '0.291834', '0.291467', '0.291834', '0.291268'], 'avg_difference': ['0.079197', '0.079147', '0.079152', '0.079223', '0.079194'], 'correctness_issue': 'Output mismatch', 'correctness_trials': '(0 / 5)', 'reference_timing_ms': 42.6, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr, hx_ptr, cx_ptr,\n    w_ih_ptr, w_hh_ptr, b_ih_ptr, b_hh_ptr,\n    h_ptr, c_ptr,\n    batch_size, input_size, hidden_size,\n    BLOCK_B: tl.constexpr, BLOCK_H: tl.constexpr\n):\n    # Compute program IDs\n    pid = tl.program_id(0)\n    \n    # Create masks for batch and hidden dimensions\n    batch_offsets = pid * BLOCK_B + tl.arange(0, BLOCK_B)\n    hidden_offsets = tl.arange(0, BLOCK_H)\n    \n    batch_mask = batch_offsets < batch_size\n    hidden_mask = hidden_offsets < (4 * hidden_size)\n    \n    # Initialize pointers for current batch\n    x_ptr += batch_offsets[:, None] * input_size\n    hx_ptr += batch_offsets[:, None] * hidden_size\n    cx_ptr += batch_offsets[:, None] * hidden_size\n    h_ptr += batch_offsets[:, None] * hidden_size\n    c_ptr += batch_offsets[:, None] * hidden_size\n    \n    # Initialize accumulators\n    gates_ih = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    gates_hh = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    \n    # Compute input-hidden gates (vectorized)\n    for i in range(0, input_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < input_size)\n        \n        w = tl.load(w_ih_ptr + offsets[None, :], mask=mask, other=0.0)\n        x = tl.load(x_ptr + offsets[None, :], mask=mask, other=0.0)\n        \n        gates_ih += tl.dot(x, w)\n    \n    # Compute hidden-hidden gates (vectorized)\n    for i in range(0, hidden_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < hidden_size)\n        \n        w = tl.load(w_hh_ptr + offsets[None, :], mask=mask, other=0.0)\n        h = tl.load(hx_ptr + offsets[None, :], mask=mask, other=0.0)\n        \n        gates_hh += tl.dot(h, w)\n    \n    # Add biases\n    gates_ih += tl.load(b_ih_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    gates_hh += tl.load(b_hh_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    \n    # Combine gates\n    gates = gates_ih + gates_hh\n    \n    # Split gates into components\n    i_gate = tl.sigmoid(gates[:, :hidden_size])\n    f_gate = tl.sigmoid(gates[:, hidden_size:2*hidden_size])\n    g_gate = tl.tanh(gates[:, 2*hidden_size:3*hidden_size])\n    o_gate = tl.sigmoid(gates[:, 3*hidden_size:4*hidden_size])\n    \n    # Load previous cell state\n    c_prev = tl.load(cx_ptr, mask=batch_mask[:, None], other=0.0)\n    \n    # Compute new cell and hidden states\n    c_next = f_gate * c_prev + i_gate * g_gate\n    h_next = o_gate * tl.tanh(c_next)\n    \n    # Store results\n    tl.store(h_ptr, h_next, mask=batch_mask[:, None])\n    tl.store(c_ptr, c_next, mask=batch_mask[:, None])\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Create LSTM weights\n        self.w_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n        self.w_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n        self.b_ih = nn.Parameter(torch.empty(4 * hidden_size))\n        self.b_hh = nn.Parameter(torch.empty(4 * hidden_size))\n        \n        # Initialize weights\n        nn.init.xavier_uniform_(self.w_ih)\n        nn.init.xavier_uniform_(self.w_hh)\n        self.b_ih.data.fill_(0)\n        self.b_hh.data.fill_(0)\n        \n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n        c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n        \n        # Process each timestep\n        for t in range(seq_len):\n            # Call Triton kernel\n            grid = lambda meta: (triton.cdiv(batch_size, meta['BLOCK_B']),)\n            lstm_kernel[grid](\n                x[:, t, :], h, c,\n                self.w_ih, self.w_hh, self.b_ih, self.b_hh,\n                h, c,\n                batch_size, x.size(-1), self.hidden_size,\n                BLOCK_B=32, BLOCK_H=64\n            )\n        \n        return self.fc(h)\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_forward_kernel(\n    x_ptr,\n    output_ptr,\n    h_ptr,\n    c_ptr,\n    w_ih_ptr,\n    w_hh_ptr,\n    b_ih_ptr,\n    b_hh_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    seq_len: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_HS: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    off_h = pid * hidden_size + tl.arange(0, BLOCK_HS)\n    mask_h = tl.arange(0, BLOCK_HS) < hidden_size\n    \n    # Initialize hidden and cell states\n    h_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    c_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    \n    # Precompute gate offsets\n    gate_offsets = tl.arange(0, 4) * hidden_size\n    for step in range(seq_len):\n        # Load input for current timestep\n        off_x = (pid * seq_len + step) * input_size\n        x = tl.load(x_ptr + off_x + tl.arange(0, input_size))\n        \n        # Compute input transformation\n        gates = tl.zeros((4, BLOCK_HS), dtype=tl.float32)\n        for i in range(4):\n            w_ih = tl.load(w_ih_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * input_size + \n                          tl.arange(0, input_size)[None, :], mask=mask_h[:, None])\n            gates = tl.store(gates, i, tl.sum(w_ih * x, axis=1) + tl.load(b_ih_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Compute hidden transformation\n        for i in range(4):\n            w_hh = tl.load(w_hh_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * hidden_size + \n                          tl.arange(0, BLOCK_HS)[None, :], mask=mask_h[:, None] & mask_h[None, :])\n            gates = tl.store(gates, i, gates[i] + tl.sum(w_hh * h_cur, axis=1) + tl.load(b_hh_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0])\n        f_gate = tl.sigmoid(gates[1])\n        g_gate = tl.tanh(gates[2])\n        o_gate = tl.sigmoid(gates[3])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_cur + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        tl.store(output_ptr + (pid * seq_len + step) * hidden_size + tl.arange(0, BLOCK_HS), \n                h_cur, mask=mask_h)\n    \n    # Store final states\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), h_cur, mask=mask_h)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), c_cur, mask=mask_h)\n\n@triton.jit\ndef lstm_backward_kernel(\n    x_ptr,\n    output_ptr,\n    h_ptr,\n    c_ptr,\n    w_ih_ptr,\n    w_hh_ptr,\n    b_ih_ptr,\n    b_hh_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    seq_len: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_HS: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    off_h = pid * hidden_size + tl.arange(0, BLOCK_HS)\n    mask_h = tl.arange(0, BLOCK_HS) < hidden_size\n    \n    # Initialize hidden and cell states\n    h_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    c_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    \n    # Precompute gate offsets\n    gate_offsets = tl.arange(0, 4) * hidden_size\n    for step in range(seq_len-1, -1, -1):\n        # Load input for current timestep\n        off_x = (pid * seq_len + step) * input_size\n        x = tl.load(x_ptr + off_x + tl.arange(0, input_size))\n        \n        # Compute input transformation\n        gates = tl.zeros((4, BLOCK_HS), dtype=tl.float32)\n        for i in range(4):\n            w_ih = tl.load(w_ih_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * input_size + \n                          tl.arange(0, input_size)[None, :], mask=mask_h[:, None])\n            gates = tl.store(gates, i, tl.sum(w_ih * x, axis=1) + tl.load(b_ih_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Compute hidden transformation\n        for i in range(4):\n            w_hh = tl.load(w_hh_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * hidden_size + \n                          tl.arange(0, BLOCK_HS)[None, :], mask=mask_h[:, None] & mask_h[None, :])\n            gates = tl.store(gates, i, gates[i] + tl.sum(w_hh * h_cur, axis=1) + tl.load(b_hh_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0])\n        f_gate = tl.sigmoid(gates[1])\n        g_gate = tl.tanh(gates[2])\n        o_gate = tl.sigmoid(gates[3])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_cur + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        tl.store(output_ptr + (pid * seq_len + step) * hidden_size + tl.arange(0, BLOCK_HS), \n                h_cur, mask=mask_h)\n    \n    # Store final states\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), h_cur, mask=mask_h)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), c_cur, mask=mask_h)\n\ndef bidirectional_lstm_triton(x, weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f,\n                              weight_ih_b, weight_hh_b, bias_ih_b, bias_hh_b, h0, c0):\n    batch_size, seq_len, input_size = x.shape\n    hidden_size = weight_ih_f.shape[0] // 4\n    \n    # Prepare outputs\n    output_f = torch.empty((batch_size, seq_len, hidden_size), device=x.device, dtype=x.dtype)\n    output_b = torch.empty((batch_size, seq_len, hidden_size), device=x.device, dtype=x.dtype)\n    hn_f = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_f = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    hn_b = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_b = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    # Flatten tensors\n    x_flat = x.contiguous().view(-1)\n    output_f_flat = output_f.view(-1)\n    output_b_flat = output_b.view(-1)\n    \n    # Compute block size\n    BLOCK_HS = triton.next_power_of_2(hidden_size)\n    \n    # Launch forward kernel\n    lstm_forward_kernel[(batch_size,)](\n        x_flat, output_f_flat, hn_f, cn_f,\n        weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f,\n        input_size, hidden_size, seq_len, batch_size, BLOCK_HS\n    )\n    \n    # Launch backward kernel\n    lstm_backward_kernel[(batch_size,)](\n        x_flat, output_b_flat, hn_b, cn_b,\n        weight_ih_b, weight_hh_b, bias_ih_b, bias_hh_b,\n        input_size, hidden_size, seq_len, batch_size, BLOCK_HS\n    )\n    \n    # Combine outputs\n    output = torch.cat((output_f, output_b), dim=-1)\n    hn = torch.stack((hn_f, hn_b), dim=0)\n    cn = torch.stack((cn_f, cn_b), dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n\n        # Forward weights\n        self.weight_ih_f = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n        self.weight_hh_f = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n        self.bias_ih_f = nn.Parameter(torch.randn(4 * hidden_size))\n        self.bias_hh_f = nn.Parameter(torch.randn(4 * hidden_size))\n        \n        # Backward weights\n        self.weight_ih_b = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n        self.weight_hh_b = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n        self.bias_ih_b = nn.Parameter(torch.randn(4 * hidden_size))\n        self.bias_hh_b = nn.Parameter(torch.randn(4 * hidden_size))\n\n        self.fc = nn.Linear(2 * hidden_size, output_size)\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        \n        # Initialize hidden states\n        h0 = torch.zeros(2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process LSTM\n        out, _ = bidirectional_lstm_triton(\n            x,\n            self.weight_ih_f, self.weight_hh_f, self.bias_ih_f, self.bias_hh_f,\n            self.weight_ih_b, self.weight_hh_b, self.bias_ih_b, self.bias_hh_b,\n            h0, c0\n        )\n        \n        # Final output\n        out = self.fc(out[:, -1, :])\n        return out\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr, hx_ptr, cx_ptr,\n    w_ih_ptr, w_hh_ptr, b_ih_ptr, b_hh_ptr,\n    h_ptr, c_ptr,\n    batch_size, input_size, hidden_size,\n    BLOCK_B: tl.constexpr, BLOCK_H: tl.constexpr\n):\n    # Compute program IDs\n    pid = tl.program_id(0)\n    \n    # Create masks for batch and hidden dimensions\n    batch_offsets = pid * BLOCK_B + tl.arange(0, BLOCK_B)\n    hidden_offsets = tl.arange(0, BLOCK_H)\n    \n    batch_mask = batch_offsets < batch_size\n    hidden_mask = hidden_offsets < (4 * hidden_size)\n    \n    # Initialize pointers for current batch\n    x_ptr += batch_offsets[:, None] * input_size\n    hx_ptr += batch_offsets[:, None] * hidden_size\n    cx_ptr += batch_offsets[:, None] * hidden_size\n    h_ptr += batch_offsets[:, None] * hidden_size\n    c_ptr += batch_offsets[:, None] * hidden_size\n    \n    # Initialize accumulators\n    gates_ih = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    gates_hh = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    \n    # Compute input-hidden gates (vectorized)\n    for i in range(0, input_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < input_size)\n        \n        w = tl.load(w_ih_ptr + offsets[None, :], mask=mask, other=0.0)\n        x = tl.load(x_ptr + offsets[None, :], mask=mask, other=0.0)\n        \n        gates_ih += tl.dot(x, w)\n    \n    # Compute hidden-hidden gates (vectorized)\n    for i in range(0, hidden_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < hidden_size)\n        \n        w = tl.load(w_hh_ptr + offsets[None, :], mask=mask, other=0.0)\n        h = tl.load(hx_ptr + offsets[None, :], mask=mask, other=0.0)\n        \n        gates_hh += tl.dot(h, w)\n    \n    # Add biases\n    gates_ih += tl.load(b_ih_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    gates_hh += tl.load(b_hh_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    \n    # Combine gates\n    gates = gates_ih + gates_hh\n    \n    # Split gates into components\n    i_gate = tl.sigmoid(gates[:, :hidden_size])\n    f_gate = tl.sigmoid(gates[:, hidden_size:2*hidden_size])\n    g_gate = tl.tanh(gates[:, 2*hidden_size:3*hidden_size])\n    o_gate = tl.sigmoid(gates[:, 3*hidden_size:4*hidden_size])\n    \n    # Load previous cell state\n    c_prev = tl.load(cx_ptr, mask=batch_mask[:, None], other=0.0)\n    \n    # Compute new cell and hidden states\n    c_next = f_gate * c_prev + i_gate * g_gate\n    h_next = o_gate * tl.tanh(c_next)\n    \n    # Store results\n    tl.store(h_ptr, h_next, mask=batch_mask[:, None])\n    tl.store(c_ptr, c_next, mask=batch_mask[:, None])\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Create LSTM weights\n        self.w_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n        self.w_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n        self.b_ih = nn.Parameter(torch.empty(4 * hidden_size))\n        self.b_hh = nn.Parameter(torch.empty(4 * hidden_size))\n        \n        # Initialize weights\n        nn.init.xavier_uniform_(self.w_ih)\n        nn.init.xavier_uniform_(self.w_hh)\n        self.b_ih.data.fill_(0)\n        self.b_hh.data.fill_(0)\n        \n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n        c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n        \n        # Process each timestep\n        for t in range(seq_len):\n            # Call Triton kernel\n            grid = lambda meta: (triton.cdiv(batch_size, meta['BLOCK_B']),)\n            lstm_kernel[grid](\n                x[:, t, :], h, c,\n                self.w_ih, self.w_hh, self.b_ih, self.b_hh,\n                h, c,\n                batch_size, x.size(-1), self.hidden_size,\n                BLOCK_B=32, BLOCK_H=64\n            )\n        \n        return self.fc(h)\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_forward_kernel(\n    x_ptr, w_ptr, b_ptr, y_ptr,\n    n, m, k,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_y0, stride_y1,\n    BLOCK_M: tl.constexpr, BLOCK_K: tl.constexpr, BLOCK_N: tl.constexpr\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    # Create block pointers\n    x_block_ptr = tl.make_block_ptr(\n        base=x_ptr,\n        shape=(n, k),\n        strides=(stride_x0, stride_x1),\n        offsets=(pid0 * BLOCK_M, 0),\n        block_shape=(BLOCK_M, BLOCK_K),\n        order=(1, 0)\n    )\n    \n    w_block_ptr = tl.make_block_ptr(\n        base=w_ptr,\n        shape=(m, k),\n        strides=(stride_w0, stride_w1),\n        offsets=(pid1 * BLOCK_N, 0),\n        block_shape=(BLOCK_N, BLOCK_K),\n        order=(1, 0)\n    )\n    \n    y_block_ptr = tl.make_block_ptr(\n        base=y_ptr,\n        shape=(n, m),\n        strides=(stride_y0, stride_y1),\n        offsets=(pid0 * BLOCK_M, pid1 * BLOCK_N),\n        block_shape=(BLOCK_M, BLOCK_N),\n        order=(1, 0)\n    )\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Blocked matrix multiplication\n    for i in range(0, tl.cdiv(k, BLOCK_K)):\n        x_block = tl.load(x_block_ptr, boundary_check=(0, 1))\n        w_block = tl.load(w_block_ptr, boundary_check=(0, 1))\n        acc += tl.dot(x_block, w_block, allow_tf32=True)\n        \n        # Update pointers\n        x_block_ptr = tl.advance(x_block_ptr, (0, BLOCK_K))\n        w_block_ptr = tl.advance(w_block_ptr, (0, BLOCK_K))\n    \n    # Add bias\n    if b_ptr is not None:\n        bias = tl.load(b_ptr + tl.arange(0, BLOCK_N) + pid1 * BLOCK_N, \n                      mask=(tl.arange(0, BLOCK_N) + pid1 * BLOCK_N) < m, other=0.0)\n        acc += bias[None, :]\n    \n    # Store result\n    tl.store(y_block_ptr, acc.to(y_ptr.dtype.element_ty), boundary_check=(0, 1))\n\nclass TritonLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        y = torch.empty(x.shape[0], self.out_features, device=x.device, dtype=x.dtype)\n        n, k = x.shape\n        m = self.out_features\n        \n        # Tune block sizes for H100 architecture\n        BLOCK_M = 64\n        BLOCK_N = 64\n        BLOCK_K = 64\n        \n        grid = (\n            triton.cdiv(n, BLOCK_M),\n            triton.cdiv(m, BLOCK_N)\n        )\n        \n        linear_forward_kernel[grid](\n            x, self.weight, self.bias, y,\n            n, m, k,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            y.stride(0), y.stride(1),\n            BLOCK_M=BLOCK_M, BLOCK_K=BLOCK_K, BLOCK_N=BLOCK_N\n        )\n        return y\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers, \n            batch_first=True, dropout=dropout, bidirectional=True\n        )\n        self.fc = TritonLinear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    batch_size,\n    stride_x,       # stride for batch dimension in x\n    stride_weight,  # stride for output feature dimension in weight\n    stride_bias,    # not used for bias (1D tensor)\n    stride_output,  # stride for batch dimension in output\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    if pid_batch >= batch_size or pid_feature >= out_features:\n        return\n        \n    x_ptr += pid_batch * stride_x\n    weight_ptr_j = weight_ptr + pid_feature * stride_weight\n    output_ptr += pid_batch * stride_output + pid_feature\n\n    acc = 0.0\n    for k in range(0, in_features, BLOCK_SIZE):\n        offs = k + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_val = tl.load(x_ptr + offs, mask=mask, other=0.0)\n        w_val = tl.load(weight_ptr_j + offs, mask=mask, other=0.0)\n        acc += tl.sum(x_val * w_val)\n    \n    if bias_ptr is not None:\n        b = tl.load(bias_ptr + pid_feature)\n        acc += b\n\n    tl.store(output_ptr, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers,\n            batch_first=True, dropout=dropout, bidirectional=True\n        )\n        in_features = hidden_size * 2\n        self.in_features = in_features\n        self.out_features = output_size\n        self.weight = nn.Parameter(torch.Tensor(output_size, in_features))\n        self.bias = nn.Parameter(torch.Tensor(output_size))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n\n        out, _ = self.lstm(x, (h0, c0))\n        last_output = out[:, -1, :].contiguous()\n\n        output = torch.empty((batch_size, self.out_features), device=last_output.device, dtype=last_output.dtype)\n        grid = (batch_size, self.out_features)\n        \n        linear_kernel[grid](\n            last_output, \n            self.weight, \n            self.bias,\n            output,\n            self.in_features,\n            self.out_features,\n            batch_size,\n            last_output.stride(0),\n            self.weight.stride(0),\n            0,  # bias stride (unused)\n            output.stride(0),\n            BLOCK_SIZE=128,\n        )\n        return output\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr,  # input tensor\n    output_ptr,  # output tensor\n    hidden_ptr,  # final hidden state\n    cell_ptr,   # final cell state\n    weight_ih_ptr,\n    weight_hh_ptr,\n    bias_ih_ptr,\n    bias_hh_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    seq_length: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    hid_offsets = tl.arange(0, hidden_size)\n    input_offsets = tl.arange(0, input_size)\n    gate_offsets = tl.arange(0, 4 * hidden_size)\n    \n    # Load initial hidden and cell states\n    h_prev = tl.load(hidden_ptr + pid * hidden_size + hid_offsets)\n    c_prev = tl.load(cell_ptr + pid * hidden_size + hid_offsets)\n    \n    for step in range(seq_length):\n        # Load input for current time step\n        x_offset = pid * seq_length * input_size + step * input_size\n        x_t = tl.load(x_ptr + x_offset + input_offsets)\n        \n        # Compute input-hidden contribution\n        part1 = tl.zeros((4 * hidden_size,), dtype=tl.float32)\n        for j in range(4 * hidden_size):\n            w_row = tl.load(weight_ih_ptr + j * input_size + input_offsets)\n            part1 = tl.store(part1, j, tl.sum(x_t * w_row))\n        \n        # Compute hidden-hidden contribution\n        part2 = tl.zeros((4 * hidden_size,), dtype=tl.float32)\n        for j in range(4 * hidden_size):\n            w_row = tl.load(weight_hh_ptr + j * hidden_size + hid_offsets)\n            part2 = tl.store(part2, j, tl.sum(h_prev * w_row))\n        \n        # Add biases\n        bias_ih = tl.load(bias_ih_ptr + gate_offsets)\n        bias_hh = tl.load(bias_hh_ptr + gate_offsets)\n        gates = part1 + part2 + bias_ih + bias_hh\n        \n        # Split gates and apply activations\n        i = tl.sigmoid(gates[0:hidden_size])\n        f = tl.sigmoid(gates[hidden_size:2*hidden_size])\n        g = tl.tanh(gates[2*hidden_size:3*hidden_size])\n        o = tl.sigmoid(gates[3*hidden_size:4*hidden_size])\n        \n        # Update cell and hidden states\n        c_t = f * c_prev + i * g\n        h_t = o * tl.tanh(c_t)\n        \n        # Store output\n        out_offset = pid * seq_length * hidden_size + step * hidden_size\n        tl.store(output_ptr + out_offset + hid_offsets, h_t.to(output_ptr.dtype.element_ty))\n        \n        # Update for next step\n        h_prev = h_t\n        c_prev = c_t\n    \n    # Store final states\n    tl.store(hidden_ptr + pid * hidden_size + hid_offsets, h_prev.to(hidden_ptr.dtype.element_ty))\n    tl.store(cell_ptr + pid * hidden_size + hid_offsets, c_prev.to(cell_ptr.dtype.element_ty))\n\ndef bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, h0, c0):\n    batch_size, seq_length, input_size = x.shape\n    hidden_size = weight_ih.shape[0] // 4\n\n    # Prepare inputs\n    x_flat = x.contiguous().view(-1)\n    output = torch.empty((batch_size, seq_length, hidden_size), device=x.device, dtype=x.dtype)\n    output_flat = output.view(-1)\n    \n    # Prepare states (use initial states as input buffers)\n    h0_flat = h0.view(-1).contiguous()\n    c0_flat = c0.view(-1).contiguous()\n    \n    # Launch kernel\n    grid = (batch_size,)\n    lstm_kernel[grid](\n        x_flat, output_flat, h0_flat, c0_flat,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size,\n        hidden_size\n    )\n    \n    # Return outputs and final states\n    hn = h0_flat.view(batch_size, hidden_size)\n    cn = c0_flat.view(batch_size, hidden_size)\n    return output, (hn.unsqueeze(0), cn.unsqueeze(0))\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n\n        # Weight parameters\n        self.weight_ih = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n        self.weight_hh = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n        self.bias_ih = nn.Parameter(torch.randn(4 * hidden_size))\n        self.bias_hh = nn.Parameter(torch.randn(4 * hidden_size))\n\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        batch_size, seq_length, input_size = x.shape\n\n        # Initialize states\n        h0 = torch.zeros(1, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(1, batch_size, self.hidden_size, device=x.device)\n\n        # Compute LSTM\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weight_ih, self.weight_hh,\n            self.bias_ih, self.bias_hh,\n            h0, c0\n        )\n\n        # Final output\n        out = self.fc(out[:, -1, :])\n        return out\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_forward_kernel(\n    x_ptr,\n    output_ptr,\n    h_ptr,\n    c_ptr,\n    w_ih_ptr,\n    w_hh_ptr,\n    b_ih_ptr,\n    b_hh_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    seq_len: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_HS: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    off_h = pid * hidden_size + tl.arange(0, BLOCK_HS)\n    mask_h = tl.arange(0, BLOCK_HS) < hidden_size\n    \n    # Initialize hidden and cell states\n    h_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    c_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    \n    # Precompute gate offsets\n    gate_offsets = tl.arange(0, 4) * hidden_size\n    for step in range(seq_len):\n        # Load input for current timestep\n        off_x = (pid * seq_len + step) * input_size\n        x = tl.load(x_ptr + off_x + tl.arange(0, input_size))\n        \n        # Compute input transformation\n        gates = tl.zeros((4, BLOCK_HS), dtype=tl.float32)\n        for i in range(4):\n            w_ih = tl.load(w_ih_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * input_size + \n                          tl.arange(0, input_size)[None, :], mask=mask_h[:, None])\n            gates = tl.store(gates, i, tl.sum(w_ih * x, axis=1) + tl.load(b_ih_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Compute hidden transformation\n        for i in range(4):\n            w_hh = tl.load(w_hh_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * hidden_size + \n                          tl.arange(0, BLOCK_HS)[None, :], mask=mask_h[:, None] & mask_h[None, :])\n            gates = tl.store(gates, i, gates[i] + tl.sum(w_hh * h_cur, axis=1) + tl.load(b_hh_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0])\n        f_gate = tl.sigmoid(gates[1])\n        g_gate = tl.tanh(gates[2])\n        o_gate = tl.sigmoid(gates[3])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_cur + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        tl.store(output_ptr + (pid * seq_len + step) * hidden_size + tl.arange(0, BLOCK_HS), \n                h_cur, mask=mask_h)\n    \n    # Store final states\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), h_cur, mask=mask_h)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), c_cur, mask=mask_h)\n\n@triton.jit\ndef lstm_backward_kernel(\n    x_ptr,\n    output_ptr,\n    h_ptr,\n    c_ptr,\n    w_ih_ptr,\n    w_hh_ptr,\n    b_ih_ptr,\n    b_hh_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    seq_len: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_HS: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    off_h = pid * hidden_size + tl.arange(0, BLOCK_HS)\n    mask_h = tl.arange(0, BLOCK_HS) < hidden_size\n    \n    # Initialize hidden and cell states\n    h_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    c_cur = tl.zeros((BLOCK_HS,), dtype=tl.float32)\n    \n    # Precompute gate offsets\n    gate_offsets = tl.arange(0, 4) * hidden_size\n    for step in range(seq_len-1, -1, -1):\n        # Load input for current timestep\n        off_x = (pid * seq_len + step) * input_size\n        x = tl.load(x_ptr + off_x + tl.arange(0, input_size))\n        \n        # Compute input transformation\n        gates = tl.zeros((4, BLOCK_HS), dtype=tl.float32)\n        for i in range(4):\n            w_ih = tl.load(w_ih_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * input_size + \n                          tl.arange(0, input_size)[None, :], mask=mask_h[:, None])\n            gates = tl.store(gates, i, tl.sum(w_ih * x, axis=1) + tl.load(b_ih_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Compute hidden transformation\n        for i in range(4):\n            w_hh = tl.load(w_hh_ptr + (gate_offsets[i] + tl.arange(0, BLOCK_HS))[:, None] * hidden_size + \n                          tl.arange(0, BLOCK_HS)[None, :], mask=mask_h[:, None] & mask_h[None, :])\n            gates = tl.store(gates, i, gates[i] + tl.sum(w_hh * h_cur, axis=1) + tl.load(b_hh_ptr + gate_offsets[i] + tl.arange(0, BLOCK_HS), mask=mask_h))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0])\n        f_gate = tl.sigmoid(gates[1])\n        g_gate = tl.tanh(gates[2])\n        o_gate = tl.sigmoid(gates[3])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_cur + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        tl.store(output_ptr + (pid * seq_len + step) * hidden_size + tl.arange(0, BLOCK_HS), \n                h_cur, mask=mask_h)\n    \n    # Store final states\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), h_cur, mask=mask_h)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, BLOCK_HS), c_cur, mask=mask_h)\n\ndef bidirectional_lstm_triton(x, weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f,\n                              weight_ih_b, weight_hh_b, bias_ih_b, bias_hh_b, h0, c0):\n    batch_size, seq_len, input_size = x.shape\n    hidden_size = weight_ih_f.shape[0] // 4\n    \n    # Prepare outputs\n    output_f = torch.empty((batch_size, seq_len, hidden_size), device=x.device, dtype=x.dtype)\n    output_b = torch.empty((batch_size, seq_len, hidden_size), device=x.device, dtype=x.dtype)\n    hn_f = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_f = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    hn_b = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_b = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    # Flatten tensors\n    x_flat = x.contiguous().view(-1)\n    output_f_flat = output_f.view(-1)\n    output_b_flat = output_b.view(-1)\n    \n    # Compute block size\n    BLOCK_HS = triton.next_power_of_2(hidden_size)\n    \n    # Launch forward kernel\n    lstm_forward_kernel[(batch_size,)](\n        x_flat, output_f_flat, hn_f, cn_f,\n        weight_ih_f, weight_hh_f, bias_ih_f, bias_hh_f,\n        input_size, hidden_size, seq_len, batch_size, BLOCK_HS\n    )\n    \n    # Launch backward kernel\n    lstm_backward_kernel[(batch_size,)](\n        x_flat, output_b_flat, hn_b, cn_b,\n        weight_ih_b, weight_hh_b, bias_ih_b, bias_hh_b,\n        input_size, hidden_size, seq_len, batch_size, BLOCK_HS\n    )\n    \n    # Combine outputs\n    output = torch.cat((output_f, output_b), dim=-1)\n    hn = torch.stack((hn_f, hn_b), dim=0)\n    cn = torch.stack((cn_f, cn_b), dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n\n        # Forward weights\n        self.weight_ih_f = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n        self.weight_hh_f = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n        self.bias_ih_f = nn.Parameter(torch.randn(4 * hidden_size))\n        self.bias_hh_f = nn.Parameter(torch.randn(4 * hidden_size))\n        \n        # Backward weights\n        self.weight_ih_b = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n        self.weight_hh_b = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n        self.bias_ih_b = nn.Parameter(torch.randn(4 * hidden_size))\n        self.bias_hh_b = nn.Parameter(torch.randn(4 * hidden_size))\n\n        self.fc = nn.Linear(2 * hidden_size, output_size)\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        \n        # Initialize hidden states\n        h0 = torch.zeros(2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process LSTM\n        out, _ = bidirectional_lstm_triton(\n            x,\n            self.weight_ih_f, self.weight_hh_f, self.bias_ih_f, self.bias_hh_f,\n            self.weight_ih_b, self.weight_hh_b, self.bias_ih_b, self.bias_hh_b,\n            h0, c0\n        )\n        \n        # Final output\n        out = self.fc(out[:, -1, :])\n        return out\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr, output_ptr, hidden_ptr, cell_ptr,\n    weight_ih_ptr, weight_hh_ptr, bias_ih_ptr, bias_hh_ptr,\n    input_size: tl.constexpr, hidden_size: tl.constexpr,\n    seq_length: tl.constexpr, batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    offsets = pid * seq_length * hidden_size + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < batch_size * seq_length * hidden_size\n    x_val = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    tl.store(output_ptr + offsets, x_val, mask=mask)\n    \n    if pid < batch_size:\n        state_offsets = pid * hidden_size + tl.arange(0, BLOCK_SIZE)\n        state_mask = state_offsets < batch_size * hidden_size\n        tl.store(hidden_ptr + state_offsets, 0.0, mask=state_mask)\n        tl.store(cell_ptr + state_offsets, 0.0, mask=state_mask)\n\ndef bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, h0, c0):\n    batch_size, seq_length, input_size = x.shape\n    hidden_size = weight_ih.shape[0] // 4\n    \n    # Process forward direction\n    output_forward = torch.empty((batch_size, seq_length, hidden_size), \n                                device=x.device, dtype=x.dtype)\n    hn_forward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_forward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    n_elements = batch_size\n    grid = (n_elements,)\n    lstm_kernel[grid](\n        x.contiguous().view(-1), output_forward.view(-1), \n        hn_forward, cn_forward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size,\n        hidden_size\n    )\n    \n    # Process backward direction\n    x_reversed = torch.flip(x, [1])\n    output_backward = torch.empty((batch_size, seq_length, hidden_size), \n                                 device=x.device, dtype=x.dtype)\n    hn_backward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    cn_backward = torch.zeros((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n    \n    lstm_kernel[grid](\n        x_reversed.contiguous().view(-1), output_backward.view(-1), \n        hn_backward, cn_backward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size,\n        hidden_size\n    )\n    output_backward = torch.flip(output_backward, [1])\n    \n    # Combine directions\n    output = torch.cat([output_forward, output_backward], dim=-1)\n    hn = torch.stack([hn_forward, hn_backward], dim=0)\n    cn = torch.stack([cn_forward, cn_backward], dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n        \n        # Create parameters for all layers\n        self.weights_ih = nn.ParameterList()\n        self.weights_hh = nn.ParameterList()\n        self.biases_ih = nn.ParameterList()\n        self.biases_hh = nn.ParameterList()\n        \n        for _ in range(num_layers * 2):  # *2 for bidirectional\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, input_size)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            input_size = hidden_size * 2  # For subsequent layers\n        \n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_length, _ = x.shape\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process through all layers\n        for layer in range(self.num_layers):\n            weight_idx = layer * 2\n            out, (hn, cn) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0[0], c0[0]\n            )\n            x = out  # Input for next layer\n        \n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a program that is failing correctness (output mismatch) and we are to fix it.\n The current program uses a Triton kernel that is overly simplistic: it just copies the input to the output and zeros the hidden and cell states.\n This is clearly not implementing an LSTM.\n\n We must rewrite the Triton kernel to actually compute the LSTM forward and backward passes.\n\n However, note that the problem is complex: we have a bidirectional LSTM with multiple layers.\n\n Let's break down the task:\n\n 1. The current `lstm_kernel` does not compute LSTM gates. We need to replace it with a proper LSTM kernel.\n\n 2. We have two directions: forward and backward. The current code processes the forward and backward separately by flipping the input.\n\n 3. The model has multiple layers. The output of one layer becomes the input to the next.\n\n 4. We are to use Triton for the LSTM computation.\n\n Given the complexity, we might consider:\n\n Approach 1: Implement a single-step LSTM kernel that processes one timestep at a time. However, this might be inefficient.\n\n Approach 2: Implement a kernel that processes an entire sequence for one layer and one direction.\n\n However, note that the provided `bidirectional_lstm_triton` function is designed to handle one layer (with two directions) at a time.\n\n We are going to write a Triton kernel that computes the entire forward pass for one layer and one direction.\n\n Since the current kernel is incorrect, we must design a new kernel.\n\n We are inspired by the diverse programs and inspiration programs, especially the ones that show the structure of an LSTM kernel.\n\n Let's look at the structure of an LSTM:\n\n   i_t = sigmoid(W_ii x_t + b_ii + W_hi h_{t-1} + b_hi)\n   f_t = sigmoid(W_if x_t + b_if + W_hf h_{t-1} + b_hf)\n   g_t = tanh(W_ig x_t + b_ig + W_hg h_{t-1} + b_hg)\n   o_t = sigmoid(W_io x_t + b_io + W_ho h_{t-1} + b_ho)\n   c_t = f_t * c_{t-1} + i_t * g_t\n   h_t = o_t * tanh(c_t)\n\n We have the weights and biases for the input-hidden and hidden-hidden transformations.\n\n The weights are stored in:\n   weight_ih: of shape (4*hidden_size, input_size)\n   weight_hh: of shape (4*hidden_size, hidden_size)\n   bias_ih: of shape (4*hidden_size)\n   bias_hh: of shape (4*hidden_size)\n\n We are processing a batch of sequences.\n\n We'll design a kernel that processes one batch element (one sequence) and one direction.\n\n Steps for the kernel:\n\n   - The kernel will be launched with `batch_size` programs (one per sequence).\n   - Each program will process one sequence (either forward or backward) and output the entire sequence of hidden states and the final state.\n\n How to handle the backward direction? We can flip the input sequence for the backward pass, then flip the output.\n\n However, note: the current function `bidirectional_lstm_triton` already flips the input for the backward pass and flips the output.\n\n So the kernel itself can be written for the forward direction and then used for the backward by flipping.\n\n Proposed kernel:\n\n   @triton.jit\n   def lstm_kernel(\n        x_ptr,           # input sequence for one batch, flattened: [seq_length, input_size]\n        output_ptr,      # output sequence: [seq_length, hidden_size] (for one batch and one direction)\n        h0_ptr,          # initial hidden state: [hidden_size]\n        c0_ptr,          # initial cell state: [hidden_size]\n        weight_ih_ptr,   # [4*hidden_size, input_size]\n        weight_hh_ptr,   # [4*hidden_size, hidden_size]\n        bias_ih_ptr,     # [4*hidden_size]\n        bias_hh_ptr,     # [4*hidden_size]\n        input_size: tl.constexpr,\n        hidden_size: tl.constexpr,\n        seq_length: tl.constexpr,\n        BLOCK_SIZE: tl.constexpr,   # we can use for hidden_size, but we need to adjust for input_size as well\n   ):\n\n        pid = tl.program_id(0)   # batch index\n\n        # We'll use offsets for the current batch\n        # For the input: [batch, seq, input_size] -> for batch pid, we have [seq_length, input_size]\n        # We'll iterate over timesteps.\n\n        # Pointers for the current batch's input and output\n        # x_batch_ptr = x_ptr + pid * (seq_length * input_size)\n        # output_batch_ptr = output_ptr + pid * (seq_length * hidden_size)\n\n        # We also have initial states h0 and c0 for this batch\n        h_prev = tl.load(h0_ptr + pid * hidden_size + tl.arange(0, hidden_size))\n        c_prev = tl.load(c0_ptr + pid * hidden_size + tl.arange(0, hidden_size))\n\n        # We'll iterate over the sequence\n        for step in range(seq_length):\n            # Load the input at step: [input_size]\n            x_t = tl.load(x_ptr + pid * (seq_length * input_size) + step * input_size + tl.arange(0, input_size))\n\n            # Compute the input-hidden part: (4*hidden_size)\n            # We do: W_ih * x_t + b_ih\n            # We'll break it into blocks? Or do a vector-matrix multiplication?\n            # We have a matrix multiplication: (1, input_size) * (input_size, 4*hidden_size) -> (1, 4*hidden_size)\n            # But Triton doesn't have a direct way to do a vector-matrix multiply? We can use tl.dot if we make x_t a row vector and weight_ih a matrix.\n\n            # Alternatively, we can do a loop over the 4*hidden_size and compute each row.\n\n            # We'll do:\n            #   part_ih = tl.zeros(4*hidden_size, dtype=tl.float32)\n            #   for j in range(4*hidden_size):\n            #       row = tl.load(weight_ih_ptr + j * input_size + tl.arange(0, input_size))\n            #       part_ih[j] = tl.sum(row * x_t) + bias_ih_ptr[j]\n            #\n            # Similarly for part_hh.\n\n            # But note: this is a lot of memory access and might be slow. However, we are constrained by the complexity.\n\n            # Alternatively, we can use tl.dot with block tiling? But the input_size and hidden_size might be large.\n\n            # Since we are only at the kernel for one batch and one timestep, we can try to do a tiled dot.\n\n            # However, for simplicity and correctness first, we do a loop.\n\n            # We'll precompute the gate_offsets: [0, hidden_size, 2*hidden_size, 3*hidden_size] for the four gates?\n            # Actually, the weights are stored as: [i, f, g, o] for each of the hidden_size blocks.\n\n            # Allocate gates\n            gates = tl.zeros((4 * hidden_size,), dtype=tl.float32)\n\n            # Compute input-hidden part\n            for j in range(4 * hidden_size):\n                # Load one row of weight_ih: j-th row\n                w_ih_row = tl.load(weight_ih_ptr + j * input_size + tl.arange(0, input_size), mask=tl.arange(0, input_size) < input_size, other=0.0)\n                # Dot product: w_ih_row (input_size) * x_t (input_size) -> scalar\n                dot = tl.sum(w_ih_row * x_t)\n                gates = tl.store(gates, j, dot + tl.load(bias_ih_ptr + j))\n\n            # Compute hidden-hidden part\n            for j in range(4 * hidden_size):\n                w_hh_row = tl.load(weight_hh_ptr + j * hidden_size + tl.arange(0, hidden_size), mask=tl.arange(0, hidden_size) < hidden_size, other=0.0)\n                dot = tl.sum(w_hh_row * h_prev)\n                gates = tl.store(gates, j, gates[j] + dot + tl.load(bias_hh_ptr + j))\n\n            # Now split the gates into i, f, g, o\n            i = tl.sigmoid(gates[0:hidden_size])\n            f = tl.sigmoid(gates[hidden_size:2*hidden_size])\n            g = tl.tanh(gates[2*hidden_size:3*hidden_size])\n            o = tl.sigmoid(gates[3*hidden_size:4*hidden_size])\n\n            # Update the cell and hidden state\n            c_cur = f * c_prev + i * g\n            h_cur = o * tl.tanh(c_cur)\n\n            # Store the hidden state for this timestep\n            tl.store(output_ptr + pid * (seq_length * hidden_size) + step * hidden_size + tl.arange(0, hidden_size), h_cur)\n\n            # Update for next timestep\n            h_prev = h_cur\n            c_prev = c_cur\n\n        # Store the final hidden and cell state\n        tl.store(h0_ptr + pid * hidden_size + tl.arange(0, hidden_size), h_cur)\n        tl.store(c0_ptr + pid * hidden_size + tl.arange(0, hidden_size), c_cur)\n\n However, note: the above kernel uses loops over the rows of the weight matrices. This might be inefficient but it's a starting point.\n\n But note: the kernel must be efficient enough. We are processing one timestep at a time and one batch element at a time.\n\n We are going to change the kernel in the current program to this new one.\n\n Also note: the current `bidirectional_lstm_triton` function is using:\n     h0 and c0 of shape [num_layers * 2, batch_size, hidden_size] for the entire model, but in the function call for one layer, we are passing h0[0] and c0[0] for the forward and then for the backward we would use h0[1] and c0[1]? Actually, in the current code, we are passing h0[0] and c0[0] for both directions? That might be a problem.\n\n But note: in the `ModelNew.forward`, we are initializing `h0` and `c0` to zeros of shape (num_layers * 2, batch_size, hidden_size). Then for each layer, we are taking `h0[0]` and `c0[0]` for the forward and backward? Actually, we are passing the same for both? We should pass the forward initial state from h0[0] and the backward initial state from h0[1]. However, in the current code, we are passing `h0[0]` and `c0[0]` for the forward and then again the same for the backward? That is incorrect.\n\n But note: the current `bidirectional_lstm_triton` function is called for each direction separately? Actually, it's called once for the forward and once for the backward? And we pass `h0[0]` for the forward and `h0[0]` for the backward? That is wrong.\n\n We must change the `bidirectional_lstm_triton` to take two initial states: one for forward and one for backward? But the function signature only takes `h0` and `c0` (as one tensor each). And in the model, we have a tensor of shape (num_layers * 2, ...). For a given layer, the forward direction should use the initial state at index [layer_index * 2] and the backward at [layer_index * 2 + 1].\n\n However, in the current `ModelNew.forward`:\n\n        for layer in range(self.num_layers):\n            weight_idx = layer * 2\n            out, (hn, cn) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0[0], c0[0]\n            )\n\n Here, `h0[0]` is of shape (batch_size, hidden_size) because `h0` is of shape (num_layers*2, batch_size, hidden_size). We are taking the first layer's forward and backward initial states? Actually, we are taking the very first initial state for the forward and then the same for the backward? We should take two: one for forward and one for backward.\n\n We need to change the call to:\n\n        h0_forward = h0[layer*2]\n        c0_forward = c0[layer*2]\n        h0_backward = h0[layer*2+1]\n        c0_backward = c0[layer*2+1]\n\n But our `bidirectional_lstm_triton` function currently only takes one h0 and one c0. We must modify it to take two.\n\n However, let's stick to the current plan: fix the kernel first and then adjust the initial states.\n\n Alternatively, we can change the `bidirectional_lstm_triton` to take two initial states for the two directions? But the function signature in the current code does not allow that.\n\n Given the complexity, we might restructure:\n\n We are going to write two separate kernels: one for forward and one for backward? Actually, we can use the same kernel and just flip the input for the backward and then flip the output? And use the same initial state for the backward as the forward? But that is not how bidirectional works. The backward should start at the last timestep and go backwards, and the initial state for the backward should be provided (and is typically learned).\n\n How about we do:\n\n   In `bidirectional_lstm_triton`:\n\n        # Forward pass: use h0_forward and c0_forward\n        # Backward pass: use h0_backward and c0_backward\n\n   But currently, we are passing `h0` and `c0` which are the initial states for the forward direction? And we don't have an initial state for the backward? In the PyTorch LSTM, the initial state for the backward is the last element of the state? Actually, no: the initial state for the backward is provided as a separate tensor (the second in the bidirectional pair).\n\n   We change the function to take two initial states? Or we assume that the initial state for the backward is zero? But the model expects to learn them.\n\n   In our model, the initial states are passed as `h0` and `c0` which have two layers per layer (for forward and backward). So for a given layer, we have two states.\n\n   We must change the function to take:\n\n        h0_forward, c0_forward, h0_backward, c0_backward\n\n   But to minimize changes, we can pass `h0` and `c0` as the entire tensor for the two directions? And then split them? Actually, in the call we are passing `h0[0]` and `c0[0]` for both directions? That is wrong.\n\n   We decide to restructure the `bidirectional_lstm_triton` function to take two initial states for the two directions.\n\n   But note: the current call in the model:\n\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n            self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n            h0[0], c0[0]\n        )\n\n   We are passing `h0[0]` and `c0[0]` which are the initial state for the forward direction? What about the backward? We should pass `h0[1]` and `c0[1]`? But the index `0` in `h0[0]` is the first layer's forward, and then we want the first layer's backward at index `1`.\n\n   So we change the call to:\n\n        h0_forward = h0[layer*2]\n        c0_forward = c0[layer*2]\n        h0_backward = h0[layer*2+1]\n        c0_backward = c0[layer*2+1]\n\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n            self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n            h0_forward, c0_forward, h0_backward, c0_backward\n        )\n\n   And then modify `bidirectional_lstm_triton` to take two sets of initial states.\n\n   Then, in the backward pass, we use `h0_backward` and `c0_backward`.\n\n   We'll change the function accordingly.\n\n   But note: the Triton kernel we are writing for one direction requires the initial state for that direction.\n\n   We'll change the kernel to take the initial state for the direction it's processing.\n\n   The kernel call for forward:\n\n        lstm_kernel_forward[grid](\n            ...,\n            h0_forward, c0_forward,\n            ...\n        )\n\n   For backward:\n\n        lstm_kernel_forward[grid](   # we can use the same kernel for backward if we flip the input and then flip the output?\n            ...,\n            h0_backward, c0_backward,\n            ...\n        )\n\n   Actually, the backward pass is just a forward pass on the reversed sequence? But note: the initial state for the backward is for the first timestep of the reversed sequence? Actually, the backward RNN starts at the last token and goes to the first. So if we reverse the sequence, then the backward becomes a forward pass? And we can use the same kernel? But then the initial state for the backward (which is for the last token in the original) becomes the first token in the reversed sequence? And we want the backward RNN to start at that token? So we can use the same kernel for the backward by reversing the input and then reversing the output.\n\n   However, we must use the provided initial state for the backward (which is the state at the original last token) as the initial state for the reversed sequence.\n\n   So we do:\n\n        x_reversed = flip(x, [1])\n        # Then run the same kernel as the forward on x_reversed, using h0_backward and c0_backward as the initial state.\n        # Then flip the output to get the backward output in the original order.\n\n   This is what the current code does, but it uses the same initial state for both? We are now passing the backward initial state.\n\n   So we change:\n\n        In bidirectional_lstm_triton:\n\n          # Forward\n          lstm_kernel[grid](\n              ...,\n              h0_forward, c0_forward,\n              ...)\n\n          # Backward\n          lstm_kernel[grid](\n              ...,\n              h0_backward, c0_backward,\n              ...)\n\n   And the kernel is the same for both.\n\n Given the above, we rewrite:\n\n   We change the `bidirectional_lstm_triton` function to take two additional arguments: `h0_forward, c0_forward, h0_backward, c0_backward`? But that would change the signature and we are using it in the model.\n\n   Alternatively, we can pass `h0` and `c0` as the entire initial state tensor and then split inside the function? But the function currently takes `h0` and `c0` as the initial state for the forward? We are going to change the function to take:\n\n        h0_forward, c0_forward, h0_backward, c0_backward\n\n   But then we must change the call in the model.\n\n   Alternatively, we can pass a tuple for the initial states? But to avoid too many changes, we change the function to take two more arguments.\n\n   However, the current function call in the model is:\n\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n            self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n            h0[0], c0[0]\n        )\n\n   We want to change it to:\n\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n            self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n            h0[layer*2], c0[layer*2],\n            h0[layer*2+1], c0[layer*2+1]\n        )\n\n   And then in the function:\n\n        def bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, h0_forward, c0_forward, h0_backward, c0_backward):\n\n   And then use `h0_forward` and `c0_forward` for the forward, and `h0_backward` and `c0_backward` for the backward.\n\n   We'll do that.\n\n   Now, the Triton kernel for one direction (we'll rename it to `lstm_forward_kernel` to avoid confusion) will be as described above.\n\n   We must note: the kernel must be efficient. The current loop over the rows might be slow for large hidden sizes. But we are at correctness first.\n\n   We'll implement the kernel as described.\n\n   Steps for the kernel:\n\n        pid: batch index\n\n        Load the initial hidden and cell state for this batch and this direction.\n\n        Loop over timesteps (from 0 to seq_length-1 for forward, but the kernel doesn't know direction because we are using the same for backward by flipping the input externally):\n\n            x_t = load input at current timestep for this batch\n\n            Compute gates = W_ih * x_t + b_ih + W_hh * h_prev + b_hh\n\n            Split gates into i, f, g, o\n\n            Update c_cur and h_cur\n\n            Store h_cur at the output for this timestep\n\n            Update h_prev = h_cur, c_prev = c_cur\n\n        Store the final hidden and cell state.\n\n   We must be cautious with masking: the input_size and hidden_size might not be multiples of the block size? We are using `tl.arange(0, input_size)` and `tl.arange(0, hidden_size)`. This assumes that the entire vector is loaded? But if we are using a block size that is less than input_size or hidden_size, we must mask.\n\n   However, note: the kernel is launched per batch element, and we are not tiling the hidden_size or input_size dimension? We are processing the entire vector in one program.\n\n   This might not be efficient for large hidden sizes? But we are at correctness.\n\n   We'll write the kernel without tiling for the hidden and input dimensions. We assume that the entire vector fits in the program.\n\n   But note: Triton has a limit on the number of registers. If hidden_size is 256, then 4*hidden_size=1024, and we are doing loops of 1024 iterations? And each iteration loads a row of length input_size (128) and then a row of hidden_size (256). This might be acceptable.\n\n   We'll try.\n\n   We change the kernel to the new implementation and adjust the function for bidirectional.\n\n   We also note: the current kernel uses a `BLOCK_SIZE` argument. We are not using it? We can remove it? Or we can use it to tile the hidden_size? We are not tiling, so we remove it? But we must keep the signature? Actually, we are going to change the kernel.\n\n   We remove the `BLOCK_SIZE` and instead use `hidden_size` and `input_size` to determine the size.\n\n   But note: the kernel call in `bidirectional_lstm_triton` currently uses `hidden_size` as the block size. We change that to the actual block size? We don't need it because we are processing the entire vector.\n\n   However, we must keep the kernel call. We can pass `hidden_size` as the block size? Actually, we are not using it in the kernel.\n\n   We decide to remove the `BLOCK_SIZE` from the kernel and replace it with `hidden_size` and `input_size` as compile-time constants.\n\n   But note: we are using `tl.arange(0, hidden_size)` and `tl.arange(0, input_size)`. This will create a vector of that size. Triton requires that the total number of elements processed by a program is less than a certain limit (e.g., 1024 for some architectures). If hidden_size is 256, then the vector is 256, which is acceptable.\n\n   We'll change the kernel signature.\n\n   Given the complexity, we are going to write a new kernel and replace the old one.\n\n   We'll call it `lstm_forward_kernel` and use it for both directions.\n\n   Steps:\n\n        @triton.jit\n        def lstm_forward_kernel(\n            x_ptr, output_ptr, h0_ptr, c0_ptr,\n            weight_ih_ptr, weight_hh_ptr, bias_ih_ptr, bias_hh_ptr,\n            input_size, hidden_size, seq_length, batch_size,\n            # We don't need BLOCK_SIZE because we are processing the entire vector per program\n        ):\n\n        pid = tl.program_id(0)   # batch index\n\n        # We are going to load the initial state for this batch\n        off_h = pid * hidden_size + tl.arange(0, hidden_size)\n        h_prev = tl.load(h0_ptr + off_h, mask=tl.arange(0, hidden_size) < hidden_size, other=0.0)\n        c_prev = tl.load(c0_ptr + off_h, mask=tl.arange(0, hidden_size) < hidden_size, other=0.0)\n\n        # Loop over timesteps\n        for step in range(seq_length):\n            off_x = pid * (seq_length * input_size) + step * input_size\n            x_t = tl.load(x_ptr + off_x + tl.arange(0, input_size), mask=tl.arange(0, input_size) < input_size, other=0.0)\n\n            # Compute input-hidden and hidden-hidden\n            gates = tl.zeros((4*hidden_size,), dtype=tl.float32)\n            for j in range(4*hidden_size):\n                # Load weight_ih row j\n                off_w_ih = j * input_size + tl.arange(0, input_size)\n                w_ih_row = tl.load(weight_ih_ptr + off_w_ih, mask=tl.arange(0, input_size) < input_size, other=0.0)\n                dot_ih = tl.sum(w_ih_row * x_t)\n                # Load weight_hh row j\n                off_w_hh = j * hidden_size + tl.arange(0, hidden_size)\n                w_hh_row = tl.load(weight_hh_ptr + off_w_hh, mask=tl.arange(0, hidden_size) < hidden_size, other=0.0)\n                dot_hh = tl.sum(w_hh_row * h_prev)\n                # Add biases\n                b_ih_val = tl.load(bias_ih_ptr + j)\n                b_hh_val = tl.load(bias_hh_ptr + j)\n                gate_val = dot_ih + b_ih_val + dot_hh + b_hh_val\n                gates = tl.store(gates, j, gate_val)\n\n            # Split gates\n            i = tl.sigmoid(gates[0:hidden_size])\n            f = tl.sigmoid(gates[hidden_size:2*hidden_size])\n            g = tl.tanh(gates[2*hidden_size:3*hidden_size])\n            o = tl.sigmoid(gates[3*hidden_size:4*hidden_size])\n\n            c_cur = f * c_prev + i * g\n            h_cur = o * tl.tanh(c_cur)\n\n            # Store output for this timestep\n            off_out = pid * (seq_length * hidden_size) + step * hidden_size + tl.arange(0, hidden_size)\n            tl.store(output_ptr + off_out, h_cur, mask=tl.arange(0, hidden_size) < hidden_size)\n\n            # Update for next timestep\n            h_prev = h_cur\n            c_prev = c_cur\n\n        # Store final state\n        tl.store(h0_ptr + off_h, h_cur, mask=tl.arange(0, hidden_size) < hidden_size)\n        tl.store(c0_ptr + off_h, c_cur, mask=tl.arange(0, hidden_size) < hidden_size)\n\n   Note: we are overwriting the initial state buffers with the final state? That is what the PyTorch LSTM does.\n\n   We then call this kernel for the forward and backward.\n\n   In `bidirectional_lstm_triton`:\n\n        # Forward\n        lstm_forward_kernel[grid](\n            x_flat, output_forward_flat, h0_forward, c0_forward,\n            weight_ih, weight_hh, bias_ih, bias_hh,\n            input_size, hidden_size, seq_length, batch_size\n        )\n\n        # Backward: use the reversed input and the backward initial states\n        lstm_forward_kernel[grid](\n            x_reversed_flat, output_backward_flat, h0_backward, c0_backward,\n            weight_ih, weight_hh, bias_ih, bias_hh,\n            input_size, hidden_size, seq_length, batch_size\n        )\n\n        Then flip output_backward_flat to get the output in the original order.\n\n   We also note: the grid is still (batch_size,)\n\n   We must change the kernel to have the correct types and to compile.\n\n   However, note: the kernel might be slow, but we are aiming for correctness.\n\n   We'll make these changes.\n\n   Also note: the current `bidirectional_lstm_triton` returns `output` and `(hn, cn)`. The `hn` and `cn` should be the final states for the forward and backward, which we stored in `h0_forward, c0_forward, h0_backward, c0_backward`? Actually, we overwrote the initial state buffers with the final states.\n\n   We then form:\n\n        hn_forward = h0_forward   # which now contains the final state for the forward\n        cn_forward = c0_forward\n        hn_backward = h0_backward\n        cn_backward = c0_backward\n\n        hn = torch.stack([hn_forward, hn_backward], dim=0)\n        cn = torch.stack([cn_forward, cn_backward], dim=0)\n\n   So we return:\n\n        output = torch.cat([output_forward, output_backward], dim=-1)\n        hn = ... # as above\n        cn = ... # as above\n\n   But note: the final state for the backward is after processing the reversed sequence, which is the state at the first token of the original sequence? So it is the backward's final state.\n\n   We are returning the final states in the buffers that were initially the initial states.\n\n   This matches the PyTorch LSTM.\n\n   We'll implement accordingly.\n\n   Due to the complexity and the fact that we are changing multiple parts, we must be cautious.\n\n   We are going to rewrite the entire `bidirectional_lstm_triton` and the kernel.\n\n   Let's code accordingly.\n\n   We note: the current program also has a fully connected layer at the end. We are not changing that.\n\n   We are only changing the LSTM kernel and the bidirectional function.\n\n   Given the above, we write the new code.\n\n   IMPORTANT: We must not change the interface of the ModelNew class.\n\n   We'll only change the Triton kernel and the bidirectional_lstm_triton function, and the call in ModelNew.forward.\n\n   We'll do it step by step.\n\n   Note: the current program is long, so we must be careful to only output the EVOLVE-BLOCK.\n\n   We are to replace the current `lstm_kernel` with `lstm_forward_kernel` and change the bidirectional function.\n\n   We are also to change the call in ModelNew.forward to pass two initial states.\n\n   We'll do:\n\n        # In ModelNew.forward, for each layer:\n        weight_idx = layer * 2\n        h0_forward = h0[layer*2]\n        c0_forward = c0[layer*2]\n        h0_backward = h0[layer*2+1]\n        c0_backward = c0[layer*2+1]\n\n        out, (hn, cn) = bidirectional_lstm_triton(\n            x,\n            self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n            self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n            h0_forward, c0_forward, h0_backward, c0_backward\n        )\n\n   And then set:\n        # We are not using hn and cn for the next layer? Actually, the next layer should take the final states of this layer as the initial states? But the current code does not do that.\n\n   We see: in the current code, we do:\n\n        out, (hn, cn) = bidirectional_lstm_triton(...)\n        x = out   # for next layer\n\n   But we are not updating h0 and c0 for the next layer? The next layer uses the same initial states as the first layer? That is wrong.\n\n   We must update the initial states for the next layer to be the final states of this layer.\n\n   However, note: the bidirectional_lstm_triton returns the final states in `(hn, cn)`. We should use them for the next layer.\n\n   But the next layer has two directions, so we need to set:\n\n        h0[layer*2] = hn[0]   # forward final state\n        h0[layer*2+1] = hn[1]   # backward final state\n        similarly for c0.\n\n   But the current code does not do that.\n\n   We must change the ModelNew.forward to update the initial states for the next layer.\n\n   We do:\n\n        for layer in range(self.num_layers):\n            weight_idx = layer * 2\n            h0_forward = h0[layer*2]\n            c0_forward = c0[layer*2]\n            h0_backward = h0[layer*2+1]\n            c0_backward = c0[layer*2+1]\n\n            out, (hn_layer, cn_layer) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0_forward, c0_forward, h0_backward, c0_backward\n            )\n\n            # Update the initial state for the next layer to be the final state of this layer\n            if layer < self.num_layers - 1:\n                # We are going to use the final states as the initial states for the next layer\n                h0[(layer+1)*2] = hn_layer[0]   # hn_layer: [2, batch_size, hidden_size]\n                h0[(layer+1)*2+1] = hn_layer[1]\n                c0[(layer+1)*2] = cn_layer[0]\n                c0[(layer+1)*2+1] = cn_layer[1]\n\n            x = out   # for next layer\n\n   But note: the initial states for the next layer are provided by the user? Or should they be the final states of the previous layer? In an LSTM, the initial state for the next layer is the final state of the previous layer.\n\n   So we do the above.\n\n   However, the initial states `h0` and `c0` are passed by the user? In our case, they are initialized to zeros. We are overwriting them.\n\n   This is acceptable.\n\n   But note: the `h0` and `c0` are of shape (num_layers * 2, batch_size, hidden_size). We are updating the next layer's initial state.\n\n   We'll do that.\n\n   Given the complexity, we are making significant changes.\n\n   We hope this will fix the correctness.\n\n   We are to output the entire code block.\n\n   Let's write the new code.\n\n   IMPORTANT: We are only allowed to output the EVOLVE-BLOCK.\n\n   We'll write the new kernel and the modified bidirectional_lstm_triton and ModelNew.forward.\n\n   We note: the kernel is not optimized, but we are at correctness.\n\n   We'll try.\n\n   If it's too slow, we can optimize later.\n\n   We are to replace the current code in the EVOLVE-BLOCK.\n\n   We write:\n</think>\nThe current implementation of the Triton LSTM kernel was simplified to just copying input data and zeroing state outputs, which doesn't perform any actual LSTM computations. The rewrite introduces a complete LSTM kernel implementation that properly calculates all LSTM gates (input, forget, cell, output) and state updates. Key improvements include:\n\n1. Added proper LSTM computations with gate activations\n2. Implemented both forward and backward passes for bidirectional processing\n3. Added state initialization and final state storage\n4. Fixed initial state handling for bidirectional layers\n5. Maintained the same input/output interface while fixing functionality\n\nThe new implementation:\n- Computes input-hidden and hidden-hidden transformations\n- Applies sigmoid/tanh activations to LSTM gates\n- Updates cell and hidden states properly\n- Handles both forward and backward directions\n- Processes all layers with state passing between layers\n\nHere's the complete rewritten implementation:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_forward_kernel(\n    x_ptr, output_ptr, h_ptr, c_ptr,\n    weight_ih_ptr, weight_hh_ptr, bias_ih_ptr, bias_hh_ptr,\n    input_size: tl.constexpr, hidden_size: tl.constexpr,\n    seq_length: tl.constexpr, batch_size: tl.constexpr\n):\n    pid = tl.program_id(0)\n    \n    # Initialize state for this sequence\n    h_prev = tl.zeros((hidden_size,), dtype=tl.float32)\n    c_prev = tl.zeros((hidden_size,), dtype=tl.float32)\n    \n    # Iterate over sequence steps\n    for step in range(seq_length):\n        # Load input for current timestep\n        x_offset = pid * seq_length * input_size + step * input_size\n        x_t = tl.load(x_ptr + x_offset + tl.arange(0, input_size))\n        \n        # Compute gates\n        gates = tl.zeros((4 * hidden_size,), dtype=tl.float32)\n        \n        # Input-hidden transformation\n        for j in range(4 * hidden_size):\n            w_ih_row = tl.load(weight_ih_ptr + j * input_size + tl.arange(0, input_size))\n            gates = tl.store(gates, j, tl.sum(w_ih_row * x_t))\n            gates = tl.store(gates, j, gates[j] + tl.load(bias_ih_ptr + j))\n            \n        # Hidden-hidden transformation\n        for j in range(4 * hidden_size):\n            w_hh_row = tl.load(weight_hh_ptr + j * hidden_size + tl.arange(0, hidden_size))\n            gates = tl.store(gates, j, gates[j] + tl.sum(w_hh_row * h_prev))\n            gates = tl.store(gates, j, gates[j] + tl.load(bias_hh_ptr + j))\n        \n        # Split gates and apply activations\n        i_gate = tl.sigmoid(gates[0:hidden_size])\n        f_gate = tl.sigmoid(gates[hidden_size:2*hidden_size])\n        g_gate = tl.tanh(gates[2*hidden_size:3*hidden_size])\n        o_gate = tl.sigmoid(gates[3*hidden_size:4*hidden_size])\n        \n        # Update cell and hidden states\n        c_cur = f_gate * c_prev + i_gate * g_gate\n        h_cur = o_gate * tl.tanh(c_cur)\n        \n        # Store output\n        out_offset = pid * seq_length * hidden_size + step * hidden_size\n        tl.store(output_ptr + out_offset + tl.arange(0, hidden_size), h_cur)\n        \n        # Update state for next timestep\n        h_prev = h_cur\n        c_prev = c_cur\n    \n    # Store final state\n    tl.store(h_ptr + pid * hidden_size + tl.arange(0, hidden_size), h_cur)\n    tl.store(c_ptr + pid * hidden_size + tl.arange(0, hidden_size), c_cur)\n\ndef bidirectional_lstm_triton(x, weight_ih, weight_hh, bias_ih, bias_hh, \n                              h0_forward, c0_forward, h0_backward, c0_backward):\n    batch_size, seq_length, input_size = x.shape\n    hidden_size = weight_ih.shape[0] // 4\n    \n    # Process forward direction\n    output_forward = torch.empty((batch_size, seq_length, hidden_size), \n                                device=x.device, dtype=x.dtype)\n    grid = (batch_size,)\n    lstm_forward_kernel[grid](\n        x.contiguous().view(-1), output_forward.view(-1), \n        h0_forward, c0_forward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size\n    )\n    \n    # Process backward direction\n    x_reversed = torch.flip(x, [1])\n    output_backward = torch.empty((batch_size, seq_length, hidden_size), \n                                 device=x.device, dtype=x.dtype)\n    lstm_forward_kernel[grid](\n        x_reversed.contiguous().view(-1), output_backward.view(-1), \n        h0_backward, c0_backward,\n        weight_ih, weight_hh, bias_ih, bias_hh,\n        input_size, hidden_size, seq_length, batch_size\n    )\n    output_backward = torch.flip(output_backward, [1])\n    \n    # Combine directions\n    output = torch.cat([output_forward, output_backward], dim=-1)\n    hn = torch.stack([h0_forward, h0_backward], dim=0)\n    cn = torch.stack([c0_forward, c0_backward], dim=0)\n    \n    return output, (hn, cn)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n        self.dropout = dropout\n        \n        # Create parameters for all layers\n        self.weights_ih = nn.ParameterList()\n        self.weights_hh = nn.ParameterList()\n        self.biases_ih = nn.ParameterList()\n        self.biases_hh = nn.ParameterList()\n        \n        for i in range(num_layers):\n            # Forward layer weights\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, \n                                                           input_size if i == 0 else hidden_size * 2)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            \n            # Backward layer weights\n            self.weights_ih.append(nn.Parameter(torch.randn(4 * hidden_size, \n                                                           input_size if i == 0 else hidden_size * 2)))\n            self.weights_hh.append(nn.Parameter(torch.randn(4 * hidden_size, hidden_size)))\n            self.biases_ih.append(nn.Parameter(torch.randn(4 * hidden_size)))\n            self.biases_hh.append(nn.Parameter(torch.randn(4 * hidden_size)))\n        \n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_length, _ = x.shape\n        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=x.device)\n        \n        # Process through all layers\n        for layer in range(self.num_layers):\n            # Get initial states for this layer\n            h0_forward = h0[layer * 2]\n            c0_forward = c0[layer * 2]\n            h0_backward = h0[layer * 2 + 1]\n            c0_backward = c0[layer * 2 + 1]\n            \n            # Get weights for this layer\n            weight_idx = layer * 2\n            out, (hn, cn) = bidirectional_lstm_triton(\n                x,\n                self.weights_ih[weight_idx], self.weights_hh[weight_idx],\n                self.biases_ih[weight_idx], self.biases_hh[weight_idx],\n                h0_forward, c0_forward, h0_backward, c0_backward\n            )\n            \n            # Update input for next layer\n            x = out\n            \n            # Store final states for next layer\n            if layer < self.num_layers - 1:\n                h0[(layer + 1) * 2] = hn[0]\n                h0[(layer + 1) * 2 + 1] = hn[1]\n                c0[(layer + 1) * 2] = cn[0]\n                c0[(layer + 1) * 2 + 1] = cn[1]\n        \n        # Final output\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}