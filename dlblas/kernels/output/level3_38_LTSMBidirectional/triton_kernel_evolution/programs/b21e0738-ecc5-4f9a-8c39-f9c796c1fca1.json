{"id": "b21e0738-ecc5-4f9a-8c39-f9c796c1fca1", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef lstm_kernel(\n    x_ptr, hx_ptr, cx_ptr,\n    w_ih_ptr, w_hh_ptr, b_ih_ptr, b_hh_ptr,\n    h_ptr, c_ptr,\n    batch_size, input_size, hidden_size,\n    BLOCK_B: tl.constexpr, BLOCK_H: tl.constexpr\n):\n    pid = tl.program_id(0)\n    batch_offsets = pid * BLOCK_B + tl.arange(0, BLOCK_B)\n    hidden_offsets = tl.arange(0, BLOCK_H)\n    \n    batch_mask = batch_offsets < batch_size\n    hidden_mask = hidden_offsets < (4 * hidden_size)\n    \n    # Precompute pointer offsets\n    x_offset = batch_offsets[:, None] * input_size\n    hx_offset = batch_offsets[:, None] * hidden_size\n    cx_offset = batch_offsets[:, None] * hidden_size\n    h_offset = batch_offsets[:, None] * hidden_size\n    c_offset = batch_offsets[:, None] * hidden_size\n    \n    # Initialize accumulators\n    gates_ih = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    gates_hh = tl.zeros((BLOCK_B, 4 * hidden_size), dtype=tl.float32)\n    \n    # Vectorized memory access\n    for i in range(0, input_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < input_size)\n        \n        w = tl.load(w_ih_ptr + offsets[None, :], mask=mask, other=0.0)\n        x = tl.load(x_ptr + x_offset + offsets[None, :], mask=mask, other=0.0)\n        gates_ih += tl.dot(x, w)\n    \n    for i in range(0, hidden_size, BLOCK_H):\n        offsets = i + hidden_offsets\n        mask = hidden_mask & (offsets < hidden_size)\n        \n        w = tl.load(w_hh_ptr + offsets[None, :], mask=mask, other=0.0)\n        h = tl.load(hx_ptr + hx_offset + offsets[None, :], mask=mask, other=0.0)\n        gates_hh += tl.dot(h, w)\n    \n    # Add biases\n    gates_ih += tl.load(b_ih_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    gates_hh += tl.load(b_hh_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    \n    gates = gates_ih + gates_hh\n    \n    # Split gates with corrected math functions\n    i_gate = tl.sigmoid(gates[:, :hidden_size])\n    f_gate = tl.sigmoid(gates[:, hidden_size:2*hidden_size])\n    g_gate = tl.math.tanh(gates[:, 2*hidden_size:3*hidden_size])\n    o_gate = tl.sigmoid(gates[:, 3*hidden_size:4*hidden_size])\n    \n    # Load previous cell state\n    c_prev = tl.load(cx_ptr + cx_offset, mask=batch_mask[:, None], other=0.0)\n    \n    # Compute new states\n    c_next = f_gate * c_prev + i_gate * g_gate\n    h_next = o_gate * tl.math.tanh(c_next)\n    \n    # Store results\n    tl.store(h_ptr + h_offset, h_next, mask=batch_mask[:, None])\n    tl.store(c_ptr + c_offset, c_next, mask=batch_mask[:, None])\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):\n        super(ModelNew, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Create LSTM weights for each layer and direction\n        self.weights_ih = nn.ParameterList()\n        self.weights_hh = nn.ParameterList()\n        self.biases_ih = nn.ParameterList()\n        self.biases_hh = nn.ParameterList()\n        \n        for layer in range(num_layers):\n            layer_input_size = input_size if layer == 0 else 2 * hidden_size\n            for _ in range(2):  # Forward and backward directions\n                w_ih = nn.Parameter(torch.empty(4 * hidden_size, layer_input_size))\n                w_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n                b_ih = nn.Parameter(torch.empty(4 * hidden_size))\n                b_hh = nn.Parameter(torch.empty(4 * hidden_size))\n                \n                nn.init.xavier_uniform_(w_ih)\n                nn.init.xavier_uniform_(w_hh)\n                b_ih.data.fill_(0)\n                b_hh.data.fill_(0)\n                \n                self.weights_ih.append(w_ih)\n                self.weights_hh.append(w_hh)\n                self.biases_ih.append(b_ih)\n                self.biases_hh.append(b_hh)\n        \n        self.fc = nn.Linear(2 * hidden_size, output_size)\n    \n    def forward(self, x):\n        batch_size, seq_len, _ = x.shape\n        x_layer = x\n        \n        for layer in range(self.num_layers):\n            # Forward direction\n            h_forward = torch.zeros(batch_size, self.hidden_size, device=x.device)\n            c_forward = torch.zeros(batch_size, self.hidden_size, device=x.device)\n            outputs_forward = []\n            \n            for t in range(seq_len):\n                grid = lambda meta: (triton.cdiv(batch_size, meta['BLOCK_B']),)\n                idx = layer * 2  # Forward weights index\n                lstm_kernel[grid](\n                    x_layer[:, t, :], h_forward, c_forward,\n                    self.weights_ih[idx], self.weights_hh[idx], \n                    self.biases_ih[idx], self.biases_hh[idx],\n                    h_forward, c_forward,\n                    batch_size, x_layer.size(-1), self.hidden_size,\n                    BLOCK_B=32, BLOCK_H=64\n                )\n                outputs_forward.append(h_forward.clone())\n            \n            # Backward direction\n            h_backward = torch.zeros(batch_size, self.hidden_size, device=x.device)\n            c_backward = torch.zeros(batch_size, self.hidden_size, device=x.device)\n            outputs_backward = []\n            \n            for t in reversed(range(seq_len)):\n                grid = lambda meta: (triton.cdiv(batch_size, meta['BLOCK_B']),)\n                idx = layer * 2 + 1  # Backward weights index\n                lstm_kernel[grid](\n                    x_layer[:, t, :], h_backward, c_backward,\n                    self.weights_ih[idx], self.weights_hh[idx], \n                    self.biases_ih[idx], self.biases_hh[idx],\n                    h_backward, c_backward,\n                    batch_size, x_layer.size(-1), self.hidden_size,\n                    BLOCK_B=32, BLOCK_H=64\n                )\n                outputs_backward.insert(0, h_backward.clone())\n            \n            # Combine directions\n            outputs_forward = torch.stack(outputs_forward, dim=1)\n            outputs_backward = torch.stack(outputs_backward, dim=1)\n            x_layer = torch.cat([outputs_forward, outputs_backward], dim=-1)\n        \n        # Final output\n        return self.fc(x_layer[:, -1, :])\n\n# Test code\nbatch_size = 10\nsequence_length = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\noutput_size = 10\ndropout = 0.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, sequence_length, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers, output_size, dropout]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "c9f9bd10-0904-4e94-947d-c9b67767f98e", "generation": 5, "timestamp": 1754593813.129695, "iteration_found": 23, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_38_LTSMBidirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpm4mm0c_j.py\", line 118, in forward\n    lstm_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language.math' has no attribute 'tanh'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 42.6, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_38_LTSMBidirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpbywwgtl9.py\", line 101, in forward\n    lstm_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language' has no attribute 'tanh'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 42.6, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}