{"id": "5d90df92-1f1f-4cef-9236-9b5672520099", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_linear_max_mean_gelu(\n    x_ptr, w_ptr, bias_ptr, output_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wk, stride_wn,\n    stride_om,\n    BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= M:\n        return\n\n    # Pointers for current row of x\n    offs_m = pid\n    x_row_ptr = x_ptr + offs_m * stride_xm\n\n    # Initialize reduction accumulators\n    row_max = -float('inf')\n    row_sum = 0.0\n\n    # Process columns in blocks\n    for n_start in range(0, N, BLOCK_N):\n        n_size = min(BLOCK_N, N - n_start)\n        seg_val = tl.zeros((BLOCK_N,), dtype=tl.float32)\n\n        # Process inner dimension in blocks\n        for k_start in range(0, K, BLOCK_K):\n            k_size = min(BLOCK_K, K - k_start)\n\n            # Load input block\n            x_ptrs = x_row_ptr + k_start * stride_xk + tl.arange(0, BLOCK_K)\n            x_block = tl.load(\n                x_ptrs, \n                mask=tl.arange(0, BLOCK_K) < k_size,\n                other=0.0\n            ).to(tl.float32)\n\n            # Load weight block\n            w_ptrs = w_ptr + n_start * stride_wn + k_start * stride_wk\n            w_offs_n = tl.arange(0, BLOCK_N)\n            w_offs_k = tl.arange(0, BLOCK_K)\n            w_ptrs += w_offs_n[:, None] * stride_wn + w_offs_k[None, :] * stride_wk\n            w_block = tl.load(\n                w_ptrs,\n                mask=(w_offs_n[:, None] < n_size) & (w_offs_k[None, :] < k_size),\n                other=0.0\n            ).to(tl.float32)\n\n            # Compute partial dot product\n            seg_val += tl.sum(x_block[None, :] * w_block, axis=1)\n\n        # Add bias for this segment\n        bias_ptrs = bias_ptr + n_start + tl.arange(0, BLOCK_N)\n        bias_block = tl.load(\n            bias_ptrs, \n            mask=tl.arange(0, BLOCK_N) < n_size,\n            other=0.0\n        )\n        seg_val += bias_block\n\n        # Update reductions\n        seg_max = tl.max(seg_val, axis=0)\n        seg_sum = tl.sum(seg_val, axis=0)\n        row_max = tl.maximum(row_max, seg_max)\n        row_sum += seg_sum\n\n    # Compute final values\n    row_mean = row_sum / N\n    centered_val = row_max - row_mean\n    gelu_val = centered_val * 0.5 * (1.0 + tl.erf(centered_val * 0.70710678118))  # sqrt(0.5)\n    \n    # Store result\n    output_ptrs = output_ptr + offs_m * stride_om\n    tl.store(output_ptrs, gelu_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, max_dim):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.max_dim = max_dim\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        M, K = x.shape\n        N = self.out_features\n        output = torch.empty(M, 1, device=x.device, dtype=torch.float32)\n\n        grid = (M, )\n        fused_linear_max_mean_gelu[grid](\n            x, self.weight, self.bias, output,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(1), self.weight.stride(0),\n            output.stride(0),\n            BLOCK_N=256, BLOCK_K=64\n        )\n        return output\n\nbatch_size = 128\nin_features = 512\nout_features = 1024\nmax_dim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, max_dim]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "0997df53-64a6-423a-9b8b-01bc59ef952a", "generation": 3, "timestamp": 1754582087.0830784, "iteration_found": 10, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_80_Gemm_Max_Subtract_GELU", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "max_difference": ["2.532146", "2.809427", "2.437568", "2.569742", "2.589556"], "avg_difference": ["1.788269", "1.802059", "1.816688", "1.828515", "1.809855"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0827, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.954, "runtime_ms": 0.0867, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0827, "speed_up": 0.954, "custom_timing": 0.0867}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}