{"id": "1d9e315a-f3c7-4eff-9a4e-0565de60e800", "code": "@triton.jit\ndef fused_softmax_bias_scale_sigmoid(\n    x_ptr,\n    bias_ptr,\n    output_ptr,\n    scaling_factor,\n    B, C, H, W,\n    stride_b, stride_c, stride_h, stride_w,\n    BLOCK_SIZE_C: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr\n):\n    pid_b = tl.program_id(0)\n    pid_hm = tl.program_id(1)   # block index for height\n    pid_wm = tl.program_id(2)   # block index for width\n\n    # spatial offsets\n    offs_h = pid_hm * BLOCK_H + tl.arange(0, BLOCK_H)\n    offs_w = pid_wm * BLOCK_W + tl.arange(0, BLOCK_W)\n    offs_c = tl.arange(0, BLOCK_SIZE_C)   # channel offsets\n\n    # create masks for boundaries\n    mask_h = offs_h < H\n    mask_w = offs_w < W\n    mask_c = offs_c < C\n    # combine masks: for the block, we have [BLOCK_H, BLOCK_W, BLOCK_SIZE_C]\n    mask = mask_h[:, None, None] & mask_w[None, :, None] & mask_c[None, None, :]\n\n    # base pointer for the batch\n    base = pid_b * stride_b\n    # pointers for the entire block: [BLOCK_H, BLOCK_W, BLOCK_SIZE_C]\n    x_ptrs = x_ptr + base + \\\n              offs_h[:, None, None] * stride_h + \\\n              offs_w[None, :, None] * stride_w + \\\n              offs_c[None, None, :] * stride_c\n\n    # load the block\n    x_block = tl.load(x_ptrs, mask=mask, other=float('-inf'))\n\n    # softmax: reduce over channel dimension (axis=2)\n    max_vals = tl.max(x_block, axis=2)   # [BLOCK_H, BLOCK_W]\n    x_block = x_block - max_vals[:, :, None]\n    x_block = tl.exp(x_block)\n    sum_vals = tl.sum(x_block, axis=2)   # [BLOCK_H, BLOCK_W]\n    softmax_out = x_block / sum_vals[:, :, None]\n\n    # load bias: [BLOCK_SIZE_C]\n    bias = tl.load(bias_ptr + offs_c, mask=mask_c, other=0.0)\n\n    # add bias, scale, and apply sigmoid\n    out_vals = softmax_out + bias[None, None, :]\n    out_vals = out_vals * scaling_factor\n    out_vals = tl.sigmoid(out_vals)\n\n    # store the block\n    output_ptrs = output_ptr + base + \\\n                  offs_h[:, None, None] * stride_h + \\\n                  offs_w[None, :, None] * stride_w + \\\n                  offs_c[None, None, :] * stride_c\n    tl.store(output_ptrs, out_vals, mask=mask)", "language": "python", "parent_id": "4d06acec-326a-4d4e-ada5-3d5fe89e530e", "generation": 2, "timestamp": 1754591541.4111223, "iteration_found": 27, "metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.121, "runtime_ms": 0.793, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0962, "speed_up": 0.121, "custom_timing": 0.793}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}