{"id": "9c3c0235-a430-4832-99b1-0df2a9ed05df", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _conv2d_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    y_ptr,\n    stride_h,\n    stride_w,\n    padding_h,\n    padding_w,\n    dilation_h,\n    dilation_w,\n    in_channels,\n    out_channels,\n    height,\n    width,\n    kernel_h,\n    kernel_w,\n    height_out,\n    width_out,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n):\n    # Program ID mapping\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    pid_block = tl.program_id(2)\n    \n    # Compute spatial block indices\n    num_blocks_w = tl.cdiv(width_out, BLOCK_W)\n    block_h = pid_block // num_blocks_w\n    block_w = pid_block % num_blocks_w\n    \n    # Starting indices for output block\n    oh_start = block_h * BLOCK_H\n    ow_start = block_w * BLOCK_W\n    \n    # Output coordinates within block\n    oh = oh_start + tl.arange(0, BLOCK_H)\n    ow = ow_start + tl.arange(0, BLOCK_W)\n    \n    # Masks for valid output positions\n    oh_mask = (oh < height_out)\n    ow_mask = (ow < width_out)\n    \n    # Accumulator initialization\n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    # Precompute tensor strides\n    x_batch_stride = in_channels * height * width\n    x_channel_stride = height * width\n    x_h_stride = width\n    x_w_stride = 1\n    \n    w_outc_stride = in_channels * kernel_h * kernel_w\n    w_inc_stride = kernel_h * kernel_w\n    w_h_stride = kernel_w\n    w_w_stride = 1\n    \n    # Main computation loop\n    for ic in range(in_channels):\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                # Compute input positions\n                ih = oh * stride_h + kh * dilation_h - padding_h\n                iw = ow * stride_w + kw * dilation_w - padding_w\n                \n                # Boundary checks\n                ih_mask = (ih >= 0) & (ih < height)\n                iw_mask = (iw >= 0) & (iw < width)\n                mask = oh_mask[:, None] & ow_mask[None, :] & ih_mask[:, None] & iw_mask[None, :]\n                \n                # Compute input offsets\n                x_offsets = pid_b * x_batch_stride + ic * x_channel_stride + ih[:, None] * x_h_stride + iw[None, :] * x_w_stride\n                x_val = tl.load(x_ptr + x_offsets, mask=mask, other=0.0)\n                \n                # Compute weight offset\n                w_offset = pid_oc * w_outc_stride + ic * w_inc_stride + kh * w_h_stride + kw * w_w_stride\n                w_val = tl.load(w_ptr + w_offset)\n                \n                # Accumulate\n                acc += x_val * w_val\n    \n    # Add bias if present\n    if b_ptr is not None:\n        bias = tl.load(b_ptr + pid_oc)\n        acc += bias\n    \n    # Compute output offsets\n    y_batch_stride = out_channels * height_out * width_out\n    y_channel_stride = height_out * width_out\n    y_h_stride = width_out\n    y_w_stride = 1\n    \n    y_offsets = pid_b * y_batch_stride + pid_oc * y_channel_stride + oh[:, None] * y_h_stride + ow[None, :] * y_w_stride\n    \n    # Store results\n    tl.store(y_ptr + y_offsets, acc, mask=oh_mask[:, None] & ow_mask[None, :])\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: int = 1, padding: tuple = (0, 0), dilation: tuple = (1, 1), bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        \n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size[0], kernel_size[1]))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n            \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Ensure contiguous tensors\n        x = x.contiguous()\n        weight = self.weight.contiguous()\n        \n        batch_size, _, height, width = x.shape\n        kernel_h, kernel_w = self.kernel_size\n        padding_h, padding_w = self.padding\n        dilation_h, dilation_w = self.dilation\n        \n        # Calculate output dimensions\n        height_out = (height + 2 * padding_h - dilation_h * (kernel_h - 1) - 1) // self.stride + 1\n        width_out = (width + 2 * padding_w - dilation_w * (kernel_w - 1) - 1) // self.stride + 1\n        \n        # Create output tensor\n        y = torch.empty(batch_size, self.out_channels, height_out, width_out, \n                        device=x.device, dtype=x.dtype)\n        \n        # Block configuration\n        BLOCK_H, BLOCK_W = 16, 16\n        num_blocks_h = (height_out + BLOCK_H - 1) // BLOCK_H\n        num_blocks_w = (width_out + BLOCK_W - 1) // BLOCK_W\n        num_blocks = num_blocks_h * num_blocks_w\n        \n        # Kernel grid\n        grid = (batch_size, self.out_channels, num_blocks)\n        \n        # Launch kernel\n        _conv2d_kernel[grid](\n            x, weight, self.bias, y,\n            self.stride, self.stride,\n            padding_h, padding_w,\n            dilation_h, dilation_w,\n            self.in_channels, self.out_channels,\n            height, width,\n            kernel_h, kernel_w,\n            height_out, width_out,\n            BLOCK_H, BLOCK_W\n        )\n        return y\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5) # Asymmetric kernel\nwidth = 256\nheight = 256\nstride = 1\npadding = (1, 2) # Asymmetric padding\ndilation = (2, 1) # Asymmetric dilation\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "6e20edaa-3ad6-4731-be40-34ea157b6a4e", "generation": 3, "timestamp": 1754649623.994793, "iteration_found": 26, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.021, "runtime_ms": 2.06, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.044, "speed_up": 0.021, "custom_timing": 2.06}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.0, "runtime_ms": 200.0, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.044, "speed_up": 0.0, "custom_timing": 200.0}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}