{"id": "9ff89801-20dc-4674-b6b9-e69a37e293ef", "code": "import math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _conv2d_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    y_ptr,\n    stride_h,\n    stride_w,\n    padding_h,\n    padding_w,\n    dilation_h,\n    dilation_w,\n    in_channels,\n    out_channels,\n    height,\n    width,\n    kernel_h,\n    kernel_w,\n    height_out,\n    width_out,\n    BLOCK_IC: tl.constexpr,\n    BLOCK_OC: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_oc_block = tl.program_id(1)\n    pid_oh_ow = tl.program_id(2)\n    \n    oh = pid_oh_ow // width_out\n    ow = pid_oh_ow % width_out\n    \n    # Create block indices for output channels\n    oc_block_idx = pid_oc_block * BLOCK_OC + tl.arange(0, BLOCK_OC)\n    oc_mask = oc_block_idx < out_channels\n    \n    # Initialize accumulator vector for output channel block\n    acc = tl.zeros((BLOCK_OC,), dtype=tl.float32)\n    \n    # Precompute some strides and constants\n    x_stride_channel = height * width\n    w_stride_channel = kernel_h * kernel_w\n    w_stride_kernel = 1  # because we are adding kh * kernel_w + kw\n    \n    # We'll loop over kernel positions first, then over input channel blocks\n    for kh in tl.static_range(kernel_h):\n        for kw in tl.static_range(kernel_w):\n            ih = oh * stride_h + kh * dilation_h - padding_h\n            iw = ow * stride_w + kw * dilation_w - padding_w\n            \n            # Check if the current kernel position is within the input image bounds\n            in_bounds = (ih >= 0) & (ih < height) & (iw >= 0) & (iw < width)\n            # Base pointer for the input for this batch and spatial location (ih, iw) and channel 0\n            if in_bounds:\n                x_ptr_spatial = x_ptr + pid_b * in_channels * x_stride_channel + ih * width + iw\n            else:\n                x_ptr_spatial = 0  # will use mask to set to zero\n            \n            # Base pointer for the weights for this kernel position and current output channel block\n            w_ptr_kernel = w_ptr + (oc_block_idx[:, None] * in_channels * w_stride_channel) + (kh * kernel_w + kw)\n            \n            for ic_block_start in range(0, in_channels, BLOCK_IC):\n                ic_offsets = ic_block_start + tl.arange(0, BLOCK_IC)\n                ic_mask = ic_offsets < in_channels\n                \n                # Load input block: for the current input channel block and spatial location\n                if in_bounds:\n                    # Input is stored as [batch, channels, height, width]\n                    # So to get to a given channel, we do: channel_index * x_stride_channel\n                    x_vals = tl.load(x_ptr_spatial + ic_offsets * x_stride_channel, mask=ic_mask, other=0.0)\n                else:\n                    x_vals = tl.zeros((BLOCK_IC,), dtype=tl.float32)\n                \n                # Load weight block: for the current kernel position, current output channel block, and current input channel block\n                # Weights are stored as [out_channels, in_channels, kernel_h, kernel_w]\n                # So for a given output channel and input channel, the weight is at [oc, ic, kh, kw]\n                # We have a base pointer per output channel and kernel position, then we add the input channel offset * w_stride_channel\n                w_vals = tl.load(w_ptr_kernel + ic_offsets[None, :] * w_stride_channel, mask=oc_mask[:, None] & ic_mask[None, :], other=0.0)\n                \n                # Accumulate: w_vals is [BLOCK_OC, BLOCK_IC], x_vals is [BLOCK_IC]\n                # We do: for each output channel, sum over input channels: w_vals[oc, :] * x_vals[:]\n                acc += tl.sum(w_vals * x_vals[None, :], axis=1)\n    \n    # Add bias if present\n    if b_ptr is not None:\n        b_vals = tl.load(b_ptr + oc_block_idx, mask=oc_mask, other=0.0)\n        acc += b_vals\n    \n    # Calculate output position and store results\n    y_index = pid_b * out_channels * height_out * width_out + \\\n             oc_block_idx * height_out * width_out + oh * width_out + ow\n    tl.store(y_ptr + y_index, acc, mask=oc_mask)\n\n# The rest of the code (ModelNew and test) remains the same.", "language": "python", "parent_id": "d4b18095-fbf5-4df7-9526-b8d012c76584", "generation": 4, "timestamp": 1754648476.6401677, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.149, "runtime_ms": 0.295, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.044, "speed_up": 0.149, "custom_timing": 0.295}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.002, "runtime_ms": 22.6, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.044, "speed_up": 0.002, "custom_timing": 22.6}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}