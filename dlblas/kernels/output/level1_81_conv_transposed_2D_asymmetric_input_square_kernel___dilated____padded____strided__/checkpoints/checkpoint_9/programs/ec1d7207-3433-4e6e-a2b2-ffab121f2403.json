{"id": "ec1d7207-3433-4e6e-a2b2-ffab121f2403", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef triton_conv_transpose2d(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    stride, padding, dilation,\n    B, IC, OC, H_in, W_in, H_out, W_out, kernel_size,\n    stride_x, stride_w, stride_out,\n    BLOCK_IC: tl.constexpr\n):\n    pid_b_oc = tl.program_id(0)\n    pid_oh = tl.program_id(1)\n    pid_ow = tl.program_id(2)\n    \n    batch_idx = pid_b_oc // OC\n    oc_idx = pid_b_oc % OC\n    acc = 0.0\n    \n    for kh in range(kernel_size):\n        for kw in range(kernel_size):\n            ih0 = pid_oh + padding - kh * dilation\n            iw0 = pid_ow + padding - kw * dilation\n            \n            # Check if coordinates are valid and divisible by stride\n            if (ih0 % stride == 0) and (iw0 % stride == 0):\n                ih = ih0 // stride\n                iw = iw0 // stride\n                \n                # Check spatial boundaries\n                if (ih >= 0) and (ih < H_in) and (iw >= 0) and (iw < W_in):\n                    x_offset = batch_idx * stride_x[0] + ih * stride_x[2] + iw * stride_x[3]\n                    weight_offset = kh * stride_w[2] + kw * stride_w[3] + oc_idx * stride_w[1]\n                    \n                    for ic_block in range(0, IC, BLOCK_IC):\n                        ic_offsets = ic_block + tl.arange(0, BLOCK_IC)\n                        mask = ic_offsets < IC\n                        \n                        # Vectorized loads\n                        x_vec = tl.load(\n                            x_ptr + x_offset + ic_offsets * stride_x[1],\n                            mask=mask,\n                            other=0.0\n                        )\n                        w_vec = tl.load(\n                            weight_ptr + weight_offset + ic_offsets * stride_w[0],\n                            mask=mask,\n                            other=0.0\n                        )\n                        acc += tl.sum(x_vec * w_vec)\n    \n    # Add bias if present\n    if bias_ptr is not None:\n        acc += tl.load(bias_ptr + oc_idx)\n    \n    # Store result\n    out_offset = (\n        batch_idx * stride_out[0] + \n        oc_idx * stride_out[1] + \n        pid_oh * stride_out[2] + \n        pid_ow * stride_out[3]\n    )\n    tl.store(output_ptr + out_offset, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, \n                 stride: int = 1, padding: int = 0, dilation: int = 1, \n                 bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        \n        self.weight = nn.Parameter(\n            torch.empty(in_channels, out_channels, kernel_size, kernel_size)\n        )\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if bias:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, IC, H_in, W_in = x.shape\n        H_out = (H_in - 1) * self.stride - 2 * self.padding + \\\n                self.dilation * (self.kernel_size - 1) + 1\n        W_out = (W_in - 1) * self.stride - 2 * self.padding + \\\n                self.dilation * (self.kernel_size - 1) + 1\n        \n        output = torch.empty((B, self.out_channels, H_out, W_out), \n                            device=x.device, dtype=x.dtype)\n        \n        grid = (B * self.out_channels, H_out, W_out)\n        bias_ptr = self.bias if self.bias is not None else None\n        \n        triton_conv_transpose2d[grid](\n            x, self.weight, bias_ptr, output,\n            self.stride, self.padding, self.dilation,\n            B, IC, self.out_channels, H_in, W_in, H_out, W_out, self.kernel_size,\n            x.stride(), self.weight.stride(), output.stride(),\n            BLOCK_IC=32\n        )\n        \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = 3\nheight_in = 64\nwidth_in = 128\nstride = 5\npadding = 1\ndilation = 2\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "2100e0f9-ea57-4d72-95e9-9aafe10e3ffc", "generation": 2, "timestamp": 1754649685.320434, "iteration_found": 11, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.0, "runtime_ms": 590.0, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.06, "speed_up": 0.0, "custom_timing": 590.0}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 0}, "artifacts_json": null, "artifact_dir": null}