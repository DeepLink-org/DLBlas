{"id": "b9bade7c-05b7-4682-a0af-dd3a6c5e533b", "code": "\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs a 3D transposed convolution operation with asymmetric input and kernel, and optional stride.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple of ints): Size of the convolution kernel in the form (kernel_size_depth, kernel_size_height, kernel_size_width).\n        stride (tuple of ints, optional): Stride of the convolution in the form (stride_depth, stride_height, stride_width). Defaults to (1, 1, 1).\n        padding (tuple of ints, optional): Padding applied to the input in the form (padding_depth, padding_height, padding_width). Defaults to (0, 0, 0).\n        output_padding (tuple of ints, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 3D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose3d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5, 7)\ndepth = 16\nheight = 32\nwidth = 64\nstride = (2, 2, 2)\npadding = (1, 2, 3)\noutput_padding = (1, 1, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, depth, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, groups]\n# =================== EVOLVE-BLOCK-END ===================\n", "language": "python", "parent_id": null, "generation": 0, "timestamp": 1754647902.6418533, "iteration_found": 0, "metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 25.5, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0744, "speed_up": 0.003, "custom_timing": 25.5}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 0}, "artifacts_json": null, "artifact_dir": null}