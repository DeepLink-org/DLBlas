{"id": "da798bc2-e342-48d3-8960-9cc5c2b0a553", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef argmax_kernel(\n    x_ptr,\n    output_ptr,\n    d0,\n    d1,\n    d2,\n    stride0,\n    stride1,\n    stride2,\n    reduction_dim: tl.constexpr,\n    row_length: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    \n    if reduction_dim == 0:\n        i1 = pid // d2\n        i2 = pid % d2\n        base = i1 * stride1 + i2 * stride2\n        step = stride0\n    elif reduction_dim == 1:\n        i0 = pid // d2\n        i2 = pid % d2\n        base = i0 * stride0 + i2 * stride2\n        step = stride1\n    else:\n        i0 = pid // d1\n        i1 = pid % d1\n        base = i0 * stride0 + i1 * stride1\n        step = stride2\n\n    max_val = tl.load(x_ptr + base)\n    max_index = 0\n    for i in range(1, row_length):\n        offset = base + i * step\n        val = tl.load(x_ptr + offset, eviction_policy=\"evict_first\")\n        if val > max_val:\n            max_val = val\n            max_index = i\n\n    tl.store(output_ptr + pid, max_index)\n\nclass ModelNew(nn.Module):\n    def __init__(self, dim: int):\n        super(ModelNew, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if x.dim() != 3 or self.dim not in [0, 1, 2]:\n            return torch.argmax(x, dim=self.dim)\n            \n        d0, d1, d2 = x.shape\n        strides = x.stride()\n        \n        if self.dim == 0:\n            output_shape = (d1, d2)\n            row_length = d0\n        elif self.dim == 1:\n            output_shape = (d0, d2)\n            row_length = d1\n        else:\n            output_shape = (d0, d1)\n            row_length = d2\n            \n        output = torch.empty(output_shape, device=x.device, dtype=torch.int64)\n        grid = (output.numel(),)\n        \n        argmax_kernel[grid](\n            x, output, d0, d1, d2, \n            strides[0], strides[1], strides[2], \n            reduction_dim=self.dim,\n            row_length=row_length\n        )\n        return output\n\nbatch_size = 16\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "716aa0fb-f408-4bca-9344-136b85c8b48e", "generation": 1, "timestamp": 1754642419.783668, "iteration_found": 7, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.274, "runtime_ms": 0.0797, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0218, "speed_up": 0.274, "custom_timing": 0.0797}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0241, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0218, "speed_up": 0.905, "custom_timing": 0.0241}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}