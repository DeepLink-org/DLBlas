{"id": "6afcf404-25ca-4114-a559-0aa866fa94e4", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef softmax_kernel(\n    output_ptr,\n    input_ptr,\n    n_channels,\n    n_depth,\n    n_height,\n    n_width,\n    stride_batch,\n    stride_channel,\n    stride_depth,\n    stride_height,\n    stride_width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_d = tl.program_id(1)\n    pid_s_chunk = tl.program_id(2)\n    \n    spatial_size = n_height * n_width\n    spatial_start = pid_s_chunk * 32\n    \n    for s_index in range(32):\n        spatial_offset = spatial_start + s_index\n        if spatial_offset < spatial_size:\n            pid_h = spatial_offset // n_width\n            pid_w = spatial_offset % n_width\n            \n            # Base pointer calculation\n            spatial_ptr = pid_h * stride_height + pid_w * stride_width\n            base = pid_b * stride_batch + pid_d * stride_depth + spatial_ptr\n            \n            # Vectorized channel access\n            offs_c = tl.arange(0, BLOCK_SIZE)\n            c_mask = offs_c < n_channels\n            input_ptrs = input_ptr + base + offs_c * stride_channel\n            channel_vals = tl.load(input_ptrs, mask=c_mask, other=-float('inf'))\n            \n            # Optimized softmax computation\n            max_val = tl.max(channel_vals, axis=0)\n            exp_vals = tl.exp(channel_vals - max_val)\n            norm = tl.sum(exp_vals, axis=0)\n            softmax_vals = exp_vals / norm\n            \n            # Vectorized store\n            output_ptrs = output_ptr + base + offs_c * stride_channel\n            tl.store(output_ptrs, softmax_vals, mask=c_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size)\n        self.pool1 = nn.MaxPool3d(pool_kernel_size)\n        self.pool2 = nn.MaxPool3d(pool_kernel_size)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        \n        B, C, D, H, W = x.shape\n        output = torch.empty_like(x)\n        spatial_size = H * W\n        grid = (B, D, triton.cdiv(spatial_size, 32))\n        \n        # Optimized block size selection for H100\n        BLOCK_SIZE = min(triton.next_power_of_2(C), 64)\n        \n        softmax_kernel[grid](\n            output, x,\n            C, D, H, W,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        x = output\n        \n        x = self.pool1(x)\n        x = self.pool2(x)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\npool_kernel_size = 2\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, pool_kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a631c3a5-8bd1-4ccd-91a0-a142571acde5", "generation": 4, "timestamp": 1754586064.7015946, "iteration_found": 28, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.067, "runtime_ms": 1.22, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0812, "speed_up": 0.067, "custom_timing": 1.22}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.05, "runtime_ms": 1.63, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0812, "speed_up": 0.05, "custom_timing": 1.63}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}