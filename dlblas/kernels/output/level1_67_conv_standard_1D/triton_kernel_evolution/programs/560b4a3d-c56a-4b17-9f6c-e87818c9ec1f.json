{"id": "560b4a3d-c56a-4b17-9f6c-e87818c9ec1f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit(num_warps=8)\ndef conv1d_kernel(\n    x_ptr, \n    weight_ptr, \n    output_ptr,\n    batch_size, \n    in_channels, \n    length, \n    out_channels, \n    kernel_size,\n    stride,\n    padding,\n    dilation,\n    groups,\n    stride_x_batch, stride_x_in, stride_x_len,\n    stride_weight_oc, stride_weight_ic, stride_weight_k,\n    stride_output_batch, stride_output_oc, stride_output_len,\n    output_length,\n    BLOCK_IC: tl.constexpr,\n    BLOCK_OC: tl.constexpr,\n    BLOCK_OL: tl.constexpr,\n):\n    pid_b = tl.program_id(0)   # batch index\n    pid_oc = tl.program_id(1)  # output channel block index\n    pid_ol = tl.program_id(2)  # output position block index\n    \n    # Compute output channel and position offsets\n    oc_offsets = pid_oc * BLOCK_OC + tl.arange(0, BLOCK_OC)\n    ol_offsets = pid_ol * BLOCK_OL + tl.arange(0, BLOCK_OL)\n    \n    # Boundary masks\n    mask_oc = oc_offsets < out_channels\n    mask_ol = ol_offsets < output_length\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_OC, BLOCK_OL), dtype=tl.float32)\n    \n    # Loop over kernel positions\n    for k in range(kernel_size):\n        # Compute input positions for this kernel offset\n        input_positions = (ol_offsets * stride - padding) + k * dilation\n        mask_pos = (input_positions >= 0) & (input_positions < length)\n        \n        # Loop over input channels in blocks\n        for ic0 in range(0, in_channels, BLOCK_IC):\n            ic_offsets = ic0 + tl.arange(0, BLOCK_IC)\n            mask_ic = ic_offsets < in_channels\n            \n            # Load weight block: [BLOCK_OC, BLOCK_IC]\n            w_ptrs = weight_ptr + oc_offsets[:, None] * stride_weight_oc + \\\n                     ic_offsets[None, :] * stride_weight_ic + \\\n                     k * stride_weight_k\n            w = tl.load(w_ptrs, mask=mask_oc[:, None] & mask_ic[None, :], other=0.0)\n            \n            # Load input block: [BLOCK_IC, BLOCK_OL]\n            x_ptrs = x_ptr + pid_b * stride_x_batch + \\\n                     ic_offsets[:, None] * stride_x_in + \\\n                     input_positions[None, :] * stride_x_len\n            x_mask = mask_ic[:, None] & mask_pos[None, :] & mask_ol[None, :]\n            x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n            \n            # Accumulate matrix multiplication using tensor cores\n            acc += tl.dot(w, x, allow_tf32=True)\n    \n    # Store results\n    output_ptrs = output_ptr + pid_b * stride_output_batch + \\\n                 oc_offsets[:, None] * stride_output_oc + \\\n                 ol_offsets[None, :] * stride_output_len\n    tl.store(output_ptrs, acc, mask=mask_oc[:, None] & mask_ol[None, :])\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.groups = groups\n        \n        # Initialize weight\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, kernel_size))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        \n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n        else:\n            self.register_parameter('bias', None)\n            \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if self.groups != 1:\n            return nn.functional.conv1d(\n                x, self.weight, self.bias, self.stride, \n                self.padding, self.dilation, self.groups\n            )\n        \n        # Compute output shape\n        batch_size, _, length = x.shape\n        output_length = (length + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1) // self.stride + 1\n        output = torch.empty(batch_size, self.out_channels, output_length, device=x.device, dtype=x.dtype)\n        \n        # Get strides\n        stride_x_batch, stride_x_in, stride_x_len = x.stride()\n        stride_weight_oc, stride_weight_ic, stride_weight_k = self.weight.stride()\n        stride_output_batch, stride_output_oc, stride_output_len = output.stride()\n        \n        # Configure grid with tiling over output channels and positions\n        BLOCK_IC = 64  # Increased for tensor core efficiency\n        BLOCK_OC = 128 # Increased for better parallelism\n        BLOCK_OL = 64  # Increased for better cache utilization\n        \n        grid = (\n            batch_size,\n            triton.cdiv(self.out_channels, BLOCK_OC),\n            triton.cdiv(output_length, BLOCK_OL)\n        )\n        \n        conv1d_kernel[grid](\n            x, self.weight, output,\n            batch_size, self.in_channels, length, self.out_channels, self.kernel_size,\n            self.stride, self.padding, self.dilation, self.groups,\n            stride_x_batch, stride_x_in, stride_x_len,\n            stride_weight_oc, stride_weight_ic, stride_weight_k,\n            stride_output_batch, stride_output_oc, stride_output_len,\n            output_length,\n            BLOCK_IC, BLOCK_OC, BLOCK_OL\n        )\n        \n        # Add bias if needed\n        if self.bias is not None:\n            output += self.bias[:, None]\n            \n        return output\n\n# Test code\nimport math\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nlength = 512\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, length, device='cuda')\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "edf4aa5b-4fe7-4faa-9942-d6e0099c4cdf", "generation": 6, "timestamp": 1754988783.839263, "iteration_found": 26, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "", "exec_log": "[Child] \u7ed1\u5b9a GPU 7, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 7, in <module>\nTypeError: jit() got an unexpected keyword argument 'num_warps'\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.55, "runtime_ms": 0.0671, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0369, "speed_up": 0.55, "custom_timing": 0.0671}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}