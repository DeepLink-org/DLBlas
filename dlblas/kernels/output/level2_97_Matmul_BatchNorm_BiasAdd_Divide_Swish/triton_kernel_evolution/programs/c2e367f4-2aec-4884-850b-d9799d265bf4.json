{"id": "c2e367f4-2aec-4884-850b-d9799d265bf4", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 128, 'BLOCK_SIZE_FEATURE': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=8),\n    ],\n    key=['batch_size', 'out_features'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    batch_mask = batch_idx < batch_size\n    \n    # Preload model_bias once per program\n    model_bias = tl.load(model_bias_ptr)\n    \n    # Process features in blocks\n    for feature_block in range(0, out_features, BLOCK_SIZE_FEATURE):\n        feature_idx = feature_block + tl.arange(0, BLOCK_SIZE_FEATURE)\n        feature_mask = feature_idx < out_features\n        block_mask = batch_mask[:, None] & feature_mask[None, :]\n        \n        # Calculate offsets for linear_out access\n        lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n        linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n        \n        # Load batchnorm parameters\n        bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n        bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n        running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n        running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n        \n        # Optimized batchnorm using rsqrt\n        inv_std = tl.math.rsqrt(running_var + bn_eps)\n        scale = bn_weight * inv_std\n        shift = bn_bias - running_mean * scale\n        bn_out = linear_out * scale[None, :] + shift[None, :]\n        \n        # Fused operations\n        normalized = (bn_out + model_bias) / divide_value\n        swish_out = normalized * tl.sigmoid(normalized)\n        \n        # Store results\n        out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n        tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),)\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "efb5c072-c0ce-4711-8b49-285e115629c2", "generation": 3, "timestamp": 1754591689.8277605, "iteration_found": 27, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 20.89999999999999, "speed_up": 1.009, "runtime_ms": 0.109, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.11, "speed_up": 1.009, "custom_timing": 0.109}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 24.800000000000004, "speed_up": 1.048, "runtime_ms": 0.105, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.11, "speed_up": 1.048, "custom_timing": 0.105}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}