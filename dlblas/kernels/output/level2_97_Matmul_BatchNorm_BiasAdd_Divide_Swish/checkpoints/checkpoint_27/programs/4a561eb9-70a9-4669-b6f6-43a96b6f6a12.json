{"id": "4a561eb9-70a9-4669-b6f6-43a96b6f6a12", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 128}, num_warps=8),\n    ],\n    key=['batch_size', 'out_features'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Optimized batchnorm computation\n    inv_std = tl.math.rsqrt(running_var + bn_eps)\n    scale = bn_weight * inv_std\n    shift = bn_bias - running_mean * scale\n    bn_out = linear_out * scale[None, :] + shift[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "fdd90896-683c-4ad5-97d4-acda3233ab92", "generation": 2, "timestamp": 1754590646.9430625, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.917, "runtime_ms": 0.12, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.11, "speed_up": 0.917, "custom_timing": 0.12}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 21.89999999999999, "speed_up": 1.019, "runtime_ms": 0.108, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.11, "speed_up": 1.019, "custom_timing": 0.108}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 1.0000\n- score: 21.9000\n- speed_up: 1.0190\n- runtime_ms: 0.1080\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.019, 'custom_timing': 0.108}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 1.0000, runtime_ms: 0.1100, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.0, 'custom_timing': 0.11}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 21.9000, speed_up: 1.0190, runtime_ms: 0.1080, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.019, 'custom_timing': 0.108}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 24.8000, speed_up: 1.0480, runtime_ms: 0.1050, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.048, 'custom_timing': 0.105}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 24.8000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=32,\n                BLOCK_SIZE_FEATURE=128\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (24.8000), Performs well on speed_up (1.0480), Performs well on runtime_ms (0.1050), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.048, 'custom_timing': 0.105})\n\n\n### Program 2 (Score: 21.9000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=32,\n                BLOCK_SIZE_FEATURE=128\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (21.9000), Performs well on speed_up (1.0190), Performs well on runtime_ms (0.1080), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:3', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.019, 'custom_timing': 0.108})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            # Optimized block sizes for better GPU utilization\n            BLOCK_B = 8\n            BLOCK_F = 64\n            grid = (\n                triton.cdiv(batch_size, BLOCK_B),\n                triton.cdiv(linear_out.size(1), BLOCK_F)\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=BLOCK_B,\n                BLOCK_SIZE_FEATURE=BLOCK_F\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.1100), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.11, 'speed_up': 1.0, 'custom_timing': 0.11})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 128}, num_warps=8),\n    ],\n    key=['batch_size', 'out_features'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Optimized batchnorm computation\n    inv_std = tl.math.rsqrt(running_var + bn_eps)\n    scale = bn_weight * inv_std\n    shift = bn_bias - running_mean * scale\n    bn_out = linear_out * scale[None, :] + shift[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_post_linear_kernel(\n    x_ptr,\n    scale_ptr,\n    shift_ptr,\n    output_ptr,\n    bias_ptr,\n    divide_value,\n    n_cols,\n    stride_x,\n    stride_scale,\n    stride_shift,\n    stride_out,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_cols\n    \n    # Calculate pointers\n    x_row_ptr = x_ptr + row_idx * stride_x\n    out_row_ptr = output_ptr + row_idx * stride_out\n    \n    # Load data\n    x = tl.load(x_row_ptr + col_offsets, mask=mask, other=0.0)\n    scale = tl.load(scale_ptr + col_offsets, mask=mask, other=0.0)\n    shift = tl.load(shift_ptr + col_offsets, mask=mask, other=0.0)\n    bias_val = tl.load(bias_ptr)  # Scalar bias\n    \n    # Fused operations\n    y = x * scale + shift + bias_val\n    y = y / divide_value\n    sig_y = tl.sigmoid(y)\n    y = y * sig_y\n    \n    # Store result\n    tl.store(out_row_ptr + col_offsets, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        self.out_features = out_features\n        \n    def forward(self, x):\n        x = self.matmul(x)\n        \n        # Precompute BN scale/shift\n        if self.training:\n            mean = x.mean(dim=0)\n            var = x.var(dim=0, unbiased=False)\n            with torch.no_grad():\n                self.bn.running_mean = (1 - self.bn.momentum) * self.bn.running_mean + self.bn.momentum * mean\n                self.bn.running_var = (1 - self.bn.momentum) * self.bn.running_var + self.bn.momentum * var\n        else:\n            mean = self.bn.running_mean\n            var = self.bn.running_var\n            \n        inv_std = 1.0 / torch.sqrt(var + self.bn.eps)\n        scale = self.bn.weight * inv_std\n        shift = self.bn.bias - mean * scale\n        \n        # Prepare output tensor\n        output = torch.empty_like(x)\n        batch_size, n_cols = x.shape\n        \n        # Launch fused kernel\n        BLOCK_SIZE = 128\n        grid = (batch_size,)\n        _fused_post_linear_kernel[grid](\n            x, scale, shift, output, \n            self.bias, self.divide_value,\n            n_cols,\n            x.stride(0), scale.stride(0), shift.stride(0), output.stride(0),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 24.8000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=32,\n                BLOCK_SIZE_FEATURE=128\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    x_ptr, \n    weight_ptr, \n    total_scale_ptr, \n    total_shift_ptr, \n    output_ptr,\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    batch_size, \n    in_features, \n    out_features,\n    BLOCK_ROW: tl.constexpr,\n    BLOCK_FEATURE: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    row_start = pid_batch * BLOCK_ROW\n    feature_start = pid_feature * BLOCK_FEATURE\n    \n    row_offsets = row_start + tl.arange(0, BLOCK_ROW)\n    feature_offsets = feature_start + tl.arange(0, BLOCK_FEATURE)\n    \n    row_mask = row_offsets < batch_size\n    feature_mask = feature_offsets < out_features\n    \n    acc = tl.zeros((BLOCK_ROW, BLOCK_FEATURE), dtype=tl.float32)\n    \n    for k in range(0, in_features, BLOCK_K):\n        k_offsets = k + tl.arange(0, BLOCK_K)\n        k_mask = k_offsets < in_features\n        \n        # Load input block [BLOCK_ROW, BLOCK_K]\n        x_ptrs = x_ptr + row_offsets[:, None] * stride_x0 + k_offsets[None, :] * stride_x1\n        x_vals = tl.load(x_ptrs, mask=row_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        # Load weight block as [BLOCK_K, BLOCK_FEATURE] for correct matmul\n        w_ptrs = weight_ptr + k_offsets[:, None] * stride_w1 + feature_offsets[None, :] * stride_w0\n        w_vals = tl.load(w_ptrs, mask=k_mask[:, None] & feature_mask[None, :], other=0.0)\n        \n        # FP16 matrix multiplication with Tensor Core optimization\n        acc += tl.dot(x_vals, w_vals, allow_tf32=True, out_dtype=tl.float32)\n    \n    # Load scale/shift parameters\n    ts_ptrs = total_scale_ptr + feature_offsets\n    total_scale = tl.load(ts_ptrs, mask=feature_mask, other=0.0)\n    \n    tsh_ptrs = total_shift_ptr + feature_offsets\n    total_shift = tl.load(tsh_ptrs, mask=feature_mask, other=0.0)\n    \n    # Fused operations: scale, shift, swish\n    output_block = acc * total_scale[None, :] + total_shift[None, :]\n    output_block = output_block * tl.sigmoid(output_block)\n    \n    # Store results with coalesced writes\n    out_ptrs = output_ptr + row_offsets[:, None] * stride_out0 + feature_offsets[None, :] * stride_out1\n    tl.store(out_ptrs, output_block, mask=row_mask[:, None] & feature_mask[None, :])\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n\n    def forward(self, x):\n        with torch.no_grad():\n            # Precompute fused parameters\n            scale_bn = self.bn.weight / torch.sqrt(self.bn.running_var + self.bn.eps)\n            shift_bn = self.bn.bias - self.bn.running_mean * scale_bn\n            total_scale = scale_bn / self.divide_value\n            total_shift = (self.matmul.bias * scale_bn + shift_bn + self.bias) / self.divide_value\n\n        x = x.contiguous()\n        batch_size, _ = x.shape\n        output = torch.empty((batch_size, self.matmul.out_features), device=x.device, dtype=x.dtype)\n        \n        # Tuned grid configuration for H100\n        grid = lambda meta: (\n            triton.cdiv(batch_size, meta['BLOCK_ROW']), \n            triton.cdiv(self.matmul.out_features, meta['BLOCK_FEATURE'])\n        )\n        \n        fused_forward_kernel[grid](\n            x, \n            self.matmul.weight, \n            total_scale, \n            total_shift, \n            output,\n            x.stride(0), x.stride(1),\n            self.matmul.weight.stride(0), self.matmul.weight.stride(1),\n            output.stride(0), output.stride(1),\n            batch_size, \n            x.size(1), \n            self.matmul.out_features,\n            BLOCK_ROW=64, \n            BLOCK_FEATURE=64, \n            BLOCK_K=128\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_post_linear_kernel(\n    x_ptr,\n    scale_ptr,\n    shift_ptr,\n    output_ptr,\n    bias_ptr,\n    divide_value,\n    n_cols,\n    stride_x,\n    stride_scale,\n    stride_shift,\n    stride_out,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_cols\n    \n    # Calculate pointers\n    x_row_ptr = x_ptr + row_idx * stride_x\n    out_row_ptr = output_ptr + row_idx * stride_out\n    \n    # Load data\n    x = tl.load(x_row_ptr + col_offsets, mask=mask, other=0.0)\n    scale = tl.load(scale_ptr + col_offsets, mask=mask, other=0.0)\n    shift = tl.load(shift_ptr + col_offsets, mask=mask, other=0.0)\n    bias_val = tl.load(bias_ptr)  # Scalar bias\n    \n    # Fused operations\n    y = x * scale + shift + bias_val\n    y = y / divide_value\n    sig_y = tl.sigmoid(y)\n    y = y * sig_y\n    \n    # Store result\n    tl.store(out_row_ptr + col_offsets, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        self.out_features = out_features\n        \n    def forward(self, x):\n        x = self.matmul(x)\n        \n        # Precompute BN scale/shift\n        if self.training:\n            mean = x.mean(dim=0)\n            var = x.var(dim=0, unbiased=False)\n            with torch.no_grad():\n                self.bn.running_mean = (1 - self.bn.momentum) * self.bn.running_mean + self.bn.momentum * mean\n                self.bn.running_var = (1 - self.bn.momentum) * self.bn.running_var + self.bn.momentum * var\n        else:\n            mean = self.bn.running_mean\n            var = self.bn.running_var\n            \n        inv_std = 1.0 / torch.sqrt(var + self.bn.eps)\n        scale = self.bn.weight * inv_std\n        shift = self.bn.bias - mean * scale\n        \n        # Prepare output tensor\n        output = torch.empty_like(x)\n        batch_size, n_cols = x.shape\n        \n        # Launch fused kernel\n        BLOCK_SIZE = 128\n        grid = (batch_size,)\n        _fused_post_linear_kernel[grid](\n            x, scale, shift, output, \n            self.bias, self.divide_value,\n            n_cols,\n            x.stride(0), scale.stride(0), shift.stride(0), output.stride(0),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            # Optimized block sizes for better GPU utilization\n            BLOCK_B = 8\n            BLOCK_F = 64\n            grid = (\n                triton.cdiv(batch_size, BLOCK_B),\n                triton.cdiv(linear_out.size(1), BLOCK_F)\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=BLOCK_B,\n                BLOCK_SIZE_FEATURE=BLOCK_F\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 5 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 128}, num_warps=8),\n    ],\n    key=['batch_size', 'out_features'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Optimized batchnorm computation\n    inv_std = tl.math.rsqrt(running_var + bn_eps)\n    scale = bn_weight * inv_std\n    shift = bn_bias - running_mean * scale\n    bn_out = linear_out * scale[None, :] + shift[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Compute batchnorm\n    scale = bn_weight / tl.sqrt(running_var + bn_eps)\n    bn_out = (linear_out - running_mean[None, :]) * scale[None, :] + bn_bias[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n                BLOCK_SIZE_BATCH=32,\n                BLOCK_SIZE_FEATURE=128\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program and asked to improve its performance.\n The current program has a speedup of 1.019 (score 21.9) and we want to increase it.\n\n Observations:\n - The current Triton kernel uses a 2D grid: one dimension for batches and one for features.\n - The kernel loads a block of the linear output (of size BLOCK_SIZE_BATCH x BLOCK_SIZE_FEATURE) and then applies:\n      batchnorm, adding a bias, dividing by a constant, and then a swish activation.\n\n Areas for potential improvement:\n 1. The current kernel does not use any shared memory. We might consider using shared memory for the batchnorm parameters (scale and shift) to reduce redundant loads? However, note that the batchnorm parameters are per-feature and are reused across batches. But the current kernel loads them for each batch block. Since the feature block is of size BLOCK_SIZE_FEATURE, and we have multiple batch blocks, we could load the batchnorm parameters once per feature block and then reuse them for all batch blocks? However, the kernel is launched with both batch and feature blocks. So each program handles one batch block and one feature block. Therefore, we are loading the same batchnorm parameters for the same feature block multiple times (for different batch blocks). This is inefficient.\n\n 2. Alternatively, we can change the kernel to have a 1D grid over batches and then have each program handle a full row (or multiple rows) and then use a loop over features? But note: the feature dimension might be large (512 in the example) and we want to use the GPU's parallelism.\n\n 3. Another idea: use a different tiling strategy. Instead of having a 2D grid, we could have a 1D grid and then use vectorized operations. However, the batchnorm parameters are per feature, so we would still need to load them for each feature. But note that the current kernel already uses vectorization for the feature dimension.\n\n 4. We can try to optimize the computation of the batchnorm by using the reformulation: \n        bn_out = linear_out * scale[None, :] + shift[None, :]\n    where shift = bn_bias - running_mean * scale. This avoids one subtraction and one multiply-add. This is done in one of the diverse programs (D1). Let's adopt that.\n\n 5. The current kernel loads the model_bias (which is a scalar) for every block. We can load it once and then broadcast? Actually, it is a scalar, so we can load it once at the beginning of the kernel and then use it. But note: the kernel is launched with multiple programs. We cannot share it via shared memory across different blocks? Actually, each program can load it once and then use it for the entire block. Currently, we are loading it inside the block. But note that the model_bias is stored in a tensor of size (1,). So we are doing:\n        model_bias = tl.load(model_bias_ptr)\n    This loads a single value. That should be efficient.\n\n 6. We can try to use the fast math operations (like tl.math.rsqrt) for the inverse square root.\n\n 7. Another idea: use autotuning for the block sizes. The current program uses fixed block sizes (32 for batch and 128 for feature). We see in the diverse programs that autotuning can be applied. Also, the top-performing program (score 24.8) used the same fixed block sizes as the current one? Actually, the top program had the same kernel but with a speedup of 1.048. However, the current program is the same as the top program? Let me check:\n\n    The top program (score 24.8) has:\n        BLOCK_SIZE_BATCH=32, BLOCK_SIZE_FEATURE=128\n\n    The current program (score 21.9) also uses:\n        BLOCK_SIZE_BATCH=32, BLOCK_SIZE_FEATURE=128\n\n    So why the difference in performance? It might be due to the environment? But note the top program had a runtime of 0.105 ms and the current 0.108 ms.\n\n    Alternatively, the top program might have been run on a different device? The meta says the same hardware (NVIDIA L20Y) but different cuda device? \n\n    However, the current program is exactly the same as the top program? Actually, the top program and the current program are identical? \n\n    Let me compare the top program and the current:\n\n        The top program (Program 1) and the current program are the same.\n\n    Why then the score difference? The top program had a speedup of 1.048 and the current 1.019? \n\n    This suggests that the performance might be variable? Or the problem is that the top program was run at a different time? \n\n    Since we cannot control the environment, we should focus on optimizing the kernel.\n\n 8. We note that the kernel does a lot of operations that might be memory bound. We are reading linear_out (a block of [BLOCK_SIZE_BATCH, BLOCK_SIZE_FEATURE]) and writing the same amount. We are also reading the batchnorm parameters (for the feature block) and the model_bias (once). \n\n 9. We can try to use vectorized loads and stores? The current code uses tl.load and tl.store without specifying the cache modifier or vectorization.\n\n 10. We can try to use the following:\n        tl.load(ptr, mask, other, cache_modifier=\".cg\") to cache globally? Or maybe \".ca\" for cache all? But note that the batchnorm parameters are reused within the block. However, the same batchnorm parameters are used for every row in the batch block. Therefore, we might want to broadcast them. But Triton doesn't have broadcast in the same way. Alternatively, we can load the batchnorm parameters into a register and then reuse.\n\n    Actually, the current code already uses:\n        scale = bn_weight * inv_std   [a vector of length BLOCK_SIZE_FEATURE]\n        shift = ...                   [a vector of length BLOCK_SIZE_FEATURE]\n\n    Then we do:\n        bn_out = linear_out * scale[None, :] + shift[None, :]\n\n    This operation is efficient because Triton will broadcast the scale and shift to the batch dimension.\n\n 11. Let's change the batchnorm computation to use the optimized version and use rsqrt.\n\n 12. We can also try to increase the block sizes? But note that the top program used 32x128 and got 1.048. The current program uses the same and gets 1.019? So maybe we need to try a different configuration.\n\n 13. Alternatively, we can use autotuning to find the best block sizes. We note that the diverse program D1 uses autotuning.\n\n 14. We can also try to change the number of warps? The current kernel does not specify the number of warps. We can try to set num_warps to 8? Or use autotuning for that too.\n\n 15. Given the above, let's do:\n      a. Change the batchnorm computation to the optimized form (using rsqrt and precomputing shift).\n      b. Introduce autotuning for the block sizes and the number of warps.\n\n 16. We note that the kernel must remain with the same interface. We are going to add the autotune decorator and then change the computation.\n\n Steps:\n\n   - Add the @triton.autotune decorator above the kernel with several configurations for BLOCK_SIZE_BATCH and BLOCK_SIZE_FEATURE, and also num_warps.\n   - Change the computation to:\n        inv_std = tl.math.rsqrt(running_var + bn_eps)\n        scale = bn_weight * inv_std\n        shift = bn_bias - running_mean * scale\n        bn_out = linear_out * scale[None, :] + shift[None, :]\n\n   - Remove the old computation.\n\n 17. We also note that the current kernel does not use any tensor cores. But the operations are element-wise? So tensor cores are not applicable.\n\n 18. We will keep the rest of the kernel the same.\n\n 19. In the ModelNew class, we change the kernel launch to use the autotuned parameters. We remove the fixed block sizes and pass them as meta parameters.\n\n 20. We change the grid function to be defined by the autotuner.\n\n 21. We note that the current kernel launch in the ModelNew.forward passes fixed block sizes (32 and 128). We need to remove these and let the autotuner decide.\n\n 22. We must be cautious: the kernel signature now has two additional parameters (BLOCK_SIZE_BATCH and BLOCK_SIZE_FEATURE) that are passed as meta-parameters. The autotuner will set them.\n\n 23. We must also note that the kernel uses these block sizes as tl.constexpr.\n\n Implementation:\n\n   We will add the autotune decorator and then change the kernel computation.\n\n   We will also remove the fixed block sizes in the kernel launch and instead let the autotuner pass them.\n\n   The grid function remains the same: it uses the meta parameters to compute the grid.\n\n 24. Let's look at the diverse program D1 for an example of autotuning.\n\n 25. We note that the autotuner requires the key to be the arguments that change the grid? We set key=['batch_size', 'out_features'].\n\n 26. We also note that the current program has a training branch and an inference branch. We are only changing the inference branch.\n\n Let's rewrite the kernel with autotuning and the optimized batchnorm.\n\n IMPORTANT: We must not change the function signature of the kernel (parameter names) and the grid configuration logic? We are changing the grid to be determined by the autotuner, but the grid function is still the same: (triton.cdiv(batch_size, BLOCK_SIZE_BATCH), triton.cdiv(out_features, BLOCK_SIZE_FEATURE)).\n\n We are going to generate a new version that uses autotuning and the optimized computation.\n\n However, note that the top-performing program (score 24.8) did not use autotuning? But we are currently at 21.9? So we are trying to get back to 24.8? \n\n But wait: the top program had a score of 24.8 and the current program (which is the same) now has 21.9? It might be due to the environment. So we are going to try to improve the kernel by the optimized math and autotuning.\n\n Alternatively, we can try to use the fixed block sizes that were best in the top program? But the autotuner might choose the same.\n\n Let's proceed.\n\n We will generate the code accordingly.\n\n Note: We are only allowed to change the Triton kernel and the launch parameters. We are not allowed to change the class name or the function signatures.\n\n We are going to:\n\n   - Add autotuning decorator with several configs (similar to D1 but adjusted for our block sizes).\n   - Change the batchnorm computation to use rsqrt and precompute shift.\n\n We'll keep the same class and the same forward method, but in the kernel launch we remove the fixed block sizes and instead pass them as meta parameters (so the autotuner can set them).\n\n Let's write the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 16, 'BLOCK_SIZE_FEATURE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_BATCH': 32, 'BLOCK_SIZE_FEATURE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_BATCH': 64, 'BLOCK_SIZE_FEATURE': 128}, num_warps=8),\n    ],\n    key=['batch_size', 'out_features'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    linear_out_ptr,\n    bn_weight_ptr,\n    bn_bias_ptr,\n    running_mean_ptr,\n    running_var_ptr,\n    model_bias_ptr,\n    divide_value,\n    output_ptr,\n    batch_size,\n    out_features,\n    bn_eps,\n    stride_lo0, stride_lo1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE_BATCH: tl.constexpr,\n    BLOCK_SIZE_FEATURE: tl.constexpr\n):\n    pid_batch = tl.program_id(0)\n    pid_feature = tl.program_id(1)\n    \n    batch_idx = pid_batch * BLOCK_SIZE_BATCH + tl.arange(0, BLOCK_SIZE_BATCH)\n    feature_idx = pid_feature * BLOCK_SIZE_FEATURE + tl.arange(0, BLOCK_SIZE_FEATURE)\n    \n    batch_mask = batch_idx < batch_size\n    feature_mask = feature_idx < out_features\n    block_mask = batch_mask[:, None] & feature_mask[None, :]\n    \n    # Calculate offsets for linear_out access\n    lo_offsets = batch_idx[:, None] * stride_lo0 + feature_idx[None, :] * stride_lo1\n    linear_out = tl.load(linear_out_ptr + lo_offsets, mask=block_mask, other=0.0)\n    \n    # Load batchnorm parameters for the feature block\n    bn_weight = tl.load(bn_weight_ptr + feature_idx, mask=feature_mask, other=0.0)\n    bn_bias = tl.load(bn_bias_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_mean = tl.load(running_mean_ptr + feature_idx, mask=feature_mask, other=0.0)\n    running_var = tl.load(running_var_ptr + feature_idx, mask=feature_mask, other=0.0)\n    \n    # Optimized batchnorm computation\n    inv_std = tl.math.rsqrt(running_var + bn_eps)\n    scale = bn_weight * inv_std\n    shift = bn_bias - running_mean * scale\n    bn_out = linear_out * scale[None, :] + shift[None, :]\n    \n    # Add model bias and divide\n    model_bias = tl.load(model_bias_ptr)\n    normalized = (bn_out + model_bias) / divide_value\n    \n    # Swish activation\n    swish_out = normalized * tl.sigmoid(normalized)\n    \n    # Store results\n    out_offsets = batch_idx[:, None] * stride_out0 + feature_idx[None, :] * stride_out1\n    tl.store(output_ptr + out_offsets, swish_out, mask=block_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, bn_eps=1e-5, bn_momentum=0.1, bias_shape=(1,), divide_value=1.0):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.bn = nn.BatchNorm1d(out_features, eps=bn_eps, momentum=bn_momentum)\n        self.bias = nn.Parameter(torch.randn(bias_shape))\n        self.divide_value = divide_value\n        \n    def forward(self, x):\n        linear_out = self.matmul(x)\n        \n        if self.training:\n            x = self.bn(linear_out)\n            x = x + self.bias\n            x = x / self.divide_value\n            return x * torch.sigmoid(x)\n        else:\n            # Inference path with fused Triton kernel\n            batch_size, _ = linear_out.shape\n            output = torch.empty_like(linear_out)\n            \n            grid = lambda meta: (\n                triton.cdiv(batch_size, meta['BLOCK_SIZE_BATCH']),\n                triton.cdiv(linear_out.size(1), meta['BLOCK_SIZE_FEATURE'])\n            )\n            \n            fused_forward_kernel[grid](\n                linear_out,\n                self.bn.weight,\n                self.bn.bias,\n                self.bn.running_mean,\n                self.bn.running_var,\n                self.bias,\n                self.divide_value,\n                output,\n                batch_size,\n                linear_out.size(1),\n                self.bn.eps,\n                linear_out.stride(0), linear_out.stride(1),\n                output.stride(0), output.stride(1),\n            )\n            return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nbn_eps = 1e-5\nbn_momentum = 0.1\nbias_shape = (1,)\ndivide_value = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, bn_eps, bn_momentum, bias_shape, divide_value]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}