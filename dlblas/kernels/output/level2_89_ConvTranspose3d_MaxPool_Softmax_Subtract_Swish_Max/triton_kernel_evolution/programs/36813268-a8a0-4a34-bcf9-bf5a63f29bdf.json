{"id": "36813268-a8a0-4a34-bcf9-bf5a63f29bdf", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef softmax_kernel(output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols, BLOCK_SIZE: tl.constexpr):\n    row_idx = tl.program_id(0)\n    row_start_ptr = input_ptr + row_idx * input_row_stride\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    input_ptrs = row_start_ptr + col_offsets\n    row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))\n    row_minus_max = row - tl.max(row, axis=0)\n    numerator = tl.exp(row_minus_max)\n    denominator = tl.sum(numerator, axis=0)\n    softmax_output = numerator / denominator\n    output_row_start_ptr = output_ptr + row_idx * output_row_stride\n    output_ptrs = output_row_start_ptr + col_offsets\n    tl.store(output_ptrs, softmax_output, mask=col_offsets < n_cols)\n\n@triton.jit\ndef max_reduction_kernel(output_ptr, input_ptr, input_row_stride, n_cols, BLOCK_SIZE: tl.constexpr):\n    row_idx = tl.program_id(0)\n    row_start_ptr = input_ptr + row_idx * input_row_stride\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    input_ptrs = row_start_ptr + col_offsets\n    row = tl.load(input_ptrs, mask=col_offsets < n_cols, other=-float('inf'))\n    row_max = tl.max(row, axis=0)\n    tl.store(output_ptr + row_idx, row_max)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.max_pool = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride, padding=pool_padding)\n        self.subtract = nn.Parameter(torch.randn(out_channels))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.max_pool(x)\n        \n        # Triton softmax implementation\n        B, C, D, H, W = x.shape\n        x_2d = x.permute(0, 2, 3, 4, 1).contiguous().view(-1, C)\n        output_softmax = torch.empty_like(x_2d)\n        n_rows = x_2d.shape[0]\n        grid = (n_rows,)\n        softmax_kernel[grid](output_softmax, x_2d, x_2d.stride(0), output_softmax.stride(0), C, BLOCK_SIZE=C)\n        x = output_softmax.view(B, D, H, W, C).permute(0, 4, 1, 2, 3).contiguous()\n        \n        # Element-wise operations\n        x = x - self.subtract.view(1, -1, 1, 1, 1)\n        x = torch.sigmoid(x) * x\n        \n        # Triton max reduction\n        B, C, D, H, W = x.shape\n        x_2d = x.permute(0, 2, 3, 4, 1).contiguous().view(-1, C)\n        output_max = torch.empty(x_2d.shape[0], device=x.device, dtype=x.dtype)\n        max_reduction_kernel[grid](output_max, x_2d, x_2d.stride(0), C, BLOCK_SIZE=C)\n        x = output_max.view(B, D, H, W)\n        \n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\npool_stride = 2\npool_padding = 0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, pool_stride, pool_padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "03df8878-9a80-4870-8f6b-5a29f766c191", "generation": 1, "timestamp": 1754580688.0653577, "iteration_found": 3, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.016, "runtime_ms": 8.2, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.129, "speed_up": 0.016, "custom_timing": 8.2}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 5.68, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.129, "speed_up": 0.023, "custom_timing": 5.68}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}