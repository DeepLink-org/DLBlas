{"id": "16554f04-3c5c-47e5-b696-7d122af4ac9e", "code": "# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=8),\n    ],\n    key=['N'],\n)\n@triton.jit\ndef vlad_compute_kernel(\n    assignment_ptr, x_ptr, clusters2_ptr, output_ptr,\n    B, N, D, K,\n    assignment_stride_bn, assignment_stride_k,\n    x_stride_b, x_stride_n, x_stride_d,\n    clusters2_stride_d, clusters2_stride_k,\n    output_stride_b, output_stride_d, output_stride_k,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid_k = tl.program_id(1)\n    pid_b = pid0 // D\n    pid_d = pid0 % D\n\n    if pid_b >= B or pid_d >= D or pid_k >= K:\n        return\n\n    vlad_part1 = 0.0\n    a_sum_part = 0.0\n\n    for n in range(0, N, BLOCK_SIZE_N):\n        n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n        mask = n_offsets < N\n\n        a_ptrs = assignment_ptr + (pid_b * N + n_offsets) * assignment_stride_bn + pid_k * assignment_stride_k\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n\n        x_ptrs = x_ptr + pid_b * x_stride_b + n_offsets * x_stride_n + pid_d * x_stride_d\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n        a_sum_part += tl.sum(a_val)\n\n    c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n    a = a_sum_part * c_val\n    result = vlad_part1 - a\n\n    output_ptrs = output_ptr + pid_b * output_stride_b + pid_d * output_stride_d + pid_k * output_stride_k\n    tl.store(output_ptrs, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x_flat = x.reshape(-1, self.feature_size)\n\n        assignment = th.matmul(x_flat, self.clusters)\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n\n        assignment = assignment.contiguous()\n        x = x.contiguous()\n\n        B, N, D, K = x.size(0), max_sample, self.feature_size, self.cluster_size\n        vlad = torch.empty((B, D, K), device=x.device, dtype=x.dtype)\n\n        clusters2_2d = self.clusters2.squeeze(0)\n        grid = (B * D, K)\n\n        vlad_compute_kernel[grid](\n            assignment, x, clusters2_2d, vlad,\n            B, N, D, K,\n            assignment.stride(0), assignment.stride(1),\n            x.stride(0), x.stride(1), x.stride(2),\n            clusters2_2d.stride(0), clusters2_2d.stride(1),\n            vlad.stride(0), vlad.stride(1), vlad.stride(2),\n            BLOCK_SIZE_N=128\n        )\n\n        vlad = F.normalize(vlad, dim=1)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "5ecfbe02-85b0-4e95-9e71-609b456e7d96", "generation": 2, "timestamp": 1754598389.7339954, "iteration_found": 24, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_47_NetVladNoGhostClusters", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpslm552wk.py\", line 119, in forward\n    vlad_compute_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\n    raise ValueError(f\"Conflicting meta-parameters: {', '.join(conflicts)}.\"\nValueError: Conflicting meta-parameters: BLOCK_SIZE_N. Make sure that you don't re-define auto-tuned symbols.\n", "runtime_error_name": "builtins.ValueError", "reference_timing_ms": 0.265, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.123, "runtime_ms": 2.15, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.265, "speed_up": 0.123, "custom_timing": 2.15}}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.1230\n- runtime_ms: 2.1500\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.123, 'custom_timing': 2.15}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8280, runtime_ms: 0.3200, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.828, 'custom_timing': 0.32}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.1230, runtime_ms: 2.1500, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.123, 'custom_timing': 2.15}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.9140, runtime_ms: 0.2900, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.914, 'custom_timing': 0.29}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _vlad_matmul_kernel(\n    x_ptr, clusters_ptr, out_ptr,\n    stride_xm, stride_xk,\n    stride_ck, stride_cn,\n    stride_om, stride_on,\n    M, K, N,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    clusters_ptrs = clusters_ptr + offs_k[:, None] * stride_ck + offs_n[None, :] * stride_cn\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_mask = offs_k < k_remaining\n        a = tl.load(x_ptrs, mask=k_mask[None, :], other=0.0)\n        b = tl.load(clusters_ptrs, mask=k_mask[:, None], other=0.0)\n        accumulator += tl.dot(a, b, allow_tf32=True)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        clusters_ptrs += BLOCK_SIZE_K * stride_ck\n\n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    tl.store(out_ptrs, accumulator, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        # The `clusters` weights are the `(w,b)` in the paper\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        # The `clusters2` weights are the visual words `c_k` in the paper\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        \"\"\"Aggregates feature maps into a fixed size representation.  In the following\n        notation, B = batch_size, N = num_features, K = num_clusters, D = feature_size.\n\n        Args:\n            x (th.Tensor): B x N x D\n\n        Returns:\n            (th.Tensor): B x DK\n        \"\"\"\n        B, N, D = x.shape\n        K = self.cluster_size\n        x_flat = x.reshape(-1, D)  # B x N x D -> (B*N) x D\n\n        if x_flat.device != self.clusters.device:\n            msg = f\"x.device {x_flat.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        M, K_in = x_flat.shape\n        N_out = self.clusters.shape[1]\n        assignment = torch.empty((M, N_out), device=x_flat.device, dtype=x_flat.dtype)\n        \n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N_out, meta['BLOCK_SIZE_N']),)\n        _vlad_matmul_kernel[grid](\n            x_flat, self.clusters, assignment,\n            x_flat.stride(0), x_flat.stride(1),\n            self.clusters.stride(0), self.clusters.stride(1),\n            assignment.stride(0), assignment.stride(1),\n            M, K_in, N_out,\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n        )\n\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)  # (B*N) x (K+G)\n        assignment = assignment[:, :K]  # remove ghost clusters -> (B*N) x K\n        assignment = assignment.view(B, N, K)  # B x N x K\n\n        a_sum = th.sum(assignment, dim=1, keepdim=True)  # B x 1 x K\n        a = a_sum * self.clusters2  # B x D x K (broadcasted)\n\n        vlad = th.matmul(x.transpose(1, 2), assignment)  # (B, D, N) @ (B, N, K) -> (B, D, K)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad, p=2, dim=1)  # Normalize along feature dimension\n        vlad = vlad.reshape(B, -1)  # B x (D*K)\n        vlad = F.normalize(vlad, p=2, dim=1)  # B x (D*K)\n\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.9140), Performs well on runtime_ms (0.2900), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.914, 'custom_timing': 0.29})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef vlad_compute_kernel(\n    assignment_ptr, x_ptr, clusters2_ptr, output_ptr,\n    B, N, D, K,\n    assignment_stride_bn, assignment_stride_k,\n    x_stride_b, x_stride_n, x_stride_d,\n    clusters2_stride_d, clusters2_stride_k,\n    output_stride_b, output_stride_d, output_stride_k,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid_k = tl.program_id(1)\n    pid_b = pid0 // D\n    pid_d = pid0 % D\n\n    if pid_b >= B or pid_d >= D or pid_k >= K:\n        return\n\n    vlad_part1 = 0.0\n    a_sum_part = 0.0\n\n    for n in range(0, N, BLOCK_SIZE_N):\n        n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n        mask = n_offsets < N\n\n        a_ptrs = assignment_ptr + (pid_b * N + n_offsets) * assignment_stride_bn + pid_k * assignment_stride_k\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n\n        x_ptrs = x_ptr + pid_b * x_stride_b + n_offsets * x_stride_n + pid_d * x_stride_d\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1 += tl.sum(a_val * x_val)\n        a_sum_part += tl.sum(a_val)\n\n    c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n    a = a_sum_part * c_val\n    result = vlad_part1 - a\n\n    output_ptrs = output_ptr + pid_b * output_stride_b + pid_d * output_stride_d + pid_k * output_stride_k\n    tl.store(output_ptrs, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x_flat = x.reshape(-1, self.feature_size)\n\n        assignment = th.matmul(x_flat, self.clusters)\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n\n        assignment = assignment.contiguous()\n        x = x.contiguous()\n\n        B, N, D, K = x.size(0), max_sample, self.feature_size, self.cluster_size\n        vlad = torch.empty((B, D, K), device=x.device, dtype=x.dtype)\n\n        clusters2_2d = self.clusters2.squeeze(0)\n        grid = (B * D, K)\n\n        vlad_compute_kernel[grid](\n            assignment, x, clusters2_2d, vlad,\n            B, N, D, K,\n            assignment.stride(0), assignment.stride(1),\n            x.stride(0), x.stride(1), x.stride(2),\n            clusters2_2d.stride(0), clusters2_2d.stride(1),\n            vlad.stride(0), vlad.stride(1), vlad.stride(2),\n            BLOCK_SIZE_N=32\n        )\n\n        vlad = F.normalize(vlad, dim=1)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.1230), Performs well on runtime_ms (2.1500), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.123, 'custom_timing': 2.15})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _vlad_matmul_kernel(\n    x_ptr, clusters_ptr, out_ptr,\n    stride_xm, stride_xk,\n    stride_ck, stride_cn,\n    stride_om, stride_on,\n    M, K, N,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    clusters_ptrs = clusters_ptr + offs_k[:, None] * stride_ck + offs_n[None, :] * stride_cn\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_mask = offs_k < k_remaining\n        a = tl.load(x_ptrs, mask=k_mask[None, :], other=0.0)\n        b = tl.load(clusters_ptrs, mask=k_mask[:, None], other=0.0)\n        accumulator += tl.dot(a, b)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        clusters_ptrs += BLOCK_SIZE_K * stride_ck\n\n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    tl.store(out_ptrs, accumulator, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        # The `clusters` weights are the `(w,b)` in the paper\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        # The `clusters2` weights are the visual words `c_k` in the paper\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        \"\"\"Aggregates feature maps into a fixed size representation.  In the following\n        notation, B = batch_size, N = num_features, K = num_clusters, D = feature_size.\n\n        Args:\n            x (th.Tensor): B x N x D\n\n        Returns:\n            (th.Tensor): B x DK\n        \"\"\"\n        max_sample = x.size()[1]\n        x = x.view(-1, self.feature_size)  # B x N x D -> BN x D\n\n        if x.device != self.clusters.device:\n            msg = f\"x.device {x.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        M, K = x.shape\n        N = self.clusters.shape[1]\n        assignment = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N, meta['BLOCK_SIZE_N']),)\n        _vlad_matmul_kernel[grid](\n            x, self.clusters, assignment,\n            x.stride(0), x.stride(1),\n            self.clusters.stride(0), self.clusters.stride(1),\n            assignment.stride(0), assignment.stride(1),\n            M, K, N,\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n        )\n\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)  # BN x (K+G) -> BN x (K+G)\n        # remove ghost assigments\n        assignment = assignment[:, :self.cluster_size]\n        assignment = assignment.view(-1, max_sample, self.cluster_size)  # -> B x N x K\n        a_sum = th.sum(assignment, dim=1, keepdim=True)  # B x N x K -> B x 1 x K\n        a = a_sum * self.clusters2\n\n        assignment = assignment.transpose(1, 2)  # B x N x K -> B x K x N\n\n        x = x.view(-1, max_sample, self.feature_size)  # BN x D -> B x N x D\n        vlad = th.matmul(assignment, x)  # (B x K x N) x (B x N x D) -> B x K x D\n        vlad = vlad.transpose(1, 2)  # -> B x D x K\n        vlad = vlad - a\n\n        # L2 intra norm\n        vlad = F.normalize(vlad)\n\n        # flattening + L2 norm\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)  # -> B x DK\n        vlad = F.normalize(vlad)\n        return vlad  # B x DK\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8280), Performs well on runtime_ms (0.3200), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.265, 'speed_up': 0.828, 'custom_timing': 0.32})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _vlad_matmul_kernel(\n    x_ptr, clusters_ptr, out_ptr,\n    stride_xm, stride_xk,\n    stride_ck, stride_cn,\n    stride_om, stride_on,\n    M, K, N,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    pid_m = pid // num_pid_m\n    pid_n = pid % num_pid_m\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    clusters_ptrs = clusters_ptr + offs_k[:, None] * stride_ck + offs_n[None, :] * stride_cn\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_mask = offs_k < k_remaining\n        a = tl.load(x_ptrs, mask=k_mask[None, :], other=0.0)\n        b = tl.load(clusters_ptrs, mask=k_mask[:, None], other=0.0)\n        accumulator += tl.dot(a, b)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        clusters_ptrs += BLOCK_SIZE_K * stride_ck\n\n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    row_mask = offs_m[:, None] < M\n    col_mask = offs_n[None, :] < N\n    tl.store(out_ptrs, accumulator, mask=row_mask & col_mask)\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        # The `clusters` weights are the `(w,b)` in the paper\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        # The `clusters2` weights are the visual words `c_k` in the paper\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        \"\"\"Aggregates feature maps into a fixed size representation.  In the following\n        notation, B = batch_size, N = num_features, K = num_clusters, D = feature_size.\n\n        Args:\n            x (th.Tensor): B x N x D\n\n        Returns:\n            (th.Tensor): B x DK\n        \"\"\"\n        B, N, D = x.shape\n        K = self.cluster_size\n        x_flat = x.reshape(-1, D)  # B x N x D -> (B*N) x D\n\n        if x_flat.device != self.clusters.device:\n            msg = f\"x.device {x_flat.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        M, K_in = x_flat.shape\n        N_out = self.clusters.shape[1]\n        assignment = torch.empty((M, N_out), device=x_flat.device, dtype=x_flat.dtype)\n        \n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N_out, meta['BLOCK_SIZE_N']),)\n        _vlad_matmul_kernel[grid](\n            x_flat, self.clusters, assignment,\n            x_flat.stride(0), x_flat.stride(1),\n            self.clusters.stride(0), self.clusters.stride(1),\n            assignment.stride(0), assignment.stride(1),\n            M, K_in, N_out,\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n        )\n\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)  # (B*N) x (K+G)\n        assignment = assignment[:, :K]  # remove ghost clusters -> (B*N) x K\n        assignment = assignment.view(B, N, K)  # B x N x K\n\n        a_sum = th.sum(assignment, dim=1, keepdim=True)  # B x 1 x K\n        a = a_sum * self.clusters2  # B x D x K (broadcasted)\n\n        vlad = th.matmul(x.transpose(1, 2), assignment)  # (B, D, N) @ (B, N, K) -> (B, D, K)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad, p=2, dim=1)  # Normalize along feature dimension\n        vlad = vlad.reshape(B, -1)  # B x (D*K)\n        vlad = F.normalize(vlad, p=2, dim=1)  # B x (D*K)\n\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_K': 256}, num_warps=4),\n        triton.Config({'BLOCK_K': 64}, num_warps=2),\n        triton.Config({'BLOCK_K': 128}, num_warps=2),\n        triton.Config({'BLOCK_K': 256}, num_warps=2),\n    ],\n    key=['D'],\n)\n@triton.jit\ndef matmul_kernel(\n    x_ptr, clusters_ptr, output_ptr,\n    B_N, D, clusters_size,\n    stride_x, stride_clusters, stride_output,\n    BLOCK_K: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_idx = tl.program_id(1)\n    \n    if row_idx >= B_N or col_idx >= clusters_size:\n        return\n        \n    acc = tl.zeros((1,), dtype=tl.float32)\n    \n    for k in range(0, D, BLOCK_K):\n        k_offs = k + tl.arange(0, BLOCK_K)\n        mask = k_offs < D\n        \n        x_val = tl.load(x_ptr + row_idx * stride_x + k_offs, mask=mask, other=0.0)\n        cluster_val = tl.load(clusters_ptr + k_offs * stride_clusters + col_idx, mask=mask, other=0.0)\n        \n        acc += tl.sum(x_val * cluster_val, axis=0)\n    \n    tl.store(output_ptr + row_idx * stride_output + col_idx, acc)\n\ndef triton_matmul(x, clusters):\n    B_N, D = x.shape\n    clusters_size = clusters.shape[1]\n    output = torch.empty(B_N, clusters_size, device=x.device, dtype=x.dtype)\n    \n    grid = (triton.cdiv(B_N, 1), clusters_size)\n    matmul_kernel[grid](\n        x, clusters, output,\n        B_N, D, clusters_size,\n        x.stride(0), clusters.stride(0), output.stride(0),\n        BLOCK_K=128\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x = x.view(-1, self.feature_size)\n\n        if x.device != self.clusters.device:\n            msg = f\"x.device {x.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        assignment = triton_matmul(x, self.clusters)\n        assignment = self.batch_norm(assignment)\n\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n        assignment = assignment.view(-1, max_sample, self.cluster_size)\n        a_sum = th.sum(assignment, dim=1, keepdim=True)\n        a = a_sum * self.clusters2\n\n        assignment = assignment.transpose(1, 2)\n\n        x = x.view(-1, max_sample, self.feature_size)\n        vlad = th.matmul(assignment, x)\n        vlad = vlad.transpose(1, 2)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _vlad_matmul_kernel(\n    x_ptr, clusters_ptr, out_ptr,\n    stride_xm, stride_xk,\n    stride_ck, stride_cn,\n    stride_om, stride_on,\n    M, K, N,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    clusters_ptrs = clusters_ptr + offs_k[:, None] * stride_ck + offs_n[None, :] * stride_cn\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_mask = offs_k < k_remaining\n        a = tl.load(x_ptrs, mask=k_mask[None, :], other=0.0)\n        b = tl.load(clusters_ptrs, mask=k_mask[:, None], other=0.0)\n        accumulator += tl.dot(a, b, allow_tf32=True)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        clusters_ptrs += BLOCK_SIZE_K * stride_ck\n\n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    tl.store(out_ptrs, accumulator, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        # The `clusters` weights are the `(w,b)` in the paper\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        # The `clusters2` weights are the visual words `c_k` in the paper\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        \"\"\"Aggregates feature maps into a fixed size representation.  In the following\n        notation, B = batch_size, N = num_features, K = num_clusters, D = feature_size.\n\n        Args:\n            x (th.Tensor): B x N x D\n\n        Returns:\n            (th.Tensor): B x DK\n        \"\"\"\n        B, N, D = x.shape\n        K = self.cluster_size\n        x_flat = x.reshape(-1, D)  # B x N x D -> (B*N) x D\n\n        if x_flat.device != self.clusters.device:\n            msg = f\"x.device {x_flat.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        M, K_in = x_flat.shape\n        N_out = self.clusters.shape[1]\n        assignment = torch.empty((M, N_out), device=x_flat.device, dtype=x_flat.dtype)\n        \n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N_out, meta['BLOCK_SIZE_N']),)\n        _vlad_matmul_kernel[grid](\n            x_flat, self.clusters, assignment,\n            x_flat.stride(0), x_flat.stride(1),\n            self.clusters.stride(0), self.clusters.stride(1),\n            assignment.stride(0), assignment.stride(1),\n            M, K_in, N_out,\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n        )\n\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)  # (B*N) x (K+G)\n        assignment = assignment[:, :K]  # remove ghost clusters -> (B*N) x K\n        assignment = assignment.view(B, N, K)  # B x N x K\n\n        a_sum = th.sum(assignment, dim=1, keepdim=True)  # B x 1 x K\n        a = a_sum * self.clusters2  # B x D x K (broadcasted)\n\n        vlad = th.matmul(x.transpose(1, 2), assignment)  # (B, D, N) @ (B, N, K) -> (B, D, K)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad, p=2, dim=1)  # Normalize along feature dimension\n        vlad = vlad.reshape(B, -1)  # B x (D*K)\n        vlad = F.normalize(vlad, p=2, dim=1)  # B x (D*K)\n\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef vlad_compute_kernel(\n    assignment_ptr, x_ptr, clusters2_ptr, output_ptr,\n    B, N, D, K,\n    assignment_stride_bn, assignment_stride_k,\n    x_stride_b, x_stride_n, x_stride_d,\n    clusters2_stride_d, clusters2_stride_k,\n    output_stride_b, output_stride_d, output_stride_k,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid_k = tl.program_id(1)\n    pid_b = pid0 // D\n    pid_d = pid0 % D\n\n    if pid_b >= B or pid_d >= D or pid_k >= K:\n        return\n\n    vlad_part1 = 0.0\n    a_sum_part = 0.0\n\n    for n in range(0, N, BLOCK_SIZE_N):\n        n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n        mask = n_offsets < N\n\n        a_ptrs = assignment_ptr + (pid_b * N + n_offsets) * assignment_stride_bn + pid_k * assignment_stride_k\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n\n        x_ptrs = x_ptr + pid_b * x_stride_b + n_offsets * x_stride_n + pid_d * x_stride_d\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n        a_sum_part += tl.sum(a_val)\n\n    c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n    a = a_sum_part * c_val\n    result = vlad_part1 - a\n\n    output_ptrs = output_ptr + pid_b * output_stride_b + pid_d * output_stride_d + pid_k * output_stride_k\n    tl.store(output_ptrs, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x_flat = x.reshape(-1, self.feature_size)\n\n        assignment = th.matmul(x_flat, self.clusters)\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n\n        assignment = assignment.contiguous()\n        x = x.contiguous()\n\n        B, N, D, K = x.size(0), max_sample, self.feature_size, self.cluster_size\n        vlad = torch.empty((B, D, K), device=x.device, dtype=x.dtype)\n\n        clusters2_2d = self.clusters2.squeeze(0)\n        grid = (B * D, K)\n\n        vlad_compute_kernel[grid](\n            assignment, x, clusters2_2d, vlad,\n            B, N, D, K,\n            assignment.stride(0), assignment.stride(1),\n            x.stride(0), x.stride(1), x.stride(2),\n            clusters2_2d.stride(0), clusters2_2d.stride(1),\n            vlad.stride(0), vlad.stride(1), vlad.stride(2),\n            BLOCK_SIZE_N=128\n        )\n\n        vlad = F.normalize(vlad, dim=1)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_K': 256}, num_warps=4),\n        triton.Config({'BLOCK_K': 64}, num_warps=2),\n        triton.Config({'BLOCK_K': 128}, num_warps=2),\n        triton.Config({'BLOCK_K': 256}, num_warps=2),\n    ],\n    key=['D'],\n)\n@triton.jit\ndef matmul_kernel(\n    x_ptr, clusters_ptr, output_ptr,\n    B_N, D, clusters_size,\n    stride_x, stride_clusters, stride_output,\n    BLOCK_K: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    col_idx = tl.program_id(1)\n    \n    if row_idx >= B_N or col_idx >= clusters_size:\n        return\n        \n    acc = tl.zeros((1,), dtype=tl.float32)\n    \n    for k in range(0, D, BLOCK_K):\n        k_offs = k + tl.arange(0, BLOCK_K)\n        mask = k_offs < D\n        \n        x_val = tl.load(x_ptr + row_idx * stride_x + k_offs, mask=mask, other=0.0)\n        cluster_val = tl.load(clusters_ptr + k_offs * stride_clusters + col_idx, mask=mask, other=0.0)\n        \n        acc += tl.sum(x_val * cluster_val, axis=0)\n    \n    tl.store(output_ptr + row_idx * stride_output + col_idx, acc)\n\ndef triton_matmul(x, clusters):\n    B_N, D = x.shape\n    clusters_size = clusters.shape[1]\n    output = torch.empty(B_N, clusters_size, device=x.device, dtype=x.dtype)\n    \n    grid = (triton.cdiv(B_N, 1), clusters_size)\n    matmul_kernel[grid](\n        x, clusters, output,\n        B_N, D, clusters_size,\n        x.stride(0), clusters.stride(0), output.stride(0),\n        BLOCK_K=128\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x = x.view(-1, self.feature_size)\n\n        if x.device != self.clusters.device:\n            msg = f\"x.device {x.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        assignment = triton_matmul(x, self.clusters)\n        assignment = self.batch_norm(assignment)\n\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n        assignment = assignment.view(-1, max_sample, self.cluster_size)\n        a_sum = th.sum(assignment, dim=1, keepdim=True)\n        a = a_sum * self.clusters2\n\n        assignment = assignment.transpose(1, 2)\n\n        x = x.view(-1, max_sample, self.feature_size)\n        vlad = th.matmul(assignment, x)\n        vlad = vlad.transpose(1, 2)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=2),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=2),\n    ],\n    key=['D', 'clusters_size'],\n)\n@triton.jit\ndef matmul_kernel(\n    x_ptr, clusters_ptr, output_ptr,\n    B_N, D, clusters_size,\n    stride_x, stride_clusters_row, stride_clusters_col, stride_output,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row = tl.program_id(0)\n    if row >= B_N:\n        return\n\n    offs_c = tl.arange(0, clusters_size)\n    acc = tl.zeros((clusters_size,), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(D, BLOCK_SIZE)):\n        offs_k = k * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask_k = offs_k < D\n        \n        x_val = tl.load(x_ptr + row * stride_x + offs_k, mask=mask_k, other=0.0)\n        cluster_vals = tl.load(\n            clusters_ptr + offs_k[:, None] * stride_clusters_row + offs_c[None, :] * stride_clusters_col,\n            mask=mask_k[:, None] & (offs_c[None, :] < clusters_size),\n            other=0.0\n        )\n        \n        x_val_2d = tl.reshape(x_val, (1, BLOCK_SIZE))\n        partial = tl.dot(x_val_2d, cluster_vals, allow_tf32=True)\n        acc += tl.reshape(partial, (clusters_size,))\n    \n    tl.store(output_ptr + row * stride_output + offs_c, acc, mask=offs_c < clusters_size)\n\ndef triton_matmul(x, clusters):\n    B_N, D = x.shape\n    _, clusters_size = clusters.shape\n    output = torch.empty(B_N, clusters_size, device=x.device, dtype=x.dtype)\n    \n    grid = (triton.cdiv(B_N, 1),)\n    matmul_kernel[grid](\n        x, clusters, output,\n        B_N, D, clusters_size,\n        x.stride(0), clusters.stride(0), clusters.stride(1), output.stride(0),\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x = x.view(-1, self.feature_size)\n\n        if x.device != self.clusters.device:\n            msg = f\"x.device {x.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        assignment = triton_matmul(x, self.clusters)\n        assignment = self.batch_norm(assignment)\n\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n        assignment = assignment.view(-1, max_sample, self.cluster_size)\n        a_sum = th.sum(assignment, dim=1, keepdim=True)\n        a = a_sum * self.clusters2\n\n        assignment = assignment.transpose(1, 2)\n\n        x = x.view(-1, max_sample, self.feature_size)\n        vlad = th.matmul(assignment, x)\n        vlad = vlad.transpose(1, 2)\n        vlad = vlad - a\n\n        vlad = F.normalize(vlad)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _vlad_matmul_kernel(\n    x_ptr, clusters_ptr, out_ptr,\n    stride_xm, stride_xk,\n    stride_ck, stride_cn,\n    stride_om, stride_on,\n    M, K, N,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk\n    clusters_ptrs = clusters_ptr + offs_k[:, None] * stride_ck + offs_n[None, :] * stride_cn\n\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, K, BLOCK_SIZE_K):\n        k_remaining = K - k\n        k_mask = offs_k < k_remaining\n        a = tl.load(x_ptrs, mask=k_mask[None, :], other=0.0)\n        b = tl.load(clusters_ptrs, mask=k_mask[:, None], other=0.0)\n        accumulator += tl.dot(a, b)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        clusters_ptrs += BLOCK_SIZE_K * stride_ck\n\n    out_ptrs = out_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    tl.store(out_ptrs, accumulator, mask=(offs_m[:, None] < M) & (offs_n[None, :] < N))\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        # The `clusters` weights are the `(w,b)` in the paper\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        # The `clusters2` weights are the visual words `c_k` in the paper\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        \"\"\"Aggregates feature maps into a fixed size representation.  In the following\n        notation, B = batch_size, N = num_features, K = num_clusters, D = feature_size.\n\n        Args:\n            x (th.Tensor): B x N x D\n\n        Returns:\n            (th.Tensor): B x DK\n        \"\"\"\n        max_sample = x.size()[1]\n        x = x.view(-1, self.feature_size)  # B x N x D -> BN x D\n\n        if x.device != self.clusters.device:\n            msg = f\"x.device {x.device} != cluster.device {self.clusters.device}\"\n            raise ValueError(msg)\n\n        M, K = x.shape\n        N = self.clusters.shape[1]\n        assignment = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N, meta['BLOCK_SIZE_N']),)\n        _vlad_matmul_kernel[grid](\n            x, self.clusters, assignment,\n            x.stride(0), x.stride(1),\n            self.clusters.stride(0), self.clusters.stride(1),\n            assignment.stride(0), assignment.stride(1),\n            M, K, N,\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n        )\n\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)  # BN x (K+G) -> BN x (K+G)\n        # remove ghost assigments\n        assignment = assignment[:, :self.cluster_size]\n        assignment = assignment.view(-1, max_sample, self.cluster_size)  # -> B x N x K\n        a_sum = th.sum(assignment, dim=1, keepdim=True)  # B x N x K -> B x 1 x K\n        a = a_sum * self.clusters2\n\n        assignment = assignment.transpose(1, 2)  # B x N x K -> B x K x N\n\n        x = x.view(-1, max_sample, self.feature_size)  # BN x D -> B x N x D\n        vlad = th.matmul(assignment, x)  # (B x K x N) x (B x N x D) -> B x K x D\n        vlad = vlad.transpose(1, 2)  # -> B x D x K\n        vlad = vlad - a\n\n        # L2 intra norm\n        vlad = F.normalize(vlad)\n\n        # flattening + L2 norm\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)  # -> B x DK\n        vlad = F.normalize(vlad)\n        return vlad  # B x DK\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef vlad_compute_kernel(\n    assignment_ptr, x_ptr, clusters2_ptr, output_ptr,\n    B, N, D, K,\n    assignment_stride_bn, assignment_stride_k,\n    x_stride_b, x_stride_n, x_stride_d,\n    clusters2_stride_d, clusters2_stride_k,\n    output_stride_b, output_stride_d, output_stride_k,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid_k = tl.program_id(1)\n    pid_b = pid0 // D\n    pid_d = pid0 % D\n\n    if pid_b >= B or pid_d >= D or pid_k >= K:\n        return\n\n    vlad_part1 = 0.0\n    a_sum_part = 0.0\n\n    for n in range(0, N, BLOCK_SIZE_N):\n        n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n        mask = n_offsets < N\n\n        a_ptrs = assignment_ptr + (pid_b * N + n_offsets) * assignment_stride_bn + pid_k * assignment_stride_k\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n\n        x_ptrs = x_ptr + pid_b * x_stride_b + n_offsets * x_stride_n + pid_d * x_stride_d\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1 += tl.sum(a_val * x_val)\n        a_sum_part += tl.sum(a_val)\n\n    c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n    a = a_sum_part * c_val\n    result = vlad_part1 - a\n\n    output_ptrs = output_ptr + pid_b * output_stride_b + pid_d * output_stride_d + pid_k * output_stride_k\n    tl.store(output_ptrs, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x_flat = x.reshape(-1, self.feature_size)\n\n        assignment = th.matmul(x_flat, self.clusters)\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n\n        assignment = assignment.contiguous()\n        x = x.contiguous()\n\n        B, N, D, K = x.size(0), max_sample, self.feature_size, self.cluster_size\n        vlad = torch.empty((B, D, K), device=x.device, dtype=x.dtype)\n\n        clusters2_2d = self.clusters2.squeeze(0)\n        grid = (B * D, K)\n\n        vlad_compute_kernel[grid](\n            assignment, x, clusters2_2d, vlad,\n            B, N, D, K,\n            assignment.stride(0), assignment.stride(1),\n            x.stride(0), x.stride(1), x.stride(2),\n            clusters2_2d.stride(0), clusters2_2d.stride(1),\n            vlad.stride(0), vlad.stride(1), vlad.stride(2),\n            BLOCK_SIZE_N=32\n        )\n\n        vlad = F.normalize(vlad, dim=1)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program, which uses a Triton kernel for computing the VLAD aggregation.\n The current program has a speed_up of 0.123 (which is very slow) and a runtime of 2.15 ms, compared to the reference timing of 0.265 ms.\n\n The current program uses a kernel that iterates over the N dimension (max_sample) in blocks and computes:\n   vlad_part1 = sum_n (assignment[b, n, k] * x[b, n, d])\n   a_sum_part = sum_n (assignment[b, n, k])\n   then: result = vlad_part1 - (a_sum_part * clusters2[d, k])\n\n However, note that the current kernel is launched with grid (B * D, K). This means we have B*D*K blocks, each processing a (d, k) pair for a given batch, and iterating over N in blocks of BLOCK_SIZE_N (32).\n\n The problem: the current kernel might be inefficient because:\n   - The grid size is B * D * K (which for B=32, D=512, K=32 is 32*512*32 = 524,288 blocks). This is a large grid and might cause overhead.\n   - Each block only does a small amount of work: iterating over N (100) in blocks of 32, so only 4 iterations per block.\n\n We note from the top performing programs that the one using a matrix multiplication kernel (with block tiling) achieved a speed_up of 0.828 (which is better but still less than 1) and 0.914 (also less than 1). We need to get at least 1.05.\n\n Let's reconsider the entire flow.\n\n The reference PyTorch code (from the original) is:\n\n   B, N, D = x.shape\n   K = self.cluster_size\n   x_flat = x.reshape(-1, D)  # (B*N, D)\n\n   assignment = self.batch_norm(th.matmul(x_flat, self.clusters))\n   assignment = F.softmax(assignment, dim=1)[:, :K]  # (B*N, K)\n   assignment = assignment.view(B, N, K)\n\n   a_sum = th.sum(assignment, dim=1, keepdim=True)  # (B, 1, K)\n   a = a_sum * self.clusters2  # (B, D, K)\n\n   vlad = th.matmul(x.transpose(1,2), assignment)  # (B, D, N) @ (B, N, K) -> (B, D, K)\n   vlad = vlad - a\n\n   vlad = F.normalize(vlad, p=2, dim=1)  # along D\n   vlad = vlad.reshape(B, -1)\n   vlad = F.normalize(vlad, p=2, dim=1)\n\n The most expensive parts are:\n   1. The matrix multiplication: (B*N, D) @ (D, clusters) -> (B*N, clusters)   [clusters = K + ghost, but then we take K]\n   2. The second matrix multiplication: (B, D, N) @ (B, N, K) -> (B, D, K)\n\n The current Triton program replaces the second matmul and the subtraction with a custom kernel, but the first matmul is done with `th.matmul`.\n\n However, the current program (above) uses `th.matmul` for the first matmul and then a Triton kernel for the second part.\n\n Why is the current Triton kernel (vlad_compute_kernel) slow?\n   - It uses a grid of (B*D, K). For each (d, k) in the output (B, D, K), we are doing:\n        vlad_part1 = sum_n (assignment[b, n, k] * x[b, n, d])\n        a_sum_part = sum_n (assignment[b, n, k])\n        result = vlad_part1 - a_sum_part * clusters2[d, k]\n\n   - This is essentially doing two reductions (over N) for each (b, d, k). The reduction over N (100) is small, but we have B*D*K (32*512*32=524288) blocks.\n\n   - The memory access pattern: for each block, we are loading a contiguous chunk of `assignment` along the n dimension (for a fixed b, k) and a contiguous chunk of `x` along the n dimension (for fixed b, d). This is not coalesced because the same n chunk is loaded for different d and k.\n\n   - The arithmetic intensity is low: we are doing 2*BLOCK_SIZE_N operations per block (if BLOCK_SIZE_N=32, then 64 operations) but we are loading 2*BLOCK_SIZE_N elements (each 4 bytes, so 256 bytes) and storing one float (4 bytes). The arithmetic intensity is about 0.25 flop/byte, which is memory bound.\n\n   - The grid is very large and might have high overhead.\n\n How can we improve?\n\n Option 1: Use a more efficient kernel for the second part by tiling over multiple dimensions.\n\n However, note that the top performing program (with the matrix multiplication kernel for the first matmul) achieved 0.828 speed_up. That program did the second matmul with `th.matmul` and then subtracted. The Triton kernel for the first matmul was:\n\n   grid = (triton.cdiv(M, 64) * triton.cdiv(N, 32), )\n   BLOCK_SIZE_M=64, BLOCK_SIZE_N=32, BLOCK_SIZE_K=64\n\n   and the kernel used tensor cores (allow_tf32=True) and was tiled.\n\n But note: the reference PyTorch code uses highly optimized cuBLAS for the matmuls. We are unlikely to beat that with a Triton kernel for such small matrices? \n\n However, the matrices in the first matmul: (B*N, D) @ (D, clusters) = (3200, 512) @ (512, 32) for B=32, N=100, D=512, clusters=32.\n This is a small matmul (3200x32 output). The second matmul: (32,512,100) @ (32,100,32) -> (32,512,32) is also small.\n\n Why are we getting speedups less than 1? Maybe because the Triton kernel for the first matmul is not as optimized as cuBLAS? \n\n But note: the top program with the matmul kernel for the first matmul had a speed_up of 0.828 and 0.914, which is better than 0.123.\n\n Alternatively, we can try to fuse the entire VLAD computation into one kernel? But that might be complex.\n\n Another idea: avoid the second custom kernel and use the optimized `th.matmul` for the second matmul, and then subtract. We note that the top program (Program 1) does:\n\n   vlad = th.matmul(x.transpose(1,2), assignment)   # (B, D, K)\n   vlad = vlad - a   # a is (B, D, K)\n\n and then normalizations.\n\n The current program (with the slow kernel) is 0.123 speed_up, but if we replace the custom kernel with the th.matmul and subtraction, we might get closer to the top program (which had 0.828).\n\n However, the assignment says: we cannot change the grid configuration or the output tensor shapes. But note: the current program uses a custom kernel for the second part. We are allowed to change the Triton kernel implementation as long as we don't change the function signature and the grid configuration.\n\n But wait, the current program uses a grid of (B * D, K). We are allowed to change the kernel code, but not the grid? Actually, we are allowed to change the kernel code and the grid if it is within the Triton kernel? The constraints say:\n\n   \u274c NEVER change @triton.jit function signatures or parameter names\n   \u274c NEVER modify grid configuration, output tensor shapes, or PID logic\n\n So we cannot change the grid configuration? The grid is set as `grid = (B * D, K)`. We are stuck with that.\n\n Alternatively, we can try to optimize the existing kernel:\n\n   - We are currently using a loop over N in blocks of BLOCK_SIZE_N (32). We can try to increase the work per block by processing multiple (d, k) pairs per block? But the grid is fixed.\n\n   - We can use vectorized loads and shared memory to reduce global memory accesses.\n\n   - We can change the kernel to process multiple k values per block? But the grid is (B*D, K). Each block is for one (d, k) and one b (because b is part of the first dimension of the grid: pid0 = b*D + d).\n\n   - We note that the current kernel does:\n        vlad_part1 = sum_n (assignment[n, k] * x[n, d])\n        a_sum_part = sum_n (assignment[n, k])\n\n   We can try to vectorize the loads and use FP16 if possible? But the tensors are float32.\n\n   - We can try to use the Tensor Cores? But the operation is a reduction and the problem size per block is small.\n\n   - We can change the BLOCK_SIZE_N to a larger value? Currently 32. But the N dimension is only 100, so we are doing 4 iterations. Increasing the block size might not help much.\n\n   - Alternatively, we can change the kernel to process multiple k values per block? But the grid is fixed: one block per (d, k). We cannot change the grid.\n\n Given the constraints, we cannot change the grid. So we have to work within the grid of (B*D, K).\n\n How about we change the kernel to process multiple n at once? We are already doing that with BLOCK_SIZE_N=32. We could try to use warp-level reductions? Or use shared memory to reduce the latency?\n\n Another idea: we are loading the same assignment[n, k] for a fixed k and the same x[n, d] for a fixed d. We could try to load a larger block and then do a reduction in shared memory? But the reduction is only over n.\n\n Since the grid is fixed, we are limited. We note that the kernel is memory bound. We can try to:\n\n   - Use vectorized loads: load float2 or float4 to reduce the number of memory transactions.\n\n   - But note: the assignment tensor and x tensor might not be contiguous in the way we are accessing. We are accessing:\n        assignment: [b, n, k] -> we are loading a contiguous chunk in n for fixed b and k.\n        x: [b, n, d] -> we are loading a contiguous chunk in n for fixed b and d.\n\n   So both are contiguous in n. We can try to load multiple elements at once.\n\n   - We can change the kernel to load a vector of assignment and a vector of x, and then do a dot product for the vlad_part1 and a sum for the a_sum_part.\n\n   - We can set BLOCK_SIZE_N to 128 and then do one iteration? But N=100, so we would set BLOCK_SIZE_N=128 and then mask the last 28 elements. Then we do one iteration. This would reduce the loop overhead.\n\n   - We can use the following:\n        tl.load(ptr, mask=mask, other=0.0, cache_modifier=\".cg\")   # to cache globally\n\n   - We can also try to use the dot product instruction? But note: we are doing:\n        vlad_part1 += tl.sum(a_val * x_val)\n        a_sum_part += tl.sum(a_val)\n\n   This is two separate reductions. We can do both with one instruction? Not directly.\n\n   - We can compute a_val * x_val and a_val in one loop and then use two registers.\n\n   - We can unroll the loop? Triton might do that automatically.\n\n   - We can change the number of warps? Currently, the kernel uses the default (1 warp?).\n\n   The kernel does not specify num_warps. We can try to set it to 1 and then use one warp per block? But the work per block is small (only 100 elements). We can try to set num_warps=1 and then use the warp to do the reduction? \n\n   Alternatively, we can try to use a larger block and then reduce with multiple threads? But the grid is fixed: one block per (d, k). We are stuck with the grid.\n\n   The kernel currently does not use shared memory. We can try to use shared memory to do the reduction? But the reduction is over a small dimension (N=100) and we are already iterating in blocks. The reduction in the block is done with `tl.sum` which uses registers.\n\n   The main issue is the grid size and the memory bound nature.\n\n Given the above, we decide to try:\n\n   - Increase BLOCK_SIZE_N to 128 (so we do one iteration for N=100) to reduce loop overhead.\n\n   - Use vectorized loads: we can try to load 4 elements at a time? We can change the dtype to float32 and load 4 elements? We can use tl.dot to do a vector dot? But note: we are doing a reduction.\n\n   Alternatively, we can use the following:\n\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1_block = tl.sum(a_val * x_val)\n        a_sum_part_block = tl.sum(a_val)\n\n   We can try to use the dot product for the a_val * x_val? But the dot product would be for two vectors of length BLOCK_SIZE_N? But we are already doing a reduction.\n\n   We can try to use tl.sum with a fast method? I don't know.\n\n   Another idea: pre-fetch the next block? But the N dimension is small and we are doing one iteration.\n\n   We try to set BLOCK_SIZE_N=128 and hope that Triton unrolls the loop and uses vectorized loads.\n\n   We also note that the kernel does not use tensor cores. We cannot use tensor cores for this reduction.\n\n   We can also try to change the number of warps? We can set num_warps=4? But the block is only processing 128 elements. We can try to set num_warps=1 (which is the default) and see if that is better? We can't test without running, but we can try to set it explicitly.\n\n   However, note: the kernel does not have an autotune config. We can add autotune for BLOCK_SIZE_N? But the constraint says we cannot change the function signature? We are allowed to change the kernel code as long as we don't change the parameter names? We can add an autotune?\n\n   But the grid configuration (the launch grid) is fixed: (B*D, K). We cannot change that. We can change the BLOCK_SIZE_N as a constant. We can make it a configurable parameter.\n\n   We can try to autotune BLOCK_SIZE_N? But note the constraint: we cannot change the function signature. We can add an autotune by making BLOCK_SIZE_N a triton constant? And then use multiple configs.\n\n   However, the current program does not have autotune. We are allowed to add it? The constraints say we can do \"Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions\", so it should be allowed.\n\n   We can do:\n\n        configs = [\n            triton.Config({'BLOCK_N': 32}, num_warps=1),\n            triton.Config({'BLOCK_N': 64}, num_warps=1),\n            triton.Config({'BLOCK_N': 128}, num_warps=1),\n            triton.Config({'BLOCK_N': 32}, num_warps=2),\n            ... \n        ]\n\n   and then use the key of N? But note N is 100, which is fixed for the input. We can use the key of N.\n\n   But note: the grid configuration is fixed and we cannot change the grid. The autotune would only change the block-level parameters.\n\n   Let's rewrite the kernel with autotune and vectorized loads? We can try to load in chunks of 4? But we don't know if the address is aligned.\n\n   Alternatively, we can rely on Triton to do vectorized loads automatically? It might already do that.\n\n   We decide to:\n\n     1. Add autotune for BLOCK_SIZE_N and num_warps.\n     2. Increase the block size for N to reduce the number of iterations.\n     3. Try to use vectorized loads by making sure we are loading contiguous data and using a large enough block.\n\n   We note that the kernel currently does:\n\n        for n in range(0, N, BLOCK_SIZE_N):\n            n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n            mask = n_offsets < N\n\n            a_ptrs = ... + n_offsets\n            x_ptrs = ... + n_offsets\n\n            a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n            x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n   We can change this to:\n\n        for n in range(0, tl.cdiv(N, BLOCK_SIZE_N)):\n            n_offs = n * BLOCK_SIZE_N\n            n_offsets = n_offs + tl.arange(0, BLOCK_SIZE_N)\n            mask = n_offsets < N\n\n            ... same ...\n\n   But it's the same.\n\n   We can try to use the dot product for the two vectors? But note, we are doing two separate reductions.\n\n   We can do:\n\n        partial_vlad = tl.sum(a_val * x_val)\n        partial_asum = tl.sum(a_val)\n\n        vlad_part1 += partial_vlad\n        a_sum_part += partial_asum\n\n   We can try to use tl.dot if we can? But the vectors are of size BLOCK_SIZE_N, and we are reducing to scalar. The tl.dot would be for two vectors and return a scalar? Yes, but it's the same as tl.sum(a_val * x_val). And it might be optimized? We can try:\n\n        partial_vlad = tl.dot(a_val, x_val)   # but note: a_val and x_val are 1D vectors.\n\n   However, the dot product in Triton for 1D vectors might be implemented efficiently? We can try that.\n\n   We change:\n\n        vlad_part1 += tl.sum(a_val * x_val)\n\n   to:\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n\n   But note: allow_tf32 is for matrix multiplications? For dot product of vectors, it might not matter. But we can try.\n\n   Also, note: the dot product might be more efficient because it uses the tensor cores? For vectors? Probably not. Tensor cores are for matrix multiplications.\n\n   We decide to try:\n\n        partial_vlad = tl.dot(a_val, x_val, allow_tf32=True)\n\n   and then accumulate.\n\n   But the dot product of two vectors is the same as the sum of their element-wise product.\n\n   We can try to use the vectorized dot product instruction? But Triton might already do that.\n\n   Alternatively, we can use the fact that the vectors are contiguous and use the dot instruction that might be optimized for contiguous memory.\n\n   We are going to:\n\n        - Add autotune for BLOCK_SIZE_N and num_warps.\n        - Use tl.dot for the vlad_part1.\n\n   We also note that the kernel currently does:\n\n        c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n\n   This is a single load, so it's fine.\n\n   We also note that the kernel does two reductions. We are doing:\n\n        vlad_part1 = dot(a_val, x_val)   [for the entire N]  -> scalar\n        a_sum_part = sum(a_val)   [for the entire N] -> scalar\n\n   We can combine these two into one loop? We are already doing that.\n\n   We change the kernel to use tl.dot for the multiplication and keep the sum for a_sum_part.\n\n   We set:\n\n        @triton.autotune(\n            configs=[\n                triton.Config({'BLOCK_SIZE_N': 32}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N': 64}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N': 128}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N': 32}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N': 64}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N': 128}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N': 32}, num_warps=4),\n                triton.Config({'BLOCK_SIZE_N': 64}, num_warps=4),\n                triton.Config({'BLOCK_SIZE_N': 128}, num_warps=4),\n            ],\n            key=['N'],\n        )\n\n   And then in the kernel, we use the config parameter for BLOCK_SIZE_N.\n\n   We also change the reduction for vlad_part1 to use tl.dot.\n\n   We note: the tl.dot for two 1D vectors returns a scalar.\n\n   We change the kernel to:\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n\n   and leave the a_sum_part as tl.sum(a_val).\n\n   We hope that the tl.dot is faster than the separate multiplication and sum.\n\n   But note: the vectors are of length BLOCK_SIZE_N (which we are autotuning) and might be small. The tl.dot might not be faster.\n\n   Alternatively, we can leave the reduction as is and rely on the autotune to pick the best block size and number of warps.\n\n   We decide to do:\n\n        vlad_part1 += tl.sum(a_val * x_val)   # or use tl.dot?\n\n   We try both? We can't test, so we rely on the autotune to pick the best.\n\n   We will use the dot product because it might be optimized for the GPU.\n\n   We also note: the current program does not use the fast math option. We can try to set allow_tf32=True for the dot product? We do that.\n\n   Steps:\n\n     1. Add autotune to the kernel for BLOCK_SIZE_N and num_warps.\n     2. Replace the reduction for vlad_part1 with tl.dot(..., allow_tf32=True).\n     3. Keep the reduction for a_sum_part as tl.sum.\n\n   We also note: the kernel must be compatible with the grid (B*D, K) and the block structure.\n\n   We change the kernel to:\n\n        @triton.autotune(...)\n        @triton.jit\n        def vlad_compute_kernel(..., BLOCK_SIZE_N: tl.constexpr, ...):\n\n   And then inside the kernel, we use BLOCK_SIZE_N as the block size for N.\n\n   We also note: the kernel currently has a parameter `BLOCK_SIZE_N: tl.constexpr`. We are going to make it configurable.\n\n   We change the kernel signature to include BLOCK_SIZE_N as a config parameter.\n\n   We also change the call site to pass BLOCK_SIZE_N as a triton constant? Actually, we don't need to change the call site because we are using autotune and the autotune will override the value.\n\n   We leave the call site as:\n\n        vlad_compute_kernel[grid](..., BLOCK_SIZE_N=config.BLOCK_SIZE_N)\n\n   But wait, the call site currently passes BLOCK_SIZE_N=32. We are going to remove that and let autotune set it? Actually, in the autotune, we set the value of BLOCK_SIZE_N in the config.\n\n   We change the call site to not specify BLOCK_SIZE_N? Actually, we can leave it as we are passing a constant (32) and the autotune will override it? We can remove the constant and pass the value from the config? But the autotune will set it.\n\n   We change the call site to:\n\n        vlad_compute_kernel[grid](\n            ...,\n            BLOCK_SIZE_N=128,   # this will be overridden by autotune? Actually, we don't pass it by name? We are passing by position? We must pass by keyword? Actually, in the kernel definition, we have BLOCK_SIZE_N as the last argument? We are currently passing by position.\n\n        We are passing: BLOCK_SIZE_N=32 at the call site. We can remove that and let autotune set it? Actually, we must pass it. We can do:\n\n            BLOCK_SIZE_N=BLOCK_SIZE_N,   # and then autotune will override?\n\n        But the autotune will set the value of BLOCK_SIZE_N in the kernel.\n\n        We change the call site to:\n\n            vlad_compute_kernel[grid](\n                ...,\n                BLOCK_SIZE_N=128,   # this is a dummy value? But the autotune will override it? Actually, the autotune sets the value for the kernel. The call site must pass the same value? Or we can remove it and let the autotune pass it?\n\n        How does autotune work? We define the configs and then Triton will try each config and pick the best. The call site does not change.\n\n        We change the kernel to have autotune and then we remove the BLOCK_SIZE_N from the call site? Actually, we cannot because it is a required argument.\n\n        We change the call site to:\n\n            BLOCK_SIZE_N=128,   # but we hope autotune will override\n\n        But the autotune will override the value of BLOCK_SIZE_N for each config. The call site value is ignored.\n\n        So we leave the call site as:\n\n            BLOCK_SIZE_N=128   # or 32, it doesn't matter because autotune will override.\n\n        But we set it to a value that is one of the configs? It doesn't matter.\n\n   We set the call site to BLOCK_SIZE_N=128, and then the autotune will try the other values.\n\n   We also note: the kernel currently has the parameter `BLOCK_SIZE_N: tl.constexpr` and we are passing it from the call site. The autotune will override it.\n\n   We write the autotune config above the kernel.\n\n   We hope that with these changes, the kernel will run faster.\n\n   Alternatively, we can try to use a different approach: do the reduction in shared memory? But the reduction is small.\n\n   We decide to try the autotune and the dot product.\n\n   Summary of changes:\n\n     - Add autotune for BLOCK_SIZE_N and num_warps, with key='N'\n     - Change the reduction for vlad_part1 to use tl.dot(a_val, x_val, allow_tf32=True)\n     - Keep the reduction for a_sum_part as tl.sum(a_val)\n\n   We note: the tl.dot might not be faster for small vectors? But we try.\n\n   We also note: the dot product might be more numerically stable? Not an issue.\n\n   We change the kernel accordingly.\n\n   IMPORTANT: We are not allowed to change the function signature? We are adding an autotune decorator and changing the body, but the parameters are the same.\n\n   We are also changing the call site to pass BLOCK_SIZE_N=128? But that's a constant, and the autotune will override. We can set it to 128 to be one of the configs.\n\n   We change the call site to:\n\n        BLOCK_SIZE_N=128   # now we are passing 128, but autotune might change it to 32 or 64.\n\n   We hope the autotune will pick the best.\n\n   Given the time constraints, we do this.\n\n   Let's rewrite the kernel with autotune and the dot product.\n\n   We note: the current program has a Triton kernel without autotune. We are adding autotune and changing the reduction to use dot.\n\n   We hope this will improve the performance.\n\n   If not, we might have to try a different approach.\n\n   But note: the grid is fixed and we cannot change it.\n\n   We output the entire code block.\n\n   We also note: the current program uses a class `ModelNew`. We must keep the same class name.\n\n   We change only the kernel and its call site.\n\n   The new kernel code:\n\n        @triton.autotune(\n            configs=[\n                triton.Config({'BLOCK_SIZE_N_TUNE': 32}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 64}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 128}, num_warps=1),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 32}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 64}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 128}, num_warps=2),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 32}, num_warps=4),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 64}, num_warps=4),\n                triton.Config({'BLOCK_SIZE_N_TUNE': 128}, num_warps=4),\n            ],\n            key=['N'],\n        )\n        @triton.jit\n        def vlad_compute_kernel(\n            ...,\n            BLOCK_SIZE_N: tl.constexpr,   # we are going to override this with BLOCK_SIZE_N_TUNE?\n            ...,\n        ):\n            # We want to use BLOCK_SIZE_N_TUNE as the block size for N?\n            # But the parameter is named BLOCK_SIZE_N. How do we use the config?\n            # We can rename the parameter? But the constraint says we cannot change the parameter names.\n\n        We have a problem: we cannot change the parameter name. We are stuck with BLOCK_SIZE_N.\n\n        How can we use the autotune parameter? We can define a new constant in the config and then use it? But the kernel parameter is fixed.\n\n        Alternatively, we can change the parameter name in the kernel to BLOCK_SIZE_N_TUNE and then at the call site pass BLOCK_SIZE_N_TUNE=value? But the call site passes BLOCK_SIZE_N=128.\n\n        We decide to change the kernel parameter name to BLOCK_SIZE_N_TUNE and then remove the old BLOCK_SIZE_N? But the call site passes BLOCK_SIZE_N. We must change the call site? But the constraint says we cannot change the function signature.\n\n        This is a problem.\n\n        We cannot change the function signature. So we cannot change the parameter name.\n\n        We decide not to use autotune? Or we use a different approach: make the autotune for a different parameter and then set BLOCK_SIZE_N to that parameter?\n\n        We can do:\n\n            @triton.autotune(...)\n            @triton.jit\n            def vlad_compute_kernel(..., BLOCK_SIZE_N: tl.constexpr, ...):\n                BLOCK_N = BLOCK_SIZE_N   # we are not using the autotune parameter for the block size? How?\n\n        This is not possible.\n\n        Alternatively, we can use the autotune to set the value of BLOCK_SIZE_N? But the autotune configs are for a different parameter? We can try to set the same parameter?\n\n        Actually, we can use the same parameter name in the autotune config? We change the config to:\n\n            triton.Config({'BLOCK_SIZE_N': 32}, ...)\n\n        Then the autotune will set the kernel parameter BLOCK_SIZE_N to 32, 64, etc.\n\n        And we remove the constant from the call site? But the call site must pass it? Actually, the autotune will override the value passed by the call site.\n\n        We change the autotune config to use the same name: 'BLOCK_SIZE_N'.\n\n        Then we do:\n\n            configs = [\n                triton.Config({'BLOCK_SIZE_N': 32}, num_warps=1),\n                ...,\n            ]\n\n        And then the kernel will be compiled with BLOCK_SIZE_N set to the config value.\n\n        The call site still passes BLOCK_SIZE_N=128, but it will be ignored? Actually, the autotune will recompile the kernel for each config and then run the kernel with the config value.\n\n        So we change the autotune config to use the parameter name 'BLOCK_SIZE_N'.\n\n        And then we remove the argument at the call site? No, we keep it because it is required by the kernel? Actually, the autotune will generate multiple kernels and then call the one with the config. The call site value is ignored.\n\n        So we leave the call site as BLOCK_SIZE_N=128 (or any value) and it will be ignored.\n\n        We do:\n\n            @triton.autotune(\n                configs=[\n                    triton.Config({'BLOCK_SIZE_N': 32}, num_warps=1),\n                    triton.Config({'BLOCK_SIZE_N': 64}, num_warps=1),\n                    triton.Config({'BLOCK_SIZE_N': 128}, num_warps=1),\n                    triton.Config({'BLOCK_SIZE_N': 32}, num_warps=2),\n                    triton.Config({'BLOCK_SIZE_N': 64}, num_warps=2),\n                    triton.Config({'BLOCK_SIZE_N': 128}, num_warps=2),\n                    triton.Config({'BLOCK_SIZE_N': 32}, num_warps=4),\n                    triton.Config({'BLOCK_SIZE_N': 64}, num_warps=4),\n                    triton.Config({'BLOCK_SIZE_N': 128}, num_warps=4),\n                ],\n                key=['N'],\n            )\n            @triton.jit\n            def vlad_compute_kernel(..., BLOCK_SIZE_N: tl.constexpr, ...):\n                ... # use BLOCK_SIZE_N as the block size for n\n\n        And at the call site, we pass BLOCK_SIZE_N=128 (or 32, it doesn't matter) because we have to.\n\n        This should work.\n\n   We make these changes.\n\n   We also change the reduction for vlad_part1 to use:\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n\n   And leave the a_sum_part as:\n\n        a_sum_part += tl.sum(a_val)\n\n   We hope this will improve the speed.\n\n   Let's write the new kernel code.\n\n   Note: We are not allowed to change the function signature, and we are not changing it.\n\n   We only add a decorator and change the body.\n\n   We output the entire code block.\n</think>\nTo improve the performance of the Triton kernel for VLAD computation, I'll optimize the kernel by:\n1. Adding autotune for optimal block size and warp configuration\n2. Using vector dot products instead of manual sum-reduce\n3. Increasing block size to reduce loop iterations\n4. Allowing TF32 math for faster computations\n\nHere's the optimized implementation:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\n# Copyright 2018 Antoine Miech All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS-IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"\nCode modified from here\nhttps://github.com/albanie/collaborative-experts/blob/master/model/net_vlad.py\n\"\"\"\n\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch as th\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=2),\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256}, num_warps=8),\n    ],\n    key=['N'],\n)\n@triton.jit\ndef vlad_compute_kernel(\n    assignment_ptr, x_ptr, clusters2_ptr, output_ptr,\n    B, N, D, K,\n    assignment_stride_bn, assignment_stride_k,\n    x_stride_b, x_stride_n, x_stride_d,\n    clusters2_stride_d, clusters2_stride_k,\n    output_stride_b, output_stride_d, output_stride_k,\n    BLOCK_SIZE_N: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid_k = tl.program_id(1)\n    pid_b = pid0 // D\n    pid_d = pid0 % D\n\n    if pid_b >= B or pid_d >= D or pid_k >= K:\n        return\n\n    vlad_part1 = 0.0\n    a_sum_part = 0.0\n\n    for n in range(0, N, BLOCK_SIZE_N):\n        n_offsets = n + tl.arange(0, BLOCK_SIZE_N)\n        mask = n_offsets < N\n\n        a_ptrs = assignment_ptr + (pid_b * N + n_offsets) * assignment_stride_bn + pid_k * assignment_stride_k\n        a_val = tl.load(a_ptrs, mask=mask, other=0.0)\n\n        x_ptrs = x_ptr + pid_b * x_stride_b + n_offsets * x_stride_n + pid_d * x_stride_d\n        x_val = tl.load(x_ptrs, mask=mask, other=0.0)\n\n        vlad_part1 += tl.dot(a_val, x_val, allow_tf32=True)\n        a_sum_part += tl.sum(a_val)\n\n    c_val = tl.load(clusters2_ptr + pid_d * clusters2_stride_d + pid_k * clusters2_stride_k)\n    a = a_sum_part * c_val\n    result = vlad_part1 - a\n\n    output_ptrs = output_ptr + pid_b * output_stride_b + pid_d * output_stride_d + pid_k * output_stride_k\n    tl.store(output_ptrs, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, cluster_size, feature_size, ghost_clusters):\n        super(ModelNew, self).__init__()\n\n        self.feature_size = feature_size\n        self.cluster_size = cluster_size\n        self.ghost_clusters = ghost_clusters\n\n        init_sc = (1 / math.sqrt(feature_size))\n        clusters = cluster_size + ghost_clusters\n\n        self.clusters = nn.Parameter(init_sc * th.randn(feature_size, clusters))\n        self.batch_norm = nn.BatchNorm1d(clusters)\n        self.clusters2 = nn.Parameter(init_sc * th.randn(1, feature_size, cluster_size))\n        self.out_dim = self.cluster_size * feature_size\n\n    def forward(self, x, mask=None):\n        max_sample = x.size()[1]\n        x_flat = x.reshape(-1, self.feature_size)\n\n        assignment = th.matmul(x_flat, self.clusters)\n        assignment = self.batch_norm(assignment)\n        assignment = F.softmax(assignment, dim=1)\n        assignment = assignment[:, :self.cluster_size]\n\n        assignment = assignment.contiguous()\n        x = x.contiguous()\n\n        B, N, D, K = x.size(0), max_sample, self.feature_size, self.cluster_size\n        vlad = torch.empty((B, D, K), device=x.device, dtype=x.dtype)\n\n        clusters2_2d = self.clusters2.squeeze(0)\n        grid = (B * D, K)\n\n        vlad_compute_kernel[grid](\n            assignment, x, clusters2_2d, vlad,\n            B, N, D, K,\n            assignment.stride(0), assignment.stride(1),\n            x.stride(0), x.stride(1), x.stride(2),\n            clusters2_2d.stride(0), clusters2_2d.stride(1),\n            vlad.stride(0), vlad.stride(1), vlad.stride(2),\n            BLOCK_SIZE_N=128\n        )\n\n        vlad = F.normalize(vlad, dim=1)\n        vlad = vlad.reshape(-1, self.cluster_size * self.feature_size)\n        vlad = F.normalize(vlad)\n        return vlad\n\nbatch_size = 32\nnum_features = 100\nnum_clusters = 32\nfeature_size = 512\nghost_clusters = 0\n\ndef get_inputs():\n  return [torch.randn(batch_size, num_features, feature_size)]\n\ndef get_init_inputs():\n  return [num_clusters, feature_size, ghost_clusters]\n\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}