{"id": "6f7f0d7f-49de-4d4a-854d-6cc92796a339", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({\"BLOCK_C\": 4, \"BLOCK_HW\": 256}, num_warps=4),\n        triton.Config({\"BLOCK_C\": 4, \"BLOCK_HW\": 512}, num_warps=4),\n        triton.Config({\"BLOCK_C\": 8, \"BLOCK_HW\": 256}, num_warps=4),\n        triton.Config({\"BLOCK_C\": 8, \"BLOCK_HW\": 512}, num_warps=4),\n        triton.Config({\"BLOCK_C\": 16, \"BLOCK_HW\": 256}, num_warps=8),\n        triton.Config({\"BLOCK_C\": 16, \"BLOCK_HW\": 512}, num_warps=8),\n    ],\n    key=[\"N\", \"C\", \"H\", \"W\"],\n)\n@triton.jit\ndef _batchnorm_forward_kernel(\n    x_ptr,\n    out_ptr,\n    mean_ptr,\n    var_ptr,\n    weight_ptr,\n    bias_ptr,\n    N, C, H, W,\n    eps: tl.constexpr,\n    BLOCK_C: tl.constexpr,\n    BLOCK_HW: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_channel_blocks = tl.cdiv(C, BLOCK_C)\n    n = pid // num_channel_blocks\n    cb = pid % num_channel_blocks\n\n    c_start = cb * BLOCK_C\n    c_offsets = c_start + tl.arange(0, BLOCK_C)\n    c_mask = c_offsets < C\n    \n    mean_vals = tl.load(mean_ptr + c_offsets, mask=c_mask)\n    var_vals = tl.load(var_ptr + c_offsets, mask=c_mask)\n    weight_vals = tl.load(weight_ptr + c_offsets, mask=c_mask)\n    bias_vals = tl.load(bias_ptr + c_offsets, mask=c_mask)\n    \n    inv_std = tl.math.rsqrt(var_vals + eps)\n    scales = weight_vals * inv_std\n    bases = bias_vals - mean_vals * scales\n    \n    total_hw = H * W\n    base_ptr = x_ptr + n * C * total_hw + c_start * total_hw\n    out_base_ptr = out_ptr + n * C * total_hw + c_start * total_hw\n    \n    for hw_start in range(0, total_hw, BLOCK_HW):\n        hw_offsets = hw_start + tl.arange(0, BLOCK_HW)\n        hw_mask = hw_offsets < total_hw\n        \n        ptrs = base_ptr + hw_offsets\n        x_vals = tl.load(ptrs, mask=c_mask[:, None] & hw_mask[None, :], other=0.0)\n        \n        normalized = x_vals * scales[:, None] + bases[:, None]\n        tl.store(out_base_ptr + hw_offsets, normalized, \n                 mask=c_mask[:, None] & hw_mask[None, :])\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_features: int):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.ones(num_features))\n        self.bias = nn.Parameter(torch.zeros(num_features))\n        self.register_buffer('running_mean', torch.zeros(num_features))\n        self.register_buffer('running_var', torch.ones(num_features))\n        self.eps = 1e-5\n        self.num_features = num_features\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if self.training:\n            return torch.nn.functional.batch_norm(\n                x, self.running_mean, self.running_var, \n                self.weight, self.bias, training=True, \n                momentum=0, eps=self.eps\n            )\n        else:\n            x = x.contiguous()\n            out = torch.empty_like(x)\n            N, C, H, W = x.shape\n            grid = (N * triton.cdiv(C, 16),)\n            _batchnorm_forward_kernel[grid](\n                x, out, \n                self.running_mean, self.running_var, \n                self.weight, self.bias,\n                N, C, H, W, self.eps, \n                BLOCK_C=16, BLOCK_HW=512\n            )\n            return out\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "fe464de8-e1d7-49d0-b26c-55e1865f03b2", "generation": 2, "timestamp": 1754638540.3436313, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.431, "runtime_ms": 0.568, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.245, "speed_up": 0.431, "custom_timing": 0.568}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.431, "runtime_ms": 0.568, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.245, "speed_up": 0.431, "custom_timing": 0.568}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}