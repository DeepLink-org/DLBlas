{"id": "42f3613b-9f7c-4d1e-8ec4-276d81c39fe3", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _batchnorm_forward_kernel(\n    x_ptr,\n    out_ptr,\n    mean_ptr,\n    var_ptr,\n    weight_ptr,\n    bias_ptr,\n    N, C, H, W,\n    eps: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n    VECTOR_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    n = pid // C\n    c = pid % C\n    \n    mean_val = tl.load(mean_ptr + c)\n    var_val = tl.load(var_ptr + c)\n    weight_val = tl.load(weight_ptr + c)\n    bias_val = tl.load(bias_ptr + c)\n    \n    inv_std = tl.math.rsqrt(var_val + eps)\n    scale = weight_val * inv_std\n    \n    base_idx = n * C * H * W + c * H * W\n    base_ptr = x_ptr + base_idx\n    out_base_ptr = out_ptr + base_idx\n    \n    total_elements = H * W\n    total_vectors = (total_elements + VECTOR_SIZE - 1) // VECTOR_SIZE\n    \n    for start in range(0, total_vectors, BLOCK_SIZE):\n        vector_offsets = start + tl.arange(0, BLOCK_SIZE)\n        mask = vector_offsets < total_vectors\n        \n        element_offsets = vector_offsets * VECTOR_SIZE + tl.arange(0, VECTOR_SIZE)[None, :]\n        element_mask = mask[:, None] & (element_offsets < total_elements)\n        \n        x_vals = tl.load(base_ptr + element_offsets, mask=element_mask, other=0.0)\n        \n        centered = x_vals - mean_val\n        scaled = centered * scale\n        normalized = scaled + bias_val\n        \n        tl.store(out_base_ptr + element_offsets, normalized, mask=element_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, num_features: int):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.ones(num_features))\n        self.bias = nn.Parameter(torch.zeros(num_features))\n        self.register_buffer('running_mean', torch.zeros(num_features))\n        self.register_buffer('running_var', torch.ones(num_features))\n        self.eps = 1e-5\n        self.num_features = num_features\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if self.training:\n            return torch.nn.functional.batch_norm(\n                x, self.running_mean, self.running_var, \n                self.weight, self.bias, training=True, \n                momentum=0, eps=self.eps\n            )\n        else:\n            x = x.contiguous()\n            out = torch.empty_like(x)\n            N, C, H, W = x.shape\n            grid = (N * C,)\n            BLOCK_SIZE = 256\n            VECTOR_SIZE = 4\n            _batchnorm_forward_kernel[grid](\n                x, out, \n                self.running_mean, self.running_var, \n                self.weight, self.bias,\n                N, C, H, W, self.eps, \n                BLOCK_SIZE=BLOCK_SIZE,\n                VECTOR_SIZE=VECTOR_SIZE\n            )\n            return out\n\nbatch_size = 16\nfeatures = 64\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, features, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "48fefa17-f809-4f9f-936f-45990782796c", "generation": 2, "timestamp": 1754635869.44392, "iteration_found": 6, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.431, "runtime_ms": 0.568, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.245, "speed_up": 0.431, "custom_timing": 0.568}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.43, "runtime_ms": 0.57, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.245, "speed_up": 0.43, "custom_timing": 0.57}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}