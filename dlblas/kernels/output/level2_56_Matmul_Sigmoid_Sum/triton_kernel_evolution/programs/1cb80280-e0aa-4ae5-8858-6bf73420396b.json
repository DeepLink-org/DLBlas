{"id": "1cb80280-e0aa-4ae5-8858-6bf73420396b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    stride_x_batch,\n    stride_x_feature,\n    stride_weight_hidden,\n    stride_weight_feature,\n    stride_bias,\n    stride_out_batch,\n    BLOCK_INPUT: tl.constexpr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    \n    # Load input row with vectorized access\n    input_start = pid * stride_x_batch\n    input_offsets = input_start + tl.arange(0, BLOCK_INPUT) * stride_x_feature\n    mask = tl.arange(0, BLOCK_INPUT) < input_size\n    x_row = tl.load(x_ptr + input_offsets, mask=mask, other=0.0)\n    \n    row_sum = 0.0\n    \n    # Process hidden units in groups of 4\n    for j in range(0, hidden_size, 4):\n        # Load 4 weight rows with vectorized access\n        w_start0 = j * stride_weight_hidden\n        w_offsets0 = w_start0 + tl.arange(0, BLOCK_INPUT) * stride_weight_feature\n        w_row0 = tl.load(weight_ptr + w_offsets0, mask=mask, other=0.0)\n        \n        w_start1 = (j+1) * stride_weight_hidden\n        w_offsets1 = w_start1 + tl.arange(0, BLOCK_INPUT) * stride_weight_feature\n        w_row1 = tl.load(weight_ptr + w_offsets1, mask=mask, other=0.0)\n        \n        w_start2 = (j+2) * stride_weight_hidden\n        w_offsets2 = w_start2 + tl.arange(0, BLOCK_INPUT) * stride_weight_feature\n        w_row2 = tl.load(weight_ptr + w_offsets2, mask=mask, other=0.0)\n        \n        w_start3 = (j+3) * stride_weight_hidden\n        w_offsets3 = w_start3 + tl.arange(0, BLOCK_INPUT) * stride_weight_feature\n        w_row3 = tl.load(weight_ptr + w_offsets3, mask=mask, other=0.0)\n        \n        # Load 4 bias elements\n        b0 = tl.load(bias_ptr + (j+0) * stride_bias)\n        b1 = tl.load(bias_ptr + (j+1) * stride_bias)\n        b2 = tl.load(bias_ptr + (j+2) * stride_bias)\n        b3 = tl.load(bias_ptr + (j+3) * stride_bias)\n        \n        # Compute dot products + bias\n        dot0 = tl.sum(x_row * w_row0) + b0\n        dot1 = tl.sum(x_row * w_row1) + b1\n        dot2 = tl.sum(x_row * w_row2) + b2\n        dot3 = tl.sum(x_row * w_row3) + b3\n        \n        # Sigmoid activation and accumulation\n        s0 = 1.0 / (1.0 + tl.exp(-dot0))\n        s1 = 1.0 / (1.0 + tl.exp(-dot1))\n        s2 = 1.0 / (1.0 + tl.exp(-dot2))\n        s3 = 1.0 / (1.0 + tl.exp(-dot3))\n        row_sum += s0 + s1 + s2 + s3\n    \n    # Store reduced result\n    output_offset = pid * stride_out_batch\n    tl.store(output_ptr + output_offset, row_sum)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n    def forward(self, x):\n        batch_size = x.shape[0]\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n        \n        # Ensure contiguous memory layout\n        weight = self.linear.weight.contiguous()\n        bias = self.linear.bias.contiguous()\n        \n        # Calculate optimal block size\n        BLOCK_INPUT = triton.next_power_of_2(self.input_size)\n        \n        # Launch kernel\n        grid = (batch_size,)\n        _forward_kernel[grid](\n            x, weight, bias, output,\n            x.stride(0), x.stride(1),\n            weight.stride(0), weight.stride(1),\n            bias.stride(0),\n            output.stride(0),\n            BLOCK_INPUT,\n            self.input_size,\n            self.hidden_size,\n        )\n        return output\n\nbatch_size = 128\ninput_size = 10\nhidden_size = 20\n\ndef get_inputs():\n    return [torch.randn(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "5534fb74-2f3f-4eb4-8f6a-5016a4e15ea2", "generation": 1, "timestamp": 1754573751.6856933, "iteration_found": 10, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.867, "runtime_ms": 0.0557, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0483, "speed_up": 0.867, "custom_timing": 0.0557}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0529, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0483, "speed_up": 0.913, "custom_timing": 0.0529}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}