{"id": "6871d67b-ab43-42a9-8db2-170c45830f84", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=['batch_size'],\n)\n@triton.jit\ndef fused_forward_kernel(\n    x_ptr, w_ptr, b_ptr, out_ptr,\n    batch_size, input_size, hidden_size,\n    x_stride, w_stride,\n    BLOCK_IN: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n\n    # Load input row with masking\n    x_offset = pid * x_stride\n    x_vals = tl.load(\n        x_ptr + x_offset + tl.arange(0, BLOCK_IN),\n        mask=tl.arange(0, BLOCK_IN) < input_size,\n        other=0.0\n    )\n    \n    row_sum = 0.0\n    # Process hidden dimension in blocks\n    for j in range(0, hidden_size, BLOCK_H):\n        # Create offsets and mask for current block\n        h_offsets = j + tl.arange(0, BLOCK_H)\n        h_mask = h_offsets < hidden_size\n        \n        # Load weight block [BLOCK_H, BLOCK_IN]\n        w_ptrs = w_ptr + h_offsets[:, None] * w_stride + tl.arange(0, BLOCK_IN)[None, :]\n        w_block = tl.load(\n            w_ptrs,\n            mask=h_mask[:, None] & (tl.arange(0, BLOCK_IN)[None, :] < input_size),\n            other=0.0\n        )\n        \n        # Load bias block [BLOCK_H]\n        b_block = tl.load(b_ptr + h_offsets, mask=h_mask, other=0.0)\n        \n        # Compute dot products [BLOCK_H]\n        dots = tl.sum(x_vals * w_block, axis=1) + b_block\n        \n        # Vectorized sigmoid\n        sigmoids = 1.0 / (1.0 + tl.exp(-dots))\n        \n        # Accumulate with masking\n        row_sum += tl.sum(tl.where(h_mask, sigmoids, 0.0))\n    \n    # Store result\n    tl.store(out_ptr + pid, row_sum)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(input_size, hidden_size)\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n    def forward(self, x):\n        batch_size = x.shape[0]\n        weight = self.linear.weight\n        bias = self.linear.bias\n        \n        # Ensure contiguous memory layout\n        x = x.contiguous()\n        weight = weight.contiguous()\n        bias = bias.contiguous()\n        \n        # Precompute strides\n        x_stride = x.stride(0)\n        w_stride = weight.stride(0)\n        \n        # Allocate output\n        output = torch.empty(batch_size, device=x.device, dtype=torch.float32)\n        \n        # Launch kernel with optimized block sizes\n        grid = (batch_size,)\n        fused_forward_kernel[grid](\n            x, weight, bias, output,\n            batch_size, self.input_size, self.hidden_size,\n            x_stride, w_stride,\n            BLOCK_IN=triton.next_power_of_2(self.input_size),\n            BLOCK_H=128,  # Fixed block size for hidden dimension\n        )\n        \n        return output.view(-1, 1)\n\nbatch_size = 128\ninput_size = 10\nhidden_size = 20\n\ndef get_inputs():\n    return [torch.randn(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a1c5c897-0d9a-4a33-b6b7-cd281f905540", "generation": 2, "timestamp": 1754575338.8335586, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.69, "runtime_ms": 0.07, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0483, "speed_up": 0.69, "custom_timing": 0.07}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_56_Matmul_Sigmoid_Sum", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpwik_gkwu.py\", line 79, in forward\n    fused_forward_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\n    fn()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\n    self.fn.run(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 561, in run\n    bound_args, specialization, options = binder(*args, **kwargs)\nTypeError: dynamic_func() missing 1 required positional argument: 'META'\n", "runtime_error_name": "builtins.TypeError", "reference_timing_ms": 0.0483, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}