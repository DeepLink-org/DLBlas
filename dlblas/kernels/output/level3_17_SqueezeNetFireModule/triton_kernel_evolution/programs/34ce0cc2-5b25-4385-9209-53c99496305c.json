{"id": "34ce0cc2-5b25-4385-9209-53c99496305c", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass TritonConv1x1Relu(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels))\n        self.bias = nn.Parameter(torch.Tensor(out_channels))\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            if fan_in > 0:\n                bound = 1 / (fan_in ** 0.5)\n                nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        batch, in_channels, height, width = x.shape\n        n = height * width\n        out_channels = self.out_channels\n        \n        # Reshape input to (batch, in_channels, n)\n        x_2d = x.reshape(batch, in_channels, n)\n        output = torch.empty(batch, out_channels, n, device=x.device, dtype=x.dtype)\n        \n        # Grid configuration optimized for tensor cores\n        BLOCK_SIZE_N = 64  # Spatial block size\n        BLOCK_SIZE_C = 64   # Channel block size\n        BLOCK_SIZE_K = 32   # Reduction block size\n        \n        grid = (\n            triton.cdiv(n, BLOCK_SIZE_N),\n            batch,\n            triton.cdiv(out_channels, BLOCK_SIZE_C)\n        )\n        \n        # Launch optimized kernel\n        conv1x1_kernel[grid](\n            x_2d, self.weight, self.bias, output,\n            batch, in_channels, out_channels, n,\n            x_2d.stride(0), x_2d.stride(1), x_2d.stride(2),\n            self.weight.stride(0), self.weight.stride(1),\n            output.stride(0), output.stride(1), output.stride(2),\n            BLOCK_SIZE_N=BLOCK_SIZE_N, \n            BLOCK_SIZE_C=BLOCK_SIZE_C,\n            BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        \n        return output.reshape(batch, out_channels, height, width)\n\n@triton.jit\ndef conv1x1_kernel(\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    batch, in_channels, out_channels, n,\n    stride_input_b, stride_input_ic, stride_input_n,\n    stride_weight_oc, stride_weight_ic,\n    stride_output_b, stride_output_oc, stride_output_n,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_C: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_n = tl.program_id(0)   # Spatial block index\n    pid_b = tl.program_id(1)   # Batch index\n    pid_c = tl.program_id(2)   # Channel block index\n    \n    # Spatial offsets\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    # Channel offsets\n    offs_c = pid_c * BLOCK_SIZE_C + tl.arange(0, BLOCK_SIZE_C)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_N, BLOCK_SIZE_C), dtype=tl.float32)\n    \n    # Loop over reduction dimension (in_channels) in blocks\n    for k in range(0, in_channels, BLOCK_SIZE_K):\n        offs_k = k + tl.arange(0, BLOCK_SIZE_K)\n        \n        # Load input block [BLOCK_SIZE_N, BLOCK_SIZE_K]\n        input_mask = (offs_n[:, None] < n) & (offs_k[None, :] < in_channels)\n        input_vals = tl.load(\n            input_ptr + pid_b * stride_input_b + \n            offs_k[None, :] * stride_input_ic + \n            offs_n[:, None] * stride_input_n,\n            mask=input_mask,\n            other=0.0\n        )\n        \n        # Load weight block [BLOCK_SIZE_K, BLOCK_SIZE_C]\n        weight_mask = (offs_k[:, None] < in_channels) & (offs_c[None, :] < out_channels)\n        weight_vals = tl.load(\n            weight_ptr + \n            offs_k[:, None] * stride_weight_ic + \n            offs_c[None, :] * stride_weight_oc,\n            mask=weight_mask,\n            other=0.0\n        )\n        \n        # Matrix multiplication using tensor cores\n        acc += tl.dot(input_vals, weight_vals, allow_tf32=True)\n    \n    # Load bias block [BLOCK_SIZE_C]\n    bias_vals = tl.load(\n        bias_ptr + offs_c,\n        mask=offs_c < out_channels,\n        other=0.0\n    )\n    \n    # Apply bias and ReLU\n    result = tl.maximum(acc + bias_vals[None, :], 0.0)\n    \n    # Store result with output mask\n    output_mask = (offs_n[:, None] < n) & (offs_c[None, :] < out_channels)\n    output_offs = (\n        pid_b * stride_output_b + \n        offs_c[None, :] * stride_output_oc + \n        offs_n[:, None] * stride_output_n\n    )\n    tl.store(\n        output_ptr + output_offs,\n        result,\n        mask=output_mask\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, squeeze_channels, expand1x1_channels, expand3x3_channels):\n        super(ModelNew, self).__init__()\n        \n        # Use Triton for 1x1 convolutions (squeeze and expand1x1)\n        self.squeeze = TritonConv1x1Relu(in_channels, squeeze_channels)\n        self.expand1x1 = TritonConv1x1Relu(squeeze_channels, expand1x1_channels)\n        \n        # Keep original for 3x3 convolution\n        self.expand3x3 = nn.Conv2d(squeeze_channels, expand3x3_channels, kernel_size=3, padding=1)\n        self.expand3x3_activation = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        x = self.squeeze(x)\n        return torch.cat([\n            self.expand1x1(x),\n            self.expand3x3_activation(self.expand3x3(x))\n        ], 1)\n\n# Test code\nbatch_size = 10\nnum_input_features = 3\nnum_output_features = 64\nheight, width = 224, 224\nsqueeze_channels = 6\nexpand1x1_channels = 64\nexpand3x3_channels = 64\n\ndef get_inputs():\n    return [torch.randn(batch_size, num_input_features, height, width)]\n\ndef get_init_inputs():\n    return [num_input_features, squeeze_channels, expand1x1_channels, expand3x3_channels]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "73f9e87d-bf34-4b64-b5ef-a1960fe8ae19", "generation": 3, "timestamp": 1754586046.7071373, "iteration_found": 18, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 33.900000000000006, "speed_up": 1.139, "runtime_ms": 0.805, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.917, "speed_up": 1.139, "custom_timing": 0.805}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.042, "runtime_ms": 21.7, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.917, "speed_up": 0.042, "custom_timing": 21.7}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}