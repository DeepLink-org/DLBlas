{"id": "ac52ed74-dc66-4132-aac3-b84c9e5576ae", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _conv2d_forward(\n    # Tensors\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    # Input tensor dimensions\n    in_channels, height, width,\n    # Weight tensor dimensions\n    out_channels, kernel_h, kernel_w,\n    # Stride, padding, dilation\n    stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w,\n    # Input tensor strides\n    input_batch_stride, input_channel_stride, input_height_stride, input_width_stride,\n    # Weight tensor strides\n    weight_out_channel_stride, weight_in_channel_stride, weight_kernel_h_stride, weight_kernel_w_stride,\n    # Output tensor strides\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    # Output dimensions\n    height_out, width_out,\n    # Meta-parameters\n    BLOCK_SIZE: tl.constexpr,\n):\n    # Compute program ID\n    pid_boc = tl.program_id(0)\n    pid_y = tl.program_id(1)\n    pid_x = tl.program_id(2)\n    \n    # Calculate batch index and output channel\n    batch_idx = pid_boc // out_channels\n    oc = pid_boc % out_channels\n    \n    # Check spatial boundaries\n    if pid_y >= height_out or pid_x >= width_out:\n        return\n    \n    # Initialize accumulator\n    accum = 0.0\n    \n    # Precompute kernel volume and input strides\n    kernel_vol = kernel_h * kernel_w\n    inner_dim = in_channels * kernel_vol\n    \n    # Process inner dimension in blocks\n    num_blocks = tl.cdiv(inner_dim, BLOCK_SIZE)\n    for block_idx in range(num_blocks):\n        # Compute inner indices for this block\n        inner_indices = block_idx * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = inner_indices < inner_dim\n        \n        # Unravel indices to (ic, kh, kw)\n        ic = inner_indices // kernel_vol\n        khw = inner_indices % kernel_vol\n        kh = khw // kernel_w\n        kw = khw % kernel_w\n        \n        # Compute input positions\n        h_in = pid_y * stride_h + kh * dilation_h - padding_h\n        w_in = pid_x * stride_w + kw * dilation_w - padding_w\n        \n        # Check input boundaries\n        in_bounds = (h_in >= 0) & (h_in < height) & (w_in >= 0) & (w_in < width)\n        full_mask = mask & in_bounds\n        \n        # Calculate input pointer offset\n        input_offset = (batch_idx * input_batch_stride + \n                       ic * input_channel_stride + \n                       h_in * input_height_stride + \n                       w_in * input_width_stride)\n        \n        # Load input values\n        input_val = tl.load(input_ptr + input_offset, mask=full_mask, other=0.0)\n        \n        # Calculate weight pointer offset\n        weight_offset = (oc * weight_out_channel_stride + \n                        ic * weight_in_channel_stride + \n                        kh * weight_kernel_h_stride + \n                        kw * weight_kernel_w_stride)\n        \n        # Load weight values\n        weight_val = tl.load(weight_ptr + weight_offset, mask=mask, other=0.0)\n        \n        # Accumulate\n        accum += tl.sum(input_val * weight_val)\n    \n    # Add bias if present\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + oc)\n        accum += bias_val\n    \n    # Calculate output pointer\n    output_offset = (batch_idx * output_batch_stride + \n                     oc * output_channel_stride + \n                     pid_y * output_height_stride + \n                     pid_x * output_width_stride)\n    tl.store(output_ptr + output_offset, accum)\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        assert groups == 1, \"Only groups=1 supported in Triton kernel\"\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.groups = groups\n        \n        # Initialize weights\n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, *kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        # Initialize parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Compute output dimensions\n        h_in, w_in = x.shape[2], x.shape[3]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.stride\n        padding_h, padding_w = self.padding\n        dilation_h, dilation_w = self.dilation\n        \n        height_out = (h_in + 2 * padding_h - dilation_h * (kernel_h - 1) - 1) // stride_h + 1\n        width_out = (w_in + 2 * padding_w - dilation_w * (kernel_w - 1) - 1) // stride_w + 1\n        \n        # Create output tensor\n        output = torch.empty((x.shape[0], self.out_channels, height_out, width_out), \n                             device=x.device, dtype=x.dtype)\n        \n        # Launch kernel with optimized block size\n        grid = (x.shape[0] * self.out_channels, height_out, width_out)\n        _conv2d_forward[grid](\n            x, self.weight, self.bias, output,\n            self.in_channels, h_in, w_in,\n            self.out_channels, kernel_h, kernel_w,\n            stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            self.weight.stride(0), self.weight.stride(1), self.weight.stride(2), self.weight.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            height_out, width_out,\n            BLOCK_SIZE=32,  # Optimized inner block size\n        )\n        \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = (3, 5)  # Asymmetric kernel\nheight = 256\nwidth = 128  # Asymmetric input dimensions\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "97db3742-f4cb-470c-9a37-5eff5788dfaa", "generation": 2, "timestamp": 1754644824.950134, "iteration_found": 24, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.003, "runtime_ms": 44.3, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.155, "speed_up": 0.003, "custom_timing": 44.3}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.001, "runtime_ms": 175.0, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.155, "speed_up": 0.001, "custom_timing": 175.0}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}