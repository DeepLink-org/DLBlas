{"id": "ce1a2958-23b3-4e14-9356-6423c9c549b4", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef rnn_kernel(\n    x_ptr,\n    hidden_ptr,\n    W_x_ptr,\n    W_h_ptr,\n    bias_ptr,\n    output_ptr,\n    input_size,\n    hidden_size,\n    BLOCK_SIZE: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    batch_id = pid // hidden_size\n    col_id = pid % hidden_size\n\n    # Load bias element\n    bias_val = tl.load(bias_ptr + col_id)\n\n    # Initialize accumulator with bias\n    acc = bias_val\n\n    # Vectorized computation for input part\n    for k in range(0, input_size, BLOCK_K):\n        k_offsets = k + tl.arange(0, BLOCK_K)\n        k_mask = k_offsets < input_size\n\n        # Load x values\n        x_val = tl.load(x_ptr + batch_id * input_size + k_offsets, mask=k_mask, other=0.0)\n        # Load W_x values\n        W_x_val = tl.load(W_x_ptr + col_id * input_size + k_offsets, mask=k_mask, other=0.0)\n        acc += tl.sum(x_val * W_x_val)\n\n    # Vectorized computation for hidden part\n    for k in range(0, hidden_size, BLOCK_K):\n        k_offsets = k + tl.arange(0, BLOCK_K)\n        k_mask = k_offsets < hidden_size\n\n        # Load hidden values\n        h_val = tl.load(hidden_ptr + batch_id * hidden_size + k_offsets, mask=k_mask, other=0.0)\n        # Load W_h values\n        W_h_val = tl.load(W_h_ptr + col_id * hidden_size + k_offsets, mask=k_mask, other=0.0)\n        acc += tl.sum(h_val * W_h_val)\n\n    # Apply tanh activation\n    output = tl.tanh(acc)\n    tl.store(output_ptr + batch_id * hidden_size + col_id, output)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.hidden = torch.randn((batch_size, hidden_size))\n        \n        # Define the RNN cell components\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.tanh = nn.Tanh()\n        \n        # Pre-split weights for Triton kernel\n        self.W_x = self.i2h.weight[:, :input_size].contiguous()\n        self.W_h = self.i2h.weight[:, input_size:].contiguous()\n        self.bias = self.i2h.bias.contiguous()\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        self.hidden = self.hidden.to(x.device)\n        \n        # Ensure tensors are contiguous\n        x_contig = x.contiguous()\n        hidden_contig = self.hidden.contiguous()\n        output = torch.empty_like(self.hidden)\n        \n        # Configure kernel launch\n        n_elements = batch_size * hidden_size\n        grid = (n_elements,)\n        \n        # Launch kernel with optimized block sizes\n        rnn_kernel[grid](\n            x_contig, \n            hidden_contig, \n            self.W_x, \n            self.W_h, \n            self.bias, \n            output,\n            self.input_size,\n            self.hidden_size,\n            BLOCK_SIZE=hidden_size,\n            BLOCK_K=64\n        )\n        \n        self.hidden = output\n        return self.hidden\n\nbatch_size = 8\ninput_size = 1024\nhidden_size = 256\noutput_size = 128\nsequence_length = 256\n\ndef get_inputs():\n    return [torch.randn(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, output_size]\n\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "5cfa8051-3c2c-4c30-9fcb-9fbe5c442999", "generation": 1, "timestamp": 1754593256.0049133, "iteration_found": 3, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_34_VanillaRNNHidden", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpwx2mzkoz.py\", line 87, in forward\n    rnn_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language' has no attribute 'tanh'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 0.0803, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.105, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0803, "speed_up": 0.765, "custom_timing": 0.105}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}