{"id": "9b846709-c989-482e-af0c-9e64292cc78f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    stride_x0, stride_x1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * stride_x0\n    num_chunks = tl.cdiv(in_features, BLOCK_SIZE)\n    acc = 0.0\n    for chunk in range(num_chunks):\n        offs = chunk * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_ptrs = x_ptr + row_start + offs * stride_x1\n        w_ptrs = w_ptr + offs\n        x_vals = tl.load(x_ptrs, mask=mask, other=0.0)\n        w_vals = tl.load(w_ptrs, mask=mask, other=0.0)\n        acc += tl.sum(x_vals * w_vals)\n    \n    bias = tl.load(b_ptr)\n    acc += bias\n    \n    out_ptr_row = out_ptr + pid * stride_out0\n    tl.store(out_ptr_row, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        total_weight = self.linear.weight.sum(dim=0)\n        if self.linear.bias is not None:\n            total_bias = self.linear.bias.sum().view(1)\n        else:\n            total_bias = torch.zeros(1, device=x.device, dtype=x.dtype)\n        \n        x = x.contiguous()\n        total_weight = total_weight.contiguous()\n        batch_size, in_features = x.shape\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size,)\n        # Optimized block size: next power-of-two capped at 1024\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n        \n        _forward_kernel[grid](\n            x, total_weight, total_bias, output,\n            batch_size, in_features,\n            x.stride(0), x.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "6be1e3e1-2b9c-44ce-8de6-e1c374f59502", "generation": 4, "timestamp": 1754569093.5859442, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 120.0, "speed_up": 2.0, "runtime_ms": 0.0805, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.161, "speed_up": 2.0, "custom_timing": 0.0805}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 132.7, "speed_up": 2.127, "runtime_ms": 0.0757, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.161, "speed_up": 2.127, "custom_timing": 0.0757}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 1.0000\n- score: 132.7000\n- speed_up: 2.1270\n- runtime_ms: 0.0757\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 2.127, 'custom_timing': 0.0757}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: score, speed_up. Consider continuing with similar changes.\n- Metrics showing regression: runtime_ms. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 113.7000, speed_up: 1.9370, runtime_ms: 0.0831, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 1.937, 'custom_timing': 0.0831}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 131.8000, speed_up: 2.1180, runtime_ms: 0.0760, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 2.118, 'custom_timing': 0.076}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 132.7000, speed_up: 2.1270, runtime_ms: 0.0757, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 2.127, 'custom_timing': 0.0757}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 132.7000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    stride_x0, stride_x1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * stride_x0\n    num_chunks = tl.cdiv(in_features, BLOCK_SIZE)\n    acc = 0.0\n    for chunk in range(num_chunks):\n        offs = chunk * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_ptrs = x_ptr + row_start + offs * stride_x1\n        w_ptrs = w_ptr + offs\n        x_vals = tl.load(x_ptrs, mask=mask, other=0.0)\n        w_vals = tl.load(w_ptrs, mask=mask, other=0.0)\n        acc += tl.sum(x_vals * w_vals)\n    \n    bias = tl.load(b_ptr)\n    acc += bias\n    \n    out_ptr_row = out_ptr + pid * stride_out0\n    tl.store(out_ptr_row, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        total_weight = self.linear.weight.sum(dim=0)\n        if self.linear.bias is not None:\n            total_bias = self.linear.bias.sum().view(1)\n        else:\n            total_bias = torch.zeros(1, device=x.device, dtype=x.dtype)\n        \n        x = x.contiguous()\n        total_weight = total_weight.contiguous()\n        batch_size, in_features = x.shape\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size,)\n        BLOCK_SIZE = 1024\n        _forward_kernel[grid](\n            x, total_weight, total_bias, output,\n            batch_size, in_features,\n            x.stride(0), x.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (132.7000), Performs well on speed_up (2.1270), Performs well on runtime_ms (0.0757), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 2.127, 'custom_timing': 0.0757})\n\n\n### Program 2 (Score: 131.8000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_col_sum_ptr,\n    b_sum_ptr,  # Changed to pointer type\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    row_start = pid * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_row = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_row = tl.load(w_col_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_row * w_row)\n    \n    # Properly load scalar value from pointer\n    b_sum = tl.load(b_sum_ptr)\n    result = dot + b_sum\n    \n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        W_col_sum = self.linear.weight.sum(0)\n        b_sum = self.linear.bias.sum()\n        \n        x = x.contiguous()\n        output = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        \n        if x.numel() > 0:\n            BLOCK_SIZE = triton.next_power_of_2(in_features)\n            grid = (x.shape[0],)\n            _forward_kernel[grid](\n                x, \n                W_col_sum, \n                b_sum.view(1),  # Ensure scalar is passed as 1-element tensor\n                output, \n                in_features, \n                BLOCK_SIZE\n            )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (131.8000), Performs well on speed_up (2.1180), Performs well on runtime_ms (0.0760), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 2.118, 'custom_timing': 0.076})\n\n\n### Program 3 (Score: 113.7000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_col_sum_ptr,\n    b_sum,\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    row_start = pid * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_row = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_row = tl.load(w_col_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_row * w_row)\n    result = dot + b_sum\n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        in_features = x.shape[1]\n        W_col_sum = self.linear.weight.sum(0)\n        b_sum_val = self.linear.bias.sum().item()\n        \n        x = x.contiguous()\n        output = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        \n        if x.numel() > 0:\n            BLOCK_SIZE = triton.next_power_of_2(in_features)\n            grid = (x.shape[0],)\n            _forward_kernel[grid](\n                x, W_col_sum, b_sum_val, output, \n                in_features, BLOCK_SIZE\n            )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (113.7000), Performs well on speed_up (1.9370), Performs well on runtime_ms (0.0831), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.161, 'speed_up': 1.937, 'custom_timing': 0.0831})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 101.7000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport triton\nimport triton.language as tl\nimport torch.nn as nn\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_sum_ptr,\n    b_sum,\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    row_start = row_idx * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_vals = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_vals = tl.load(w_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_vals * w_vals)\n    result = dot + b_sum\n    tl.store(output_ptr + row_idx, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.in_features = in_features\n\n    def forward(self, x):\n        w_sum = self.linear.weight.sum(dim=0).contiguous()\n        b_sum_val = self.linear.bias.sum().item()\n\n        output_vec = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        if x.shape[0] > 0:\n            grid = (x.shape[0],)\n            BLOCK_SIZE = triton.next_power_of_2(self.in_features)\n            _forward_kernel[grid](\n                x.contiguous(), \n                w_sum, \n                b_sum_val, \n                output_vec, \n                self.in_features, \n                BLOCK_SIZE=BLOCK_SIZE\n            )\n        output = output_vec.unsqueeze(1)\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_matvec_kernel(\n    x_ptr,\n    w_ptr,\n    bias,\n    output_ptr,\n    batch_size,\n    in_features,\n    stride_x,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    if row_idx >= batch_size:\n        return\n    \n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < in_features\n    \n    x_start = row_idx * stride_x\n    x_vals = tl.load(x_ptr + x_start + col_offsets, mask=mask, other=0.0)\n    w_vals = tl.load(w_ptr + col_offsets, mask=mask, other=0.0)\n    \n    product = x_vals * w_vals\n    dot_result = tl.sum(product, axis=0)\n    dot_result += bias\n    \n    tl.store(output_ptr + row_idx, dot_result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.in_features = in_features\n        \n        with torch.no_grad():\n            self.weight_sum = self.linear.weight.sum(dim=0)\n            self.bias_sum = self.linear.bias.sum()\n\n    def forward(self, x):\n        x = x.contiguous()\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, device=x.device, dtype=x.dtype)\n        \n        P2 = triton.next_power_of_2(self.in_features)\n        grid = (batch_size,)\n        \n        fused_matvec_kernel[grid](\n            x,\n            self.weight_sum,\n            self.bias_sum,\n            output,\n            batch_size,\n            self.in_features,\n            x.stride(0),\n            BLOCK_SIZE=P2\n        )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_matvec_kernel(\n    x_ptr,\n    w_ptr,\n    bias,\n    output_ptr,\n    batch_size,\n    in_features,\n    stride_x,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    if row_idx >= batch_size:\n        return\n    \n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < in_features\n    \n    x_start = row_idx * stride_x\n    x_vals = tl.load(x_ptr + x_start + col_offsets, mask=mask, other=0.0)\n    w_vals = tl.load(w_ptr + col_offsets, mask=mask, other=0.0)\n    \n    product = x_vals * w_vals\n    dot_result = tl.sum(product, axis=0)\n    dot_result += bias\n    \n    tl.store(output_ptr + row_idx, dot_result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.in_features = in_features\n        \n        with torch.no_grad():\n            self.weight_sum = self.linear.weight.sum(dim=0)\n            self.bias_sum = self.linear.bias.sum()\n\n    def forward(self, x):\n        x = x.contiguous()\n        batch_size, _ = x.shape\n        output = torch.empty(batch_size, device=x.device, dtype=x.dtype)\n        \n        P2 = triton.next_power_of_2(self.in_features)\n        grid = (batch_size,)\n        \n        fused_matvec_kernel[grid](\n            x,\n            self.weight_sum,\n            self.bias_sum,\n            output,\n            batch_size,\n            self.in_features,\n            x.stride(0),\n            BLOCK_SIZE=P2\n        )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport triton\nimport triton.language as tl\nimport torch.nn as nn\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr, \n    w_sum_ptr,\n    b_sum,\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    acc = 0.0\n    for k in range(0, in_features, BLOCK_SIZE):\n        offsets = k + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < in_features\n        x_vals = tl.load(x_ptr + row_idx * in_features + offsets, mask=mask, other=0.0)\n        w_vals = tl.load(w_sum_ptr + offsets, mask=mask, other=0.0)\n        acc += tl.sum(x_vals * w_vals)\n    acc += b_sum\n    tl.store(output_ptr + row_idx, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        w_sum = self.linear.weight.sum(dim=0)\n        b_sum = self.linear.bias.sum()\n\n        output_vec = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        if x.shape[0] > 0:\n            grid = (x.shape[0],)\n            BLOCK_SIZE = 128\n            _forward_kernel[grid](x, w_sum, b_sum, output_vec, in_features, BLOCK_SIZE=BLOCK_SIZE)\n        output = output_vec.unsqueeze(1)\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 101.7000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport triton\nimport triton.language as tl\nimport torch.nn as nn\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_sum_ptr,\n    b_sum,\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    row_idx = tl.program_id(0)\n    row_start = row_idx * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_vals = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_vals = tl.load(w_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_vals * w_vals)\n    result = dot + b_sum\n    tl.store(output_ptr + row_idx, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.in_features = in_features\n\n    def forward(self, x):\n        w_sum = self.linear.weight.sum(dim=0).contiguous()\n        b_sum_val = self.linear.bias.sum().item()\n\n        output_vec = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        if x.shape[0] > 0:\n            grid = (x.shape[0],)\n            BLOCK_SIZE = triton.next_power_of_2(self.in_features)\n            _forward_kernel[grid](\n                x.contiguous(), \n                w_sum, \n                b_sum_val, \n                output_vec, \n                self.in_features, \n                BLOCK_SIZE=BLOCK_SIZE\n            )\n        output = output_vec.unsqueeze(1)\n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 4 (Score: 131.8000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_col_sum_ptr,\n    b_sum_ptr,  # Changed to pointer type\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    row_start = pid * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_row = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_row = tl.load(w_col_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_row * w_row)\n    \n    # Properly load scalar value from pointer\n    b_sum = tl.load(b_sum_ptr)\n    result = dot + b_sum\n    \n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        W_col_sum = self.linear.weight.sum(0)\n        b_sum = self.linear.bias.sum()\n        \n        x = x.contiguous()\n        output = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        \n        if x.numel() > 0:\n            BLOCK_SIZE = triton.next_power_of_2(in_features)\n            grid = (x.shape[0],)\n            _forward_kernel[grid](\n                x, \n                W_col_sum, \n                b_sum.view(1),  # Ensure scalar is passed as 1-element tensor\n                output, \n                in_features, \n                BLOCK_SIZE\n            )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_col_sum_ptr,\n    b_sum,\n    output_ptr,\n    in_features,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    row_start = pid * in_features\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < in_features\n\n    x_row = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    w_row = tl.load(w_col_sum_ptr + tl.arange(0, BLOCK_SIZE), mask=mask, other=0.0)\n\n    dot = tl.sum(x_row * w_row)\n    result = dot + b_sum\n    tl.store(output_ptr + pid, result)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        W_col_sum = self.linear.weight.sum(0)\n        b_sum = self.linear.bias.sum()\n        \n        x = x.contiguous()\n        output = torch.empty(x.shape[0], device=x.device, dtype=x.dtype)\n        \n        if x.numel() > 0:\n            BLOCK_SIZE = triton.next_power_of_2(in_features)\n            grid = (x.shape[0],)\n            _forward_kernel[grid](\n                x, W_col_sum, b_sum, output, \n                in_features, BLOCK_SIZE\n            )\n        \n        return output.unsqueeze(1)\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    stride_x0, stride_x1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * stride_x0\n    num_chunks = tl.cdiv(in_features, BLOCK_SIZE)\n    acc = 0.0\n    for chunk in range(num_chunks):\n        offs = chunk * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_ptrs = x_ptr + row_start + offs * stride_x1\n        w_ptrs = w_ptr + offs\n        x_vals = tl.load(x_ptrs, mask=mask, other=0.0)\n        w_vals = tl.load(w_ptrs, mask=mask, other=0.0)\n        acc += tl.sum(x_vals * w_vals)\n    \n    bias = tl.load(b_ptr)\n    acc += bias\n    \n    out_ptr_row = out_ptr + pid * stride_out0\n    tl.store(out_ptr_row, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        total_weight = self.linear.weight.sum(dim=0)\n        if self.linear.bias is not None:\n            total_bias = self.linear.bias.sum().view(1)\n        else:\n            total_bias = torch.zeros(1, device=x.device, dtype=x.dtype)\n        \n        x = x.contiguous()\n        total_weight = total_weight.contiguous()\n        batch_size, in_features = x.shape\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size,)\n        BLOCK_SIZE = 1024\n        _forward_kernel[grid](\n            x, total_weight, total_bias, output,\n            batch_size, in_features,\n            x.stride(0), x.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program which is already performing well (score 132.7, speed_up 2.127). \n However, the task is to rewrite to improve performance.\n\n The current kernel uses a loop over chunks (each of BLOCK_SIZE) to compute the dot product for one row.\n The BLOCK_SIZE is fixed at 1024. Since the in_features is only 10 (from the example), the loop runs only one chunk (with BLOCK_SIZE=1024, but only 10 elements are loaded).\n\n Potential improvements:\n 1. We note that the problem size (in_features=10) is very small. Therefore, we can avoid the loop and use a single block that covers the entire row.\n    However, the kernel is written to handle any in_features by chunking. But for small in_features, we can adjust the block size to be the next power of two of in_features to avoid looping.\n\n 2. The current kernel uses a fixed BLOCK_SIZE of 1024. This might be inefficient for small in_features because:\n    - We are loading 1024 elements per chunk but only 10 are used (masked). This leads to wasted memory bandwidth and computation.\n\n 3. We can set BLOCK_SIZE to be the next power of two of in_features, which in this case is 16 (since 2^4=16). Then we only need one chunk.\n\n 4. Additionally, we can avoid the loop entirely when the row fits in one block. We can compute the block size as the minimum between 1024 and the next power of two of in_features? \n    But note: the example has in_features=10, so we can set BLOCK_SIZE to 16 and remove the loop.\n\n 5. However, the kernel must be general for any in_features. So we can keep the loop but set BLOCK_SIZE to a more appropriate value (like the next power of two) and then use that.\n\n 6. Alternatively, we can change the kernel to not use a loop and instead have a single block that loads the entire row. But we must be cautious because the maximum block size in Triton is 1024 per dimension? \n    And if in_features is larger than 1024, we must loop. So we can do:\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n    But note: the example in_features=10 -> BLOCK_SIZE=16, which is less than 1024.\n\n 7. We can change the kernel to use a block size that is the next power of two of in_features, but capped at 1024. Then we only need one chunk if in_features <= 1024? Actually, the next power of two might be 2048 for in_features=2000, so we cap at 1024.\n\n 8. Alternatively, we can set BLOCK_SIZE as a tunable parameter and let Triton autotune it. But the problem says the grid configuration is locked. However, we are allowed to change the block size in the kernel.\n\n 9. Let's restructure the kernel to:\n    - Use a block size that is the next power of two of the row size, but capped at 1024. Then we can avoid the loop if the row fits in one block? Actually, we cannot avoid the loop entirely for large rows because the block size is limited by hardware (1024). So we keep the loop.\n\n 10. However, for the given problem (in_features=10) we are using 1024 as block size and only one chunk. We can make it 16, which would reduce the number of memory transactions and the amount of masked elements.\n\n 11. We can change the kernel to use a block size that is the next power of two of the row size (but not exceeding 1024) and then adjust the number of chunks accordingly.\n\n 12. But note: the current kernel already uses a loop and the block size is passed as a constant. We can change the way we set BLOCK_SIZE in the call from the host.\n\n 13. In the host code, we are setting BLOCK_SIZE=1024. We can change that to:\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n    However, if in_features is 2000, then the next power of two is 2048, so we cap at 1024. Then we still need multiple chunks.\n\n 14. Alternatively, we can set BLOCK_SIZE to 1024 for large in_features and a smaller block for small in_features. This might help for small rows.\n\n 15. Let's change the host code to set BLOCK_SIZE to the next power of two of in_features, but capped at 1024.\n\n 16. Also, we can note that the current kernel does not use shared memory or any tensor cores. Since the operation is a dot product, we are limited by memory bandwidth.\n\n 17. Another idea: we can use vectorized loads and stores. Currently, we are loading one element per thread. We can load multiple elements per thread by having a smaller block and then each thread handling multiple elements? But note: the block size is set to the chunk size.\n\n 18. However, the problem size is small (only 10 elements per row). We can have one thread process the entire row? But the maximum number of threads per block is 1024, and we have 128 rows (batch_size=128). We are launching one block per row. So we can have one block per row and within the block, we use a single thread? That would be inefficient.\n\n 19. Alternatively, we can use a block of 16 threads for one row? Then we can split the 10 elements among 16 threads? But that would require synchronization and reduction within the block.\n\n 20. The current kernel does the entire row in one block? Actually, the kernel is launched with grid = (batch_size,). So we have one program per row. And within that program, we are looping over chunks. Each chunk is processed by a single thread? Actually, the chunk is loaded by a vector of BLOCK_SIZE elements using tl.arange(0, BLOCK_SIZE). So it's a single thread doing the entire row? \n\n    That is not efficient because a single thread is doing all the work for one row. We are not using multiple threads per row.\n\n 21. We can restructure the kernel to use multiple threads per row. For example, we can have:\n\n        pid = tl.program_id(0)   # row index\n        num_threads = ...         # threads per row\n\n    But note: the grid is set to (batch_size,) and we cannot change the grid configuration (it's locked). So we cannot easily launch more threads.\n\n 22. Alternatively, we can change the grid to be (batch_size * num_blocks_per_row) and then use a two-dimensional grid? But the constraint says: \"NEVER modify grid configuration\". So we cannot.\n\n 23. Therefore, we are stuck with one thread per row? That is inefficient for large in_features. But for small in_features (10) it might be acceptable.\n\n 24. However, the current kernel uses a loop over chunks. For in_features=10, it does one chunk of 1024, but only 10 elements are loaded. The rest is masked. This is inefficient because we are issuing a load for 1024 elements but only 10 are used.\n\n 25. We can change the BLOCK_SIZE to be the exact in_features? But then if in_features is not a power of two, it might be inefficient? And also, if in_features is large (like 2000) we would have to do two chunks of 1024 and 976? So we keep the next power of two but capped at 1024.\n\n 26. Let's change the host code to set BLOCK_SIZE to:\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n    Then for in_features=10, BLOCK_SIZE=16. This reduces the wasted memory bandwidth.\n\n 27. Also, we can note that the kernel currently uses:\n\n        offs = chunk * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n\n    and then the mask is `offs < in_features`. This is correct.\n\n 28. We can also try to use vectorized loads. The Triton documentation suggests that vectorized loads can improve memory efficiency. We can try to load 128-bit (i.e., 4 floats) at a time? But note: the data type is float, and we are loading contiguous elements.\n\n    We can change:\n\n        x_vals = tl.load(x_ptrs, mask=mask, other=0.0)\n        w_vals = tl.load(w_ptrs, mask=mask, other=0.0)\n\n    to:\n\n        # We assume BLOCK_SIZE is divisible by 4? If not, we cannot vectorize the entire block.\n        # Instead, we can break the block into vectors of 4.\n\n    But we are constrained by the fact that the starting offset of each chunk might not be aligned? We can require that the in_features is a multiple of 4? But we cannot.\n\n 29. Alternatively, we can use the `cache` option in tl.load to cache the data in L1 or L2? But without more information, it might not help.\n\n 30. Given the above, the most straightforward improvement is to change the BLOCK_SIZE to be the next power of two of in_features (capped at 1024) to minimize wasted memory transactions.\n\n 31. Let's change the host code to set:\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n 32. Also, we can change the kernel to use a more efficient reduction? Currently, we are doing:\n\n        acc += tl.sum(x_vals * w_vals)\n\n    This is a reduction across the entire vector in the chunk. Then we do a scalar accumulation across chunks.\n\n    We can use a more efficient parallel reduction within the chunk? But note: the chunk is processed by a single thread? Because the entire chunk is loaded by a single thread (via tl.arange). So we cannot parallelize within the chunk.\n\n 33. Since we are limited to one thread per row, we cannot do much about the reduction.\n\n 34. Another idea: we can preload the weight vector into shared memory? But we are processing one row at a time and the weight vector is the same for all rows. However, we are using one thread per row and the grid is (batch_size,). There is no shared memory between different rows (each row is independent). And within a row, we are only using one thread. So shared memory is not helpful.\n\n 35. Therefore, the main improvement is to set the BLOCK_SIZE appropriately.\n\n 36. We change the host code in the forward function:\n\n        # Instead of fixed BLOCK_SIZE=1024, set:\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n 37. We must be cautious: if in_features is 0, then next_power_of_2 is 0, but we need at least 1? However, the example has in_features=10.\n\n 38. Let's write the code accordingly.\n\n 39. Also, note that the kernel uses a loop that runs `num_chunks = tl.cdiv(in_features, BLOCK_SIZE)`. This is correct.\n\n 40. We will change only the host code setting of BLOCK_SIZE.\n\n 41. Alternatively, we can change the kernel to use a smaller block size by default? But the block size is passed as a parameter.\n\n 42. We change:\n\n        BLOCK_SIZE = 1024   # in the host code\n\n    to:\n\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n 43. Let's see the effect: for in_features=10, BLOCK_SIZE becomes 16. Then the kernel loads 16 elements per chunk, but only 10 are used. This is better than 1024.\n\n 44. Also, we can try to set the block size to the exact in_features? But if in_features is not a power of two, it might be inefficient. However, the next power of two is the standard approach.\n\n 45. We'll make that change.\n\n 46. Additionally, we can consider using the autotune feature to select the best block size? But the problem size is fixed (in_features=10) and we are only running once. So we can do without.\n\n 47. Let's update the code accordingly.\n\n 48. We note that the current program has a high score (132.7) and we are making a change that reduces the amount of memory loaded per row. This should improve performance for the given problem.\n\n 49. We change the host code in the forward function:\n\n        # Replace:\n        #   BLOCK_SIZE = 1024\n        # with:\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n 50. We must import triton in the host if we haven't? Actually, we already have `import triton`.\n\n 51. Let's write the updated code.\n\n 52. Also, note that for very large in_features (like 1000000), we are still using a block size of 1024 and looping 1000000/1024 ~ 977 times. This is acceptable.\n\n 53. We output the entire block.\n\n 54. We are only changing one line in the host code.\n\n 55. But note: the kernel itself remains unchanged.\n\n 56. We write the new code:\n\n        ... [same as before until the forward function] ...\n\n        batch_size, in_features = x.shape\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n\n        grid = (batch_size,)\n        # Change: set BLOCK_SIZE to next_power_of_2(in_features) but capped at 1024\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n\n        _forward_kernel[grid]( ... )\n\n 57. We hope that this reduces the runtime for small in_features (like 10) by reducing the amount of memory loaded per row.\n\n 58. Since the current runtime for the custom kernel is 0.0757 ms, and the reference is 0.161 ms, we hope to get an even lower runtime.\n\n 59. We output the entire code block.\n\n 60. IMPORTANT: We are only allowed to output the code block between EVOLVE-BLOCK-START and EVOLVE-BLOCK-END.\n\n Let's write the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    out_ptr,\n    batch_size,\n    in_features,\n    stride_x0, stride_x1,\n    stride_out0, stride_out1,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * stride_x0\n    num_chunks = tl.cdiv(in_features, BLOCK_SIZE)\n    acc = 0.0\n    for chunk in range(num_chunks):\n        offs = chunk * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n        mask = offs < in_features\n        x_ptrs = x_ptr + row_start + offs * stride_x1\n        w_ptrs = w_ptr + offs\n        x_vals = tl.load(x_ptrs, mask=mask, other=0.0)\n        w_vals = tl.load(w_ptrs, mask=mask, other=0.0)\n        acc += tl.sum(x_vals * w_vals)\n    \n    bias = tl.load(b_ptr)\n    acc += bias\n    \n    out_ptr_row = out_ptr + pid * stride_out0\n    tl.store(out_ptr_row, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n\n    def forward(self, x):\n        total_weight = self.linear.weight.sum(dim=0)\n        if self.linear.bias is not None:\n            total_bias = self.linear.bias.sum().view(1)\n        else:\n            total_bias = torch.zeros(1, device=x.device, dtype=x.dtype)\n        \n        x = x.contiguous()\n        total_weight = total_weight.contiguous()\n        batch_size, in_features = x.shape\n        output = torch.empty(batch_size, 1, device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size,)\n        # Optimized block size: next power-of-two capped at 1024\n        BLOCK_SIZE = min(1024, triton.next_power_of_2(in_features))\n        \n        _forward_kernel[grid](\n            x, total_weight, total_bias, output,\n            batch_size, in_features,\n            x.stride(0), x.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 10\nout_features = 5\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}