{"id": "deaa31a5-d239-49d5-915e-45c73ec6798d", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef group_norm_kernel(\n    x_ptr,\n    y_ptr,\n    gamma_ptr,\n    beta_ptr,\n    n_channels,\n    n_groups,\n    eps,\n    H,\n    W,\n    stride_b,\n    stride_h,\n    stride_w,\n    stride_c,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n    BLOCK_C: tl.constexpr\n):\n    pid = tl.program_id(0)\n    group_idx = pid % n_groups\n    batch_idx = pid // n_groups\n    channels_per_group = n_channels // n_groups\n    start_c = group_idx * channels_per_group\n\n    # Accumulators for statistics\n    mean_acc = 0.0\n    var_acc = 0.0\n    count_acc = 0.0\n\n    # First pass: compute mean and variance\n    for block_h in range(0, H, BLOCK_H):\n        h_offsets = block_h + tl.arange(0, BLOCK_H)\n        h_mask = h_offsets < H\n        \n        for block_w in range(0, W, BLOCK_W):\n            w_offsets = block_w + tl.arange(0, BLOCK_W)\n            w_mask = w_offsets < W\n            \n            spatial_mask = h_mask[:, None] & w_mask[None, :]\n            spatial_count = tl.sum(tl.where(spatial_mask, 1.0, 0.0))\n            \n            # Compute base pointer offset\n            base_offset = (\n                batch_idx * stride_b + \n                block_h * stride_h + \n                block_w * stride_w + \n                start_c * stride_c\n            )\n            \n            # 3D offsets: [BLOCK_H, BLOCK_W, BLOCK_C]\n            h_off = tl.reshape(h_offsets, (BLOCK_H, 1, 1)) * stride_h\n            w_off = tl.reshape(w_offsets, (1, BLOCK_W, 1)) * stride_w\n            c_off = tl.reshape(tl.arange(0, BLOCK_C), (1, 1, BLOCK_C)) * stride_c\n            offsets = base_offset + h_off + w_off + c_off\n            \n            # Create mask and load data\n            c_mask = tl.arange(0, BLOCK_C) < channels_per_group\n            full_mask = spatial_mask[:, :, None] & c_mask[None, None, :]\n            x_vals = tl.load(x_ptr + offsets, mask=full_mask, other=0.0)\n            \n            # Update accumulators\n            block_sum = tl.sum(x_vals)\n            block_sq_sum = tl.sum(x_vals * x_vals)\n            block_count = spatial_count * BLOCK_C\n            \n            mean_acc += block_sum\n            var_acc += block_sq_sum\n            count_acc += block_count\n\n    # Compute group statistics\n    mean = mean_acc / count_acc\n    variance = var_acc / count_acc - mean * mean\n    inv_std = 1.0 / tl.sqrt(variance + eps)\n    \n    # Load scale/shift parameters\n    gamma = tl.load(gamma_ptr + start_c + tl.arange(0, BLOCK_C))\n    beta = tl.load(beta_ptr + start_c + tl.arange(0, BLOCK_C))\n\n    # Second pass: normalize and store\n    for block_h in range(0, H, BLOCK_H):\n        h_offsets = block_h + tl.arange(0, BLOCK_H)\n        h_mask = h_offsets < H\n        \n        for block_w in range(0, W, BLOCK_W):\n            w_offsets = block_w + tl.arange(0, BLOCK_W)\n            w_mask = w_offsets < W\n            \n            spatial_mask = h_mask[:, None] & w_mask[None, :]\n            \n            # Compute base pointer offset\n            base_offset = (\n                batch_idx * stride_b + \n                block_h * stride_h + \n                block_w * stride_w + \n                start_c * stride_c\n            )\n            \n            # 3D offsets: [BLOCK_H, BLOCK_W, BLOCK_C]\n            h_off = tl.reshape(h_offsets, (BLOCK_H, 1, 1)) * stride_h\n            w_off = tl.reshape(w_offsets, (1, BLOCK_W, 1)) * stride_w\n            c_off = tl.reshape(tl.arange(0, BLOCK_C), (1, 1, BLOCK_C)) * stride_c\n            offsets = base_offset + h_off + w_off + c_off\n            \n            # Create mask and load data\n            c_mask = tl.arange(0, BLOCK_C) < channels_per_group\n            full_mask = spatial_mask[:, :, None] & c_mask[None, None, :]\n            x_vals = tl.load(x_ptr + offsets, mask=full_mask, other=0.0)\n            \n            # Normalize and store\n            normalized = (x_vals - mean) * inv_std\n            y_vals = normalized * gamma + beta\n            tl.store(y_ptr + offsets, y_vals, mask=full_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, num_groups):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = torch.nn.functional.gelu(x)\n        \n        # Convert to channels-last format for efficient memory access\n        x = x.contiguous(memory_format=torch.channels_last)\n        n, c, h, w = x.shape\n        y = torch.empty_like(x)\n        \n        # Kernel parameters\n        channels_per_group = c // self.group_norm.num_groups\n        grid = (n * self.group_norm.num_groups,)\n        \n        # Launch optimized kernel\n        group_norm_kernel[grid](\n            x, y,\n            self.group_norm.weight,\n            self.group_norm.bias,\n            c, self.group_norm.num_groups, self.group_norm.eps,\n            h, w,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            BLOCK_H=8, BLOCK_W=8, BLOCK_C=channels_per_group\n        )\n        \n        return y\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nheight, width = 32, 32\nkernel_size = 4\nstride = 2\ngroups = 8\nnum_groups = 8\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, groups, num_groups]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "077ef646-0ad6-4056-a85a-4a0c5e97b96a", "generation": 3, "timestamp": 1754571400.2966976, "iteration_found": 25, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_19_ConvTranspose2d_GELU_GroupNorm", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "max_difference": ["10.667388", "9.424166", "9.749063", "10.098853", "10.113348"], "avg_difference": ["0.550394", "0.550086", "0.549930", "0.550145", "0.550021"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.107, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.149, "runtime_ms": 0.719, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.107, "speed_up": 0.149, "custom_timing": 0.719}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}