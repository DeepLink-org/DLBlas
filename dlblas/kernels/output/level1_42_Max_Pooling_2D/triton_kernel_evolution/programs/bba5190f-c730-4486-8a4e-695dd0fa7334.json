{"id": "bba5190f-c730-4486-8a4e-695dd0fa7334", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef maxpool2d_kernel(\n    x_ptr,\n    output_ptr,\n    x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    input_height, input_width,\n    channels,\n    kernel_size: tl.constexpr,\n    stride: tl.constexpr,\n    padding: tl.constexpr,\n    dilation: tl.constexpr\n):\n    # Vectorization over width dimension (process 128 elements per thread)\n    BLOCK_SIZE = 128\n    \n    # Get program IDs\n    bc = tl.program_id(0)\n    h = tl.program_id(1)\n    w_block = tl.program_id(2)\n    \n    # Compute batch and channel indices\n    batch = bc // channels\n    channel_index = bc % channels\n    \n    # Calculate output width for boundary checks\n    output_width = (input_width + 2 * padding - dilation * (kernel_size - 1) - 1) // stride + 1\n    \n    # Compute width offsets for this block\n    w_offsets = w_block * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    w_mask = w_offsets < output_width\n    \n    # Initialize max values to -infinity\n    max_vals = tl.full((BLOCK_SIZE,), float('-inf'), dtype=tl.float32)\n    \n    # Iterate over kernel window\n    for di in range(0, kernel_size):\n        for dj in range(0, kernel_size):\n            # Compute input coordinates\n            i = h * stride - padding + di * dilation\n            j = (w_offsets * stride - padding) + dj * dilation\n            \n            # Check input boundaries\n            in_bounds_i = (i >= 0) & (i < input_height)\n            in_bounds_j = (j >= 0) & (j < input_width)\n            in_bounds = in_bounds_i & in_bounds_j & w_mask\n            \n            # Compute memory offsets\n            base = batch * x_batch_stride + channel_index * x_channel_stride + i * x_height_stride\n            addrs = base + j * x_width_stride\n            \n            # Load values with boundary masking\n            vals = tl.load(x_ptr + addrs, mask=in_bounds, other=float('-inf'), dtype=tl.float32)\n            \n            # Update max values\n            max_vals = tl.maximum(max_vals, vals)\n    \n    # Compute output offsets\n    out_base = batch * output_batch_stride + channel_index * output_channel_stride + h * output_height_stride\n    out_addrs = out_base + w_offsets * output_width_stride\n    \n    # Convert to output dtype and store results\n    output_dtype = tl.dtype(output_ptr.dtype.element_ty)\n    tl.store(output_ptr + out_addrs, max_vals.to(output_dtype), mask=w_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, kernel_size: int, stride: int, padding: int, dilation: int):\n        super(ModelNew, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, channels, height, width = x.shape\n        \n        # Calculate output dimensions\n        output_height = ((height + 2 * self.padding - \n                          self.dilation * (self.kernel_size - 1) - 1) // \n                         self.stride) + 1\n        output_width = ((width + 2 * self.padding - \n                         self.dilation * (self.kernel_size - 1) - 1) // \n                        self.stride) + 1\n        \n        # Create output tensor\n        output = torch.empty((batch_size, channels, output_height, output_width), \n                             device=x.device, dtype=x.dtype)\n        \n        # Skip computation if output is empty\n        if output.numel() == 0:\n            return output\n        \n        # Launch kernel with optimized grid\n        BLOCK_SIZE = 128\n        grid = (\n            batch_size * channels, \n            output_height,\n            triton.cdiv(output_width, BLOCK_SIZE)\n        )\n        maxpool2d_kernel[grid](\n            x, output,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            height, width,\n            channels,\n            self.kernel_size, self.stride, self.padding, self.dilation\n        )\n        return output\n\nbatch_size = 16\nchannels = 32\nheight = 128\nwidth = 128\nkernel_size = 2\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.randn(batch_size, channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a1a3fb59-63a7-49be-9e15-eccf15d3249c", "generation": 2, "timestamp": 1754644336.6174319, "iteration_found": 13, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_42_Max_Pooling_2D", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "runtime_error": "Traceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\n    return _semantic.arange(start, end)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 574, in arange\n    raise ValueError(\"arange's arguments must be of type tl.constexpr\")\nValueError: arange's arguments must be of type tl.constexpr\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp9yerizb6.py\", line 106, in forward\n    maxpool2d_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 29:39:\n    h = tl.program_id(1)\n    w_block = tl.program_id(2)\n\n    # Compute batch and channel indices\n    batch = bc // channels\n    channel_index = bc % channels\n\n    # Calculate output width for boundary checks\n    output_width = (input_width + 2 * padding - dilation * (kernel_size - 1) - 1) // stride + 1\n\n    # Compute width offsets for this block\n    w_offsets = w_block * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n                                       ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 1654, in arange\n    return _semantic.arange(start, end)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 574, in arange\n    raise ValueError(\"arange's arguments must be of type tl.constexpr\")\nValueError: arange's arguments must be of type tl.constexpr\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 0.023, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.018, "runtime_ms": 1.31, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.023, "speed_up": 0.018, "custom_timing": 1.31}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}