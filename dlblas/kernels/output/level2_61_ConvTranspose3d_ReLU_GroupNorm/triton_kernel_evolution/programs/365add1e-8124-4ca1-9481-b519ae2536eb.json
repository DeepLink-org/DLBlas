{"id": "365add1e-8124-4ca1-9481-b519ae2536eb", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef group_norm_kernel(\n    x_ptr, y_ptr, weight_ptr, bias_ptr,\n    N, C, D, H, W, groups, eps,\n    stride_n, stride_c, stride_d, stride_h, stride_w,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid_n = tl.program_id(0)\n    pid_g = tl.program_id(1)\n    \n    channels_per_group = C // groups\n    spatial_size = D * H * W\n    group_size = channels_per_group * spatial_size\n    \n    # Calculate start channel for this group\n    start_c = pid_g * channels_per_group\n    # Offsets and masks for reduction\n    offs = tl.arange(0, BLOCK_SIZE)\n    c_idx = offs // spatial_size\n    s_idx = offs % spatial_size\n    mask = offs < group_size\n    \n    # Calculate tensor offsets\n    c = start_c + c_idx\n    d = s_idx // (H * W)\n    hw = s_idx % (H * W)\n    h = hw // W\n    w = hw % W\n    x_offset = pid_n * stride_n + c * stride_c + d * stride_d + h * stride_h + w * stride_w\n    \n    # Load data\n    x = tl.load(x_ptr + x_offset, mask=mask, other=0.0)\n    \n    # Compute mean and variance\n    sum_x = tl.sum(x, axis=0)\n    sum_x2 = tl.sum(x * x, axis=0)\n    mean = sum_x / group_size\n    var = (sum_x2 / group_size) - (mean * mean)\n    rstd = tl.sqrt(var + eps)\n    \n    # Normalize and apply affine transformation\n    x_norm = (x - mean) / rstd\n    weight = tl.load(weight_ptr + c, mask=mask, other=0.0)\n    bias = tl.load(bias_ptr + c, mask=mask, other=0.0)\n    y = x_norm * weight + bias\n    \n    # Store results\n    tl.store(y_ptr + x_offset, y, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, groups, bias=False):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, bias=bias)\n        self.relu = nn.ReLU()\n        self.groups = groups\n        self.eps = 1e-5\n        self.weight = nn.Parameter(torch.ones(out_channels))\n        self.bias = nn.Parameter(torch.zeros(out_channels))\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.relu(x)\n        \n        # Prepare for Triton kernel\n        N, C, D, H, W = x.shape\n        y = torch.empty_like(x)\n        stride_n, stride_c, stride_d, stride_h, stride_w = x.stride()\n        \n        # Launch kernel\n        grid = (N, self.groups)\n        group_norm_kernel[grid](\n            x, y, self.weight, self.bias,\n            N, C, D, H, W, self.groups, self.eps,\n            stride_n, stride_c, stride_d, stride_h, stride_w,\n            BLOCK_SIZE=triton.next_power_of_2((C // self.groups) * D * H * W)\n        )\n        return y\n\nbatch_size = 16\nin_channels = 64\nout_channels = 128\nD, H, W = 8, 16, 16\nkernel_size = 3\ngroups = 8\nbias = False\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, D, H, W)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, groups, bias]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "75289a24-d8eb-4305-a1b2-c6c4e62496e1", "generation": 1, "timestamp": 1754573358.2462814, "iteration_found": 3, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.216, "runtime_ms": 1.52, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.329, "speed_up": 0.216, "custom_timing": 1.52}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.33, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.329, "speed_up": 0.997, "custom_timing": 0.33}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}