{"id": "2c4d551a-c5de-4d28-810e-77999466a0d9", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _depthwise_conv2d_kernel(\n    x_ptr,\n    weight_ptr,\n    output_ptr,\n    bias_ptr,\n    batch_size, in_channels, height, width,\n    out_height, out_width,\n    stride_h, stride_w,\n    padding_h, padding_w,\n    dilation_h, dilation_w,\n    kernel_size_h, kernel_size_w,\n    x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n    weight_channel_stride, weight_height_stride, weight_width_stride,\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    HAS_BIAS: tl.constexpr,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr,\n):\n    pid_bc = tl.program_id(0)\n    pid_oh_block = tl.program_id(1)\n    pid_ow_block = tl.program_id(2)\n    \n    pid_batch = pid_bc // in_channels\n    pid_channel = pid_bc % in_channels\n    \n    oh_start = pid_oh_block * BLOCK_H\n    ow_start = pid_ow_block * BLOCK_W\n    \n    ohs = oh_start + tl.arange(0, BLOCK_H)\n    ows = ow_start + tl.arange(0, BLOCK_W)\n    \n    mask_oh = ohs < out_height\n    mask_ow = ows < out_width\n    output_mask = mask_oh[:, None] & mask_ow[None, :]\n    \n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    for kh in range(0, kernel_size_h):\n        for kw in range(0, kernel_size_w):\n            ihs = ohs * stride_h - padding_h + kh * dilation_h\n            iws = ows * stride_w - padding_w + kw * dilation_w\n            \n            mask_ih = (ihs >= 0) & (ihs < height)\n            mask_iw = (iws >= 0) & (iws < width)\n            mask = mask_ih[:, None] & mask_iw[None, :] & output_mask\n            \n            x_offsets = (pid_batch * x_batch_stride + \n                         pid_channel * x_channel_stride + \n                         ihs[:, None] * x_height_stride + \n                         iws[None, :] * x_width_stride)\n            \n            x_val = tl.load(x_ptr + x_offsets, mask=mask, other=0.0)\n            \n            weight_val = tl.load(weight_ptr + pid_channel * weight_channel_stride + \n                                kh * weight_height_stride + kw * weight_width_stride)\n            \n            acc += x_val * weight_val\n\n    if HAS_BIAS:\n        bias_val = tl.load(bias_ptr + pid_channel)\n        acc += bias_val\n\n    output_offsets = (pid_batch * output_batch_stride + \n                      pid_channel * output_channel_stride + \n                      ohs[:, None] * output_height_stride + \n                      ows[None, :] * output_width_stride)\n    \n    tl.store(output_ptr + output_offsets, acc, mask=output_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size_h: int, kernel_size_w: int, stride_h: int = 1, stride_w: int = 1, padding_h: int = 0, padding_w: int = 0, dilation_h: int = 1, dilation_w: int = 1, groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        assert groups == in_channels, \"Depthwise convolution requires groups = in_channels\"\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size_h = kernel_size_h\n        self.kernel_size_w = kernel_size_w\n        self.stride_h = stride_h\n        self.stride_w = stride_w\n        self.padding_h = padding_h\n        self.padding_w = padding_w\n        self.dilation_h = dilation_h\n        self.dilation_w = dilation_w\n        self.groups = groups\n        \n        self.weight = nn.Parameter(torch.empty(out_channels, 1, kernel_size_h, kernel_size_w))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, _, height, width = x.shape\n        out_height = (height + 2 * self.padding_h - self.dilation_h * (self.kernel_size_h - 1) - 1) // self.stride_h + 1\n        out_width = (width + 2 * self.padding_w - self.dilation_w * (self.kernel_size_w - 1) - 1) // self.stride_w + 1\n        \n        output = torch.empty((batch_size, self.out_channels, out_height, out_width), \n                             device=x.device, dtype=x.dtype)\n        \n        x = x.contiguous()\n        weight = self.weight.contiguous()\n        \n        has_bias = self.bias is not None\n        bias = self.bias.contiguous() if has_bias else torch.empty(0, device=x.device)\n        \n        BLOCK_H, BLOCK_W = 16, 16\n        grid = (\n            batch_size * self.in_channels,\n            triton.cdiv(out_height, BLOCK_H),\n            triton.cdiv(out_width, BLOCK_W)\n        )\n        \n        _depthwise_conv2d_kernel[grid](\n            x, weight, output, bias,\n            batch_size, self.in_channels, height, width,\n            out_height, out_width,\n            self.stride_h, self.stride_w,\n            self.padding_h, self.padding_w,\n            self.dilation_h, self.dilation_w,\n            self.kernel_size_h, self.kernel_size_w,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            weight.stride(0), weight.stride(2), weight.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            has_bias,\n            BLOCK_H=BLOCK_H, BLOCK_W=BLOCK_W\n        )\n        \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = in_channels\nkernel_size_h = 3\nkernel_size_w = 5\nwidth = 256\nheight = 128\nstride_h = 1\nstride_w = 1\npadding_h = 0\npadding_w = 0\ndilation_h = 1\ndilation_w = 1\ngroups = in_channels\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size_h, kernel_size_w, stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w, groups]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b5adcb9e-7739-4d8c-8cc2-cc45bedb69cb", "generation": 3, "timestamp": 1754649260.434504, "iteration_found": 23, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.527, "runtime_ms": 0.0773, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0407, "speed_up": 0.527, "custom_timing": 0.0773}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.014, "runtime_ms": 2.88, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0407, "speed_up": 0.014, "custom_timing": 2.88}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}