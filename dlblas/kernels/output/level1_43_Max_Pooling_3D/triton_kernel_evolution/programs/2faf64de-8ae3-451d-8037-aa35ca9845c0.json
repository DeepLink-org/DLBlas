{"id": "2faf64de-8ae3-451d-8037-aa35ca9845c0", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef max_pooling_3d_kernel(\n    input_ptr,\n    output_ptr,\n    input_batch,\n    input_channels,\n    input_d,\n    input_h,\n    input_w,\n    kernel_size: tl.constexpr,\n    stride: tl.constexpr,\n    padding: tl.constexpr,\n    dilation: tl.constexpr,\n    output_d,\n    output_h,\n    output_w,\n    stride_b, stride_c, stride_d, stride_h, stride_w\n):\n    pid = tl.program_id(0)\n    total_output_elements = input_batch * input_channels * output_d * output_h * output_w\n    if pid >= total_output_elements:\n        return\n\n    # Calculate 5D indices (b, c, d, h, w) from pid\n    w = pid % output_w\n    pid //= output_w\n    h = pid % output_h\n    pid //= output_h\n    d = pid % output_d\n    pid //= output_d\n    c = pid % input_channels\n    b = pid // input_channels\n\n    # Compute start position of pooling window\n    d_start = d * stride - padding\n    h_start = h * stride - padding\n    w_start = w * stride - padding\n\n    max_val = tl.full((), float('-inf'), dtype=tl.float32)\n    base = b * stride_b + c * stride_c\n    \n    # Iterate over kernel window with static unrolling\n    for dd in tl.static_range(0, kernel_size):\n        d_in = d_start + dd * dilation\n        for hh in tl.static_range(0, kernel_size):\n            h_in = h_start + hh * dilation\n            for ww in tl.static_range(0, kernel_size):\n                w_in = w_start + ww * dilation\n                \n                # Check boundaries\n                in_bounds = (d_in >= 0) & (d_in < input_d) & \\\n                            (h_in >= 0) & (h_in < input_h) & \\\n                            (w_in >= 0) & (w_in < input_w)\n                \n                # Calculate input offset\n                input_offset = base + \\\n                               d_in * stride_d + \\\n                               h_in * stride_h + \\\n                               w_in * stride_w\n                \n                # Load value with boundary mask\n                val = tl.load(input_ptr + input_offset, mask=in_bounds, other=float('-inf'))\n                max_val = tl.maximum(max_val, val)\n\n    # Calculate output offset\n    output_offset = b * output_d * output_h * output_w * input_channels + \\\n                    c * output_d * output_h * output_w + \\\n                    d * output_h * output_w + \\\n                    h * output_w + w\n    tl.store(output_ptr + output_offset, max_val)\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model that performs Max Pooling 3D using Triton.\n    \"\"\"\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        super(ModelNew, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.return_indices = return_indices\n        self.ceil_mode = ceil_mode\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Ensure input is contiguous\n        x = x.contiguous()\n        \n        # Compute output dimensions\n        def output_size(dim):\n            temp = dim + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1\n            if temp < 0:\n                return 0\n            if self.ceil_mode:\n                return (temp + self.stride - 1) // self.stride + 1\n            else:\n                return temp // self.stride + 1\n        \n        out_d = output_size(x.size(2))\n        out_h = output_size(x.size(3))\n        out_w = output_size(x.size(4))\n        \n        # Allocate output tensor\n        output = torch.empty((x.size(0), x.size(1), out_d, out_h, out_w), device=x.device, dtype=x.dtype)\n        \n        # Launch kernel only if output has elements\n        total_elements = x.size(0) * x.size(1) * out_d * out_h * out_w\n        if total_elements > 0:\n            grid = (total_elements,)\n            max_pooling_3d_kernel[grid](\n                x,\n                output,\n                x.size(0),\n                x.size(1),\n                x.size(2),\n                x.size(3),\n                x.size(4),\n                self.kernel_size,\n                self.stride,\n                self.padding,\n                self.dilation,\n                out_d,\n                out_h,\n                out_w,\n                x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4)\n            )\n        return output\n\nbatch_size = 16\nchannels = 32\ndim1 = 64\ndim2 = 64\ndim3 = 64\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.randn(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "f60db484-34fe-4592-b5cb-69314b83b25d", "generation": 3, "timestamp": 1754644922.818327, "iteration_found": 19, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.018, "runtime_ms": 26.6, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 0.018, "custom_timing": 26.6}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.018, "runtime_ms": 26.8, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 0.018, "custom_timing": 26.8}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}