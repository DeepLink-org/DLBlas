{"id": "f817796e-f401-42f2-b60f-1a824c5ddf08", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef max_pool_3d_kernel(\n    input_ptr,\n    output_ptr,\n    batch, channels, D1, D2, D3,\n    out_d1, out_d2, out_d3,\n    kernel_size: tl.constexpr,\n    stride: tl.constexpr,\n    padding: tl.constexpr,\n    dilation: tl.constexpr,\n    stride_batch, stride_channel, stride_d1, stride_d2, stride_d3,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_programs = batch * channels * out_d1 * out_d2 * out_d3\n    \n    num_per_batch = channels * out_d1 * out_d2 * out_d3\n    b = pid // num_per_batch\n    remainder = pid % num_per_batch\n    num_per_channel = out_d1 * out_d2 * out_d3\n    c = remainder // num_per_channel\n    remainder = remainder % num_per_channel\n    num_per_d1 = out_d2 * out_d3\n    i = remainder // num_per_d1\n    remainder = remainder % num_per_d1\n    j = remainder // out_d3\n    k = remainder % out_d3\n\n    start_d1 = i * stride - padding\n    start_d2 = j * stride - padding\n    start_d3 = k * stride - padding\n\n    max_val = tl.full((), -float('inf'), dtype=tl.float32)\n\n    for di in tl.static_range(0, kernel_size):\n        for dj in tl.static_range(0, kernel_size):\n            for dk in tl.static_range(0, kernel_size):\n                d1_index = start_d1 + di * dilation\n                d2_index = start_d2 + dj * dilation\n                d3_index = start_d3 + dk * dilation\n                \n                if d1_index >= 0 and d1_index < D1 and d2_index >=0 and d2_index < D2 and d3_index>=0 and d3_index < D3:\n                    offset = (b * stride_batch + \n                              c * stride_channel + \n                              d1_index * stride_d1 + \n                              d2_index * stride_d2 + \n                              d3_index * stride_d3)\n                    val = tl.load(input_ptr + offset)\n                    max_val = tl.maximum(max_val, val)\n\n    offset_out = (b * channels * out_d1 * out_d2 * out_d3 + \n                  c * out_d1 * out_d2 * out_d3 + \n                  i * out_d2 * out_d3 + \n                  j * out_d3 + \n                  k)\n    tl.store(output_ptr + offset_out, max_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        super(ModelNew, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.ceil_mode = ceil_mode\n        self.return_indices = return_indices\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x.contiguous()\n        batch, channels, D1, D2, D3 = x.shape\n        kernel_size = self.kernel_size\n        stride = self.stride\n        padding = self.padding\n        dilation = self.dilation\n        ceil_mode = self.ceil_mode\n\n        def compute_out_dim(dim):\n            numerator = dim + 2 * padding - dilation * (kernel_size - 1) - 1\n            extra = stride - 1 if ceil_mode else 0\n            return (numerator + extra) // stride + 1\n\n        out_d1 = compute_out_dim(D1)\n        out_d2 = compute_out_dim(D2)\n        out_d3 = compute_out_dim(D3)\n\n        output = torch.empty((batch, channels, out_d1, out_d2, out_d3), device=x.device, dtype=x.dtype).contiguous()\n\n        if output.numel() == 0:\n            return output\n\n        stride_batch, stride_channel, stride_d1, stride_d2, stride_d3 = x.stride()\n        total_programs = batch * channels * out_d1 * out_d2 * out_d3\n\n        grid = lambda meta: (total_programs,)\n        max_pool_3d_kernel[grid](\n            x, output,\n            batch, channels, D1, D2, D3,\n            out_d1, out_d2, out_d3,\n            kernel_size, stride, padding, dilation,\n            stride_batch, stride_channel, stride_d1, stride_d2, stride_d3,\n            BLOCK_SIZE=1\n        )\n\n        return output\n\nbatch_size = 16\nchannels = 32\ndim1 = 64\ndim2 = 64\ndim3 = 64\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.randn(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "363f0b65-65ae-4b46-a7a7-78a97af66e97", "generation": 1, "timestamp": 1754641652.3777792, "iteration_found": 2, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.015, "runtime_ms": 32.0, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 0.015, "custom_timing": 32.0}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.473, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 1.03, "custom_timing": 0.473}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}