{"id": "37b225f0-0b22-45d1-af07-a4a0e4b92df6", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef max_pool3d_kernel(\n    input_ptr,\n    output_ptr,\n    # Tensor dimensions\n    B, C, D, H, W,\n    D_out, H_out, W_out,\n    # Input tensor strides\n    input_stride_b, input_stride_c, input_stride_d, input_stride_h, input_stride_w,\n    # Output tensor strides\n    output_stride_b, output_stride_c, output_stride_d, output_stride_h, output_stride_w,\n    # Pooling parameters\n    kernel_d: tl.constexpr, kernel_h: tl.constexpr, kernel_w: tl.constexpr,\n    stride_d: tl.constexpr, stride_h: tl.constexpr, stride_w: tl.constexpr,\n    padding_d: tl.constexpr, padding_h: tl.constexpr, padding_w: tl.constexpr,\n    dilation_d: tl.constexpr, dilation_h: tl.constexpr, dilation_w: tl.constexpr,\n    # Block size (unused in this implementation but kept for compatibility)\n    BLOCK_SIZE: tl.constexpr\n):\n    # Program indices\n    pid_b = tl.program_id(0)\n    pid_c = tl.program_id(1)\n    pid_s = tl.program_id(2)\n    \n    # Decompose spatial index\n    hw_size = H_out * W_out\n    d_out = pid_s // hw_size\n    hw = pid_s % hw_size\n    h_out = hw // W_out\n    w_out = hw % W_out\n\n    # Check bounds\n    if pid_b >= B or pid_c >= C or d_out >= D_out or h_out >= H_out or w_out >= W_out:\n        return\n\n    # Calculate starting indices\n    start_d = d_out * stride_d - padding_d\n    start_h = h_out * stride_h - padding_h\n    start_w = w_out * stride_w - padding_w\n    \n    # Precompute base pointer for this batch/channel\n    base = input_ptr + pid_b * input_stride_b + pid_c * input_stride_c\n    \n    # Initialize max value\n    max_val = -float('inf')\n    \n    # Generic kernel handling with static unrolling\n    for kd in tl.static_range(0, kernel_d):\n        d_in = start_d + kd * dilation_d\n        for kh in tl.static_range(0, kernel_h):\n            h_in = start_h + kh * dilation_h\n            for kw in tl.static_range(0, kernel_w):\n                w_in = start_w + kw * dilation_w\n                \n                # Check bounds\n                in_bounds = (d_in >= 0) & (d_in < D) & \\\n                            (h_in >= 0) & (h_in < H) & \\\n                            (w_in >= 0) & (w_in < W)\n                \n                # Compute memory offset\n                offset = d_in * input_stride_d + h_in * input_stride_h + w_in * input_stride_w\n                # Load value with bounds masking\n                val = tl.load(base + offset, mask=in_bounds, other=-float('inf'))\n                \n                # Update max value\n                if val > max_val:\n                    max_val = val\n    \n    # Calculate output offset\n    out_offset = (\n        pid_b * output_stride_b + \n        pid_c * output_stride_c + \n        d_out * output_stride_d + \n        h_out * output_stride_h + \n        w_out * output_stride_w\n    )\n    \n    # Store result\n    tl.store(output_ptr + out_offset, max_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0, \n                 dilation: int = 1, return_indices: bool = False, ceil_mode: bool = False):\n        super(ModelNew, self).__init__()\n        self.kernel_size = kernel_size\n        self.stride = stride if stride is not None else kernel_size\n        self.padding = padding\n        self.dilation = dilation\n        self.return_indices = return_indices\n        self.ceil_mode = ceil_mode\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Ensure input is contiguous\n        x = x.contiguous()\n        \n        # Get input dimensions\n        B, C, D, H, W = x.shape\n        \n        # Convert parameters to tuples\n        kernel_size = (self.kernel_size, self.kernel_size, self.kernel_size)\n        stride = (self.stride, self.stride, self.stride)\n        padding = (self.padding, self.padding, self.padding)\n        dilation = (self.dilation, self.dilation, self.dilation)\n        \n        # Calculate output dimensions\n        def output_dim(dim, k, p, d, s):\n            numerator = dim + 2 * p - d * (k - 1) - 1\n            if self.ceil_mode:\n                return int(math.ceil(numerator / s)) + 1\n            return (numerator // s) + 1\n            \n        D_out = output_dim(D, kernel_size[0], padding[0], dilation[0], stride[0])\n        H_out = output_dim(H, kernel_size[1], padding[1], dilation[1], stride[1])\n        W_out = output_dim(W, kernel_size[2], padding[2], dilation[2], stride[2])\n        \n        # Create output tensor\n        output = torch.empty((B, C, D_out, H_out, W_out), \n                             device=x.device, dtype=x.dtype)\n        \n        # Grid configuration\n        grid = (B, C, D_out * H_out * W_out)\n        \n        # Launch kernel\n        max_pool3d_kernel[grid](\n            x, output,\n            B, C, D, H, W,\n            D_out, H_out, W_out,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3), output.stride(4),\n            kernel_size[0], kernel_size[1], kernel_size[2],\n            stride[0], stride[1], stride[2],\n            padding[0], padding[1], padding[2],\n            dilation[0], dilation[1], dilation[2],\n            BLOCK_SIZE=1\n        )\n        \n        return output\n\nbatch_size = 16\nchannels = 32\ndim1 = 64\ndim2 = 64\ndim3 = 64\nkernel_size = 3\nstride = 2\npadding = 1\ndilation = 3\n\ndef get_inputs():\n    x = torch.randn(batch_size, channels, dim1, dim2, dim3)\n    return [x]\n\ndef get_init_inputs():\n    return [kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "48a43dd4-345c-40be-bd4f-c676b7d4e7f1", "generation": 2, "timestamp": 1754642733.0333712, "iteration_found": 7, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.018, "runtime_ms": 26.6, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 0.018, "custom_timing": 26.6}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.018, "runtime_ms": 26.9, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.487, "speed_up": 0.018, "custom_timing": 26.9}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}