{"id": "d915d417-4e9e-49d7-8fd7-2c7d4dfe6d91", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.maxpool_kernel_size = maxpool_kernel_size\n        self.maxpool_stride = maxpool_stride\n        self.hardtanh_min = hardtanh_min\n        self.hardtanh_max = hardtanh_max\n        \n        # Initialize weights and biases\n        weight = torch.empty(out_channels, in_channels, kernel_size, kernel_size)\n        bias = torch.empty(out_channels)\n        torch.nn.init.kaiming_uniform_(weight)\n        torch.nn.init.zeros_(bias)\n        self.register_buffer(\"weight\", weight)\n        self.register_buffer(\"bias\", bias)\n\n    @triton.jit\n    def _forward_kernel(\n        input_ptr, weight_ptr, bias_ptr, output_ptr,\n        in_channels, out_channels, kernel_size, stride, padding,\n        maxpool_kernel_size, maxpool_stride,\n        hardtanh_min, hardtanh_max,\n        input_batch_stride, input_channel_stride, input_height_stride, input_width_stride,\n        weight_out_channel_stride, weight_in_channel_stride, weight_height_stride, weight_width_stride,\n        output_batch_stride, output_channel_stride,\n        height, width,\n        BLOCK_SIZE: tl.constexpr\n    ):\n        pid_batch = tl.program_id(0)\n        pid_channel = tl.program_id(1)\n        \n        # Calculate spatial dimensions after operations\n        transposed_h = (height - 1) * stride + kernel_size - 2 * padding\n        transposed_w = (width - 1) * stride + kernel_size - 2 * padding\n        pooled_h = (transposed_h - maxpool_kernel_size) // maxpool_stride + 1\n        pooled_w = (transposed_w - maxpool_kernel_size) // maxpool_stride + 1\n        \n        # Accumulator for final mean value\n        spatial_sum = 0.0\n        \n        # Process each spatial position in the pooled output\n        for ph in range(pooled_h):\n            for pw in range(pooled_w):\n                max_val = -tl.inf\n                \n                # Process maxpool window\n                for kh in range(maxpool_kernel_size):\n                    for kw in range(maxpool_kernel_size):\n                        h_out = ph * maxpool_stride + kh\n                        w_out = pw * maxpool_stride + kw\n                        conv_val = 0.0\n                        \n                        # Add bias\n                        conv_val += tl.load(bias_ptr + pid_channel)\n                        \n                        # Process input channels and kernel\n                        for ic in range(in_channels):\n                            for kx in range(kernel_size):\n                                for ky in range(kernel_size):\n                                    # Calculate input position\n                                    h_in = (h_out - kx + padding) / stride\n                                    w_in = (w_out - ky + padding) / stride\n                                    \n                                    # Check if input position is valid\n                                    if h_in >= 0 and w_in >= 0 and h_in < height and w_in < width:\n                                        if h_in % 1 == 0 and w_in % 1 == 0:  # Integer positions\n                                            h_in = tl.math.floor(h_in)\n                                            w_in = tl.math.floor(w_in)\n                                            \n                                            # Calculate offsets\n                                            input_offset = pid_batch * input_batch_stride + \\\n                                                           ic * input_channel_stride + \\\n                                                           h_in * input_height_stride + \\\n                                                           w_in * input_width_stride\n                                            weight_offset = pid_channel * weight_out_channel_stride + \\\n                                                            ic * weight_in_channel_stride + \\\n                                                            kx * weight_height_stride + \\\n                                                            ky * weight_width_stride\n                                            \n                                            # Load and accumulate\n                                            input_val = tl.load(input_ptr + input_offset)\n                                            weight_val = tl.load(weight_ptr + weight_offset)\n                                            conv_val += input_val * weight_val\n                        \n                        # Update max value in window\n                        if conv_val > max_val:\n                            max_val = conv_val\n                \n                # Apply hardtanh\n                max_val = tl.minimum(tl.maximum(max_val, hardtanh_min), hardtanh_max)\n                spatial_sum += max_val\n        \n        # Calculate mean and apply tanh\n        mean_val = spatial_sum / (pooled_h * pooled_w)\n        out_val = tl.tanh(mean_val)\n        \n        # Store final result\n        output_offset = pid_batch * output_batch_stride + pid_channel * output_channel_stride\n        tl.store(output_ptr + output_offset, out_val)\n\n    def forward(self, x):\n        batch_size, _, height, width = x.shape\n        \n        # Pre-calculate output shape\n        transposed_h = (height - 1) * self.stride + self.kernel_size - 2 * self.padding\n        transposed_w = (width - 1) * self.stride + self.kernel_size - 2 * self.padding\n        pooled_h = (transposed_h - self.maxpool_kernel_size) // self.maxpool_stride + 1\n        pooled_w = (transposed_w - self.maxpool_kernel_size) // self.maxpool_stride + 1\n        \n        # Prepare output tensor\n        output = torch.empty(\n            (batch_size, self.out_channels, 1, 1),\n            device=x.device, dtype=torch.float32\n        )\n        \n        # Get tensor strides\n        x_stride = [s.item() for s in x.stride()]\n        w_stride = [s.item() for s in self.weight.stride()]\n        o_stride = [s.item() for s in output.stride()]\n        \n        # Launch kernel\n        grid = (batch_size, self.out_channels)\n        self._forward_kernel[grid](\n            x, self.weight, self.bias, output,\n            self.in_channels, self.out_channels,\n            self.kernel_size, self.stride, self.padding,\n            self.maxpool_kernel_size, self.maxpool_stride,\n            self.hardtanh_min, self.hardtanh_max,\n            x_stride[0], x_stride[1], x_stride[2], x_stride[3],\n            w_stride[0], w_stride[1], w_stride[2], w_stride[3],\n            o_stride[0], o_stride[1],\n            height, width,\n            BLOCK_SIZE=32\n        )\n        return output\n\nbatch_size = 128\nin_channels = 32\nout_channels = 64\nheight, width = 16, 16\nkernel_size = 4\nstride = 2\npadding = 1\nmaxpool_kernel_size = 2\nmaxpool_stride = 2\nhardtanh_min = -1\nhardtanh_max = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, maxpool_kernel_size, maxpool_stride, hardtanh_min, hardtanh_max]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "6829c0ab-6db8-4846-8bf8-189c0ee531e7", "generation": 1, "timestamp": 1754566745.0842745, "iteration_found": 3, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_10_ConvTranspose2d_MaxPool_Hardtanh_Mean_Tanh", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp3cq99s7u.py\", line 127, in forward\n    x_stride = [s.item() for s in x.stride()]\n  File \"/tmp/tmp3cq99s7u.py\", line 127, in <listcomp>\n    x_stride = [s.item() for s in x.stride()]\nAttributeError: 'int' object has no attribute 'item'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 0.165, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.17, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.165, "speed_up": 0.971, "custom_timing": 0.17}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}