{"id": "dbf7eac9-41ed-423f-88fd-05d11b353f5a", "code": "import triton\nimport triton.language as tl\n\n@triton.jit\ndef _leaky_relu_kernel(\n    x_ptr,\n    output_ptr,\n    negative_slope,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    # Compute LeakyReLU: x >= 0 ? x : negative_slope * x\n    # Note: negative_slope is passed as a scalar (constant for the kernel)\n    # We use tl.where(condition, x, y) -> condition is x>=0? But note: condition must be element-wise.\n    # Alternatively, we can do: \n    #   zero = 0.0\n    #   result = tl.where(x >= zero, x, negative_slope * x)\n    # But we can avoid the multiplication for positive values? It's pointwise so it's cheap.\n\n    # Alternatively, we can use: \n    #   result = x * tl.where(x >= 0, 1.0, negative_slope)\n    # But note: tl.where returns a tensor of the same shape.\n\n    # We'll do:\n    #   condition = (x >= 0)\n    #   scale = tl.where(condition, 1.0, negative_slope)\n    #   output = x * scale\n    # But note: negative_slope is a scalar, so we can broadcast.\n\n    # However, a simpler way is to use:\n    output = tl.where(x >= 0, x, negative_slope * x)\n    tl.store(output_ptr + offsets, output, mask=mask)", "language": "python", "parent_id": "dd514334-564d-4120-b55e-f2a3a0ff9e00", "generation": 1, "timestamp": 1754634372.1414764, "iteration_found": 3, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 26.600000000000005, "speed_up": 1.066, "runtime_ms": 0.0167, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0178, "speed_up": 1.066, "custom_timing": 0.0167}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0164, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0178, "speed_up": 1.085, "custom_timing": 0.0164}}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.0164\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0178, 'speed_up': 1.085, 'custom_timing': 0.0164}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.0164, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0178, 'speed_up': 1.085, 'custom_timing': 0.0164}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LeakyReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with LeakyReLU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\nbatch_size = 16\ndim = 16384\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.0164), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:0', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0178, 'speed_up': 1.085, 'custom_timing': 0.0164})\n\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Applies LeakyReLU activation to the input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of any shape.\n\n        Returns:\n            torch.Tensor: Output tensor with LeakyReLU applied, same shape as input.\n        \"\"\"\n        return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\nbatch_size = 16\ndim = 16384\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a simple LeakyReLU model implemented in PyTorch. The goal is to rewrite the forward pass using Triton to potentially gain speedup.\n\nThe current implementation uses `torch.nn.functional.leaky_relu` which is already optimized in PyTorch. However, we can try to write a Triton kernel for the LeakyReLU operation to see if we can get better performance.\n\nPlan:\n1. We will write a Triton kernel for LeakyReLU. The kernel will be applied element-wise.\n2. The kernel will load a block of data, apply the LeakyReLU function (which is: `x if x>=0 else negative_slope * x`), and then store the result.\n3. We will use a grid of blocks that covers the entire tensor. Since the tensor is of shape [batch_size, dim] (with batch_size=16, dim=16384), we can have each program handle a contiguous block of elements.\n\nNote: The LeakyReLU operation is pointwise and memory-bound. Therefore, we need to focus on efficient memory access.\n\nConstraints:\n- We must not change the function signature of the ModelNew class.\n- The forward function must return a tensor of the same shape and with the same values (within tolerance) as the original.\n\nApproach:\n- We will create a triton kernel that is launched with one program for each row? Actually, we can flatten the entire tensor and process it in 1D.\n- The kernel will have a 1D grid: total number of elements divided by the block size.\n\nKernel parameters:\n- pointers to input and output tensors\n- negative_slope\n- total number of elements (to handle boundaries)\n\nSteps in the kernel:\n1. Compute the index for the current program.\n2. Create a range of indices for the block.\n3. Check mask for boundaries.\n4. Load the input elements.\n5. Compute: for each element, if it is >=0 then keep, else multiply by negative_slope.\n6. Store the result.\n\nHowever, note that the current PyTorch implementation is already quite efficient. We must hope that by writing a Triton kernel we can reduce overhead and achieve better memory throughput.\n\nBut note: the tensor is 16 * 16384 = 262144 elements. This is a moderate size. We can use a block size of 1024 (for example) and then we would have 256 blocks.\n\nWe will write the kernel and then replace the forward function to call this kernel.\n\nImportant: We must maintain the same interface and also provide the same non-Triton path for CPU? But the problem says we are on GPU. We assume the input is on GPU.\n\nWe will define the kernel and then call it from the forward method.\n\nLet's design:\n\nWe are going to write:\n  @triton.jit\n  def _leaky_relu_kernel(...)\n\nThen in the forward method of ModelNew:\n  - Check that x is contiguous and on CUDA.\n  - Allocate output tensor of same shape and dtype.\n  - Compute total number of elements.\n  - Set grid and block (using triton's grid function).\n  - Launch kernel.\n\nWe must also consider that the negative_slope is a scalar. We can pass it as a constant to the kernel.\n\nWe note that the current performance has a speed_up of 1.085 (which is the custom_timing being faster than reference) but that is for the entire model? Actually, the current implementation is the reference and we are about to replace it.\n\nBut wait: the current program is the reference (PyTorch) and we are going to replace it with Triton. We are in the process of evolving.\n\nWe are going to write a Triton kernel for the forward pass.\n\nLet's code accordingly.\n\nWe must be cautious of the mask for out-of-bound elements.\n\nWe'll set:\n  BLOCK_SIZE = 1024  (or we can autotune this)\n\nBut note: the problem says we can do adaptive tuning. However, for simplicity we can start with a fixed block size and then in the next step we can autotune.\n\nWe are allowed to change the internal implementation of the forward function.\n\nWe are going to replace the body of the forward function.\n\nSteps:\n\n1. Import triton and triton.language as tl.\n2. Define the kernel function.\n3. In the forward function, if the tensor is on CUDA, use the Triton kernel; otherwise, fall back to PyTorch? But the problem says we are on GPU. We assume CUDA.\n\nBut note: the problem says the hardware is NVIDIA L20Y (same as H100). So we can assume CUDA.\n\nWe will write:\n\n```python\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _leaky_relu_kernel(\n    x_ptr,\n    output_ptr,\n    negative_slope,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    # Compute LeakyReLU: x >= 0 ? x : negative_slope * x\n    # Note: negative_slope is passed as a scalar (constant for the kernel)\n    # We use tl.where(condition, x, y) -> condition is x>=0? But note: condition must be element-wise.\n    # Alternatively, we can do: \n    #   zero = 0.0\n    #   result = tl.where(x >= zero, x, negative_slope * x)\n    # But we can avoid the multiplication for positive values? It's pointwise so it's cheap.\n\n    # Alternatively, we can use: \n    #   result = x * tl.where(x >= 0, 1.0, negative_slope)\n    # But note: tl.where returns a tensor of the same shape.\n\n    # We'll do:\n    #   condition = (x >= 0)\n    #   scale = tl.where(condition, 1.0, negative_slope)\n    #   output = x * scale\n    # But note: negative_slope is a scalar, so we can broadcast.\n\n    # However, a simpler way is to use:\n    output = tl.where(x >= 0, x, negative_slope * x)\n    tl.store(output_ptr + offsets, output, mask=mask)\n```\n\nThen in the forward function:\n\n```python\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # If we are not on CUDA, use the PyTorch version\n        if not x.is_cuda:\n            return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\n        # We are on CUDA: use Triton kernel\n        output = torch.empty_like(x)\n        n_elements = x.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        # We need to pass the negative_slope as a float\n        _leaky_relu_kernel[grid](x, output, self.negative_slope, n_elements, BLOCK_SIZE=1024)\n        return output\n```\n\nWe must choose a block size. 1024 is a common choice. But we can also make it configurable via autotuning? However, the problem says we can do adaptive tuning. But for now, we'll start with 1024.\n\nBut note: the problem says we must not change the grid configuration? Actually, we are allowed to change the block dimensions? The constraint says: \"NEVER modify grid configuration, output tensor shapes, or PID logic\". However, in this case we are defining the grid and block for the kernel. The constraint probably means the way we compute the program ID and the grid structure? But note, the constraint says \"PID logic\", meaning the way we compute the program ID. We are using a 1D grid and the PID is along axis=0, which is standard.\n\nBut note: the constraint says \"NEVER modify grid configuration\" - meaning the overall grid structure? Actually, we are allowed to change the block dimensions? The constraint says \"NEVER modify grid configuration\" but we are setting the grid and block. However, we are following the standard pattern.\n\nWe are going to write the kernel and then test it in the evolution system.\n\nBut note: the current program includes the batch_size and dim, and the get_inputs function. We must not change these because they are outside the EVOLVE-BLOCK? Actually, the entire code is inside the EVOLVE-BLOCK. We are going to replace the entire block.\n\nHowever, we note that the original code had:\n  batch_size = 16\n  dim = 16384\n\nWe must keep these because they are used in get_inputs.\n\nSo we will keep the same structure and only change the ModelNew class and add the kernel.\n\nWe are going to output the entire code block.\n\nBut note: the original code had:\n  import torch\n  import torch.nn as nn\n\nWe are going to add:\n  import triton\n  import triton.language as tl\n\nWe must be cautious: the kernel definition must be inside the EVOLVE-BLOCK? Yes, because we are replacing the entire block.\n\nWe are going to write:\n\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _leaky_relu_kernel(\n    x_ptr,\n    output_ptr,\n    negative_slope,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    output = tl.where(x >= 0, x, negative_slope * x)\n    tl.store(output_ptr + offsets, output, mask=mask)\n\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a LeakyReLU activation.\n    \"\"\"\n    def __init__(self, negative_slope: float = 0.01):\n        \"\"\"\n        Initializes the LeakyReLU module.\n\n        Args:\n            negative_slope (float, optional): The negative slope of the activation function. Defaults to 0.01.\n        \"\"\"\n        super(ModelNew, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # If we are not on CUDA, use the PyTorch version\n        if not x.is_cuda:\n            return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n\n        # We are on CUDA: use Triton kernel\n        output = torch.empty_like(x)\n        n_elements = x.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        # Note: We use 1024 as the block size. We can tune this later.\n        _leaky_relu_kernel[grid](x, output, self.negative_slope, n_elements, BLOCK_SIZE=1024)\n        return output\n\nbatch_size = 16\ndim = 16384\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed\n# =================== EVOLVE-BLOCK-END ===================\n```\n\nBut note: the kernel is defined at the top level. This is acceptable because the ModelNew class will be used and the kernel is defined only once.\n\nHowever, we must test for correctness and performance.\n\nWe are taking a small step. We hope that this Triton kernel will be faster than the PyTorch leaky_relu.\n\nBut note: the PyTorch leaky_relu is already highly optimized. We might not get a big speedup, but we are in the early stage of evolution.\n\nWe are also providing a fallback for non-CUDA tensors.\n\nLet's output the code accordingly.\n\nImportant: We are not changing the get_inputs and get_init_inputs functions.\n\nWe are only changing the ModelNew class and adding the kernel.\n\nWe must be cautious: the kernel uses tl.where and the operations are element-wise.\n\nWe are using a 1D grid and 1D block.\n\nWe are using a fixed block size of 1024. We can later autotune the block size and the number of warps, but for now we keep it simple.\n\nWe hope that this kernel will be efficient because it is memory bound and we are doing contiguous accesses.\n\nWe are loading and storing in contiguous chunks.\n\nLet's output the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef leaky_relu_kernel(\n    x_ptr,\n    output_ptr,\n    negative_slope,\n    n_elements,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n    x = tl.load(x_ptr + offsets, mask=mask)\n    output = tl.where(x >= 0, x, x * negative_slope)\n    tl.store(output_ptr + offsets, output, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, negative_slope: float = 0.01):\n        super(ModelNew, self).__init__()\n        self.negative_slope = negative_slope\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if not x.is_cuda:\n            return torch.nn.functional.leaky_relu(x, negative_slope=self.negative_slope)\n            \n        output = torch.empty_like(x)\n        n_elements = x.numel()\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        leaky_relu_kernel[grid](\n            x, output, self.negative_slope, n_elements,\n            BLOCK_SIZE=1024\n        )\n        return output\n\nbatch_size = 16\ndim = 16384\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim)\n    return [x]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}