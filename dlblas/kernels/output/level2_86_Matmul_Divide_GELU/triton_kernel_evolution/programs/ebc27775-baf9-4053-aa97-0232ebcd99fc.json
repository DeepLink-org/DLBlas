{"id": "ebc27775-baf9-4053-aa97-0232ebcd99fc", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'BLOCK_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256, 'BLOCK_K': 64}, num_warps=8),\n    ],\n    key=['input_size', 'output_size'],\n)\n@triton.jit\ndef _fused_linear_div_gelu(\n    x_ptr, weight_ptr, bias_ptr, output_ptr,\n    input_size, output_size, divisor,\n    batch_size, stride_x, stride_out,\n    BLOCK_SIZE: tl.constexpr, BLOCK_K: tl.constexpr,\n    HAS_BIAS: tl.constexpr,\n):\n    # Compute program IDs\n    pid_batch = tl.program_id(0)\n    pid_output_block = tl.program_id(1)\n    \n    # Create output block offset\n    output_offset = pid_output_block * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n    output_mask = output_offset < output_size\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n    \n    # Loop over input features in blocks\n    for k in range(0, input_size, BLOCK_K):\n        k_offset = k + tl.arange(0, BLOCK_K)\n        k_mask = k_offset < input_size\n        \n        # Load input block\n        x_ptr_offset = pid_batch * stride_x + k_offset\n        x_block = tl.load(x_ptr + x_ptr_offset, mask=k_mask, other=0.0)\n        \n        # Load weight block\n        w_ptr_offset = output_offset[:, None] * input_size + k_offset[None, :]\n        w_block = tl.load(weight_ptr + w_ptr_offset, mask=output_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        # Compute partial dot product\n        acc += tl.sum(x_block[None, :] * w_block, axis=1)\n    \n    # Load bias if exists\n    if HAS_BIAS:\n        bias_block = tl.load(bias_ptr + output_offset, mask=output_mask, other=0.0)\n        acc += bias_block\n    \n    # Apply division and approximate GELU\n    scaled = acc / divisor\n    gelu = scaled * 0.5 * (1.0 + tl.erf(scaled * 0.7071067811865475))\n    \n    # Store output\n    out_ptr_offset = pid_batch * stride_out + output_offset\n    tl.store(output_ptr + out_ptr_offset, gelu, mask=output_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, output_size, divisor):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.divisor = divisor\n        \n        # Initialize parameters as in nn.Linear\n        self.weight = nn.Parameter(torch.empty(output_size, input_size))\n        self.bias = nn.Parameter(torch.empty(output_size))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty((batch_size, self.output_size), \n                             device=x.device, dtype=x.dtype)\n        \n        # Dynamic grid based on autotuned BLOCK_SIZE\n        grid = lambda meta: (batch_size, triton.cdiv(self.output_size, meta['BLOCK_SIZE']))\n        \n        # Launch kernel\n        _fused_linear_div_gelu[grid](\n            x, self.weight, self.bias, output,\n            self.input_size, self.output_size, self.divisor,\n            batch_size, x.stride(0), output.stride(0),\n            HAS_BIAS=True\n        )\n        return output\n\nbatch_size = 128\ninput_size = 512\noutput_size = 1024\ndivisor = 10.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, output_size, divisor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "f8b17584-b68a-4788-82ca-0192b5e3c081", "generation": 2, "timestamp": 1754580569.8280456, "iteration_found": 4, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.415, "runtime_ms": 0.127, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0527, "speed_up": 0.415, "custom_timing": 0.127}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_86_Matmul_Divide_GELU", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "max_difference": ["0.178050", "0.187824", "0.193828", "0.186985"], "avg_difference": ["0.016259", "0.016318", "0.016305", "0.016288"], "correctness_issue": "Output mismatch", "correctness_trials": "(1 / 5)", "reference_timing_ms": 0.0527, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}