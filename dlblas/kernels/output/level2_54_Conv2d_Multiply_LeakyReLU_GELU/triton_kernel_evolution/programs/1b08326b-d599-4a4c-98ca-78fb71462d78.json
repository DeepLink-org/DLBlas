{"id": "1b08326b-d599-4a4c-98ca-78fb71462d78", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_ops_kernel(\n    x_ptr,\n    multiplier_ptr,\n    output_ptr,\n    negative_slope,\n    B, C, H, W,\n    stride_b, stride_c, stride_h, stride_w,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n    VEC_SIZE: tl.constexpr,\n):\n    # Combine batch and channel dimensions\n    pid_bc = tl.program_id(0)\n    pid_h_block = tl.program_id(1)\n    pid_w_block = tl.program_id(2)\n    \n    # Calculate batch and channel indices\n    pid_b = pid_bc // C\n    pid_c = pid_bc % C\n    \n    # Starting indices for the tile\n    start_h = pid_h_block * BLOCK_H\n    start_w = pid_w_block * BLOCK_W\n    \n    # Load multiplier once per channel\n    multiplier = tl.load(multiplier_ptr + pid_c)\n    \n    # Process each row in the tile\n    for h_offset in range(BLOCK_H):\n        h_idx = start_h + h_offset\n        if h_idx < H:\n            base = pid_b * stride_b + pid_c * stride_c + h_idx * stride_h\n            \n            # Vectorized processing along width dimension\n            for w_offset in range(0, BLOCK_W, VEC_SIZE):\n                w_offsets = start_w + w_offset + tl.arange(0, VEC_SIZE)\n                mask = w_offsets < W\n                \n                ptrs = base + w_offsets * stride_w\n                x_vec = tl.load(x_ptr + ptrs, mask=mask, other=0.0)\n                \n                # Fused operations\n                x_vec = x_vec * multiplier\n                x_vec = tl.where(x_vec >= 0, x_vec, x_vec * negative_slope)\n                x_vec = x_vec * 0.5 * (1.0 + tl.erf(x_vec * 0.7071067811865475))\n                \n                tl.store(output_ptr + ptrs, x_vec, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        output = torch.empty_like(x)\n        neg_slope = self.leaky_relu.negative_slope\n        \n        stride_b, stride_c, stride_h, stride_w = x.stride()\n        multiplier_flat = self.multiplier.view(-1).contiguous()\n        \n        # Optimized tile sizes\n        BLOCK_H = 4\n        BLOCK_W = 32  # Matches width dimension\n        VEC_SIZE = 16  # Optimized vector size for memory coalescing\n        \n        grid = (\n            B * C, \n            (H + BLOCK_H - 1) // BLOCK_H,\n            (W + BLOCK_W - 1) // BLOCK_W\n        )\n        \n        _fused_ops_kernel[grid](\n            x, multiplier_flat, output, neg_slope,\n            B, C, H, W,\n            stride_b, stride_c, stride_h, stride_w,\n            BLOCK_H=BLOCK_H,\n            BLOCK_W=BLOCK_W,\n            VEC_SIZE=VEC_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "9a198728-1c83-4487-aa10-d1f499a0fa11", "generation": 4, "timestamp": 1754578016.9737875, "iteration_found": 29, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.737, "runtime_ms": 0.106, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0781, "speed_up": 0.737, "custom_timing": 0.106}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.144, "runtime_ms": 0.542, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0781, "speed_up": 0.144, "custom_timing": 0.542}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}