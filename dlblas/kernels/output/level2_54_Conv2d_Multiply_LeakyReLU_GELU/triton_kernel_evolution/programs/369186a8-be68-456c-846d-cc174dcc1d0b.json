{"id": "369186a8-be68-456c-846d-cc174dcc1d0b", "code": "import torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise_kernel(\n    input_ptr,\n    multiplier_ptr,\n    output_ptr,\n    negative_slope,\n    n_elements,\n    channel_size: tl.constexpr,\n    n_channels: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    block_start = pid * BLOCK_SIZE\n    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n\n    # Load input element\n    x = tl.load(input_ptr + offsets, mask=mask, other=0.0)\n    \n    # Calculate channel index using integer division\n    channel_idx = (offsets // channel_size) % n_channels\n    \n    # Load multiplier for corresponding channel\n    multiplier = tl.load(multiplier_ptr + channel_idx, mask=mask, other=1.0)\n    \n    # Pointwise operations\n    x = x * multiplier\n    # LeakyReLU with configurable slope\n    x = tl.where(x >= 0, x, x * negative_slope)\n    # GELU using erf (more accurate and Triton-compatible)\n    gelu_x = 0.5 * x * (1.0 + tl.erf(x * 0.7071067811865475))\n    \n    tl.store(output_ptr + offsets, gelu_x, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        B, C, H, W = x.shape\n        n_elements = B * C * H * W\n        channel_size = H * W\n        neg_slope = self.leaky_relu.negative_slope\n        \n        # Reshape to 1D for efficient kernel processing\n        x_flat = x.contiguous().view(-1)\n        output = torch.empty_like(x_flat)\n        \n        # Launch kernel with optimal block size\n        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n        fused_pointwise_kernel[grid](\n            x_flat,\n            self.multiplier.view(-1),\n            output,\n            neg_slope,\n            n_elements,\n            channel_size,\n            C,\n            BLOCK_SIZE=1024\n        )\n        \n        return output.view(B, C, H, W)\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\nmultiplier_shape = (out_channels, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, multiplier_shape]", "language": "python", "parent_id": "124702ba-0f9b-4419-8f22-584fd5a35c93", "generation": 3, "timestamp": 1754575936.4725492, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.925, "runtime_ms": 0.0844, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0781, "speed_up": 0.925, "custom_timing": 0.0844}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.723, "runtime_ms": 0.108, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0781, "speed_up": 0.723, "custom_timing": 0.108}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}