{"id": "ec6637f0-866e-40a2-8cf5-2cc7b1797b85", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef cross_entropy_kernel(\n    logits_ptr,\n    targets_ptr,\n    output_ptr,\n    n_classes,\n    stride_logits_batch,\n    stride_logits_class,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    target_idx = tl.load(targets_ptr + pid)\n    row_start = pid * stride_logits_batch\n    \n    # Load target logit directly instead of masked reduction\n    target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n    \n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_classes\n    logits_ptrs = logits_ptr + row_start + col_offsets * stride_logits_class\n    logits = tl.load(logits_ptrs, mask=mask, other=-float('inf'))\n    \n    max_val = tl.max(logits, axis=0)\n    logits_shifted = logits - max_val\n    target_logit_shifted = target_logit_orig - max_val\n    \n    exp_logits = tl.exp(logits_shifted)\n    sum_exp = tl.sum(exp_logits, axis=0)\n    \n    log_softmax = target_logit_shifted - tl.log(sum_exp)\n    loss = -log_softmax\n    tl.store(output_ptr + pid, loss)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        batch_size, n_classes = predictions.shape[0], predictions.shape[1]\n        \n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        BLOCK_SIZE = triton.next_power_of_2(n_classes)\n        \n        grid = (triton.cdiv(batch_size, 128) * 128,)\n        cross_entropy_kernel[grid](\n            predictions, targets, per_sample_loss,\n            n_classes,\n            predictions.stride(0), predictions.stride(1),\n            batch_size,\n            BLOCK_SIZE\n        )\n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "334f291b-2916-40e5-8566-26642a1799cc", "generation": 2, "timestamp": 1754991268.6895962, "iteration_found": 13, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.409, "runtime_ms": 0.0609, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0249, "speed_up": 0.409, "custom_timing": 0.0609}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.441, "runtime_ms": 0.0564, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0249, "speed_up": 0.441, "custom_timing": 0.0564}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 0.0000\n- score: 20.0000\n- speed_up: 0.4410\n- runtime_ms: 0.0564\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.441, 'custom_timing': 0.0564}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: speed_up. Consider continuing with similar changes.\n- Metrics showing regression: runtime_ms. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.3850, runtime_ms: 0.0647, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.385, 'custom_timing': 0.0647}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.4310, runtime_ms: 0.0578, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.431, 'custom_timing': 0.0578}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.4410, runtime_ms: 0.0564, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.441, 'custom_timing': 0.0564}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef cross_entropy_kernel(\n    logits_ptr,\n    targets_ptr,\n    output_ptr,\n    n_classes,\n    stride_logits_batch,\n    stride_logits_class,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    target_idx = tl.load(targets_ptr + pid)\n    row_start = pid * stride_logits_batch\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_classes\n    \n    logits_ptrs = logits_ptr + row_start + col_offsets * stride_logits_class\n    logits = tl.load(logits_ptrs, mask=mask, other=-float('inf'))\n    \n    max_val = tl.max(logits, axis=0)\n    logits = logits - max_val\n    exp_logits = tl.exp(logits)\n    sum_exp = tl.sum(exp_logits, axis=0)\n    \n    mask_target = col_offsets == target_idx\n    target_logit = tl.sum(tl.where(mask_target, logits, 0.0), axis=0)\n    \n    log_softmax = target_logit - tl.log(sum_exp)\n    loss = -log_softmax\n    tl.store(output_ptr + pid, loss)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        batch_size, n_classes = predictions.shape[0], predictions.shape[1]\n        \n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        BLOCK_SIZE = triton.next_power_of_2(n_classes)\n        \n        grid = (triton.cdiv(batch_size, 128) * 128,)\n        cross_entropy_kernel[grid](\n            predictions, targets, per_sample_loss,\n            n_classes,\n            predictions.stride(0), predictions.stride(1),\n            batch_size,\n            BLOCK_SIZE\n        )\n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.4410), Performs well on runtime_ms (0.0564), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.441, 'custom_timing': 0.0564})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef cross_entropy_kernel(\n    logits_ptr,\n    targets_ptr,\n    output_ptr,\n    n_classes,\n    stride_logits_batch,\n    stride_logits_class,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    target_idx = tl.load(targets_ptr + pid)\n    row_start = pid * stride_logits_batch\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_classes\n    \n    # Vectorized load for small classes\n    if BLOCK_SIZE <= 32:\n        logits = tl.load(logits_ptr + row_start + col_offsets * stride_logits_class, mask=mask, other=-1e9)\n    else:\n        logits = tl.load(logits_ptr + row_start + col_offsets * stride_logits_class, mask=mask, other=-1e9)\n    \n    # Online max computation with early exit\n    max_val = tl.max(logits, axis=0)\n    shifted = logits - max_val\n    \n    # Fast exponential and sum approximation\n    exp_vals = tl.exp(shifted)\n    sum_exp = tl.sum(exp_vals, axis=0)\n    \n    # Direct target extraction using vector operations\n    target_val = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n    target_shifted = target_val - max_val\n    \n    # Stable log-softmax calculation\n    log_softmax = target_shifted - tl.log(sum_exp)\n    loss = -log_softmax\n    tl.store(output_ptr + pid, loss)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        batch_size, n_classes = predictions.shape[0], predictions.shape[1]\n        \n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        BLOCK_SIZE = triton.next_power_of_2(n_classes)\n        \n        grid = (triton.cdiv(batch_size, 128) * 128,)\n        cross_entropy_kernel[grid](\n            predictions, targets, per_sample_loss,\n            n_classes,\n            predictions.stride(0), predictions.stride(1),\n            batch_size,\n            BLOCK_SIZE,\n            num_warps=4 if BLOCK_SIZE <= 32 else 8,\n            num_stages=2\n        )\n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.4310), Performs well on runtime_ms (0.0578), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:7', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.431, 'custom_timing': 0.0578})\n\n\n### Program 3 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=['batch_size', 'num_classes']\n)\n@triton.jit\ndef _cross_entropy_forward_kernel(\n    predictions_ptr,\n    targets_ptr,\n    per_sample_loss_ptr,\n    batch_size: tl.constexpr,\n    num_classes: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * num_classes\n    offs = tl.arange(0, BLOCK_SIZE)\n    mask = offs < num_classes\n    row = tl.load(predictions_ptr + row_start + offs, mask=mask, other=-float('inf'))\n    \n    row_max = tl.max(row, axis=0)\n    row_shifted = row - row_max\n    row_exp = tl.exp(row_shifted)\n    row_sum_exp = tl.sum(row_exp, axis=0)\n    \n    target_index = tl.load(targets_ptr + pid)\n    target_val = tl.load(predictions_ptr + row_start + target_index)\n    target_val_shifted = target_val - row_max\n    \n    log_softmax_target = target_val_shifted - tl.log(row_sum_exp)\n    loss_i = -log_softmax_target\n    \n    tl.store(per_sample_loss_ptr + pid, loss_i)\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        \n        batch_size, num_classes = predictions.shape\n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        \n        BLOCK_SIZE = triton.next_power_of_2(num_classes)\n        grid = (batch_size,)\n        \n        _cross_entropy_forward_kernel[grid](\n            predictions, \n            targets, \n            per_sample_loss,\n            batch_size,\n            num_classes,\n            BLOCK_SIZE\n        )\n        \n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes, )\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.3850), Performs well on runtime_ms (0.0647), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0249, 'speed_up': 0.385, 'custom_timing': 0.0647})\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 20.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=['batch_size', 'num_classes']\n)\n@triton.jit\ndef _cross_entropy_forward_kernel(\n    predictions_ptr,\n    targets_ptr,\n    per_sample_loss_ptr,\n    batch_size: tl.constexpr,\n    num_classes: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * num_classes\n    offs = tl.arange(0, BLOCK_SIZE)\n    mask = offs < num_classes\n    row = tl.load(predictions_ptr + row_start + offs, mask=mask, other=-float('inf'))\n    \n    row_max = tl.max(row, axis=0)\n    row_shifted = row - row_max\n    row_exp = tl.exp(row_shifted)\n    row_sum_exp = tl.sum(row_exp, axis=0)\n    \n    target_index = tl.load(targets_ptr + pid)\n    target_val = tl.load(predictions_ptr + row_start + target_index)\n    target_val_shifted = target_val - row_max\n    \n    log_softmax_target = target_val_shifted - tl.log(row_sum_exp)\n    loss_i = -log_softmax_target\n    \n    tl.store(per_sample_loss_ptr + pid, loss_i)\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        \n        batch_size, num_classes = predictions.shape\n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        \n        BLOCK_SIZE = triton.next_power_of_2(num_classes)\n        grid = (batch_size,)\n        \n        _cross_entropy_forward_kernel[grid](\n            predictions, \n            targets, \n            per_sample_loss,\n            batch_size,\n            num_classes,\n            BLOCK_SIZE\n        )\n        \n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes, )\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Excellent correctness (1.000)\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef cross_entropy_kernel(\n    logits_ptr,\n    targets_ptr,\n    output_ptr,\n    n_classes,\n    stride_logits_batch,\n    stride_logits_class,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    target_idx = tl.load(targets_ptr + pid)\n    row_start = pid * stride_logits_batch\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_classes\n    \n    logits_ptrs = logits_ptr + row_start + col_offsets * stride_logits_class\n    logits = tl.load(logits_ptrs, mask=mask, other=-float('inf'))\n    \n    max_val = tl.max(logits, axis=0)\n    logits = logits - max_val\n    exp_logits = tl.exp(logits)\n    sum_exp = tl.sum(exp_logits, axis=0)\n    \n    mask_target = col_offsets == target_idx\n    target_logit = tl.sum(tl.where(mask_target, logits, 0.0), axis=0)\n    \n    log_softmax = target_logit - tl.log(sum_exp)\n    loss = -log_softmax\n    tl.store(output_ptr + pid, loss)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        batch_size, n_classes = predictions.shape[0], predictions.shape[1]\n        \n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        BLOCK_SIZE = triton.next_power_of_2(n_classes)\n        \n        grid = (triton.cdiv(batch_size, 128) * 128,)\n        cross_entropy_kernel[grid](\n            predictions, targets, per_sample_loss,\n            n_classes,\n            predictions.stride(0), predictions.stride(1),\n            batch_size,\n            BLOCK_SIZE\n        )\n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a Triton kernel for cross-entropy loss that is currently slower than the PyTorch reference (speed_up=0.44). The goal is to improve the performance.\n\nObservations on the current kernel:\n1. The kernel processes one row (sample) per program ID (pid).\n2. For each row, it loads a block of logits (with BLOCK_SIZE being the next power of two of the number of classes).\n3. It then computes the max, subtracts it for numerical stability, exponentiates, and sums the exponentials.\n4. It then extracts the target logit (by creating a mask and then doing a sum of the masked logits) and computes the loss.\n\nPotential bottlenecks and improvements:\n- The current method for extracting the target logit is inefficient: it creates a mask for the entire row and then does a sum over the row multiplied by the mask. Instead, we can directly load the target logit by computing its address.\n- The kernel does not use vectorized loads/stores. Since the block size might be small (num_classes=10, so BLOCK_SIZE=16), we might not get the full benefit of vectorization, but it's still worth trying to use vectorized loads if possible. However, note that the mask might make vectorization difficult.\n- We can try to optimize the computation of the log softmax by avoiding the entire row operation for the target. Specifically, we can:\n   a) Compute the max and the sum of exponentials for the entire row (as we do now).\n   b) Then, instead of masking the entire row to get the target logit, we can directly load the target logit (using the target index) and then compute the log_softmax for that index.\n\nProposed changes:\n1. Instead of using `mask_target` and `tl.where` to get the target logit, we can compute the address of the target logit and load it. This avoids the unnecessary computation over the entire row.\n2. We note that the current method of computing `target_logit` by a masked sum is equivalent to just the logit at the target index (because the mask is one only at the target and zero elsewhere). So we can replace:\n   ```\n   mask_target = col_offsets == target_idx\n   target_logit = tl.sum(tl.where(mask_target, logits, 0.0), axis=0)\n   ```\n   with:\n   ```\n   target_logit = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n   ```\n   But note: we have already shifted the logits by `max_val` in the variable `logits`? Actually, no: we have a variable `logits` that is the original logits, then we subtract `max_val` to get a new `logits` (which we then use for exp). However, we have stored the shifted logits in the same variable. Then we use that shifted `logits` for the mask_target sum. So we must load the target logit from the original logits and then subtract `max_val`? Or we can note that the target logit in the shifted logits is just the value at the target index in the array `logits` (which is the shifted version). But wait: the array `logits` is the shifted one. However, we cannot directly index into the `logits` array because it is a block that we loaded. We have the target index, but note that the target index might not be in the loaded block? Actually, we are loading the entire row (with padding beyond `n_classes` set to -inf). The target index is in the range [0, n_classes-1] so it is within the valid part. But note: the loaded `logits` array is of length BLOCK_SIZE, but the target index is an integer in [0, n_classes-1] which is less than BLOCK_SIZE (because BLOCK_SIZE is the next power of two and >= n_classes). So we can use the target index as an offset in the loaded `logits` array? However, the loaded `logits` array is in the order of `col_offsets` (from 0 to BLOCK_SIZE-1). The target index is the class index, which corresponds to the same offset in the row. Therefore, we can do:\n   ```\n   target_logit = logits[target_idx]   # This is not directly possible because logits is a 1D array and target_idx is a scalar, and we cannot use a dynamic index in Triton.\n   ```\n   Alternatively, we can note that the target index might not be aligned with the block we loaded? Actually, we loaded the entire row. So the target index is within [0, n_classes-1] and we have loaded that entire range. Therefore, we can use:\n   ```\n   target_logit = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n   ```\n   and then subtract `max_val`? But wait: we have already computed the shifted logits and stored them in the variable `logits`. We don't have the original logits anymore. We could recompute the shifted target logit by:\n   ```\n   target_logit_shifted = target_logit_original - max_val\n   ```\n   However, we have the entire row of shifted logits in the variable `logits`. So if we can extract the element at the target index from the `logits` array, that would be the shifted target logit. But Triton does not support dynamic indexing of the vector register.\n\nAnother approach: we can use `tl.advance` to get the pointer to the target logit in the row and then load it. But note: we have already loaded the entire row? Then why not use the fact that we have it in the `logits` array? Unfortunately, Triton does not let us index a vector with a dynamic index. Therefore, we have two options:\n\nOption A: After computing the shifted logits, we can do a second load for the target logit (only one element). This would be one memory access. We would compute:\n   original_target_logit = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n   target_logit_shifted = original_target_logit - max_val\n\nOption B: We can use a reduction to extract the element at the target index from the `logits` array. We can do:\n   target_logit_shifted = tl.sum(tl.where(mask_target, logits, 0.0), axis=0)\n   which is what we are currently doing.\n\nBut note: the current method (Option B) requires a mask and a sum over the entire block. This is O(BLOCK_SIZE) operations. Option A is a single memory load. Since BLOCK_SIZE is 16 (for n_classes=10) and the memory load might be cached, Option A might be faster.\n\nHowever, we must note that the entire row is already in the L1 cache because we just loaded it. So the additional load for the target logit would be very fast. Therefore, Option A is likely more efficient.\n\nLet me restructure the kernel:\n\nSteps:\n1. Load the entire row of logits (as before) into `logits_row`.\n2. Compute `max_val = tl.max(logits_row, axis=0)`\n3. Shift the row: `shifted_row = logits_row - max_val`\n4. Compute `exp_shifted_row = tl.exp(shifted_row)`\n5. Compute `sum_exp = tl.sum(exp_shifted_row, axis=0)`\n6. Load the original target logit: `target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)`\n   But note: we have the shifted row in a register. We don't have the original row? Actually, we have `logits_row` which is the original row? We overwrote it? We did:\n   `logits = tl.load(...)` -> then we do `logits = logits - max_val` -> so we lost the original. So we either:\n   a) Keep the original row in a separate variable? That would double the register usage (which might be acceptable because BLOCK_SIZE is small).\n   b) Reload the target logit? Then we don't need the original row? We can compute the shifted target logit by subtracting max_val.\n\nWe choose to reload the target logit? But note: we have the entire row in `logits_row` (the original) and then we shifted it. We could have saved the original? Alternatively, we can avoid storing the original row twice by reloading the target logit. Since the row is in cache, reloading one element is cheap.\n\nAlternatively, we can avoid the reload by storing the original target logit before we shift the row? But we don't know the target index until after we load the row? Actually, we have the target index at the beginning.\n\nSo let's do:\n\n   target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n\nBut note: we are going to load the entire row immediately after. So we are loading the same row twice? The target logit is part of the row. This would be one extra load. However, the entire row is 16 elements (if BLOCK_SIZE=16) and we are loading 16 elements and then one extra element. It might be better to just extract the target logit from the row we have already loaded? But without dynamic indexing, we cannot.\n\nTherefore, we have two choices:\n\nChoice 1: Load the entire row and then also load the target logit separately (so two loads: one for the entire row and one for the target logit). Then we can shift the entire row and the target logit by the same max_val.\n\nChoice 2: Use a reduction to extract the target logit from the loaded row (which we are currently doing) and avoid the extra load.\n\nGiven that the row is small, the reduction might be cheap. However, let's compare:\n\nCurrent: one load for the row (16 elements) and then a reduction over 16 elements to get the target logit (which is a masked sum).\n\nProposed: one load for the row (16 elements) and one load for the target logit (1 element). \n\nThe second load might be faster because it is one element, but it requires an extra memory access. However, because the row is already in the cache, the extra load should be very fast. And the reduction requires 16 operations (which are in registers). Since 16 is small, it might be a wash.\n\nBut note: the reduction method requires creating a mask (which is a comparison of the entire block of col_offsets with the target index) and then a multiplication and sum. This might be more expensive than one extra load? Especially because the extra load is to the same row and likely in L1.\n\nTherefore, we try to replace the reduction with an extra load.\n\nWe also note that the current method for the target logit in the kernel is:\n\n   mask_target = col_offsets == target_idx\n   target_logit = tl.sum(tl.where(mask_target, logits, 0.0), axis=0)\n\nWe want to replace that with:\n\n   target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n   target_logit_shifted = target_logit_orig - max_val\n\nand then use `target_logit_shifted` in the log_softmax.\n\nBut note: the current variable `logits` is the shifted row? Actually, we have:\n\n   logits = logits - max_val   -> so we shifted the entire row.\n\nThen we compute the exp and the sum. Then we use the shifted row to extract the target logit? But we don't have the shifted row in memory, we only have it in a register. So we cannot load the shifted target logit from memory. Therefore, we must compute the shifted target logit by subtracting max_val from the original target logit.\n\nSo steps:\n\n   ... [load entire row] ...\n   max_val = tl.max(logits, axis=0)\n   # Now, we want the shifted target logit: we can either shift the entire row and then extract (by reduction) OR we can shift the target logit separately.\n\n   Option A (current): shift the entire row, then use reduction to extract the target logit from the shifted row.\n\n   Option B: don't shift the entire row? Then how do we compute the exponentials? We must shift for numerical stability.\n\n   Alternatively, we can do:\n\n   shifted_row = logits - max_val\n   # Now we need the shifted target logit: we can compute it by:\n   target_logit_shifted = (the original target logit) - max_val\n\n   But we don't have the original target logit? We can load it again? Or we can save it before shifting? We can load the target logit at the beginning? \n\n   We can do:\n\n   target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n\n   Then, after computing max_val, we do:\n\n   target_logit_shifted = target_logit_orig - max_val\n\n   And then we shift the entire row? But note: we have the entire row in `logits`. We can shift it and then compute the exponentials.\n\n   So:\n\n   logits_shifted = logits - max_val\n   exp_logits = tl.exp(logits_shifted)\n   ... etc ...\n\n   and then use `target_logit_shifted` for the log_softmax.\n\n   This avoids the reduction. We do an extra load (for the target logit) but we avoid the reduction over the entire row.\n\n   Also note: we are already loading the entire row. The extra load for one element is negligible.\n\nTherefore, we change the kernel to:\n\n   pid = tl.program_id(0)\n   if pid >= batch_size:\n        return\n\n   target_idx = tl.load(targets_ptr + pid)\n   row_start = pid * stride_logits_batch\n\n   # Load the entire row\n   col_offsets = tl.arange(0, BLOCK_SIZE)\n   mask = col_offsets < n_classes\n   logits_ptrs = logits_ptr + row_start + col_offsets * stride_logits_class\n   logits = tl.load(logits_ptrs, mask=mask, other=-float('inf'))\n\n   # Also load the target logit separately\n   target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n\n   max_val = tl.max(logits, axis=0)\n   logits_shifted = logits - max_val\n   target_logit_shifted = target_logit_orig - max_val\n\n   exp_logits = tl.exp(logits_shifted)\n   sum_exp = tl.sum(exp_logits, axis=0)\n\n   log_softmax = target_logit_shifted - tl.log(sum_exp)\n   loss = -log_softmax\n   tl.store(output_ptr + pid, loss)\n\nThis should be more efficient because we avoid the reduction for the target logit.\n\nAdditionally, we can try to use vectorized loads. However, the current load is already a vector load (using `tl.load` with a vector of pointers). So we are already loading the entire row in a vectorized way.\n\nWe can also try to adjust the block size and grid size? The current grid is set to `(triton.cdiv(batch_size, 128) * 128,)` which is a multiple of 128. This is good for occupancy.\n\nWe might also try to use the autotuner? But the problem size is fixed (batch_size=4096, num_classes=10) so we can tune for that.\n\nHowever, the current kernel does not use autotuning. We can add it? But the instructions say: \"Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions\" \u2014 but note that our BLOCK_SIZE is fixed to the next power of two of n_classes (which is 16). So we don't have a tunable block size? Actually, we are using BLOCK_SIZE as the block for the row. It is fixed.\n\nWe can try to change the number of warps? The current kernel does not specify the number of warps or stages. We can add autotuning for the number of warps and stages.\n\nBut note: the problem is very small per thread (only 16 elements). So we might want to use fewer warps? Actually, each thread is processing one row. The number of rows is 4096. We are launching 4096 threads? Actually, the grid is set to a multiple of 128 (which is 4096, because 4096/128=32, then 32*128=4096). So we are launching 4096 threads.\n\nWe can try to use 1 warp per row? That would be inefficient because a warp has 32 threads, and we are only using one thread per row. So we are launching 4096 threads -> 4096/32 = 128 warps. This is acceptable.\n\nAlternatively, we can have each thread process multiple rows? But the kernel is written for one row per thread. Given the small number of classes, we might try to have each thread process multiple rows? But that would require a change in the kernel structure.\n\nGiven the time, let's first try the change of replacing the reduction with an extra load.\n\nWe'll modify the kernel accordingly.\n\nAlso note: we must be cautious about the boundary condition for the target logit load: the target index is in [0, n_classes-1] and we have mask for the row that sets values beyond n_classes to -inf. But when we load the target logit, it is within [0, n_classes-1] so it is valid. So no mask is needed for that load.\n\nLet's write the new kernel.\n\nWe also note: the current kernel uses `tl.log(sum_exp)`. We assume that `sum_exp` is positive? It should be. But if the row is all -inf, then sum_exp would be 0? Then log(0) would be -inf. That is acceptable because then the loss would be -(-inf) = inf? But that's the correct behavior.\n\nWe'll keep the rest the same.\n\nWe'll also try to add autotuning for the number of warps? Since the current kernel does not specify, we can try to add an autotuner. But note: the kernel is called with a fixed batch_size and num_classes. We can try a few configurations.\n\nWe can do:\n\n   configs = [\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n   ]\n\nBut note: each thread is independent and the work per thread is very small (16 elements). So using fewer warps might be better? Actually, using 1 warp per thread is not possible because a warp is 32 threads. We are launching 4096 threads. The number of warps per block? The kernel is launched with one block per 128 threads? Actually, the grid is (4096,) so we are launching 4096 threads in one-dimensional grid. The block size is not specified? Then it is one thread per block? That would be inefficient.\n\nWait, the grid is set to `(triton.cdiv(batch_size, 128) * 128,)` which is 4096. But we are not specifying the block size? Then by default, Triton uses one thread per block? That would be 4096 blocks. That is inefficient because the GPU has limited blocks in flight.\n\nWe should specify a block size? We can set the block size to 128? Then we would have 4096/128 = 32 blocks.\n\nWe can change the kernel launch to:\n\n   grid = (triton.cdiv(batch_size, 128),)\n   cross_entropy_kernel[grid, 128](...)\n\nBut note: the kernel currently expects one thread per row. So we would need to adjust the kernel to use a block of threads and then have each block process multiple rows? That would be a bigger change.\n\nAlternatively, we can set the block size to 1? Then we have 4096 blocks. That might be acceptable because the GPU can handle thousands of blocks.\n\nBut to improve occupancy, we might want to have more threads per block. We can change the kernel to process multiple rows per block? But that would be a significant rewrite.\n\nGiven the time, we'll stick to one thread per row and try to change the block size in the grid. Currently, the grid is set to (4096,) and the block size is not specified (so it defaults to 1). We can change the launch to use a block of 128 threads? Then we would have:\n\n   grid = (triton.cdiv(batch_size, 128),)   # 4096/128 = 32 blocks\n   and then in the kernel, we would have:\n\n   pid = tl.program_id(0) * 128 + tl.program_id(1)\n\n   but wait, the kernel is written for one-dimensional grid.\n\nAlternatively, we can change the kernel to use a two-dimensional grid? But that would require more changes.\n\nWe can instead set the grid to (32,) and the block size to 128, and then have each thread process multiple rows? Specifically, each thread would process 4096/(32*128) = 1 row? Actually, 32*128=4096, so each thread processes one row.\n\nSo we can do:\n\n   grid = (32,)\n   block = (128,)\n\n   and then in the kernel:\n\n   pid = tl.program_id(0) * 128 + tl.thread_id_x\n\n   and then if pid < batch_size, process the row.\n\nBut note: the kernel uses `tl.program_id(0)` to get the row index. We are changing the grid to be 32 blocks of 128 threads. So we must compute the global row index.\n\nWe can do:\n\n   row_idx = tl.program_id(0) * 128 + tl.thread_id_x\n   if row_idx >= batch_size:\n        return\n\n   then use row_idx as the row index.\n\nThis would be more efficient because we are using 128 threads per block. The current kernel is using one thread per block? That is very inefficient.\n\nBut the current grid is set to `(triton.cdiv(batch_size, 128) * 128,)` which is 4096. This is the total number of threads? And then we are not specifying the block size? Then Triton uses one thread per block? That is 4096 blocks.\n\nWe want to use 128 threads per block and 4096/128 = 32 blocks. We can change the grid function to return (32,) and then set the block size to 128? But note: in Triton, the grid is the number of blocks, and the block size is the number of threads per block.\n\nSo we can change:\n\n   grid = (triton.cdiv(batch_size, 128),)   # 32 blocks\n   cross_entropy_kernel[grid, 128](...)\n\nThen in the kernel, we must adjust the way we compute the row index:\n\n   pid = tl.program_id(0) * 128 + tl.arange(0, 128)   -> no, we are in a vectorized kernel? Actually, the kernel is written for one row per thread. We are using scalar operations? Actually, the kernel uses `tl.arange(0, BLOCK_SIZE)` to load a vector of logits. So each thread is processing one row, but the row is loaded as a vector. This is fine.\n\nBut how do we get the row index for each thread? We are using `tl.program_id(0)` to be the block index, and then we have 128 threads in the block. We can compute:\n\n   pid = tl.program_id(0) * 128 + tl.thread_id_x\n\nBut note: the kernel is written in Triton with `@triton.jit` and uses `tl.program_id(0)` and `tl.arange(0, BLOCK_SIZE)`. The `tl.thread_id_x` is not directly available? Instead, we can use:\n\n   pid = tl.program_id(0) * 128 + tl.arange(0, 1)[0]   -> not really.\n\nAlternatively, we can change the kernel to be aware of the block dimension? Actually, the kernel is written for a one-dimensional grid of threads. We are now launching a two-dimensional grid? We are launching one-dimensional grid of blocks and then one-dimensional blocks. So the total number of threads is 32*128=4096. We can compute the global thread id as:\n\n   pid = tl.program_id(0) * 128 + tl.thread_id(0)\n\nBut note: the function `tl.thread_id(0)` returns the thread id within the block in the first dimension. However, we are not using the second dimension. So we can do:\n\n   pid = tl.program_id(0) * 128 + tl.thread_id(0)\n\nBut we must note: the kernel currently uses `tl.program_id(0)` to index the row. We are changing that to a global thread id.\n\nAlternatively, we can leave the kernel as is and change the grid to be (4096,) and then set the block size to 1? But that is inefficient.\n\nGiven the complexity, and because the current kernel is slow, we will first try the change of replacing the reduction with an extra load and then see if we can also change the block size.\n\nBut note: the instructions say: \"NEVER change grid configuration, output tensor shapes, or PID logic\". So we are not allowed to change the grid configuration? The current grid is set to:\n\n   grid = (triton.cdiv(batch_size, 128) * 128,)\n\nWe are not allowed to change that? So we must keep the grid as a one-dimensional grid of 4096.\n\nTherefore, we cannot change the block structure. We are stuck with one thread per block? That is inefficient, but we are constrained.\n\nSo we focus on the kernel computation.\n\nWe will change the kernel to load the target logit separately and avoid the reduction.\n\nLet's write the new kernel accordingly.\n\nWe also note: the current kernel uses `logits = logits - max_val` and then uses `logits` for the exp. We are going to change that variable to `logits_shifted`? Actually, we can keep the same variable name? We are going to do:\n\n   logits = tl.load(...)   # the original logits\n   target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n   max_val = tl.max(logits, axis=0)\n   logits = logits - max_val   # now logits becomes the shifted logits\n   target_logit_shifted = target_logit_orig - max_val\n\n   ... then use logits for the exp and target_logit_shifted for the log_softmax.\n\nThis is acceptable.\n\nWe'll also change the variable names for clarity? Not necessary.\n\nWe'll update the kernel accordingly.\n\nWe'll also try to add autotuning for the number of warps? But note: the kernel is launched with one thread per block? Then the number of warps per block is 1 warp per block (since one thread) and we cannot change that. So autotuning for the number of warps doesn't make sense? Actually, the number of warps must be at least ceil(1/32)=1. We can set it to 1? But it doesn't matter because the block has only one thread.\n\nTherefore, we skip autotuning.\n\nWe'll only make the change in the kernel.\n\nLet's write the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef cross_entropy_kernel(\n    logits_ptr,\n    targets_ptr,\n    output_ptr,\n    n_classes,\n    stride_logits_batch,\n    stride_logits_class,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    target_idx = tl.load(targets_ptr + pid)\n    row_start = pid * stride_logits_batch\n    \n    # Load target logit directly instead of masked reduction\n    target_logit_orig = tl.load(logits_ptr + row_start + target_idx * stride_logits_class)\n    \n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_classes\n    logits_ptrs = logits_ptr + row_start + col_offsets * stride_logits_class\n    logits = tl.load(logits_ptrs, mask=mask, other=-float('inf'))\n    \n    max_val = tl.max(logits, axis=0)\n    logits_shifted = logits - max_val\n    target_logit_shifted = target_logit_orig - max_val\n    \n    exp_logits = tl.exp(logits_shifted)\n    sum_exp = tl.sum(exp_logits, axis=0)\n    \n    log_softmax = target_logit_shifted - tl.log(sum_exp)\n    loss = -log_softmax\n    tl.store(output_ptr + pid, loss)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        batch_size, n_classes = predictions.shape[0], predictions.shape[1]\n        \n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        BLOCK_SIZE = triton.next_power_of_2(n_classes)\n        \n        grid = (triton.cdiv(batch_size, 128) * 128,)\n        cross_entropy_kernel[grid](\n            predictions, targets, per_sample_loss,\n            n_classes,\n            predictions.stride(0), predictions.stride(1),\n            batch_size,\n            BLOCK_SIZE\n        )\n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}