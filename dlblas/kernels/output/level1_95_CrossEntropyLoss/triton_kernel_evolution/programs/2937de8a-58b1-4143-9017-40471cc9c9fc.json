{"id": "2937de8a-58b1-4143-9017-40471cc9c9fc", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=['batch_size', 'num_classes']\n)\n@triton.jit\ndef _cross_entropy_forward_kernel(\n    predictions_ptr,\n    targets_ptr,\n    per_sample_loss_ptr,\n    batch_size: tl.constexpr,\n    num_classes: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * num_classes\n    offs = tl.arange(0, BLOCK_SIZE)\n    mask = offs < num_classes\n    row = tl.load(predictions_ptr + row_start + offs, mask=mask, other=-float('inf'))\n    \n    row_max = tl.max(row, axis=0)\n    row_shifted = row - row_max\n    row_exp = tl.exp(row_shifted)\n    row_sum_exp = tl.sum(row_exp, axis=0)\n    \n    target_index = tl.load(targets_ptr + pid)\n    target_mask = offs == target_index\n    target_val_shifted = tl.sum(tl.where(target_mask, row_shifted, 0.0))\n    \n    log_softmax_target = target_val_shifted - tl.log(row_sum_exp)\n    loss_i = -log_softmax_target\n    \n    tl.store(per_sample_loss_ptr + pid, loss_i)\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, predictions, targets):\n        predictions = predictions.contiguous()\n        targets = targets.contiguous()\n        \n        batch_size, num_classes = predictions.shape\n        per_sample_loss = torch.empty(batch_size, device=predictions.device, dtype=predictions.dtype)\n        \n        BLOCK_SIZE = triton.next_power_of_2(num_classes)\n        grid = (batch_size,)\n        \n        _cross_entropy_forward_kernel[grid](\n            predictions, \n            targets, \n            per_sample_loss,\n            batch_size,\n            num_classes,\n            BLOCK_SIZE\n        )\n        \n        return per_sample_loss.mean()\n\nbatch_size = 4096\nnum_classes = 10\ninput_shape = (num_classes, )\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randint(0, num_classes, (batch_size,))]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "7fbce3a8-4d6f-4513-856e-27af6b6218da", "generation": 2, "timestamp": 1754993971.9708016, "iteration_found": 28, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.357, "runtime_ms": 0.0698, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0249, "speed_up": 0.357, "custom_timing": 0.0698}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.385, "runtime_ms": 0.0647, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0249, "speed_up": 0.385, "custom_timing": 0.0647}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}