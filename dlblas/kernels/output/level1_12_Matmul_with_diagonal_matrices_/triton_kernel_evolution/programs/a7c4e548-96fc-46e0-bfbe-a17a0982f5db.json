{"id": "a7c4e548-96fc-46e0-bfbe-a17a0982f5db", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, A, B):\n        N, M = B.shape\n        A = A.contiguous()\n        B = B.contiguous()\n        C = torch.empty_like(B)\n        if N * M == 0:\n            return C\n            \n        grid = (N,)\n        self.diag_mult_kernel[grid](A, B, C, M)\n        return C\n\n    @staticmethod\n    @triton.autotune(\n        configs=[\n            triton.Config({'BLOCK_SIZE': 128}, num_warps=1),\n            triton.Config({'BLOCK_SIZE': 128}, num_warps=2),\n            triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n            triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n            triton.Config({'BLOCK_SIZE': 256}, num_warps=1),\n            triton.Config({'BLOCK_SIZE': 256}, num_warps=2),\n            triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n            triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n            triton.Config({'BLOCK_SIZE': 512}, num_warps=1),\n            triton.Config({'BLOCK_SIZE': 512}, num_warps=2),\n            triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n            triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n            triton.Config({'BLOCK_SIZE': 1024}, num_warps=1),\n            triton.Config({'BLOCK_SIZE': 1024}, num_warps=2),\n            triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n            triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n        ],\n        key=['M'],\n    )\n    @triton.jit\n    def diag_mult_kernel(\n        A_ptr, \n        B_ptr, \n        C_ptr, \n        M, \n        BLOCK_SIZE: tl.constexpr\n    ):\n        pid = tl.program_id(0)\n        a_val = tl.load(A_ptr + pid)\n        col_offsets = tl.arange(0, BLOCK_SIZE)\n        \n        for col_start in tl.range(0, M, BLOCK_SIZE):\n            col_idx = col_start + col_offsets\n            mask = col_idx < M\n            \n            row_start = pid * M\n            b_ptrs = B_ptr + row_start + col_idx\n            b_vals = tl.load(b_ptrs, mask=mask, other=0.0, cache_modifier=\".cg\")\n            \n            c_vals = a_val * b_vals\n            c_ptrs = C_ptr + row_start + col_idx\n            tl.store(c_ptrs, c_vals, mask=mask)\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.randn(N, device='cuda')\n    B = torch.randn(N, M, device='cuda')\n    return [A, B]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "0e161958-ef7c-421c-8351-2560a8051be1", "generation": 3, "timestamp": 1754640181.2520294, "iteration_found": 28, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.526, "runtime_ms": 0.0891, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0469, "speed_up": 0.526, "custom_timing": 0.0891}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.535, "runtime_ms": 0.0876, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0469, "speed_up": 0.535, "custom_timing": 0.0876}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}