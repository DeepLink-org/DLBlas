{"id": "8fee8384-e7dc-4867-bf27-1a341414ebfc", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Optimized model for diag(A) * B using Triton with autotuning\n    \"\"\"\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, A, B):\n        N = A.shape[0]\n        M = B.shape[1]\n        C = torch.empty((N, M), device=A.device, dtype=A.dtype)\n        \n        # Only use Triton on CUDA devices\n        if A.is_cuda and B.is_cuda:\n            # Dynamic grid calculation based on autotune parameters\n            grid = lambda meta: (N, triton.cdiv(M, meta['BLOCK_SIZE_N']))\n            self.diag_matmul_kernel[grid](\n                A, B, C,\n                N, M,\n                B.stride(0), B.stride(1),\n                C.stride(0), C.stride(1),\n            )\n        else:\n            # Fallback to PyTorch for non-CUDA\n            C = torch.diag(A) @ B\n            \n        return C\n\n    @staticmethod\n    @triton.autotune(\n        configs=[\n            triton.Config({'BLOCK_SIZE_N': 128}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 128}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 128}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 128}, num_warps=8),\n            triton.Config({'BLOCK_SIZE_N': 256}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 256}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 256}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 256}, num_warps=8),\n            triton.Config({'BLOCK_SIZE_N': 512}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 512}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 512}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 512}, num_warps=8),\n            triton.Config({'BLOCK_SIZE_N': 1024}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 1024}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 1024}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 1024}, num_warps=8),\n            triton.Config({'BLOCK_SIZE_N': 2048}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 2048}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 2048}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 2048}, num_warps=8),\n            triton.Config({'BLOCK_SIZE_N': 4096}, num_warps=1),\n            triton.Config({'BLOCK_SIZE_N': 4096}, num_warps=2),\n            triton.Config({'BLOCK_SIZE_N': 4096}, num_warps=4),\n            triton.Config({'BLOCK_SIZE_N': 4096}, num_warps=8),\n        ],\n        key=['M'],\n    )\n    @triton.jit\n    def diag_matmul_kernel(\n        A_ptr, \n        B_ptr, \n        C_ptr,\n        N, M,\n        stride_bm, stride_bn,\n        stride_cm, stride_cn,\n        BLOCK_SIZE_N: tl.constexpr\n    ):\n        row_idx = tl.program_id(0)\n        col_block_idx = tl.program_id(1)\n        \n        # Skip out-of-bound rows\n        if row_idx >= N:\n            return\n        \n        # Column offsets\n        col_offsets = col_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        col_mask = col_offsets < M\n        \n        # Load scalar from A\n        a_val = tl.load(A_ptr + row_idx)\n        \n        # Load row segment from B\n        b_ptrs = B_ptr + row_idx * stride_bm + col_offsets * stride_bn\n        b_vals = tl.load(b_ptrs, mask=col_mask)\n        \n        # Compute element-wise product\n        result = a_val * b_vals\n        \n        # Store results\n        c_ptrs = C_ptr + row_idx * stride_cm + col_offsets * stride_cn\n        tl.store(c_ptrs, result, mask=col_mask)\n\nM = 4096\nN = 4096\n\ndef get_inputs():\n    A = torch.randn(N)\n    B = torch.randn(N, M)\n    return [A, B]\n\ndef get_init_inputs():\n    return []  # No special initialization inputs needed\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "ce2bf701-4ff8-4d65-bc5c-a7668c7b814d", "generation": 2, "timestamp": 1754638935.1899524, "iteration_found": 20, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.46, "runtime_ms": 0.102, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0469, "speed_up": 0.46, "custom_timing": 0.102}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.56, "runtime_ms": 0.0838, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0469, "speed_up": 0.56, "custom_timing": 0.0838}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}