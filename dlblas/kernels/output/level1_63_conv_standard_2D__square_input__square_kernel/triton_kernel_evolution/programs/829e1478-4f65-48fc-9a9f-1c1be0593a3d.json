{"id": "829e1478-4f65-48fc-9a9f-1c1be0593a3d", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.groups = groups\n        \n        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, kernel_size, kernel_size))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        \n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        B, C, H, W = x.shape\n        K = self.kernel_size\n        H_out = (H + 2 * self.padding - dilation * (K - 1) - 1) // self.stride + 1\n        W_out = (W + 2 * self.padding - dilation * (K - 1) - 1) // self.stride + 1\n        \n        # Convert to FP16 for Tensor Core acceleration\n        x_fp16 = x.to(torch.float16)\n        weight_fp16 = self.weight.view(self.out_channels, -1).to(torch.float16)\n        \n        # Precompute flattened dimensions\n        M = B * H_out * W_out\n        N = self.out_channels\n        K_total = self.in_channels * K * K\n        \n        # Allocate output tensor (FP32 for accumulation)\n        output = torch.empty(B, N, H_out, W_out, device=x.device, dtype=torch.float32)\n        \n        # Launch Triton kernel with autotuning\n        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE_M']), triton.cdiv(N, meta['BLOCK_SIZE_N']))\n        _conv2d_forward[grid](\n            x_fp16, weight_fp16, output,\n            # Tensor dimensions\n            B, C, H, W, N, K,\n            # Convolution parameters\n            self.stride, self.padding, self.dilation,\n            H_out, W_out,\n            # Tensor strides\n            x_fp16.stride(0), x_fp16.stride(1), x_fp16.stride(2), x_fp16.stride(3),\n            weight_fp16.stride(0), weight_fp16.stride(1),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            # Kernel parameters\n            M, K_total,\n            # Tile sizes (autotuned)\n            BLOCK_SIZE_M=128, BLOCK_SIZE_N=64, BLOCK_SIZE_K=32\n        )\n        \n        # Add bias if needed\n        if self.bias is not None:\n            output += self.bias[None, :, None, None]\n            \n        return output\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['M', 'N'],\n)\n@triton.jit\ndef _conv2d_forward(\n    # Pointers to tensors\n    input_ptr, weight_ptr, output_ptr,\n    # Tensor dimensions\n    B, C, H, W, F, K,\n    # Convolution parameters\n    stride, padding, dilation,\n    H_out, W_out,\n    # Input tensor strides\n    input_batch_stride, input_channel_stride, input_height_stride, input_width_stride,\n    # Weight tensor strides\n    weight_out_channel_stride, weight_kernel_stride,\n    # Output tensor strides\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    # Flattened dimensions\n    M, K_total,\n    # Tile sizes\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid_m = tl.program_id(0)\n    pid_n = tl.program_id(1)\n    \n    # Create ranges for block processing\n    rm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    rn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    rk = tl.arange(0, BLOCK_SIZE_K)\n    \n    # Mask for output positions\n    m_mask = rm < M\n    # Compute batch and spatial indices\n    batch_idx = rm // (H_out * W_out)\n    spatial_idx = rm % (H_out * W_out)\n    h_out = spatial_idx // W_out\n    w_out = spatial_idx % W_out\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    # Loop over kernel blocks\n    for k in range(0, tl.cdiv(K_total, BLOCK_SIZE_K)):\n        rk = k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n        k_mask = rk < K_total\n        \n        # Map kernel index to 3D coordinates\n        kernel_idx = rk\n        c = kernel_idx // (K * K)\n        kh = (kernel_idx % (K * K)) // K\n        kw = kernel_idx % K\n        \n        # Compute input positions\n        h_in = h_out[:, None] * stride + kh[None, :] * dilation - padding\n        w_in = w_out[:, None] * stride + kw[None, :] * dilation - padding\n        \n        # Create input pointer mask\n        in_bounds = (h_in >= 0) & (h_in < H) & (w_in >= 0) & (w_in < W)\n        full_mask = m_mask[:, None] & k_mask[None, :] & in_bounds\n        \n        # Compute input pointers\n        input_offsets = (\n            batch_idx[:, None] * input_batch_stride +\n            c[None, :] * input_channel_stride +\n            h_in * input_height_stride +\n            w_in * input_width_stride\n        )\n        input_block = tl.load(input_ptr + input_offsets, mask=full_mask, other=0.0)\n        \n        # Load weight block\n        weight_block = tl.load(\n            weight_ptr + rn[None, :] * weight_out_channel_stride + rk[:, None] * weight_kernel_stride,\n            mask=k_mask[:, None] & (rn[None, :] < F),\n            other=0.0\n        )\n        \n        # Accumulate matrix product\n        input_block = input_block.to(tl.float16)\n        weight_block = weight_block.to(tl.float16)\n        acc += tl.dot(input_block, weight_block, allow_tf32=True)\n    \n    # Compute output pointers\n    output_offsets = (\n        batch_idx[:, None] * output_batch_stride +\n        rn[None, :] * output_channel_stride +\n        h_out[:, None] * output_height_stride +\n        w_out[:, None] * output_width_stride\n    )\n    tl.store(output_ptr + output_offsets, acc, mask=m_mask[:, None] & (rn[None, :] < F))\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nwidth = 256\nheight = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "8ea2f6c1-fd74-4643-bdd0-634dfa5992e2", "generation": 1, "timestamp": 1754642142.9734757, "iteration_found": 4, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_63_conv_standard_2D__square_input__square_kernel", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpk7a4w92z.py\", line 34, in forward\n    H_out = (H + 2 * self.padding - dilation * (K - 1) - 1) // self.stride + 1\nNameError: name 'dilation' is not defined\n", "runtime_error_name": "builtins.NameError", "reference_timing_ms": 0.0418, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.273, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0418, "speed_up": 0.153, "custom_timing": 0.273}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}