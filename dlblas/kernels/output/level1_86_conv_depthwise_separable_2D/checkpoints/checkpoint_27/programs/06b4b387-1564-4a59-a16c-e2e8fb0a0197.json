{"id": "06b4b387-1564-4a59-a16c-e2e8fb0a0197", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels, bias=bias)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n        \n    @staticmethod\n    @triton.jit\n    def _depthwise_conv_kernel(\n        x_ptr,\n        weight_ptr,\n        output_ptr,\n        in_channels, height, width,\n        stride_h, stride_w,\n        padding_h, padding_w,\n        dilation_h, dilation_w,\n        kernel_size,\n        output_height, output_width,\n        x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n        weight_channel_stride, weight_height_stride, weight_width_stride,\n        output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n        BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr\n    ):\n        pid_b = tl.program_id(0)\n        pid_c = tl.program_id(1)\n        pid_hw = tl.program_id(2)\n        \n        output_width_blocks = tl.cdiv(output_width, BLOCK_W)\n        pid_h = pid_hw // output_width_blocks\n        pid_w = pid_hw % output_width_blocks\n        \n        h_start = pid_h * BLOCK_H\n        w_start = pid_w * BLOCK_W\n        \n        h_offsets = h_start + tl.arange(0, BLOCK_H)\n        w_offsets = w_start + tl.arange(0, BLOCK_W)\n        \n        h_mask = h_offsets < output_height\n        w_mask = w_offsets < output_width\n        block_mask = h_mask[:, None] & w_mask[None, :]\n        \n        accumulator = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n        \n        for ki in range(kernel_size):\n            for kj in range(kernel_size):\n                input_i = h_offsets * stride_h + ki * dilation_h - padding_h\n                input_j = w_offsets * stride_w + kj * dilation_w - padding_w\n                \n                input_i_mask = (input_i >= 0) & (input_i < height)\n                input_j_mask = (input_j >= 0) & (input_j < width)\n                input_mask = input_i_mask[:, None] & input_j_mask[None, :] & block_mask\n                \n                input_ptr = x_ptr + pid_b * x_batch_stride + pid_c * x_channel_stride\n                input_val = tl.load(\n                    input_ptr + input_i[:, None] * x_height_stride + input_j[None, :] * x_width_stride,\n                    mask=input_mask,\n                    other=0.0\n                )\n                \n                weight_val = tl.load(\n                    weight_ptr + pid_c * weight_channel_stride + ki * weight_height_stride + kj * weight_width_stride\n                )\n                \n                accumulator += input_val * weight_val\n        \n        output_ptr_base = output_ptr + pid_b * output_batch_stride + pid_c * output_channel_stride\n        output_offsets = h_offsets[:, None] * output_height_stride + w_offsets[None, :] * output_width_stride\n        tl.store(output_ptr_base + output_offsets, accumulator, mask=block_mask)\n                    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        stride = self.depthwise.stride\n        padding = self.depthwise.padding\n        dilation = self.depthwise.dilation\n        weight = self.depthwise.weight\n        bias = self.depthwise.bias\n        \n        batch, in_channels, height, width = x.shape\n        kernel_size = weight.shape[2]\n        \n        output_height = (height + 2 * padding[0] - dilation[0] * (kernel_size - 1) - 1) // stride[0] + 1\n        output_width = (width + 2 * padding[1] - dilation[1] * (kernel_size - 1) - 1) // stride[1] + 1\n        \n        x = x.contiguous()\n        weight = weight.contiguous()\n        output = torch.empty((batch, in_channels, output_height, output_width), device=x.device, dtype=x.dtype)\n        \n        grid = (batch, in_channels, triton.cdiv(output_height, 16) * triton.cdiv(output_width, 16))\n        \n        self._depthwise_conv_kernel[grid](\n            x, weight, output,\n            in_channels, height, width,\n            stride[0], stride[1],\n            padding[0], padding[1],\n            dilation[0], dilation[1],\n            kernel_size,\n            output_height, output_width,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            weight.stride(0), weight.stride(2), weight.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_H=16, BLOCK_W=16\n        )\n        \n        if bias is not None:\n            output += bias.reshape(1, -1, 1, 1)\n            \n        output = self.pointwise(output)\n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nout_channels = 64\nkernel_size = 3\nwidth = 256\nheight = 256\nstride = 1\npadding = 0\ndilation = 1\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "3ba1f3f9-8a6b-4ce4-87ad-871a39e62fca", "generation": 1, "timestamp": 1754648122.7026372, "iteration_found": 7, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.273, "runtime_ms": 0.198, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0541, "speed_up": 0.273, "custom_timing": 0.198}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.157, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0541, "speed_up": 0.345, "custom_timing": 0.157}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}