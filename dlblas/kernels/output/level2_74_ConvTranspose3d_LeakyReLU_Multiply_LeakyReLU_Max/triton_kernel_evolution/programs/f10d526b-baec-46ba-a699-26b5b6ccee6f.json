{"id": "f10d526b-baec-46ba-a699-26b5b6ccee6f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise_pool_kernel(\n    input_ptr,\n    output_ptr,\n    multiplier_ptr,\n    input_batch_stride,\n    input_channel_stride,\n    input_depth_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    output_depth_stride,\n    output_height_stride,\n    output_width_stride,\n    num_batch,\n    num_channels,\n    input_depth,\n    input_height,\n    input_width,\n    BLOCK_D: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_programs = tl.num_programs(0)\n    \n    # Coalesce output dimensions\n    output_size = num_batch * num_channels * (input_depth//2) * (input_height//2) * (input_width//2)\n    if pid >= output_size:\n        return\n\n    # Reconstruct 5D output indices\n    b_idx = pid // (num_channels * (input_depth//2) * (input_height//2) * (input_width//2))\n    remainder = pid % (num_channels * (input_depth//2) * (input_height//2) * (input_width//2))\n    c_idx = remainder // ((input_depth//2) * (input_height//2) * (input_width//2))\n    remainder = remainder % ((input_depth//2) * (input_height//2) * (input_width//2))\n    d_idx = remainder // ((input_height//2) * (input_width//2))\n    remainder = remainder % ((input_height//2) * (input_width//2))\n    h_idx = remainder // (input_width//2)\n    w_idx = remainder % (input_width//2)\n\n    # Input window for pooling (2x2x2)\n    d_start = d_idx * 2\n    h_start = h_idx * 2\n    w_start = w_idx * 2\n    \n    # Load multiplier for this channel\n    multiplier = tl.load(multiplier_ptr + c_idx)\n    \n    max_val = -3.4028235e+38  # Min float32 value\n    for dd in range(2):\n        for dh in range(2):\n            for dw in range(2):\n                d_in = d_start + dd\n                h_in = h_start + dh\n                w_in = w_start + dw\n                \n                # Boundary check\n                within_bounds = (d_in < input_depth) & (h_in < input_height) & (w_in < input_width)\n                if within_bounds:\n                    # Calculate input pointer offset\n                    input_offset = (\n                        b_idx * input_batch_stride +\n                        c_idx * input_channel_stride +\n                        d_in * input_depth_stride +\n                        h_in * input_height_stride +\n                        w_in * input_width_stride\n                    )\n                    val = tl.load(input_ptr + input_offset)\n                    \n                    # Apply fused pointwise operations: LeakyReLU -> Multiply -> LeakyReLU\n                    val = tl.where(val >= 0, val, val * 0.2)  # First LeakyReLU\n                    val = val * multiplier\n                    val = tl.where(val >= 0, val, val * 0.2)   # Second LeakyReLU\n                    \n                    # Update max pooling value\n                    max_val = tl.maximum(max_val, val)\n    \n    # Calculate output pointer offset\n    output_offset = (\n        b_idx * output_batch_stride +\n        c_idx * output_channel_stride +\n        d_idx * output_depth_stride +\n        h_idx * output_height_stride +\n        w_idx * output_width_stride\n    )\n    tl.store(output_ptr + output_offset, max_val)\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n        self.max_pool = nn.MaxPool3d(kernel_size=2)\n        \n    def forward(self, x):\n        x = self.conv_transpose(x)\n        \n        # Capture output shape for kernel configuration\n        B, C, D, H, W = x.shape\n        output = torch.empty(B, C, D//2, H//2, W//2, device=x.device, dtype=x.dtype)\n        \n        # Calculate strides for tensor access\n        def get_strides(tensor):\n            return (\n                tensor.stride(0),\n                tensor.stride(1),\n                tensor.stride(2),\n                tensor.stride(3),\n                tensor.stride(4)\n            )\n        \n        input_strides = get_strides(x)\n        output_strides = get_strides(output)\n        \n        # Configure kernel launch parameters\n        grid_size = B * C * (D//2) * (H//2) * (W//2)\n        \n        # Launch fused kernel with fixed grid tuple\n        fused_pointwise_pool_kernel[(grid_size,)](\n            x,\n            output,\n            self.multiplier,\n            input_strides[0],\n            input_strides[1],\n            input_strides[2],\n            input_strides[3],\n            input_strides[4],\n            output_strides[0],\n            output_strides[1],\n            output_strides[2],\n            output_strides[3],\n            output_strides[4],\n            B,\n            C,\n            D,\n            H,\n            W,\n            BLOCK_D=2,\n            BLOCK_H=2,\n            BLOCK_W=2\n        )\n        \n        return output\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "c6f89b47-3930-4407-b314-7ca6ffad4bac", "generation": 2, "timestamp": 1754580259.7308557, "iteration_found": 8, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.006, "runtime_ms": 19.0, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.114, "speed_up": 0.006, "custom_timing": 19.0}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_74_ConvTranspose3d_LeakyReLU_Multiply_LeakyReLU_Max", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpulgspjnm.py\", line 130, in forward\n    fused_pointwise_pool_kernel[grid_size](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 611, in run\n    grid_size = len(grid)\nTypeError: object of type 'int' has no len()\n", "runtime_error_name": "builtins.TypeError", "reference_timing_ms": 0.114, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}