{"id": "4158a8c8-5a22-4a25-aabe-616810ee5e9e", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_ops_pool_kernel(\n    input_ptr,\n    multiplier_ptr,\n    output_ptr,\n    batch_size, out_channels, D_in, H_in, W_in,\n    stride_b, stride_c, stride_d, stride_h, stride_w,\n    multiplier_stride_c,\n    D_out, H_out, W_out,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    elements_per_program = tl.cdiv(batch_size * out_channels * D_out * H_out * W_out, num_pid)\n    start_idx = pid * elements_per_program\n    end_idx = min(start_idx + elements_per_program, batch_size * out_channels * D_out * H_out * W_out)\n    \n    for idx in range(start_idx, end_idx, BLOCK_SIZE):\n        offsets = idx + tl.arange(0, BLOCK_SIZE)\n        mask = offsets < end_idx\n        \n        # Compute 5D indices\n        w_out = offsets % W_out\n        h_out = (offsets // W_out) % H_out\n        d_out = (offsets // (W_out * H_out)) % D_out\n        c = (offsets // (W_out * H_out * D_out)) % out_channels\n        b = offsets // (W_out * H_out * D_out * out_channels)\n        \n        # Input spatial indices\n        d_in_start = d_out * 2\n        h_in_start = h_out * 2\n        w_in_start = w_out * 2\n        \n        # Process 2x2x2 window\n        max_vals = tl.full((BLOCK_SIZE,), float('-inf'), dtype=tl.float32)\n        for di in range(2):\n            for dj in range(2):\n                for dk in range(2):\n                    d_in = d_in_start + di\n                    h_in = h_in_start + dj\n                    w_in = w_in_start + dk\n                    \n                    # Check boundaries\n                    in_bounds = (d_in < D_in) & (h_in < H_in) & (w_in < W_in)\n                    in_offsets = b*stride_b + c*stride_c + d_in*stride_d + h_in*stride_h + w_in*stride_w\n                    \n                    # Load input with boundary check\n                    x_val = tl.load(input_ptr + in_offsets, mask=mask & in_bounds, other=0.0)\n                    \n                    # First LeakyReLU\n                    x_val = tl.where(x_val >= 0, x_val, x_val * 0.2)\n                    \n                    # Multiply by per-channel scalar\n                    scale = tl.load(multiplier_ptr + c * multiplier_stride_c)\n                    x_val = x_val * scale\n                    \n                    # Second LeakyReLU\n                    x_val = tl.where(x_val >= 0, x_val, x_val * 0.2)\n                    \n                    # Update max value\n                    max_vals = tl.maximum(max_vals, x_val)\n        \n        # Store results\n        out_offsets = b * (out_channels * D_out * H_out * W_out) + \\\n                      c * (D_out * H_out * W_out) + \\\n                      d_out * (H_out * W_out) + \\\n                      h_out * W_out + w_out\n        tl.store(output_ptr + out_offsets, max_vals, mask=mask)\n\ndef fused_ops_pool(x, multiplier):\n    batch_size, out_channels, D_in, H_in, W_in = x.shape\n    D_out, H_out, W_out = D_in // 2, H_in // 2, W_in // 2\n    output = torch.empty((batch_size, out_channels, D_out, H_out, W_out), \n                         device=x.device, dtype=x.dtype)\n    \n    # Prepare multiplier\n    multiplier = multiplier.squeeze().contiguous()\n    \n    # Launch kernel\n    grid = lambda meta: (triton.cdiv(batch_size * out_channels * D_out * H_out * W_out, meta['BLOCK_SIZE']),)\n    fused_ops_pool_kernel[grid](\n        x, multiplier, output,\n        batch_size, out_channels, D_in, H_in, W_in,\n        x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),\n        multiplier.stride(0),\n        D_out, H_out, W_out,\n        BLOCK_SIZE=1024\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, \n                                                 stride=stride, padding=padding, \n                                                 output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n    \n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = fused_ops_pool(x, self.multiplier)\n        return x\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "2ad42d29-dcce-46df-ab53-dc917a739ca1", "generation": 1, "timestamp": 1754579855.4644299, "iteration_found": 3, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.128, "runtime_ms": 0.889, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.114, "speed_up": 0.128, "custom_timing": 0.889}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 1.49, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.114, "speed_up": 0.077, "custom_timing": 1.49}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}