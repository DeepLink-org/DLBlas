{"id": "7ff41ada-8506-452d-aa7c-365cbd485bf9", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_pointwise_pool_kernel(\n    input_ptr,\n    output_ptr,\n    multiplier_ptr,\n    input_batch_stride,\n    input_channel_stride,\n    input_depth_stride,\n    input_height_stride,\n    input_width_stride,\n    output_batch_stride,\n    output_channel_stride,\n    output_depth_stride,\n    output_height_stride,\n    output_width_stride,\n    num_batch,\n    num_channels,\n    input_depth,\n    input_height,\n    input_width,\n    BLOCK_D: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    \n    # Compute total output elements for boundary guard\n    total_output_elements = num_batch * num_channels * (input_depth//2) * (input_height//2) * (input_width//2)\n    if pid >= total_output_elements:\n        return\n\n    # Reconstruct 5D output indices\n    b_idx = pid // (num_channels * (input_depth//2) * (input_height//2) * (input_width//2))\n    remainder = pid % (num_channels * (input_depth//2) * (input_height//2) * (input_width//2))\n    c_idx = remainder // ((input_depth//2) * (input_height//2) * (input_width//2))\n    remainder = remainder % ((input_depth//2) * (input_height//2) * (input_width//2))\n    d_idx = remainder // ((input_height//2) * (input_width//2))\n    remainder = remainder % ((input_height//2) * (input_width//2))\n    h_idx = remainder // (input_width//2)\n    w_idx = remainder % (input_width//2)\n\n    # Input window for pooling (2x2x2)\n    d_start = d_idx * 2\n    h_start = h_idx * 2\n    w_start = w_idx * 2\n    \n    # Load multiplier for this channel\n    multiplier = tl.load(multiplier_ptr + c_idx)\n    \n    # Initialize with minimum float value\n    max_val = float('-inf')\n    \n    # Precompute base pointer offsets\n    base_offset = (\n        b_idx * input_batch_stride +\n        c_idx * input_channel_stride\n    )\n    \n    for dd in range(2):\n        d_in = d_start + dd\n        if d_in < input_depth:\n            d_offset = d_in * input_depth_stride\n            for dh in range(2):\n                h_in = h_start + dh\n                if h_in < input_height:\n                    h_offset = h_in * input_height_stride\n                    for dw in range(2):\n                        w_in = w_start + dw\n                        if w_in < input_width:\n                            # Calculate input pointer offset\n                            input_offset = base_offset + d_offset + h_offset + w_in * input_width_stride\n                            val = tl.load(input_ptr + input_offset)\n                            \n                            # Apply fused pointwise operations\n                            val = tl.where(val >= 0, val, val * 0.2)  # First LeakyReLU\n                            val = val * multiplier\n                            val = tl.where(val >= 0, val, val * 0.2)   # Second LeakyReLU\n                            \n                            # Update max pooling value\n                            if val > max_val:\n                                max_val = val\n    \n    # Calculate output pointer offset\n    output_offset = (\n        b_idx * output_batch_stride +\n        c_idx * output_channel_stride +\n        d_idx * output_depth_stride +\n        h_idx * output_height_stride +\n        w_idx * output_width_stride\n    )\n    tl.store(output_ptr + output_offset, max_val)\n\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))\n        \n    def forward(self, x):\n        x = self.conv_transpose(x)\n        \n        # Capture output shape for kernel configuration\n        B, C, D, H, W = x.shape\n        output = torch.empty(B, C, D//2, H//2, W//2, device=x.device, dtype=x.dtype)\n        \n        # Calculate strides for tensor access\n        input_strides = (\n            x.stride(0),\n            x.stride(1),\n            x.stride(2),\n            x.stride(3),\n            x.stride(4)\n        )\n        output_strides = (\n            output.stride(0),\n            output.stride(1),\n            output.stride(2),\n            output.stride(3),\n            output.stride(4)\n        )\n        \n        # Configure kernel launch parameters\n        grid_size = B * C * (D//2) * (H//2) * (W//2)\n        \n        # Launch fused kernel\n        fused_pointwise_pool_kernel[(grid_size,)](\n            x,\n            output,\n            self.multiplier,\n            input_strides[0],\n            input_strides[1],\n            input_strides[2],\n            input_strides[3],\n            input_strides[4],\n            output_strides[0],\n            output_strides[1],\n            output_strides[2],\n            output_strides[3],\n            output_strides[4],\n            B,\n            C,\n            D,\n            H,\n            W,\n            BLOCK_D=2,\n            BLOCK_H=2,\n            BLOCK_W=2\n        )\n        \n        return output\n\nbatch_size = 16\nin_channels = 16\nout_channels = 32\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\nmultiplier_shape = (out_channels, 1, 1, 1)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "969ce856-97bc-4052-9c99-70bc16f1fcbc", "generation": 2, "timestamp": 1754582056.036541, "iteration_found": 18, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.009, "runtime_ms": 13.1, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.114, "speed_up": 0.009, "custom_timing": 13.1}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "no_valid_triton_code", "feedback": "You need to generate real and valid triton code for the core function. The key word 'import triton' is not found."}, "island": 1}, "artifacts_json": null, "artifact_dir": null}