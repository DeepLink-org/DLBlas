{"id": "4d7c2e72-bcf2-4b04-9261-b14c4ef0032b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_gelu_pool_kernel(\n    input_ptr,\n    output_ptr,\n    batch_size,\n    out_channels,\n    height,\n    width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_channels = batch_size * out_channels\n    if pid >= total_channels:\n        return\n    \n    batch_idx = pid // out_channels\n    channel_idx = pid % out_channels\n    num_elements = height * width\n    \n    input_channel_ptr = input_ptr + batch_idx * (out_channels * num_elements) + channel_idx * num_elements\n    \n    total_local = 0.0\n    for offset in range(0, num_elements, BLOCK_SIZE):\n        idx = offset + tl.arange(0, BLOCK_SIZE)\n        mask = idx < num_elements\n        val = tl.load(input_channel_ptr + idx, mask=mask, other=0.0)\n        gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n        total_local += tl.where(mask, gelu_val, 0.0)\n    \n    total_sum = tl.sum(total_local, axis=0)\n    avg_val = total_sum / num_elements\n    \n    mask_store = tl.arange(0, BLOCK_SIZE) == 0\n    output_index = batch_idx * out_channels + channel_idx\n    tl.store(output_ptr + output_index, avg_val, mask=mask_store)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        batch_size, out_channels, height, width = x.shape\n        x = x.contiguous()\n        output = torch.empty(batch_size, out_channels, device=x.device, dtype=x.dtype)\n        total_channels = batch_size * out_channels\n        grid = (total_channels,)\n        fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "88d7a66c-6ba0-4dba-a6ad-61040ed325b7", "generation": 1, "timestamp": 1754581783.497969, "iteration_found": 0, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_67_Conv2d_GELU_GlobalAvgPool", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpwyvan5b3.py\", line 55, in forward\n    fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 22:4:\n    total_channels = batch_size * out_channels\n    if pid >= total_channels:\n        return\n\n    batch_idx = pid // out_channels\n    channel_idx = pid % out_channels\n    num_elements = height * width\n\n    input_channel_ptr = input_ptr + batch_idx * (out_channels * num_elements) + channel_idx * num_elements\n\n    total_local = 0.0\n    for offset in range(0, num_elements, BLOCK_SIZE):\n    ^\nAssertionError(\"Loop-carried variable total_local has initial type fp32 but is re-assigned to <['1024'], fp32> in loop! Please make sure that the type stays consistent.\")\n\n\nThe above exception was the direct cause of the following exception:\n\nAssertionError: Loop-carried variable total_local has initial type fp32 but is re-assigned to <['1024'], fp32> in loop! Please make sure that the type stays consistent.\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 0.0655, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0581, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0655, "speed_up": 1.127, "custom_timing": 0.0581}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.0581\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0655, 'speed_up': 1.127, 'custom_timing': 0.0581}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.0581, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0655, 'speed_up': 1.127, 'custom_timing': 0.0581}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.0581), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:6', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0655, 'speed_up': 1.127, 'custom_timing': 0.0581})\n\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a convolution, applies GELU, and then performs global average pooling.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, in_channels, height, width)\n        Returns:\n            Output tensor of shape (batch_size, out_channels)\n        \"\"\"\n        x = self.conv(x)\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a PyTorch model that does:\n  1. Convolution\n  2. GELU activation\n  3. Global average pooling (adaptive to 1x1)\n  4. Squeeze the last two dimensions\n\nThe current implementation is using high-level PyTorch operations. We are to rewrite it using Triton for performance.\n\nHowever, note that the entire model is written in PyTorch and the convolution is done by nn.Conv2d. We cannot rewrite the convolution with Triton in the context of the entire model without a detailed understanding of the convolution parameters? But note the task: we are allowed to change only the Triton kernel within the EVOLVE-BLOCK.\n\nBut wait: the current code does not have any Triton kernel. We are to introduce Triton to speed up?\n\nLooking at the context, we are in the \"Evolution\" system and the previous code (the current program) is a pure PyTorch model. The task is to rewrite the program to improve performance.\n\nHowever, note the constraints: we are only allowed to change the Triton kernel source within the EVOLVE-BLOCK. But the current code doesn't have a Triton kernel. So we are to replace the entire forward pass with a Triton kernel? Or only a part?\n\nBut note: the problem says that we are to generate Triton implementations for the reference_code (which is the PyTorch code). The example given was a quantization function. Similarly, we are to write a Triton kernel for the entire model? That might be complex.\n\nAlternatively, we might break down the model and write Triton for the GELU and the pooling? But the convolution is the most expensive part.\n\nBut note: the convolution is handled by highly optimized cuDNN. It might be difficult to beat with Triton. However, the problem says we are to rewrite the entire model? Or we can use a combination?\n\nLooking at the example: they replaced the entire per_row_quantize_int8 function with a Triton kernel.\n\nSimilarly, we are to write a Triton kernel that replaces the entire forward pass? That is, from input to output? That would be a single kernel that does convolution, GELU, and pooling? That is a tall order.\n\nAlternatively, we can break the model into steps and write Triton for the activation and pooling? But the convolution is the bulk.\n\nBut note: the problem says we are allowed to change only the Triton kernel source within the EVOLVE-BLOCK. The rest of the code (like the class definition and the get_inputs, etc.) is locked? Actually, the problem says: \"Modify ONLY the Triton kernel source within this block - all other code is LOCKED.\" and the example output included the entire function.\n\nIn the current code, we have a PyTorch model. We are to replace the forward function with a Triton-based implementation? How?\n\nWe can write a Triton kernel that does the entire forward pass? But that is complex.\n\nAlternatively, we can replace the GELU and the pooling with Triton? But note that the convolution is in the middle.\n\nAnother idea: we can fuse the convolution with the GELU and the pooling? That is, we write a Triton kernel that does the convolution (with weights as parameters) and then GELU and then pooling? But note that the convolution weights are learnable and stored in the module.\n\nBut the problem does not specify that the model is to be trained. We are only concerned with the forward pass for performance.\n\nHowever, the constraints say: \"NEVER change @triton.jit function signatures or parameter names\" and \"NEVER modify grid configuration, output tensor shapes, or PID logic\". But we are introducing a new kernel.\n\nGiven the complexity, let's reconsider: the problem says we are to rewrite the PyTorch reference into a Triton implementation. The reference is the entire forward pass of the model.\n\nWe have two options:\n  1. Write a single Triton kernel that does everything (convolution, GELU, pooling) for the entire model.\n  2. Write separate Triton kernels for each step and then call them in the forward.\n\nBut note: the example replaced the entire function with a Triton kernel and a wrapper.\n\nWe are going to do the same: replace the forward pass of the model with a Triton kernel.\n\nSteps:\n  - We will write a Triton kernel that takes:\n        input tensor (x)\n        weight tensor (from the convolution layer)\n        bias (if any, but the current nn.Conv2d uses bias by default? We have to check the default of nn.Conv2d -> yes, bias=True)\n  - We will compute the convolution, then GELU, then adaptive average pooling (which for output size 1x1 is just the average of the entire feature map) and then we remove the last two dimensions.\n\nBut note: the convolution in the current model is 2D. We have to handle 2D convolution.\n\nHowever, writing a high-performance 2D convolution in Triton is non-trivial and may not beat cuDNN. But the problem says we are to optimize for H100.\n\nAlternatively, we can use the existing convolution and then fuse the GELU and the pooling? But the convolution is done by PyTorch and then we have to pass the output to Triton for the rest.\n\nBut note: the problem says we are to rewrite the entire function. We are allowed to change the internal implementation arbitrarily as long as the inputs and outputs remain the same.\n\nGiven the time and complexity, and that the convolution is already optimized by cuDNN, it might be more efficient to keep the convolution as is and then write a Triton kernel for the GELU and the pooling? But the GELU is a pointwise operation and the pooling is a reduction.\n\nAlternatively, we can write a kernel that fuses the GELU and the pooling? That would reduce memory bandwidth.\n\nBut note: the convolution output is a tensor of shape [batch_size, out_channels, height_out, width_out]. Then we do GELU (pointwise) and then adaptive average pooling (which is a reduction over the spatial dimensions) to [batch_size, out_channels, 1, 1] and then we squeeze to [batch_size, out_channels].\n\nWe can write a Triton kernel that does:\n  - Load the convolution output (which is a 4D tensor)\n  - Apply GELU to each element (this is pointwise and can be done in the same kernel as the reduction, but note: we need to do the reduction after the GELU? Actually, we can compute the average of the GELU activated values? Yes, that is the same as: GELU then average.\n\nBut note: the current model does:\n  x = self.conv(x)   -> [batch, out_channels, H, W]\n  x = gelu(x)        -> [batch, out_channels, H, W]\n  x = adaptive_avg_pool2d(x, 1) -> [batch, out_channels, 1, 1]\n  x = squeeze -> [batch, out_channels]\n\nWe can combine the GELU and the pooling into one kernel that:\n  - For each batch and each channel, we compute the average of the GELU of the elements.\n\nThis avoids writing the entire GELU activated tensor to global memory and then reading it again for the pooling.\n\nSo the plan:\n  1. Keep the convolution in PyTorch (using nn.Conv2d) because it's already optimized.\n  2. After the convolution, instead of calling F.gelu and then F.adaptive_avg_pool2d and then squeeze, we call a Triton kernel that does:\n        input: the convolution output (4D tensor: [batch, out_channels, H, W])\n        output: a 2D tensor [batch, out_channels]\n\n        For each batch and each channel, the kernel:\n          - Loads all the elements in the spatial dimension (H x W) for that batch and channel.\n          - Applies GELU to each element.\n          - Computes the average of these GELU values.\n\n  3. Then we return the 2D tensor.\n\nThis avoids the intermediate storage of the GELU activated tensor and the subsequent pooling.\n\nWe must write the Triton kernel for the fused GELU and spatial average.\n\nHow to write the kernel:\n  - We can have each program handle one channel in one batch? Then the grid would be (batch, out_channels).\n  - But note: the number of elements per channel (H*W) might be large. We have to do the reduction in multiple steps.\n\nAlternatively, we can use a two-stage reduction? But note that H and W are 32? Actually, the input is 32x32, and after convolution with kernel_size=3 and without padding, the output size would be (32-3+1)=30? Actually, the convolution output size: \n  H_out = (H_in - kernel_size + 1) [if stride=1 and padding=0] -> 30x30.\n\nSo each channel has 900 elements. That is a lot for one thread block? We can use a reduction within a thread block and then across blocks? But we want one output per (batch, channel).\n\nWe can use a 1D grid of size (batch * out_channels) and then each block reduces over 900 elements.\n\nBut 900 is not too big. We can use one block per (batch, channel) and then have 1024 threads (which is the maximum block size) and then do a reduction.\n\nSteps for the kernel:\n\n  pid = tl.program_id(0)\n  batch_size, out_channels, height, width = input_tensor.shape\n  total_channels = batch_size * out_channels\n  pid = tl.program_id(0)\n  if pid >= total_channels:\n      return\n\n  # Compute the batch index and channel index:\n  batch_idx = pid // out_channels\n  channel_idx = pid % out_channels\n\n  # Now, we need to compute the base pointer for the input for this batch and channel.\n  input_ptr = input_tensor + batch_idx * (out_channels * height * width) + channel_idx * (height * width)\n\n  # We are going to load the entire channel and reduce it.\n  # We use a loop to load the data in chunks.\n\n  # How many elements? H*W = 900.\n  # We can use a loop with block stride.\n\n  # We'll use BLOCK_SIZE = 1024 (or more, but we have to split the 900 elements over multiple blocks? Actually, we are using one block per channel. So we can have a 1D grid of total_channels and a 1D block of BLOCK_SIZE threads.\n\n  # We are going to have a reduction in shared memory? But Triton doesn't have shared memory? Actually, it does, but we can use registers and atomic operations? Or we can use tl.associative_scan?\n\n  Alternatively, we can use the fact that 900 is less than 1024? Then we can have 1024 threads and each thread loads one element (if index < 900) and then we do a tree reduction.\n\n  Steps:\n    - Initialize a register for the sum (and count? Actually, we are averaging) -> we want the sum and then divide by (height*width). But note: we are doing GELU first.\n\n  We can do:\n    total = 0.0\n    for offset in range(0, height*width, BLOCK_SIZE):\n        idx = offset + tl.arange(0, BLOCK_SIZE)\n        mask = idx < (height * width)\n        val = tl.load(input_ptr + idx, mask=mask, other=0.0)\n        # Apply GELU: we can use an approximation: x * 0.5 * (1.0 + tl.erf(x / math.sqrt(2.0)))\n        gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))   # 0.7071067811865475 = 1/sqrt(2)\n        total += tl.sum(gelu_val, axis=0)   # But wait: we are doing a reduction over the entire channel? Actually, we want the sum of all gelu_val.\n\n    Then we store the total divided by (height*width) at the output for this channel.\n\n  However, note: we cannot do a sum over the entire block in one instruction? We have to do a reduction within the block? And then use atomic add across blocks? But we are using one block per channel. So we don't need atomic operations. Each block writes one output.\n\n  But the above loop is within a block? Actually, we are using one block per channel. The block has BLOCK_SIZE threads. We are loading in chunks of BLOCK_SIZE. We need to reduce within the block for each chunk? And then accumulate the chunk sums? Then at the end, we do a reduction of the chunk sums? Then we divide by the total number of elements.\n\n  We can do:\n\n    # We'll use a register to accumulate the sum for the entire channel.\n    total = 0.0\n\n    # We'll loop over the channel in chunks of BLOCK_SIZE\n    for i in range(0, height*width, BLOCK_SIZE):\n        # Create a range for the current chunk\n        idx = i + tl.arange(0, BLOCK_SIZE)\n        mask = idx < (height * width)\n        val = tl.load(input_ptr + idx, mask=mask, other=0.0)\n        gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n        # Now, we want to sum gelu_val over the entire chunk? We can use tl.sum, but note: that would sum over the entire vector? Actually, we are loading a vector of BLOCK_SIZE. We can do:\n        chunk_sum = tl.sum(gelu_val, axis=0)   # This is a scalar for the entire chunk? But wait: the tl.sum over the vector returns a scalar per thread? Actually, no: it returns a scalar for the entire block? How does tl.sum work in Triton?\n\n        Actually, tl.sum is a reduction across the entire block? But note: we are loading a vector and then we want to reduce it. We can use:\n          chunk_sum = tl.sum(gelu_val, axis=0)   # This will return a scalar for the entire block? But the gelu_val is a vector of BLOCK_SIZE. The tl.sum will reduce along the first dimension? So it returns a scalar? And that scalar is the same for every thread? Actually, no: the tl.sum in Triton is a reduction that broadcasts the result to all threads? We don't want to broadcast? We just want to accumulate the chunk_sum to the total.\n\n        But note: we are in a loop. We want to accumulate the sum of the entire channel. We can do:\n\n          total = total + tl.sum(gelu_val, axis=0)   # But this will be the same for every thread? Then we are adding the same value multiple times? Actually, we are in a block and we are doing a parallel reduction. We want to have the total for the entire channel. We can do:\n\n        Actually, we can use a single accumulator per thread? Then we do a tree reduction? That would be more efficient? But the tl.sum already does a reduction across the block? And then we are accumulating the chunk sums? But the problem is that the tl.sum returns the same value to every thread? Then we are all adding the same chunk_sum to our total? That would be correct? And then at the end, we have the same total in every thread? Then we can have one thread write the result? Or we can use one thread per block to write? Actually, we can have thread 0 write.\n\n        Alternatively, we can avoid the chunk_sum and use a local accumulator per thread? Then we do a reduction at the end? That would be more efficient? Because we avoid the reduction in every chunk.\n\n        We can do:\n\n          # Each thread will have its own accumulator\n          total_local = 0.0\n          for i in range(0, height*width, BLOCK_SIZE):\n              idx = i + tl.arange(0, BLOCK_SIZE)\n              mask = idx < (height * width)\n              val = tl.load(input_ptr + idx, mask=mask, other=0.0)\n              gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n              # Now, each thread has one element? Actually, the load returns a vector of BLOCK_SIZE? And then we are iterating? Actually, the loop is over the entire channel? And each thread in the block is responsible for one element per chunk? Actually, the tl.arange(0, BLOCK_SIZE) creates a vector of BLOCK_SIZE. Then each thread gets one element? Actually, yes: the Triton kernel is written in a SIMD way.\n\n          So each thread has one value in the chunk. Then we can do:\n\n              total_local += tl.where(mask, gelu_val, 0.0)\n\n          Then at the end, we do a reduction across the block to get the total for the channel.\n\n        This is more efficient? Because we avoid the reduction in every chunk.\n\n        So:\n\n          total_local = 0.0\n          for offset in range(0, height*width, BLOCK_SIZE):\n              idx = offset + tl.arange(0, BLOCK_SIZE)\n              mask = idx < (height * width)\n              val = tl.load(input_ptr + idx, mask=mask, other=0.0)\n              gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n              total_local += tl.where(mask, gelu_val, 0.0)\n\n          # Now, we need to reduce total_local across the block to get the sum for the entire channel.\n          total = tl.sum(total_local, axis=0)   # This reduces across the block and returns the same value to every thread.\n\n          Then we compute the average: total = total / (height * width)\n\n          And then we have thread 0 store the result.\n\n        But note: we must be cautious because the block might have more threads than the number of elements? Actually, we set BLOCK_SIZE to the next power of two? Or we can set it to min(1024, height*width) but we are looping. We can set BLOCK_SIZE to 1024 and then if the number of elements is not a multiple, we mask.\n\n        Actually, we can set BLOCK_SIZE to 1024 and then the loop will cover the entire channel.\n\n  Then we write the output at the position [batch_idx, channel_idx] (which is a 2D tensor) to total.\n\n  We have to be careful: the output tensor is 2D of shape [batch_size, out_channels]. So we can set:\n        output_ptr = output + batch_idx * out_channels + channel_idx\n        if the current thread is the first in the block? Actually, we can have every thread write? But that would be inefficient. We can have one thread write? How?\n\n        We can use:\n          if tl.program_id(1) == 0:   # But we are in a 1D grid? Actually, we are using a 1D grid and 1D block. We can do:\n\n          We can use the first thread in the block (thread index 0) to write.\n\n          We do:\n            pid_in_block = tl.arange(0, BLOCK_SIZE)\n            if pid_in_block[0] == 0:   # Actually, we can use tl.program_id(1) for the block dimension? We are using 1D block.\n\n          Alternatively, we can use:\n            if tl.arange(0, BLOCK_SIZE)[0] == 0:   -> This is not per thread. We need per thread.\n\n          Actually, we can do:\n            if tl.program_id(0) < total_channels:   # we already have the condition at the beginning? And then we do:\n                # But we are in the block. We want thread 0 of the block to write.\n\n            We can do: \n                if tl.arange(0, BLOCK_SIZE)[0] == 0:   -> This is the same for all threads? Actually, we need to know the thread id in the block.\n\n          We can use:\n            thread_id = tl.program_id(1)   # but we are using 1D block? Actually, we are using a 1D grid and 1D block. The block is 1D. We can get the thread index in the block with:\n            thread_idx = tl.arange(0, BLOCK_SIZE)   # This is a vector? Actually, we are in the kernel and we can get the current thread's index? How?\n\n          We can use: \n            thread_idx = tl.arange(0, 1)   -> but that doesn't work.\n\n          Actually, we can use:\n            thread_id = tl.program_id(1)   # if we set the block to 1D? Actually, the kernel is called with a grid and a block. But in Triton, we don't specify the block? We specify the number of warps? Actually, the block is defined by the BLOCK_SIZE in the kernel? And the grid by the program_id.\n\n          Alternatively, we can use:\n            We don't need to worry about multiple writes? Because every thread in the block has the same total? Then we can do:\n\n            output = total / (height * width)\n            tl.store(output_ptr, output, mask=thread_idx==0)   # but we don't have thread_idx? \n\n          We can get the thread index in the block by:\n            idx_in_block = tl.arange(0, BLOCK_SIZE)   # This is a vector of size BLOCK_SIZE? And we are in a block of BLOCK_SIZE threads? Then each thread has its own index? Actually, we can use:\n\n            thread_id = tl.arange(0, BLOCK_SIZE)[0]   # This gives the first element? But we want the current thread's index? Actually, the way Triton works is that the kernel is written in a vectorized way. We are processing BLOCK_SIZE elements at a time? And each thread is responsible for one element? Then we can use:\n\n            # We don't have a thread id? Actually, we can use the mask for the first element? \n\n          Alternatively, we can use:\n            if tl.program_id(0) is the channel index and we are in the block? Actually, we are writing one value per channel. We can do:\n\n            # We create an output pointer for the entire block? And then we store only once? How?\n\n          We can use:\n            output_ptr = output + batch_idx * out_channels + channel_idx\n            # Now, we want to store only once? We can use an atomic operation? But that would be inefficient? Or we can do:\n\n            # We can use the fact that every thread has the same value? Then we can do:\n            tl.store(output_ptr, total / (height*width))\n\n          But that would write BLOCK_SIZE times? We can use a mask: only the first thread writes.\n\n          How to get the first thread? We can use:\n\n            if tl.arange(0, BLOCK_SIZE)[0] == 0:   -> but this is the same for all threads? Actually, we need to know the thread index. In Triton, we can get the current thread's index in the block by:\n\n            pid_in_block = tl.program_id(1)   # but we are using 1D grid and 1D block? Actually, the kernel in Triton is defined by the program_id(axis) and the block is defined by the BLOCK_SIZE and the number of warps? We don't have explicit block and thread indices? \n\n          Actually, we can use the mask: we can do a store with a mask that is true only for the first element in the block? How?\n\n          We can define:\n            mask_store = tl.arange(0, BLOCK_SIZE) == 0   # This is a vector of booleans? And then we do:\n\n            tl.store(output_ptr, total / (height*width), mask=mask_store)\n\n          But note: the output_ptr is a scalar address? We are storing a scalar? Then we are storing from every thread? And the mask has one true and the rest false? Then only the first thread will store? Actually, the store operation is per thread? Then each thread will try to store to the same address? And the mask will be true only for the first thread? \n\n          But note: the first thread in the block is the one that has the first element of the vector? And the vector is of size BLOCK_SIZE? Then the first thread (the one that holds the first element) will write? The others will not.\n\n          So we can do:\n\n            mask_store = tl.arange(0, BLOCK_SIZE) == 0   # This creates a vector of length BLOCK_SIZE: [True, False, False, ...]\n            # Then we store only the first thread? Actually, we can do:\n\n            tl.store(output_ptr, total / (height*width), mask=mask_store)\n\n          But note: the store instruction is per thread? And each thread has a different value for mask_store? Only the first thread has mask_store[0] = True? Then only that thread will write.\n\n          So we can do that.\n\n  Summary of the kernel:\n\n    @triton.jit\n    def fused_gelu_pool_kernel(\n        input_ptr,\n        output_ptr,\n        batch_size,\n        out_channels,\n        height,\n        width,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        total_channels = batch_size * out_channels\n        if pid >= total_channels:\n            return\n\n        batch_idx = pid // out_channels\n        channel_idx = pid % out_channels\n\n        # Compute the base pointer for the input for this batch and channel.\n        input_channel_ptr = input_ptr + batch_idx * (out_channels * height * width) + channel_idx * (height * width)\n\n        # Loop over the channel in chunks of BLOCK_SIZE\n        total_local = 0.0\n        num_elements = height * width\n        for offset in range(0, num_elements, BLOCK_SIZE):\n            idx = offset + tl.arange(0, BLOCK_SIZE)\n            mask = idx < num_elements\n            val = tl.load(input_channel_ptr + idx, mask=mask, other=0.0)\n            gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n            total_local += tl.where(mask, gelu_val, 0.0)\n\n        # Reduce across the block\n        total_sum = tl.sum(total_local, axis=0)   # This reduces the entire block? Actually, it reduces along the vector? But total_local is a scalar per thread? Then we are reducing a vector of BLOCK_SIZE scalars? Yes.\n\n        # Compute the average\n        avg_val = total_sum / num_elements\n\n        # Store the result: only the first thread in the block writes.\n        mask_store = tl.arange(0, BLOCK_SIZE) == 0\n        output_index = batch_idx * out_channels + channel_idx\n        tl.store(output_ptr + output_index, avg_val, mask=mask_store)\n\n  Then in the forward function of the model, we do:\n        x = self.conv(x)   # [batch, out_channels, H, W]\n        # Now, we want to apply the fused kernel\n        # We need to reshape x to [batch, out_channels, H, W] -> but we are treating it as a 4D tensor? The kernel expects a 4D tensor.\n\n        # We will create an output tensor of shape [batch, out_channels] (contiguous)\n        output = torch.empty(batch_size, out_channels, device=x.device, dtype=torch.float32)\n\n        # Grid: total_channels = batch_size * out_channels\n        grid = (batch_size * out_channels,)\n        # We set BLOCK_SIZE to min(1024, height*width) but we are using a fixed BLOCK_SIZE? Actually, we are looping. We can set BLOCK_SIZE to 1024.\n\n        fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n\n        return output\n\n  But note: the height and width of the convolution output? We have to compute them? The current convolution: \n        input: [batch, in_channels, 32, 32]\n        conv: nn.Conv2d(in_channels, out_channels, kernel_size=3, bias=True) -> output shape: [batch, out_channels, 30, 30]\n\n  So we can compute the output height and width by:\n        height_out = x.shape[2]\n        width_out = x.shape[3]\n\n  But in the kernel, we are passing the height and width? We can get them from x.\n\n  We have to be cautious: the convolution output might not be contiguous? We should make it contiguous.\n\n  Also, note: the GELU approximation we are using is the same as torch.nn.functional.gelu? By default, PyTorch uses an approximation? Actually, the exact expression is x * 0.5 * (1.0 + erf(x/sqrt(2))). So we are using the exact.\n\n  But the erf function in Triton? We use tl.erf.\n\n  We have to check the tolerance? The problem says numerical correctness within float32 tolerance.\n\n  We are using the same formula? So it should be correct.\n\n  Also, note: the adaptive average pooling: we are averaging over the entire spatial dimensions? That is exactly what we are doing.\n\n  And then we are returning a 2D tensor? Exactly.\n\n  So we can replace:\n        x = torch.nn.functional.gelu(x)\n        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)\n        x = x.squeeze(-1).squeeze(-1)\n\n  with the fused kernel.\n\n  We expect this to be faster because:\n    - We avoid writing the entire gelu activated tensor to memory and then reading it again for the pooling.\n    - We do the gelu and the pooling in one pass.\n\n  Let's update the model:\n\n    We remove the gelu and the pooling and replace with the kernel.\n\n  But note: the convolution output is the input to the kernel.\n\n  We have to pass the convolution output to the kernel.\n\n  Steps in the model:\n\n    def forward(self, x):\n        x = self.conv(x)   # [batch, out_channels, H, W]\n        # Now, we want to apply the fused kernel\n        batch_size, out_channels, height, width = x.shape\n        output = torch.empty(batch_size, out_channels, device=x.device, dtype=x.dtype)\n\n        # We have to define the grid and call the kernel\n        total_channels = batch_size * out_channels\n        grid = (total_channels,)\n        # We set the BLOCK_SIZE to 1024? But note: the kernel loops. We can set it to 1024.\n\n        # We need to make sure x is contiguous\n        x = x.contiguous()\n\n        fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n\n        return output\n\n  We must define the kernel inside the class? Or outside? We can define it outside.\n\n  But note: the problem says we are to output the entire EVOLVE-BLOCK. We will put the kernel definition inside the block? But the block is the entire code? We are to replace the entire block? Actually, the current block is:\n\n        import torch\n        import torch.nn as nn\n\n        class ModelNew ... and then the functions.\n\n  We are going to write the Triton kernel and then the model? And then the get_inputs and get_init_inputs.\n\n  We'll put the kernel at the top? And then the model.\n\n  We are also going to remove the old forward and replace it with the new one.\n\n  We must not change the signature of the class? And the __init__ remains the same.\n\n  Let's write the code.\n\n  Important: we must include the necessary imports for Triton.\n\n  We'll add:\n        import triton\n        import triton.language as tl\n\n  And we must define the kernel with @triton.jit.\n\n  Also, note: the kernel uses tl.erf, which is available.\n\n  We'll write the kernel and then the model.\n\n  We set the grid and the kernel call.\n\n  We must note: the kernel uses a 1D grid of size batch_size * out_channels.\n\n  We are using BLOCK_SIZE=1024 for the kernel's internal block? That is the number of threads per block? Actually, in Triton, the BLOCK_SIZE in the kernel is the number of elements we process in one iteration? And we are using a grid of total_channels blocks? And each block has 1024 threads? Actually, the kernel is written in a way that the block is of size BLOCK_SIZE? But we are not launching a block in the kernel? We are launching a grid of blocks? Actually, the kernel is written to handle one (batch, channel) per program_id(0). And then within the block, we have BLOCK_SIZE threads? So the total number of threads is total_channels * BLOCK_SIZE? That might be too many? But total_channels is batch_size * out_channels = 128 * 16 = 2048? And then 2048 * 1024 = 2e6 threads? That is acceptable.\n\n  Alternatively, we can set the block size to 1024 and the grid to (ceil(total_channels / 1024),) and then adjust? But our kernel is written for one (batch, channel) per block. We are using the grid to be total_channels? Then we are launching total_channels blocks? And each block has 1024 threads? That is acceptable.\n\n  But note: the kernel uses a loop over the spatial dimension. The spatial dimension is 30*30=900. So we only need one iteration? Because 900 < 1024? Then the loop will run once? Then we can set BLOCK_SIZE to 900? But we want it to be a power of two? Actually, we can set it to 1024 and mask the extra? That is what we are doing.\n\n  We'll write the kernel as described.\n\n  Let's code.\n\n  Important: the problem says to output only the code within the EVOLVE-BLOCK. We are replacing the entire block.\n\n  We must not change the get_inputs and get_init_inputs? They are the same.\n\n  We'll write:\n\n        # ================== EVOLVE-BLOCK-START ==================\n        import torch\n        import torch.nn as nn\n        import triton\n        import triton.language as tl\n\n        @triton.jit\n        def fused_gelu_pool_kernel(\n            input_ptr,\n            output_ptr,\n            batch_size,\n            out_channels,\n            height,\n            width,\n            BLOCK_SIZE: tl.constexpr,\n        ):\n            pid = tl.program_id(0)\n            total_channels = batch_size * out_channels\n            if pid >= total_channels:\n                return\n\n            batch_idx = pid // out_channels\n            channel_idx = pid % out_channels\n            num_elements = height * width\n\n            # Compute the base pointer for the input for this batch and channel.\n            input_channel_ptr = input_ptr + batch_idx * (out_channels * num_elements) + channel_idx * num_elements\n\n            total_local = 0.0\n            for offset in range(0, num_elements, BLOCK_SIZE):\n                idx = offset + tl.arange(0, BLOCK_SIZE)\n                mask = idx < num_elements\n                val = tl.load(input_channel_ptr + idx, mask=mask, other=0.0)\n                # GELU: x * 0.5 * (1.0 + tl.erf(x * 0.7071067811865475))\n                gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n                total_local += tl.where(mask, gelu_val, 0.0)\n\n            # Reduce across the block to get the sum for the entire channel\n            total_sum = tl.sum(total_local, axis=0)\n            avg_val = total_sum / num_elements\n\n            # Store the result: only the first thread in the block writes.\n            mask_store = tl.arange(0, BLOCK_SIZE) == 0\n            output_index = batch_idx * out_channels + channel_idx\n            tl.store(output_ptr + output_index, avg_val, mask=mask_store)\n\n        class ModelNew(nn.Module):\n            def __init__(self, in_channels, out_channels, kernel_size):\n                super(ModelNew, self).__init__()\n                self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n            def forward(self, x):\n                x = self.conv(x)\n                batch_size, out_channels, height, width = x.shape\n                # Make sure the input is contiguous\n                x = x.contiguous()\n                # Create output tensor\n                output = torch.empty(batch_size, out_channels, device=x.device, dtype=x.dtype)\n                total_channels = batch_size * out_channels\n                grid = (total_channels,)\n                # Launch kernel\n                fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n                return output\n\n        batch_size = 128\n        in_channels = 3\n        out_channels = 16\n        height, width = 32, 32\n        kernel_size = 3\n\n        def get_inputs():\n            return [torch.randn(batch_size, in_channels, height, width)]\n\n        def get_init_inputs():\n            return [in_channels, out_channels, kernel_size]\n        # =================== EVOLVE-BLOCK-END ===================\n\n  But note: the convolution output height and width are 30? We are getting them from x.shape.\n\n  We must test? But we are in an evolution system.\n\n  This is a significant change. We hope it will speed up by avoiding the intermediate.\n\n  Let me check: the original had:\n        conv -> gelu (pointwise) -> adaptive_avg_pool2d (reduction) -> squeeze\n\n  We replaced gelu and the pooling with a fused kernel.\n\n  We expect a speedup.\n\n  We are done.\n\n  Note: we are using a fixed BLOCK_SIZE=1024. We could autotune? But the problem says we can do adaptive tuning. But for simplicity, we use 1024.\n\n  Also, note: the kernel might not be optimal? But it's a start.\n\n  We output the code as above.\n\n  IMPORTANT: the problem says to return ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.\n\n  We have done that.\n\n  Let me write the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_gelu_pool_kernel(\n    input_ptr,\n    output_ptr,\n    batch_size,\n    out_channels,\n    height,\n    width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    total_channels = batch_size * out_channels\n    if pid >= total_channels:\n        return\n    \n    batch_idx = pid // out_channels\n    channel_idx = pid % out_channels\n    num_elements = height * width\n    \n    input_channel_ptr = input_ptr + batch_idx * (out_channels * num_elements) + channel_idx * num_elements\n    \n    total_local = 0.0\n    for offset in range(0, num_elements, BLOCK_SIZE):\n        idx = offset + tl.arange(0, BLOCK_SIZE)\n        mask = idx < num_elements\n        val = tl.load(input_channel_ptr + idx, mask=mask, other=0.0)\n        gelu_val = val * 0.5 * (1.0 + tl.erf(val * 0.7071067811865475))\n        total_local += tl.where(mask, gelu_val, 0.0)\n    \n    total_sum = tl.sum(total_local, axis=0)\n    avg_val = total_sum / num_elements\n    \n    mask_store = tl.arange(0, BLOCK_SIZE) == 0\n    output_index = batch_idx * out_channels + channel_idx\n    tl.store(output_ptr + output_index, avg_val, mask=mask_store)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        batch_size, out_channels, height, width = x.shape\n        x = x.contiguous()\n        output = torch.empty(batch_size, out_channels, device=x.device, dtype=x.dtype)\n        total_channels = batch_size * out_channels\n        grid = (total_channels,)\n        fused_gelu_pool_kernel[grid](x, output, batch_size, out_channels, height, width, BLOCK_SIZE=1024)\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}