{"id": "86fd6daf-a006-4b72-a7ba-f9affe636485", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef conv_transpose2d_kernel(\n    # Input tensor pointers\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    # Tensor dimensions\n    batch_size, in_channels, height, width,\n    out_channels, output_height, output_width,\n    # Convolution parameters\n    stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w,\n    kernel_h, kernel_w, groups,\n    # Tensor strides\n    input_stride_b, input_stride_c, input_stride_h, input_stride_w,\n    weight_stride_oc, weight_stride_ic, weight_stride_h, weight_stride_w,\n    output_stride_b, output_stride_c, output_stride_h, output_stride_w,\n    # Other parameters\n    in_channels_per_group, out_channels_per_group,\n    total_elements,\n    # Block configuration\n    BLOCK_SIZE: tl.constexpr\n):\n    # Linear index of elements to process\n    pid = tl.program_id(0)\n    start_idx = pid * BLOCK_SIZE\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < total_elements\n\n    # Convert linear indices to 4D tensor indices\n    # [batch, out_channel, height, width]\n    tmp = tl.full([BLOCK_SIZE], output_height * output_width, dtype=tl.int32)\n    ow = offsets % output_width\n    oh = (offsets // output_width) % output_height\n    oc = (offsets // (output_width * output_height)) % out_channels\n    b = offsets // (output_width * output_height * out_channels)\n\n    # Calculate group information\n    group_idx = oc // out_channels_per_group\n    base_ic = group_idx * in_channels_per_group\n\n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE,), dtype=tl.float32)\n\n    # Loop through input channels and kernel positions\n    for ic in range(in_channels_per_group):\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                # Calculate input coordinates\n                ih = oh + padding_h - kh * dilation_h\n                iw = ow + padding_w - kw * dilation_w\n\n                # Check if coordinates are divisible by stride\n                cond_h = (ih % stride_h == 0)\n                cond_w = (iw % stride_w == 0)\n                valid = cond_h & cond_w\n\n                # Compute input indices\n                ih_idx = tl.where(valid, ih // stride_h, -1)\n                iw_idx = tl.where(valid, iw // stride_w, -1)\n\n                # Check boundaries\n                in_bounds = (ih_idx >= 0) & (ih_idx < height) & (iw_idx >= 0) & (iw_idx < width)\n                valid_mask = valid & in_bounds\n\n                # Calculate memory offsets\n                input_offsets = (b * input_stride_b + \n                                (base_ic + ic) * input_stride_c + \n                                ih_idx * input_stride_h + \n                                iw_idx * input_stride_w)\n                weight_offsets = (oc * weight_stride_oc + \n                                 ic * weight_stride_ic + \n                                 kh * weight_stride_h + \n                                 kw * weight_stride_w)\n\n                # Load input and weight values\n                input_val = tl.load(input_ptr + input_offsets, mask=mask & valid_mask, other=0.0)\n                weight_val = tl.load(weight_ptr + weight_offsets, mask=mask, other=0.0)\n                \n                # Accumulate\n                acc += tl.where(valid_mask, input_val * weight_val, 0.0)\n\n    # Add bias if present\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + oc, mask=mask, other=0.0)\n        acc += bias_val\n\n    # Calculate output offset and store result\n    output_offsets = (b * output_stride_b + \n                     oc * output_stride_c + \n                     oh * output_stride_h + \n                     ow * output_stride_w)\n    tl.store(output_ptr + output_offsets, acc, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, \n                 stride: tuple = (1, 1), padding: tuple = (0, 0), \n                 dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.groups = groups\n        \n        # Validate parameters\n        assert groups > 0, \"groups must be positive\"\n        assert in_channels % groups == 0, \"in_channels must be divisible by groups\"\n        assert out_channels % groups == 0, \"out_channels must be divisible by groups\"\n        \n        # Weight parameters\n        kernel_h, kernel_w = kernel_size\n        self.weight = nn.Parameter(torch.empty(\n            out_channels, \n            in_channels // groups, \n            kernel_h, \n            kernel_w\n        ))\n        \n        # Optional bias\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_channels))\n        else:\n            self.register_parameter('bias', None)\n            \n        # Initialize parameters\n        self.reset_parameters()\n        \n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            nn.init.uniform_(self.bias, -bound, bound)\n            \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Get input dimensions\n        batch_size, in_channels, height, width = x.shape\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.stride\n        padding_h, padding_w = self.padding\n        dilation_h, dilation_w = self.dilation\n        groups = self.groups\n        \n        # Calculate output dimensions\n        output_height = (height - 1) * stride_h - 2 * padding_h + dilation_h * (kernel_h - 1) + 1\n        output_width = (width - 1) * stride_w - 2 * padding_w + dilation_w * (kernel_w - 1) + 1\n        \n        # Create output tensor\n        output = torch.empty(\n            batch_size, \n            self.out_channels, \n            output_height, \n            output_width,\n            device=x.device,\n            dtype=x.dtype\n        )\n        \n        # Handle empty tensor case\n        if output.numel() == 0:\n            return output\n            \n        # Prepare tensor pointers\n        bias_ptr = self.bias.data_ptr() if self.bias is not None else None\n        \n        # Get tensor strides\n        input_stride = x.stride()\n        weight_stride = self.weight.stride()\n        output_stride = output.stride()\n        \n        # Calculate total elements and grid size\n        total_elements = output.numel()\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        \n        # Launch kernel\n        conv_transpose2d_kernel[grid](\n            x, self.weight, bias_ptr, output,\n            batch_size, in_channels, height, width,\n            self.out_channels, output_height, output_width,\n            stride_h, stride_w, padding_h, padding_w, dilation_h, dilation_w,\n            kernel_h, kernel_w, groups,\n            in_channels // groups, self.out_channels // groups,\n            input_stride[0], input_stride[1], input_stride[2], input_stride[3],\n            weight_stride[0], weight_stride[1], weight_stride[2], weight_stride[3],\n            output_stride[0], output_stride[1], output_stride[2], output_stride[3],\n            total_elements,\n            BLOCK_SIZE=128\n        )\n        \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (2, 3)\npadding = (1, 2)\ndilation = (2, 1)\ngroups = 4\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, dilation, groups]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b965da3e-5b5c-489b-8ed3-d65c132ad112", "generation": 1, "timestamp": 1754646209.9391663, "iteration_found": 2, "metrics": {"compiled": false, "correctness": false, "score": 1, "stage": "compile_error", "compile_log": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/evaluator.py\", line 173, in _verification_worker\n    result: KernelExecResult = eval_kernel_against_ref(\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 578, in eval_kernel_against_ref\n    graceful_eval_cleanup(context, device, tempfile)\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 230, in graceful_eval_cleanup\n    torch.cuda.empty_cache()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/cuda/memory.py\", line 224, in empty_cache\n    torch._C._cuda_emptyCache()\ntorch.AcceleratorError: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n", "exec_log": "[Child] \u7ed1\u5b9a GPU 1, torch sees 1 device(s)\n\n[Exception]\nTraceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/code_executor.py\", line 71, in _exec_worker\n    exec(textwrap.dedent(code_src), mod.__dict__)\n  File \"<string>\", line 9, in <module>\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 844, in jit\n    return decorator(fn)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 832, in decorator\n    return JITFunction(\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 635, in __init__\n    self.starting_line_number = inspect.getsourcelines(fn)[1]\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n    lines, lnum = findsource(object)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/inspect.py\", line 958, in findsource\n    raise OSError('could not get source code')\nOSError: could not get source code\n", "exit_code": "1"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 6.68, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.057, "speed_up": 0.009, "custom_timing": 6.68}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}