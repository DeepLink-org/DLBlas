{"id": "06da328d-6b6b-47cc-a027-7c093a7a3aa9", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _triton_bmm_kernel(\n    A_ptr, B_ptr, C_ptr,\n    N, M, K, L,\n    stride_an, stride_am, stride_ak,\n    stride_bk, stride_bn,\n    stride_cn, stride_cm, stride_cl,\n    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr\n):\n    pid_n = tl.program_id(0)\n    pid_m = tl.program_id(1)\n    pid_l = tl.program_id(2)\n    \n    # Create pointers for the batch\n    offs_n = pid_n\n    a_base = A_ptr + offs_n * stride_an\n    c_base = C_ptr + offs_n * stride_cn\n    \n    # Offsets for M and L dimensions\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_l = pid_l * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = tl.arange(0, BLOCK_K)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Pointers to the starting blocks of A and B\n    a_ptrs = a_base + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak\n    b_ptrs = B_ptr + offs_k[:, None] * stride_bk + offs_l[None, :] * stride_bn\n    \n    # Loop over K dimension with vectorized loads\n    for k in range(0, tl.cdiv(K, BLOCK_K)):\n        # Create masks for boundary checks\n        a_mask = (offs_m[:, None] < M) & (offs_k[None, :] < K - k * BLOCK_K)\n        b_mask = (offs_k[:, None] < K - k * BLOCK_K) & (offs_l[None, :] < L)\n        \n        # Load blocks from A and B\n        a = tl.load(a_ptrs, mask=a_mask, other=0.0)\n        b = tl.load(b_ptrs, mask=b_mask, other=0.0)\n        \n        # Compute matrix multiplication\n        acc += tl.dot(a, b, allow_tf32=True)\n        \n        # Update pointers for next block\n        a_ptrs += BLOCK_K * stride_ak\n        b_ptrs += BLOCK_K * stride_bk\n    \n    # Store result with boundary mask\n    c_ptrs = c_base + offs_m[:, None] * stride_cm + offs_l[None, :] * stride_cl\n    c_mask = (offs_m[:, None] < M) & (offs_l[None, :] < L)\n    tl.store(c_ptrs, acc, mask=c_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self):\n        super(ModelNew, self).__init__()\n    \n    def forward(self, A, B):\n        N, M, K = A.shape\n        L = B.shape[1]\n        C = torch.empty((N, M, L), device=A.device, dtype=A.dtype)\n        \n        # Compute strides\n        stride_an = A.stride(0)\n        stride_am = A.stride(1)\n        stride_ak = A.stride(2)\n        stride_bk = B.stride(0)\n        stride_bn = B.stride(1)\n        stride_cn = C.stride(0)\n        stride_cm = C.stride(1)\n        stride_cl = C.stride(2)\n        \n        # Block dimensions (optimized for H100 architecture)\n        BLOCK_M = 64\n        BLOCK_N = 64\n        BLOCK_K = 32\n        \n        # Grid configuration\n        grid = (N, triton.cdiv(M, BLOCK_M), triton.cdiv(L, BLOCK_N))\n        \n        # Launch kernel\n        _triton_bmm_kernel[grid](\n            A, B, C, N, M, K, L,\n            stride_an, stride_am, stride_ak,\n            stride_bk, stride_bn,\n            stride_cn, stride_cm, stride_cl,\n            BLOCK_M, BLOCK_N, BLOCK_K\n        )\n        return C\n\nN = 16\nM = 1024\nK = 2048\nL = 768\n\ndef get_inputs():\n    A = torch.randn(N, M, K, device='cuda')\n    B = torch.randn(K, L, device='cuda')\n    return [A, B]\n\ndef get_init_inputs():\n    return []\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "4cf70bb4-36b8-4938-b26c-b2792b6afb4c", "generation": 1, "timestamp": 1754634781.7432692, "iteration_found": 3, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_10_3D_tensor_matrix_multiplication", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "max_difference": ["0.196243", "0.192368", "0.207581", "0.193771", "0.208481"], "avg_difference": ["0.027962", "0.027944", "0.027942", "0.027942", "0.027952"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0294, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 1.04, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0294, "speed_up": 0.028, "custom_timing": 1.04}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}