{"id": "ba5e13c6-f470-4618-8b14-9f558cbd9321", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, out_channels, kernel_size[0], kernel_size[1]))\n        self.bias = nn.Parameter(torch.randn(out_channels)) if bias else None\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, height, width = x.shape\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.stride\n        padding_h, padding_w = self.padding\n        \n        # Compute output dimensions\n        out_height = (height - 1) * stride_h - 2 * padding_h + kernel_h\n        out_width = (width - 1) * stride_w - 2 * padding_w + kernel_w\n        output = torch.zeros(batch_size, self.out_channels, out_height, out_width, \n                             device=x.device, dtype=x.dtype)\n        \n        # Calculate grid size for Triton\n        def grid(META):\n            return (triton.cdiv(out_height, META['BLOCK_H']) * \n                    triton.cdiv(out_width, META['BLOCK_W']) * \n                    batch_size * self.out_channels)\n        \n        # Call Triton kernel\n        _conv_transpose2d_kernel[grid](\n            x, self.weight, output, self.bias,\n            batch_size, in_channels, self.out_channels,\n            height, width, out_height, out_width,\n            kernel_h, kernel_w,\n            stride_h, stride_w,\n            padding_h, padding_w,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_H=16, BLOCK_W=16\n        )\n        return output\n\n@triton.jit\ndef _conv_transpose2d_kernel(\n    x_ptr, weight_ptr, output_ptr, bias_ptr,\n    batch_size, in_channels, out_channels,\n    height, width, out_height, out_width,\n    kernel_h, kernel_w,\n    stride_h, stride_w,\n    padding_h, padding_w,\n    x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n    out_batch_stride, out_channel_stride, out_height_stride, out_width_stride,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_b = out_height // BLOCK_H + (1 if out_height % BLOCK_H != 0 else 0)\n    num_pid_w = out_width // BLOCK_W + (1 if out_width % BLOCK_W != 0 else 0)\n    num_pid = num_pid_b * num_pid_w\n    \n    # Compute indices\n    channel_idx = pid % out_channels\n    batch_idx = (pid // out_channels) % batch_size\n    spatial_idx = pid // (out_channels * batch_size)\n    \n    block_h_idx = (spatial_idx // num_pid_w) * BLOCK_H\n    block_w_idx = (spatial_idx % num_pid_w) * BLOCK_W\n    \n    # Offsets for current block\n    h_offsets = block_h_idx + tl.arange(0, BLOCK_H)\n    w_offsets = block_w_idx + tl.arange(0, BLOCK_W)\n    h_mask = h_offsets < out_height\n    w_mask = w_offsets < out_width\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    # Loop over input channels\n    for c in range(in_channels):\n        weight_channel_offset = c * out_channels + channel_idx\n        # Loop over kernel dimensions\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                # Compute corresponding input position\n                input_h = (h_offsets[:, None] - kh + padding_h) / stride_h\n                input_w = (w_offsets[None, :] - kw + padding_w) / stride_w\n                \n                # Check if input position is integer and within bounds\n                is_int_h = (h_offsets[:, None] - kh + padding_h) % stride_h == 0\n                is_int_w = (w_offsets[None, :] - kw + padding_w) % stride_w == 0\n                valid_mask = is_int_h & is_int_w\n                \n                input_h_int = tl.math.floor(input_h)\n                input_w_int = tl.math.floor(input_w)\n                in_bounds = (input_h_int >= 0) & (input_h_int < height) & \\\n                            (input_w_int >= 0) & (input_w_int < width)\n                \n                # Combined mask\n                mask = valid_mask & in_bounds & h_mask[:, None] & w_mask[None, :]\n                \n                # Compute memory offsets\n                x_offset = (batch_idx * x_batch_stride + \n                            c * x_channel_stride + \n                            input_h_int * x_height_stride + \n                            input_w_int * x_width_stride)\n                weight_offset = weight_channel_offset * kernel_h * kernel_w + kh * kernel_w + kw\n                \n                # Load input and weight\n                x_val = tl.load(x_ptr + x_offset, mask=mask, other=0.0)\n                w_val = tl.load(weight_ptr + weight_offset)\n                \n                # Accumulate\n                acc += tl.where(mask, x_val * w_val, 0.0)\n    \n    # Add bias if present\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + channel_idx)\n        acc += bias_val\n    \n    # Store results\n    output_offset = (batch_idx * out_batch_stride + \n                     channel_idx * out_channel_stride + \n                     h_offsets[:, None] * out_height_stride + \n                     w_offsets[None, :] * out_width_stride)\n    tl.store(output_ptr + output_offset, acc, mask=h_mask[:, None] & w_mask[None, :])\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (1, 1)\npadding = (1, 2)\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "f161f445-64c3-46f0-81b9-8e63782c56df", "generation": 1, "timestamp": 1754645566.7945294, "iteration_found": 1, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_78_conv_transposed_2D_asymmetric_input_asymmetric_kernel___padded__", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpnuqejyc1.py\", line 38, in forward\n    _conv_transpose2d_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\ntriton.compiler.errors.CompilationError: at 65:32:\n                # Combined mask\n                mask = valid_mask & in_bounds & h_mask[:, None] & w_mask[None, :]\n\n                # Compute memory offsets\n                x_offset = (batch_idx * x_batch_stride + \n                            c * x_channel_stride + \n                            input_h_int * x_height_stride + \n                            input_w_int * x_width_stride)\n                weight_offset = weight_channel_offset * kernel_h * kernel_w + kh * kernel_w + kw\n\n                # Load input and weight\n                x_val = tl.load(x_ptr + x_offset, mask=mask, other=0.0)\n                                ^\nIncompatibleTypeErrorImpl('invalid operands of type pointer<fp32> and triton.language.float32')\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 900, in __add__\n    return add(self, other, sanitize_overflow=True, _semantic=_semantic)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2468, in add\n    return _semantic.add(x, y, sanitize_overflow)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 226, in add\n    input, other = self.binary_op_type_checking_impl(input, other, True, True)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 184, in binary_op_type_checking_impl\n    self.check_ptr_type_impl(lhs_sca_ty, rhs_sca_ty, allow_lhs_ptr)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 167, in check_ptr_type_impl\n    raise IncompatibleTypeErrorImpl(type_a, type_b)\ntriton.language.semantic.IncompatibleTypeErrorImpl: invalid operands of type pointer<fp32> and triton.language.float32\n", "runtime_error_name": "triton.compiler.errors.CompilationError", "reference_timing_ms": 0.0523, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.35, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0523, "speed_up": 0.149, "custom_timing": 0.35}}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.3500\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0523, 'speed_up': 0.149, 'custom_timing': 0.35}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.3500, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0523, 'speed_up': 0.149, 'custom_timing': 0.35}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and kernel, with optional padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (1, 1)\npadding = (1, 2)\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.3500), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0523, 'speed_up': 0.149, 'custom_timing': 0.35})\n\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs a 2D transposed convolution operation with asymmetric input and kernel, with optional padding.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Size of the convolution kernel (height, width).\n        stride (tuple, optional): Stride of the convolution (height, width). Defaults to (1, 1).\n        padding (tuple, optional): Padding applied to the input (height, width). Defaults to (0, 0).\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the 2D transposed convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (1, 1)\npadding = (1, 2)\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a PyTorch model that uses `nn.ConvTranspose2d` for transposed convolution.\n The current implementation is a simple wrapper around the PyTorch module.\n\n The goal is to replace the PyTorch implementation with a custom Triton kernel for the transposed convolution operation.\n\n However, note that the problem states:\n   \"Modify ONLY the Triton kernel source within this block - all other code is LOCKED.\"\n\n But in the provided code, there is no Triton kernel. We are currently using a high-level PyTorch module.\n\n Therefore, we must design a Triton kernel for the transposed convolution (also called deconvolution).\n\n Steps:\n\n 1. We need to implement the forward pass of the transposed convolution using Triton.\n\n 2. We note that the transposed convolution can be implemented by reversing the forward and backward passes of a regular convolution.\n    Alternatively, we can think of it as a convolution on an input that has been padded with zeros (to increase the spatial dimensions).\n\n 3. The Triton kernel will have to handle:\n    - Input: `x` of shape (batch_size, in_channels, height, width)\n    - Weight: of shape (in_channels, out_channels, kernel_height, kernel_width)\n    - Optional bias: of shape (out_channels,)\n\n 4. The output dimensions are computed as:\n      height_out = (height - 1) * stride[0] - 2 * padding[0] + kernel_size[0] \n      width_out  = (width - 1) * stride[1] - 2 * padding[1] + kernel_size[1]\n\n    But note: in PyTorch, for `nn.ConvTranspose2d`, the output size is:\n        H_out = (H_in - 1) * stride[0] - 2 * padding[0] + kernel_size[0] + output_padding[0]\n    However, in the given problem, there is no output_padding (it defaults to 0) and we are not using dilation.\n\n 5. We will design a Triton kernel that performs the transposed convolution.\n\n 6. We note that the transposed convolution can be implemented as:\n      Y = conv2d_input(input_shape, weight, X, stride, padding, ...)\n    but in terms of direct computation, we can use the following:\n\n    Alternatively, we can use the following approach:\n\n      Step 1: Create an empty tensor for the output with the desired shape.\n      Step 2: Unfold the input tensor (using im2col) but in a way that corresponds to the transposed convolution.\n\n    However, note that the transposed convolution is equivalent to a regular convolution of the input (with zero inserted upsampling) by the kernel (rotated 180 degrees).\n\n 7. Due to the complexity, we will break the operation into:\n\n      a. Upsample the input by inserting zeros in between the elements according to the stride.\n      b. Pad the upsampled input with `padding` (but note: the padding in transposed convolution is actually removing padding in the regular convolution sense? Actually, we pad with zeros and then convolve with the kernel).\n\n    But note: the relationship is that the transposed convolution of input with a kernel is equivalent to the gradient of a regular convolution with respect to its input.\n\n 8. However, we are constrained by the fact that we cannot change the function signature of the forward method.\n\n 9. We are going to implement the forward pass using Triton. We will have to initialize the weights and bias in the __init__.\n\n    But note: the original code uses `nn.ConvTranspose2d` which has trainable parameters. We must preserve the same parameters.\n\n    We are allowed to change the internal implementation of the forward pass.\n\n 10. We will:\n\n      - Keep the same parameters (weight and bias) by storing them as `nn.Parameter`.\n      - In the forward pass, we will call a custom Triton kernel that performs the transposed convolution.\n\n 11. Steps for the Triton kernel:\n\n      We are going to use an approach similar to im2col for transposed convolution.\n\n      However, note that the transposed convolution can be implemented by:\n\n        output[b, c_out, i, j] = \n            sum_{c_in, di, dj} weight[c_in, c_out, di, dj] * \n                input_padded[b, c_in, i*stride[0] + di - padding[0], j*stride[1] + dj - padding[1]]\n\n        but note: the input_padded has a larger spatial size.\n\n      Actually, the standard way is to note that the input is upsampled by stride and then convolved with the kernel.\n\n      We can do:\n\n        Step 1: Upsample the input by inserting zeros. The upsampled input will have shape:\n            [batch, in_channels, height * stride[0], width * stride[1]]\n        Step 2: Pad the upsampled input with `padding` on each side.\n        Step 3: Convolve with the kernel (which is the same as the weight, but note: we don't rotate 180? Actually, in transposed convolution we do not rotate the kernel? It's the same as the original kernel.)\n\n      However, note that in PyTorch, the transposed convolution uses the kernel as is (without rotation).\n\n      But wait: the mathematical definition of transposed convolution is that it uses the kernel without rotation? Actually, the gradient of convolution with respect to input uses the flipped kernel. But in PyTorch, `ConvTranspose2d` uses the same kernel (without flipping) and the operation is defined as:\n\n        output[b, c_out, i, j] = \n            bias[c_out] + \n            sum_{c_in, di, dj} weight[c_in, c_out, di, dj] * \n                input[b, c_in, (i - di + padding[0]) / stride[0], (j - dj + padding[1]) / stride[1]]\n\n        but only when the denominator divides exactly.\n\n      This is complex.\n\n 12. Alternatively, we can use the following known equivalence:\n\n        Conv2D (forward) and ConvTranspose2d (backward) are adjoints. But for implementation, we can use the im2col approach for transposed convolution by creating a matrix from the input and then multiplying by the kernel matrix (transposed).\n\n      However, we are targeting a GPU kernel and we want efficiency.\n\n 13. Given the complexity and time, we note that writing a full transposed convolution in Triton is non-trivial.\n\n 14. However, the problem states that we are to rewrite the program to improve performance. The current implementation uses the PyTorch built-in which is already optimized. But we are to use Triton to get even better performance.\n\n 15. We will design a Triton kernel that uses tiling and shared memory to compute the transposed convolution.\n\n    Steps for the kernel:\n\n      Let:\n        batch_size, in_channels, height, width = x.shape\n        out_channels = self.out_channels\n        kernel_h, kernel_w = self.kernel_size\n\n        output_height = (height - 1) * stride[0] - 2 * padding[0] + kernel_h\n        output_width  = (width - 1) * stride[1] - 2 * padding[1] + kernel_w\n\n      We are going to launch a grid of [batch_size * out_channels * output_height * output_width] but that is too big.\n\n      Instead, we will use a 2D grid:\n\n        grid = (triton.cdiv(output_height, BLOCK_SIZE) * triton.cdiv(output_width, BLOCK_SIZE), batch_size * out_channels)\n\n      But note: we have to consider the channels and batch.\n\n      Alternatively, we can do:\n\n        grid = (batch_size, out_channels, output_height, output_width)\n\n      and then use 4D grid. But Triton only supports 1D grid. So we will flatten.\n\n      We can do:\n\n        pid = tl.program_id(0)\n        num_pid = tl.num_programs(0)\n\n        We then compute indices for batch, c_out, h_out, w_out from pid.\n\n      However, we are constrained by the maximum grid size.\n\n 16. We will break the output tensor into blocks of [BLOCK_H, BLOCK_W] in the spatial dimensions.\n\n      We can let:\n\n        pid_batch = pid // (out_channels * output_height * output_width)\n        pid_rest = pid % (out_channels * output_height * output_width)\n        pid_outc = pid_rest // (output_height * output_width)\n        pid_spatial = pid_rest % (output_height * output_width)\n        pid_h = pid_spatial // output_width\n        pid_w = pid_spatial % output_width\n\n      But this might lead to inefficient memory access.\n\n 17. We can also break by:\n\n        pid = pid_b * (out_channels * output_height * output_width) + \n              pid_c * (output_height * output_width) + \n              pid_h * output_width + \n              pid_w\n\n      and then we can use a 1D grid.\n\n 18. However, we note that the computation for one output pixel:\n\n        output[b, c_out, h_out, w_out] = \n            bias[c_out] + \n            sum_{c_in, dh, dw} weight[c_in, c_out, dh, dw] * \n                input[b, c_in, h_in, w_in]\n\n        where:\n\n            h_in = (h_out + padding[0] - dh) / stride[0]\n            w_in = (w_out + padding[1] - dw) / stride[1]\n\n        but note: we are only non-zero when (h_out + padding[0] - dh) is divisible by stride[0] and similarly for w.\n\n      Actually, the input index is:\n\n            h_in = (h_out - dh + padding[0]) // stride[0]\n            w_in = (w_out - dw + padding[1]) // stride[1]\n\n        and then we require that the division is exact and h_in in [0, height) and w_in in [0, width).\n\n 19. Therefore, we can iterate over the kernel dimensions (dh, dw) and the input channels (c_in) for each output element.\n\n 20. We can design the kernel to compute a block of output elements (e.g., a tile of [BLOCK_H, BLOCK_W]) for a fixed batch and output channel.\n\n 21. We will:\n\n        - Precompute the output shape.\n        - Launch a grid of batch_size * out_channels * (output_height // BLOCK_H) * (output_width // BLOCK_W) ... but we need to handle boundaries.\n\n 22. However, note that the constraints say: \"\u274c NEVER change grid configuration\" ... but in the current code there is no grid configuration because it's using PyTorch. We are allowed to define the grid for the Triton kernel.\n\n    But the problem says: \"Modify ONLY the Triton kernel source within this block - all other code is LOCKED.\" meaning we can change the forward method and the __init__? Actually, the entire block is replaceable.\n\n    The block currently includes the class definition and the test code.\n\n 23. We are going to restructure the class:\n\n      - In __init__, we will store the parameters (in_channels, out_channels, kernel_size, stride, padding, bias) and create the weight and bias as nn.Parameter.\n      - We will not use nn.ConvTranspose2d.\n\n 24. We note: the original nn.ConvTranspose2d has weight of shape (in_channels, out_channels, kernel_size[0], kernel_size[1]) and bias of shape (out_channels,).\n\n 25. We will initialize the weight and bias similarly.\n\n 26. Then, in the forward pass, we will call a Triton kernel that we write.\n\n 27. Due to the complexity and the fact that we are not given a Triton kernel to start with, we are going to write a basic kernel that may not be fully optimized but will be correct.\n\n 28. We will then hope to optimize it in subsequent iterations.\n\n 29. Steps for the forward pass in Triton:\n\n      We are going to write a kernel that:\n\n        - Takes pointers to input, weight, output, and optionally bias.\n        - The input has shape (batch_size, in_channels, height, width)\n        - The weight has shape (in_channels, out_channels, kernel_h, kernel_w)  [Note: PyTorch uses (in_channels, out_channels, ...) but in convolution, we often use (out_channels, in_channels, ...). However, note the original ConvTranspose2d uses (in_channels, out_channels, ...).]\n\n      But note: the PyTorch documentation for `nn.ConvTranspose2d` says:\n          weight: (in_channels, out_channels, kernel_size[0], kernel_size[1])\n\n      So we use that.\n\n      The kernel:\n\n        for each output element (b, c_out, h_out, w_out) in a block:\n\n          value = 0.0\n          for c_in in range(in_channels):\n            for dh in range(kernel_h):\n              for dw in range(kernel_w):\n                h_in = (h_out - dh + padding[0]) / stride[0]\n                w_in = (w_out - dw + padding[1]) / stride[1]\n\n                # Check if h_in is integer and within [0, height) and similarly for w_in\n                if h_in is integer and w_in is integer and 0 <= h_in < height and 0 <= w_in < width:\n                  h_in = int(h_in)\n                  w_in = int(w_in)\n                  value += weight[c_in, c_out, dh, dw] * input[b, c_in, h_in, w_in]\n\n          if bias is not None:\n            value += bias[c_out]\n\n          output[b, c_out, h_out, w_out] = value\n\n      But note: the above condition on h_in and w_in being integers is equivalent to:\n\n          (h_out - dh + padding[0]) % stride[0] == 0 and (w_out - dw + padding[1]) % stride[1] == 0\n\n      However, we can precompute:\n\n          h_in = (h_out - dh + padding[0]) // stride[0]\n          w_in = (w_out - dw + padding[1]) // stride[1]\n\n        and then check the remainder? Actually, we can compute the remainder and skip if not zero.\n\n      But note: the formula in PyTorch is:\n\n          input_x = (output_x - kernel_x + padding_x) / stride_x   ... for convolution?\n\n      For transposed convolution, the relationship is:\n\n          output_x = (input_x - 1) * stride_x - 2 * padding_x + kernel_x\n\n      and the mapping from output to input is:\n\n          input_x = (output_x - kernel_x + padding_x) / stride_x   ... but this might not be integer.\n\n      Actually, the correct mapping is:\n\n          input_x = (output_x + padding_x - kernel_x) // stride_x + 1   ... I'm confused.\n\n 30. Let me refer to the PyTorch documentation for ConvTranspose2d:\n\n      The output size is given by:\n          H_out = (H_in - 1) * stride[0] - 2 * padding[0] + kernel_size[0] + output_padding[0]\n\n      and the relation between input and output is:\n\n          H_in = (H_out + 2 * padding[0] - kernel_size[0]) / stride[0] + 1\n\n      Therefore, for a given output position (h_out) and kernel offset (dh), the corresponding input index is:\n\n          h_in = (h_out + padding[0] - dh) / stride[0]   ... but note the entire kernel is placed so that the top-left corner is at h_out = dh - padding[0] (which might be negative).\n\n      Actually, the input element at (b, c_in, h_in, w_in) contributes to the output element at:\n\n          h_out = h_in * stride[0] + dh - padding[0]\n          w_out = w_in * stride[1] + dw - padding[1]\n\n      Therefore, to compute output[b, c_out, h_out, w_out], we have:\n\n          h_in = (h_out - dh + padding[0]) / stride[0]\n          w_in = (w_out - dw + padding[1]) / stride[1]\n\n        and we require that (h_out - dh + padding[0]) is divisible by stride[0] and similarly for w.\n\n      But note: h_in must be an integer and in [0, height) and w_in in [0, width).\n\n 31. Therefore, in the kernel, we can:\n\n        for dh in range(kernel_h):\n          for dw in range(kernel_w):\n            remainder_h = (h_out - dh + padding[0]) % stride[0]\n            remainder_w = (w_out - dw + padding[1]) % stride[1]\n            if remainder_h == 0 and remainder_w == 0:\n              h_in = (h_out - dh + padding[0]) // stride[0]\n              w_in = (w_out - dw + padding[1]) // stride[1]\n              if 0 <= h_in < height and 0 <= w_in < width:\n                value += weight[c_in, c_out, dh, dw] * input[b, c_in, h_in, w_in]\n\n      However, note: we are iterating over c_in, dh, dw.\n\n 32. But this condition is expensive and the modulo operation is slow.\n\n 33. Alternatively, we can precompute the set of (dh, dw) for which (h_out - dh + padding[0]) is divisible by stride[0] and similarly for w. But that is also complex.\n\n 34. We note that the condition on (h_out, dh) is:\n\n        (h_out + padding[0] - dh) must be divisible by stride[0] and non-negative.\n\n      We can rewrite:\n\n        dh = h_out + padding[0] - k * stride[0]   for some integer k.\n\n      Then k = (h_out + padding[0] - dh) / stride[0] must be an integer and then h_in = k.\n\n      And then we require 0 <= k < height.\n\n      So:\n\n        dh_min = max(0, h_out + padding[0] - (height-1)*stride[0])\n        dh_max = min(kernel_h, h_out + padding[0] + 1)\n\n      and then dh in [dh_min, dh_max) and (h_out + padding[0] - dh) must be divisible by stride[0].\n\n      This is complex.\n\n 35. Given the time, we will implement a simple kernel that iterates over the entire kernel and input channels for each output element, and use the condition with modulo.\n\n 36. We will hope that the kernel is correct and then optimize in subsequent steps.\n\n 37. We note that the current speed_up is 0.149 (which is less than 1) meaning the current PyTorch implementation is faster. We are replacing the PyTorch implementation with a naive Triton kernel that might be slower. But we are to optimize it in the future.\n\n 38. However, the problem says: \"Target \u22655% speedup\". We are in the early stage.\n\n 39. We will write the kernel and then profile.\n\n 40. Steps:\n\n      - We will remove the nn.ConvTranspose2d and create our own parameters.\n      - We will write a Triton kernel for the forward pass.\n      - We will compute the output shape.\n\n 41. We note that the output shape is fixed and can be computed as:\n\n        output_height = (height - 1) * stride[0] - 2 * padding[0] + kernel_size[0]\n        output_width  = (width - 1) * stride[1] - 2 * padding[1] + kernel_size[1]\n\n      But note: the formula in PyTorch for ConvTranspose2d without output_padding and dilation is:\n\n          H_out = (H_in - 1) * stride[0] - 2 * padding[0] + kernel_size[0]\n\n      So we use that.\n\n 42. We will write the kernel with a 1D grid, and each program will handle one output element? That would be very slow.\n\n      Instead, we will use tiling: each program will handle a block of output elements (for a fixed batch and output channel) in the spatial dimensions.\n\n      We will iterate over the input channels and kernel dimensions.\n\n 43. We design:\n\n        BLOCK_H = 16\n        BLOCK_W = 16\n\n      Then we launch:\n\n        grid = (batch_size * out_channels * triton.cdiv(output_height, BLOCK_H) * triton.cdiv(output_width, BLOCK_W))\n\n      And then in the kernel:\n\n        pid = tl.program_id(0)\n        num_pid_batch = batch_size\n        num_pid_outc = out_channels\n        num_pid_h = triton.cdiv(output_height, BLOCK_H)\n        num_pid_w = triton.cdiv(output_width, BLOCK_W)\n\n        pid_batch = pid // (num_pid_outc * num_pid_h * num_pid_w)\n        pid_outc = (pid % (num_pid_outc * num_pid_h * num_pid_w)) // (num_pid_h * num_pid_w)\n        pid_h = (pid % (num_pid_h * num_pid_w)) // num_pid_w\n        pid_w = pid % num_pid_w\n\n        Then the block of output we compute:\n          h_start = pid_h * BLOCK_H\n          w_start = pid_w * BLOCK_W\n          h_end = min(h_start + BLOCK_H, output_height)\n          w_end = min(w_start + BLOCK_W, output_width)\n\n        Then for each output element in [h_start, h_end) x [w_start, w_end) and for the batch index pid_batch and output channel pid_outc, we compute the sum over input channels and kernel.\n\n 44. We note that the weight tensor is of shape (in_channels, out_channels, kernel_h, kernel_w). We will need to access:\n\n          weight_ptr + [c_in, pid_outc, dh, dw]\n\n      We can precompute strides for the weight.\n\n 45. Similarly, the input tensor is (batch_size, in_channels, height, width).\n\n 46. We will precompute the strides and then use tl.load.\n\n 47. Due to the complexity and the fact that we are not allowed to change the signature arbitrarily (but we are allowed to define the Triton kernel as we wish as long as the function of the module is preserved) we proceed.\n\n 48. We will write the kernel and hope that it compiles.\n\n 49. We note: we must handle the bias.\n\n 50. We must also handle boundaries: when the computed input index (h_in, w_in) is out of bounds, we skip.\n\n 51. We will use:\n\n        for c_in in range(0, in_channels):\n          for dh in range(0, kernel_h):\n            for dw in range(0, kernel_w):\n              h_out = h_idx  # which is in [h_start, h_end)\n              w_out = w_idx  # which is in [w_start, w_end)\n\n              remainder_h = (h_out - dh + padding[0]) % stride[0]\n              remainder_w = (w_out - dw + padding[1]) % stride[1]\n\n              if remainder_h == 0 and remainder_w == 0:\n                h_in = (h_out - dh + padding[0]) // stride[0]\n                w_in = (w_out - dw + padding[1]) // stride[1]\n\n                if h_in >= 0 and h_in < height and w_in >=0 and w_in < width:\n                  # load input value\n                  input_val = tl.load(input_ptr + [pid_batch, c_in, h_in, w_in])\n                  weight_val = tl.load(weight_ptr + [c_in, pid_outc, dh, dw])\n                  value += input_val * weight_val\n\n        if bias_ptr is not None:\n          bias_val = tl.load(bias_ptr + pid_outc)\n          value += bias_val\n\n        tl.store(output_ptr + [pid_batch, pid_outc, h_out, w_out], value)\n\n 52. However, note that the loops over c_in, dh, dw are inside the kernel and will be unrolled. This might be inefficient for large kernels or many input channels.\n\n 53. We are aware that this might be slow, but we are in the first iteration.\n\n 54. We will write the kernel accordingly.\n\n 55. We note: the grid configuration must be set in the forward pass.\n\n 56. We will now write the code.\n\n 57. Due to the complexity and length, we will only show the code for the forward pass and the kernel.\n\n 58. We note: the problem says to return only the code within the EVOLVE-BLOCK.\n\n 59. We will replace the entire class and the test code with our new implementation.\n\n 60. IMPORTANT: We must not change the test code (get_inputs and get_init_inputs) because the evaluation uses them.\n\n 61. We will keep the test code as is.\n\n 62. Let's write the code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\nimport math\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels, out_channels, kernel_size[0], kernel_size[1]))\n        self.bias = nn.Parameter(torch.randn(out_channels)) if bias else None\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, height, width = x.shape\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.stride\n        padding_h, padding_w = self.padding\n        \n        # Compute output dimensions\n        out_height = (height - 1) * stride_h - 2 * padding_h + kernel_h\n        out_width = (width - 1) * stride_w - 2 * padding_w + kernel_w\n        output = torch.zeros(batch_size, self.out_channels, out_height, out_width, \n                             device=x.device, dtype=x.dtype)\n        \n        # Calculate grid size for Triton\n        def grid(META):\n            return (triton.cdiv(out_height, META['BLOCK_H']) * \n                    triton.cdiv(out_width, META['BLOCK_W']) * \n                    batch_size * self.out_channels)\n        \n        # Call Triton kernel\n        _conv_transpose2d_kernel[grid](\n            x, self.weight, output, self.bias,\n            batch_size, in_channels, self.out_channels,\n            height, width, out_height, out_width,\n            kernel_h, kernel_w,\n            stride_h, stride_w,\n            padding_h, padding_w,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            BLOCK_H=16, BLOCK_W=16\n        )\n        return output\n\n@triton.jit\ndef _conv_transpose2d_kernel(\n    x_ptr, weight_ptr, output_ptr, bias_ptr,\n    batch_size, in_channels, out_channels,\n    height, width, out_height, out_width,\n    kernel_h, kernel_w,\n    stride_h, stride_w,\n    padding_h, padding_w,\n    x_batch_stride, x_channel_stride, x_height_stride, x_width_stride,\n    out_batch_stride, out_channel_stride, out_height_stride, out_width_stride,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr\n):\n    pid = tl.program_id(0)\n    num_pid_b = out_height // BLOCK_H + (1 if out_height % BLOCK_H != 0 else 0)\n    num_pid_w = out_width // BLOCK_W + (1 if out_width % BLOCK_W != 0 else 0)\n    num_pid = num_pid_b * num_pid_w\n    \n    # Compute indices\n    channel_idx = pid % out_channels\n    batch_idx = (pid // out_channels) % batch_size\n    spatial_idx = pid // (out_channels * batch_size)\n    \n    block_h_idx = (spatial_idx // num_pid_w) * BLOCK_H\n    block_w_idx = (spatial_idx % num_pid_w) * BLOCK_W\n    \n    # Offsets for current block\n    h_offsets = block_h_idx + tl.arange(0, BLOCK_H)\n    w_offsets = block_w_idx + tl.arange(0, BLOCK_W)\n    h_mask = h_offsets < out_height\n    w_mask = w_offsets < out_width\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    # Loop over input channels\n    for c in range(in_channels):\n        weight_channel_offset = c * out_channels + channel_idx\n        # Loop over kernel dimensions\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                # Compute corresponding input position\n                input_h = (h_offsets[:, None] - kh + padding_h) / stride_h\n                input_w = (w_offsets[None, :] - kw + padding_w) / stride_w\n                \n                # Check if input position is integer and within bounds\n                is_int_h = (h_offsets[:, None] - kh + padding_h) % stride_h == 0\n                is_int_w = (w_offsets[None, :] - kw + padding_w) % stride_w == 0\n                valid_mask = is_int_h & is_int_w\n                \n                input_h_int = tl.math.floor(input_h)\n                input_w_int = tl.math.floor(input_w)\n                in_bounds = (input_h_int >= 0) & (input_h_int < height) & \\\n                            (input_w_int >= 0) & (input_w_int < width)\n                \n                # Combined mask\n                mask = valid_mask & in_bounds & h_mask[:, None] & w_mask[None, :]\n                \n                # Compute memory offsets\n                x_offset = (batch_idx * x_batch_stride + \n                            c * x_channel_stride + \n                            input_h_int * x_height_stride + \n                            input_w_int * x_width_stride)\n                weight_offset = weight_channel_offset * kernel_h * kernel_w + kh * kernel_w + kw\n                \n                # Load input and weight\n                x_val = tl.load(x_ptr + x_offset, mask=mask, other=0.0)\n                w_val = tl.load(weight_ptr + weight_offset)\n                \n                # Accumulate\n                acc += tl.where(mask, x_val * w_val, 0.0)\n    \n    # Add bias if present\n    if bias_ptr is not None:\n        bias_val = tl.load(bias_ptr + channel_idx)\n        acc += bias_val\n    \n    # Store results\n    output_offset = (batch_idx * out_batch_stride + \n                     channel_idx * out_channel_stride + \n                     h_offsets[:, None] * out_height_stride + \n                     w_offsets[None, :] * out_width_stride)\n    tl.store(output_ptr + output_offset, acc, mask=h_mask[:, None] & w_mask[None, :])\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight = 128\nwidth = 256\nstride = (1, 1)\npadding = (1, 2)\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}