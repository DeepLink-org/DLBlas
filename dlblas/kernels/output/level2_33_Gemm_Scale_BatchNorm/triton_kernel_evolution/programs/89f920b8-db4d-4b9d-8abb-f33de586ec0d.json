{"id": "89f920b8-db4d-4b9d-8abb-f33de586ec0d", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _fused_linear_scale_kernel(\n    x_ptr, \n    w_ptr,\n    b_ptr,\n    s_ptr,\n    output_ptr,\n    M,  # batch_size\n    K,  # in_features\n    N,  # out_features\n    stride_xb, stride_xk,\n    stride_wk, stride_wn,\n    stride_ob, stride_on,\n    BLOCK_SIZE_M: tl.constexpr,\n    BLOCK_SIZE_N: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    batch_offsets = pid0 * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    feature_offsets = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + batch_offsets[:, None] * stride_xb + k_offsets[None, :] * stride_xk\n    w_ptrs = w_ptr + k_offsets[:, None] * stride_wk + feature_offsets[None, :] * stride_wn\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        k_current = tl.minimum(BLOCK_SIZE_K, K - k * BLOCK_SIZE_K)\n        \n        # Load input block with boundary checks\n        x_mask = (batch_offsets[:, None] < M) & (k_offsets[None, :] < k_current)\n        x_val = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block with boundary checks\n        w_mask = (k_offsets[:, None] < k_current) & (feature_offsets[None, :] < N)\n        w_val = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        acc += tl.dot(x_val, w_val, allow_tf32=True)\n        \n        # Move pointers to next block\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    # Load bias and scale\n    bias = tl.load(b_ptr + feature_offsets, mask=feature_offsets < N, other=0.0)\n    scale = tl.load(s_ptr + feature_offsets, mask=feature_offsets < N, other=0.0)\n    \n    # Apply bias and scaling\n    acc += bias[None, :]\n    acc *= scale[None, :]\n    \n    # Store results with boundary checks\n    output_ptrs = output_ptr + batch_offsets[:, None] * stride_ob + feature_offsets[None, :] * stride_on\n    output_mask = (batch_offsets[:, None] < M) & (feature_offsets[None, :] < N)\n    tl.store(output_ptrs, acc, mask=output_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(in_features, out_features)\n        self.scale = nn.Parameter(torch.randn(scale_shape))\n        self.bn = nn.BatchNorm1d(out_features, eps=eps, momentum=momentum)\n\n    def forward(self, x):\n        batch_size, _ = x.shape\n        output = torch.empty((batch_size, self.gemm.out_features), device=x.device, dtype=x.dtype)\n        \n        M, K, N = batch_size, self.gemm.in_features, self.gemm.out_features\n        \n        # Pre-transpose weight for contiguous access\n        weight_t = self.gemm.weight.t().contiguous()\n        \n        # Configure kernel blocks\n        BLOCK_SIZE_M = 64\n        BLOCK_SIZE_N = 64\n        BLOCK_SIZE_K = 32\n        \n        grid = (triton.cdiv(M, BLOCK_SIZE_M), triton.cdiv(N, BLOCK_SIZE_N))\n        \n        _fused_linear_scale_kernel[grid](\n            x, weight_t, self.gemm.bias, self.scale, output,\n            M, K, N,\n            x.stride(0), x.stride(1),\n            weight_t.stride(0), weight_t.stride(1),\n            output.stride(0), output.stride(1),\n            BLOCK_SIZE_M=BLOCK_SIZE_M, \n            BLOCK_SIZE_N=BLOCK_SIZE_N, \n            BLOCK_SIZE_K=BLOCK_SIZE_K\n        )\n        \n        output = self.bn(output)\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscale_shape = (out_features,)\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scale_shape]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "770816cb-9605-43c1-90d9-278b56c3a485", "generation": 3, "timestamp": 1754568670.0700352, "iteration_found": 14, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.615, "runtime_ms": 0.119, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0732, "speed_up": 0.615, "custom_timing": 0.119}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_33_Gemm_Scale_BatchNorm", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "max_difference": ["6.595462", "6.001471", "6.032952", "5.998363", "5.866656"], "avg_difference": ["1.127103", "1.123145", "1.126018", "1.128559", "1.126724"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0732, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}