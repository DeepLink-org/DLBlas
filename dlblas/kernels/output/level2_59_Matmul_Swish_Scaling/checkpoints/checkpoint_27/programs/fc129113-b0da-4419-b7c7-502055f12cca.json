{"id": "fc129113-b0da-4419-b7c7-502055f12cca", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 32}, num_warps=4),\n        # New configurations optimized for problem dimensions\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_M: tl.constexpr, \n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_m = pid // tl.cdiv(N, BLOCK_N)\n    pid_n = pid % tl.cdiv(N, BLOCK_N)\n    \n    # Offsets for output block\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Compute pointer offsets for input x and weights\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + tl.arange(0, BLOCK_K)[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + tl.arange(0, BLOCK_K)[:, None] * stride_wk\n    \n    # Loop over K dimension\n    for k in range(0, K, BLOCK_K):\n        # Load input block\n        k_offs = k + tl.arange(0, BLOCK_K)\n        x_mask = (offs_m[:, None] < M) & (k_offs[None, :] < K)\n        x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (k_offs[:, None] < K) & (offs_n[None, :] < N)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Compute block matrix multiplication\n        acc += tl.dot(x, w, allow_tf32=True)\n        \n        # Update pointers for next block\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    # Apply bias\n    b = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n    acc += b[None, :]\n    \n    # Apply Swish activation and scaling\n    sig = tl.sigmoid(acc)\n    output = acc * sig * scaling_factor\n    \n    # Write back result\n    out_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, output, mask=out_mask)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    M, K = x.shape\n    N, _ = weight.shape\n    \n    # Allocate output\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    # Grid definition\n    grid = lambda opt: (triton.cdiv(M, opt['BLOCK_M']) * triton.cdiv(N, opt['BLOCK_N']),)\n    \n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "93ddd6b3-c367-47ec-89ca-e61883be6137", "generation": 4, "timestamp": 1754576870.9139483, "iteration_found": 22, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.992, "runtime_ms": 0.0752, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0746, "speed_up": 0.992, "custom_timing": 0.0752}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 22.200000000000003, "speed_up": 1.022, "runtime_ms": 0.073, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0746, "speed_up": 1.022, "custom_timing": 0.073}}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 1.0000\n- score: 22.2000\n- speed_up: 1.0220\n- runtime_ms: 0.0730\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.022, 'custom_timing': 0.073}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: score, speed_up. Consider continuing with similar changes.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1504, in dot\\n    and rhs.shape[-1].value >= min_dot_size[1], \\\\\\nAssertionError: Input shapes should have M >= 16, N >= 16 and K >= 16\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp6nbo1sps.py\", line 109, in forward\\n    fused_linear_swish_scale[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\\n    fn()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\\n    self.fn.run(\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 55:18:\\n        # Vectorized weight load with appropriate mask\\n        weight_vals = tl.load(\\n            weight_ptrs,\\n            mask=mask_oc[:, None] & mask_k[None, :],\\n            other=0.0,\\n            eviction_policy=\"evict_first\"\\n        )\\n\\n        # Use tensor core dot product for better performance\\n        input_vals_2D = tl.reshape(input_vals, (1, BLOCK_K))\\n        weight_vals_2D = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\\n        product = tl.dot(input_vals_2D, tl.trans(weight_vals_2D), allow_tf32=True)\\n                  ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1504, in dot\\n    and rhs.shape[-1].value >= min_dot_size[1], \\\\\\nAssertionError: Input shapes should have M >= 16, N >= 16 and K >= 16\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 0.0000, score: 20.0000, speed_up: 0.8540, runtime_ms: 0.0874, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 0.854, 'custom_timing': 0.0874}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 22.2000, speed_up: 1.0220, runtime_ms: 0.0730, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.022, 'custom_timing': 0.073}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 22.2000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 32}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_M: tl.constexpr, \n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_m = pid // tl.cdiv(N, BLOCK_N)\n    pid_n = pid % tl.cdiv(N, BLOCK_N)\n    \n    # Offsets for output block\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Compute pointer offsets for input x and weights\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + tl.arange(0, BLOCK_K)[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + tl.arange(0, BLOCK_K)[:, None] * stride_wk\n    \n    # Loop over K dimension\n    for k in range(0, K, BLOCK_K):\n        # Load input block\n        k_offs = k + tl.arange(0, BLOCK_K)\n        x_mask = (offs_m[:, None] < M) & (k_offs[None, :] < K)\n        x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (k_offs[:, None] < K) & (offs_n[None, :] < N)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Compute block matrix multiplication\n        acc += tl.dot(x, w, allow_tf32=True)\n        \n        # Update pointers for next block\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    # Apply bias\n    b = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n    acc += b[None, :]\n    \n    # Apply Swish activation and scaling\n    sig = tl.sigmoid(acc)\n    output = acc * sig * scaling_factor\n    \n    # Write back result\n    out_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, output, mask=out_mask)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    M, K = x.shape\n    N, _ = weight.shape\n    \n    # Allocate output\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    # Grid definition\n    grid = lambda opt: (triton.cdiv(M, opt['BLOCK_M']) * triton.cdiv(N, opt['BLOCK_N']),)\n    \n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (22.2000), Performs well on speed_up (1.0220), Performs well on runtime_ms (0.0730), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.022, 'custom_timing': 0.073})\n\n\n### Program 2 (Score: 20.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['out_features', 'in_features'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    batch_size, in_features, out_features,\n    # Strides\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Map program ids to the block of the output they should compute.\n    pid = tl.program_id(0)\n    num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n    batch_idx = pid // num_out_blocks\n    out_block_idx = pid % num_out_blocks\n\n    # This program will compute a block of the output for the given batch index and a block of the out_features.\n    offs_out = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Create pointers for the weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n    w_ptrs = w_ptr + offs_out[:, None] * stride_w0 + offs_k[None, :] * stride_w1\n\n    # Accumulator for the output block\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n    # Loop over the in_features dimension in blocks of BLOCK_SIZE_K\n    num_k_blocks = tl.cdiv(in_features, BLOCK_SIZE_K)\n    for k in range(0, num_k_blocks):\n        k_offs = k * BLOCK_SIZE_K\n        # Load a block of x for the current batch and the current K block.\n        x_ptrs = x_ptr + batch_idx * stride_x0 + (k_offs + offs_k) * stride_x1\n        mask_x = (k_offs + offs_k) < in_features\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n\n        # Load a block of weights for the current K block and the current out block.\n        mask_w = (offs_out[:, None] < out_features) & ((k_offs + offs_k)[None, :] < in_features)\n        w_block = tl.load(w_ptrs + k_offs * stride_w1, mask=mask_w, other=0.0)\n\n        # Compute the dot product for this block\n        acc += tl.sum(w_block * x_block[None, :], axis=1)\n\n    # Load bias for the current out block\n    b_ptrs = b_ptr + offs_out\n    mask_bias = offs_out < out_features\n    bias = tl.load(b_ptrs, mask=mask_bias, other=0.0)\n    acc += bias\n\n    # Apply Swish: acc * sigmoid(acc)\n    swish_output = acc * tl.sigmoid(acc)\n    # Scale\n    swish_output = swish_output * scaling_factor\n\n    # Write back the result\n    out_ptrs = output_ptr + batch_idx * stride_out0 + offs_out * stride_out1\n    tl.store(out_ptrs, swish_output, mask=mask_bias)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    # Allocate output\n    output = torch.empty((batch, out_features), device=x.device, dtype=x.dtype)\n    # The grid is batch * ceil(out_features / 64) to ensure sufficient coverage\n    grid = (batch * triton.cdiv(out_features, 64),)\n    # Launch kernel without passing BLOCK_SIZE parameters\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        batch, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor,\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    Uses a fused Triton kernel for the operation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        # initialize the parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        # We use the fused kernel\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (0.0000), Performs well on score (20.0000), Performs well on speed_up (0.8540), Performs well on runtime_ms (0.0874), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 0.854, 'custom_timing': 0.0874})\n\n\n### Program 3 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8, num_stages=3),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    \n    oc_offs = pid_oc * BLOCK_N + tl.arange(0, BLOCK_N)\n    mask_oc = oc_offs < out_features\n    \n    # Precompute base weight pointers for the current output block\n    base_weight_ptrs = weight_ptr + oc_offs * stride_weight\n    \n    # Initialize accumulator in fp32 for numerical stability\n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    bias = tl.load(bias_ptr + oc_offs, mask=mask_oc, other=0.0)\n    \n    # Loop over K dimension with vectorized loads\n    for k in range(0, tl.cdiv(in_features, BLOCK_K)):\n        k_offs = k * BLOCK_K + tl.arange(0, BLOCK_K)\n        mask_k = k_offs < in_features\n        \n        # Coalesced memory access for input\n        input_vals = tl.load(\n            input_ptr + pid_b * stride_input + k_offs,\n            mask=mask_k,\n            other=0.0,\n            eviction_policy=\"evict_last\"\n        )\n        \n        # Compute weight pointers for current K block\n        weight_ptrs = base_weight_ptrs[:, None] + k_offs[None, :]\n        \n        # Vectorized weight load with appropriate mask\n        weight_vals = tl.load(\n            weight_ptrs,\n            mask=mask_oc[:, None] & mask_k[None, :],\n            other=0.0,\n            eviction_policy=\"evict_first\"\n        )\n        \n        # Use tensor core dot product for better performance\n        input_vals_2D = tl.reshape(input_vals, (1, BLOCK_K))\n        weight_vals_2D = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\n        product = tl.dot(input_vals_2D, tl.trans(weight_vals_2D), allow_tf32=True)\n        acc += tl.reshape(product, (BLOCK_N,))\n    \n    # Fused activation and scaling\n    result = (acc + bias) * tl.sigmoid(acc + bias) * scaling_factor\n    \n    # Coalesced output store\n    tl.store(\n        output_ptr + pid_b * stride_output + oc_offs,\n        result,\n        mask=mask_oc\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        \n        # Dynamic grid calculation using autotuned BLOCK_N\n        grid = lambda meta: (\n            x.size(0), \n            triton.cdiv(self.out_features, meta['BLOCK_N'])\n        )\n        \n        fused_linear_swish_scale[grid](\n            x, self.weight, self.bias, output,\n            self.in_features, self.out_features,\n            self.scaling_factor,\n            x.stride(0), self.weight.stride(0), output.stride(0)\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1504, in dot\\n    and rhs.shape[-1].value >= min_dot_size[1], \\\\\\nAssertionError: Input shapes should have M >= 16, N >= 16 and K >= 16\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp6nbo1sps.py\", line 109, in forward\\n    fused_linear_swish_scale[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 160, in _bench\\n    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/testing.py\", line 149, in do_bench\\n    fn()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 146, in kernel_call\\n    self.fn.run(\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\\n    kernel = self.compile(src, target=target, options=options.__dict__)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 339, in compile\\n    module = src.make_ir(options, codegen_fns, module_map, context)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 83, in make_ir\\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\\ntriton.compiler.errors.CompilationError: at 55:18:\\n        # Vectorized weight load with appropriate mask\\n        weight_vals = tl.load(\\n            weight_ptrs,\\n            mask=mask_oc[:, None] & mask_k[None, :],\\n            other=0.0,\\n            eviction_policy=\"evict_first\"\\n        )\\n\\n        # Use tensor core dot product for better performance\\n        input_vals_2D = tl.reshape(input_vals, (1, BLOCK_K))\\n        weight_vals_2D = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\\n        product = tl.dot(input_vals_2D, tl.trans(weight_vals_2D), allow_tf32=True)\\n                  ^\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 42, in wrapper\\n    return fn(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/core.py\", line 2045, in dot\\n    return _semantic.dot(input, other, acc, input_precision, max_num_imprecise_acc, out_dtype)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/language/semantic.py\", line 1504, in dot\\n    and rhs.shape[-1].value >= min_dot_size[1], \\\\\\nAssertionError: Input shapes should have M >= 16, N >= 16 and K >= 16\\n', 'runtime_error_name': 'triton.compiler.errors.CompilationError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['out_features', 'in_features'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    batch_size, in_features, out_features,\n    # Strides\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Map program ids to the block of the output they should compute.\n    pid = tl.program_id(0)\n    num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n    batch_idx = pid // num_out_blocks\n    out_block_idx = pid % num_out_blocks\n\n    # This program will compute a block of the output for the given batch index and a block of the out_features.\n    offs_out = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Create pointers for the weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n    w_ptrs = w_ptr + offs_out[:, None] * stride_w0 + offs_k[None, :] * stride_w1\n\n    # Accumulator for the output block\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n    # Loop over the in_features dimension in blocks of BLOCK_SIZE_K\n    num_k_blocks = tl.cdiv(in_features, BLOCK_SIZE_K)\n    for k in range(0, num_k_blocks):\n        k_offs = k * BLOCK_SIZE_K\n        # Load a block of x for the current batch and the current K block.\n        x_ptrs = x_ptr + batch_idx * stride_x0 + (k_offs + offs_k) * stride_x1\n        mask_x = (k_offs + offs_k) < in_features\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n\n        # Load a block of weights for the current K block and the current out block.\n        mask_w = (offs_out[:, None] < out_features) & ((k_offs + offs_k)[None, :] < in_features)\n        w_block = tl.load(w_ptrs + k_offs * stride_w1, mask=mask_w, other=0.0)\n\n        # Compute the dot product for this block\n        acc += tl.sum(w_block * x_block[None, :], axis=1)\n\n    # Load bias for the current out block\n    b_ptrs = b_ptr + offs_out\n    mask_bias = offs_out < out_features\n    bias = tl.load(b_ptrs, mask=mask_bias, other=0.0)\n    acc += bias\n\n    # Apply Swish: acc * sigmoid(acc)\n    swish_output = acc * tl.sigmoid(acc)\n    # Scale\n    swish_output = swish_output * scaling_factor\n\n    # Write back the result\n    out_ptrs = output_ptr + batch_idx * stride_out0 + offs_out * stride_out1\n    tl.store(out_ptrs, swish_output, mask=mask_bias)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    # Allocate output\n    output = torch.empty((batch, out_features), device=x.device, dtype=x.dtype)\n    # The grid is batch * ceil(out_features / BLOCK_SIZE_N)\n    grid = (batch * triton.cdiv(out_features, 128),)  # we use 128 as a base BLOCK_SIZE_N for grid, but the kernel will use the autotuned one\n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        batch, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor,\n        BLOCK_SIZE_N=128,  # This will be overridden by autotuner if a config is provided\n        BLOCK_SIZE_K=32,    # same\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    Uses a fused Triton kernel for the operation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        # initialize the parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        # We use the fused kernel\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8, num_stages=3),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_bias,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    \n    oc_offs = pid_oc * BLOCK_N + tl.arange(0, BLOCK_N)\n    mask_oc = oc_offs < out_features\n    \n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    bias = tl.load(bias_ptr + oc_offs, mask=mask_oc, other=0.0)\n    \n    for k in range(0, in_features, BLOCK_K):\n        k_offs = k + tl.arange(0, BLOCK_K)\n        mask_k = k_offs < in_features\n        \n        input_vals = tl.load(\n            input_ptr + pid_b * stride_input + k_offs,\n            mask=mask_k,\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_vals = tl.load(\n            weight_ptr + oc_offs[:, None] * stride_weight + k_offs[None, :],\n            mask=mask_oc[:, None] & mask_k[None, :],\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_matrix = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\n        input_vector = tl.reshape(input_vals, (BLOCK_K, 1))\n        acc += tl.dot(weight_matrix, input_vector).to(tl.float32)\n    \n    acc = tl.reshape(acc, (BLOCK_N,)) + bias\n    sig = 1.0 / (1.0 + tl.exp(-acc))\n    result = acc * sig * scaling_factor\n    \n    tl.store(\n        output_ptr + pid_b * stride_output + oc_offs,\n        result,\n        mask=mask_oc\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        grid = (x.size(0), triton.cdiv(self.out_features, 128))\n        \n        fused_linear_swish_scale[grid](\n            x, self.weight, self.bias, output,\n            self.in_features, self.out_features,\n            self.scaling_factor,\n            x.stride(0), self.weight.stride(0), 0, output.stride(0),\n            BLOCK_N=128, BLOCK_K=64\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['out_features', 'in_features'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    batch_size, in_features, out_features,\n    # Strides\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Map program ids to the block of the output they should compute.\n    pid = tl.program_id(0)\n    num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n    batch_idx = pid // num_out_blocks\n    out_block_idx = pid % num_out_blocks\n\n    # This program will compute a block of the output for the given batch index and a block of the out_features.\n    offs_out = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Create pointers for the weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n    w_ptrs = w_ptr + offs_out[:, None] * stride_w0 + offs_k[None, :] * stride_w1\n\n    # Accumulator for the output block\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n    # Loop over the in_features dimension in blocks of BLOCK_SIZE_K\n    num_k_blocks = tl.cdiv(in_features, BLOCK_SIZE_K)\n    for k in range(0, num_k_blocks):\n        k_offs = k * BLOCK_SIZE_K\n        # Load a block of x for the current batch and the current K block.\n        x_ptrs = x_ptr + batch_idx * stride_x0 + (k_offs + offs_k) * stride_x1\n        mask_x = (k_offs + offs_k) < in_features\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n\n        # Load a block of weights for the current K block and the current out block.\n        mask_w = (offs_out[:, None] < out_features) & ((k_offs + offs_k)[None, :] < in_features)\n        w_block = tl.load(w_ptrs + k_offs * stride_w1, mask=mask_w, other=0.0)\n\n        # Compute the dot product for this block\n        acc += tl.sum(w_block * x_block[None, :], axis=1)\n\n    # Load bias for the current out block\n    b_ptrs = b_ptr + offs_out\n    mask_bias = offs_out < out_features\n    bias = tl.load(b_ptrs, mask=mask_bias, other=0.0)\n    acc += bias\n\n    # Apply Swish: acc * sigmoid(acc)\n    swish_output = acc * tl.sigmoid(acc)\n    # Scale\n    swish_output = swish_output * scaling_factor\n\n    # Write back the result\n    out_ptrs = output_ptr + batch_idx * stride_out0 + offs_out * stride_out1\n    tl.store(out_ptrs, swish_output, mask=mask_bias)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    # Allocate output\n    output = torch.empty((batch, out_features), device=x.device, dtype=x.dtype)\n    # The grid is batch * ceil(out_features / BLOCK_SIZE_N)\n    grid = (batch * triton.cdiv(out_features, 128),)  # we use 128 as a base BLOCK_SIZE_N for grid, but the kernel will use the autotuned one\n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        batch, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor,\n        BLOCK_SIZE_N=128,  # This will be overridden by autotuner if a config is provided\n        BLOCK_SIZE_K=32,    # same\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    Uses a fused Triton kernel for the operation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        # initialize the parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        # We use the fused kernel\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 2 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef _forward_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    M, N, K, scaling_factor,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_bn,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    pid_m = pid // num_pid_n\n    pid_n = pid % num_pid_n\n\n    offs_m = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_k[:, None] * stride_wk + offs_n[None, :] * stride_wn)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    \n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        k_remaining = K - k * BLOCK_SIZE_K\n        k_mask = offs_k < k_remaining\n        \n        # Create proper 2D masks\n        mask_x = (offs_m[:, None] < M) & (k_mask[None, :])\n        mask_w = k_mask[:, None] & (offs_n[None, :] < N)\n        \n        # Convert to FP16 for Tensor Core acceleration\n        x = tl.load(x_ptrs, mask=mask_x, other=0.0).to(tl.float16)\n        w = tl.load(w_ptrs, mask=mask_w, other=0.0).to(tl.float16)\n        \n        # Accumulate with tensor cores\n        acc += tl.dot(x, w, allow_tf32=True, out_dtype=tl.float32)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wk\n    \n    # Load bias with boundary check\n    bias = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n    acc += bias[None, :]\n    \n    # Apply fused Swish and scaling\n    swish = acc * tl.sigmoid(acc) * scaling_factor\n    \n    # Create output pointers with boundary mask\n    mask_out = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    out_ptrs = output_ptr + (offs_m[:, None] * stride_om + offs_n[None, :] * stride_on)\n    tl.store(out_ptrs, swish, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.zeros(out_features))\n    \n    def forward(self, x):\n        output = torch.empty((x.size(0), self.out_features), \n                             device=x.device, dtype=x.dtype)\n        \n        M, K = x.shape\n        N = self.weight.shape[0]\n        \n        grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),)\n        \n        _forward_kernel[grid](\n            x, self.weight, self.bias, output,\n            M, N, K, self.scaling_factor,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            self.bias.stride(0),\n            output.stride(0), output.stride(1)\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nUnique approach: Excellent compiled (1.000), Excellent correctness (1.000), Alternative passed approach\n\n\n### Inspiration 4 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_blocks_out = tl.cdiv(out_features, BLOCK_N)\n    total_programs = tl.cdiv(in_features, BLOCK_K) * num_blocks_out\n    if pid >= total_programs:\n        return\n\n    k_block = pid // num_blocks_out\n    out_block_idx = pid % num_blocks_out\n\n    batch_idx = tl.program_id(1)\n    offs_n = out_block_idx * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = k_block * BLOCK_K + tl.arange(0, BLOCK_K)\n    \n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n\n    input_ptrs = input_ptr + batch_idx * stride_input + offs_k\n    weight_ptrs = weight_ptr + offs_n[:, None] * stride_weight + offs_k[None, :]\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    \n    # Load input block (ensure within bounds)\n    input_block = tl.load(input_ptrs, mask=mask_k, other=0.0)\n    \n    # Load weight block (ensure within bounds)\n    weight_block = tl.load(weight_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n    \n    # Compute partial dot product\n    acc += tl.sum(weight_block * input_block[None, :], axis=1)\n    \n    # Use atomic add to accumulate results\n    output_ptrs = output_ptr + batch_idx * stride_output + offs_n\n    tl.atomic_add(output_ptrs, acc, mask=mask_n)\n\n    # After all K blocks, apply bias, swish, and scaling\n    tl.debug_barrier()\n    \n    if k_block == 0:\n        # Load accumulated result\n        out_val = tl.load(output_ptrs, mask=mask_n, other=0.0)\n        # Load bias\n        bias = tl.load(bias_ptr + offs_n, mask=mask_n, other=0.0)\n        # Add bias\n        out_val += bias\n        # Apply Swish activation\n        swish = out_val * tl.sigmoid(out_val)\n        # Apply scaling\n        result = swish * scaling_factor\n        # Store final result\n        tl.store(output_ptrs, result, mask=mask_n)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    \n    # Allocate output tensor\n    output = torch.zeros((batch, out_features), device=x.device, dtype=x.dtype)\n    \n    # Compute grid dimensions\n    grid = (triton.cdiv(in_features, 64) * triton.cdiv(out_features, 128), batch)\n    \n    # Launch kernel\n    fused_linear_swish_scale[grid](\n        x, weight, bias, output,\n        in_features, out_features,\n        scaling_factor,\n        x.stride(0), weight.stride(0), output.stride(0),\n        BLOCK_N=128, BLOCK_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n### Inspiration 5 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8, num_stages=3),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_bias,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    \n    oc_offs = pid_oc * BLOCK_N + tl.arange(0, BLOCK_N)\n    mask_oc = oc_offs < out_features\n    \n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    bias = tl.load(bias_ptr + oc_offs, mask=mask_oc, other=0.0)\n    \n    for k in range(0, in_features, BLOCK_K):\n        k_offs = k + tl.arange(0, BLOCK_K)\n        mask_k = k_offs < in_features\n        \n        input_vals = tl.load(\n            input_ptr + pid_b * stride_input + k_offs,\n            mask=mask_k,\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_vals = tl.load(\n            weight_ptr + oc_offs[:, None] * stride_weight + k_offs[None, :],\n            mask=mask_oc[:, None] & mask_k[None, :],\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_matrix = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\n        input_vector = tl.reshape(input_vals, (BLOCK_K, 1))\n        acc += tl.dot(weight_matrix, input_vector).to(tl.float32)\n    \n    acc = tl.reshape(acc, (BLOCK_N,)) + bias\n    sig = 1.0 / (1.0 + tl.exp(-acc))\n    result = acc * sig * scaling_factor\n    \n    tl.store(\n        output_ptr + pid_b * stride_output + oc_offs,\n        result,\n        mask=mask_oc\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        grid = (x.size(0), triton.cdiv(self.out_features, 128))\n        \n        fused_linear_swish_scale[grid](\n            x, self.weight, self.bias, output,\n            self.in_features, self.out_features,\n            self.scaling_factor,\n            x.stride(0), self.weight.stride(0), 0, output.stride(0),\n            BLOCK_N=128, BLOCK_K=64\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 32}, num_warps=4),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_M: tl.constexpr, \n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_m = pid // tl.cdiv(N, BLOCK_N)\n    pid_n = pid % tl.cdiv(N, BLOCK_N)\n    \n    # Offsets for output block\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Compute pointer offsets for input x and weights\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + tl.arange(0, BLOCK_K)[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + tl.arange(0, BLOCK_K)[:, None] * stride_wk\n    \n    # Loop over K dimension\n    for k in range(0, K, BLOCK_K):\n        # Load input block\n        k_offs = k + tl.arange(0, BLOCK_K)\n        x_mask = (offs_m[:, None] < M) & (k_offs[None, :] < K)\n        x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (k_offs[:, None] < K) & (offs_n[None, :] < N)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Compute block matrix multiplication\n        acc += tl.dot(x, w, allow_tf32=True)\n        \n        # Update pointers for next block\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    # Apply bias\n    b = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n    acc += b[None, :]\n    \n    # Apply Swish activation and scaling\n    sig = tl.sigmoid(acc)\n    output = acc * sig * scaling_factor\n    \n    # Write back result\n    out_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, output, mask=out_mask)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    M, K = x.shape\n    N, _ = weight.shape\n    \n    # Allocate output\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    # Grid definition\n    grid = lambda opt: (triton.cdiv(M, opt['BLOCK_M']) * triton.cdiv(N, opt['BLOCK_N']),)\n    \n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program, which is the top-performing one (Score: 22.2000) with a speed_up of 1.0220.\n The goal is to further improve the performance (speed_up) without breaking correctness.\n\n The current kernel uses a block matrix multiplication with autotuning. However, note that the current kernel\n uses a 2D grid where each block computes a [BLOCK_M, BLOCK_N] block of the output by iterating over K in blocks of BLOCK_K.\n\n We note the following:\n  - The current kernel uses `tl.dot` which leverages tensor cores when the dimensions are appropriately aligned.\n  - The problem dimensions: batch_size=128, in_features=1024, out_features=512.\n\n Areas for potential improvement:\n\n  1. **Data Type Conversion for Tensor Cores**: The tensor cores on H100 (SM8.9) are optimized for FP16 and BF16.\n     The current kernel uses FP32 for accumulation (which is good for precision) but the inputs are in FP16? \n     The problem does not specify the data type of the input. However, the reference PyTorch code might be in FP32.\n\n     Since the current program uses `x.dtype` for output, and the parameters are initialized as standard FP32 in PyTorch,\n     we must check the input. In the `get_inputs` function, we see `torch.randn` which by default is FP32.\n\n     However, in the provided context, we are not told the data type. But note that the Triton kernel uses `tl.float32` for accumulation.\n\n     We can try to use FP16 for the matrix multiplication if the inputs are in FP16. But the problem does not specify.\n\n  2. **Blocking and Tiling**: The current autotuning configurations are for BLOCK_M, BLOCK_N, BLOCK_K. We might try to adjust the tiling to better fit the problem size.\n\n     Specifically, for the given problem: M=128, N=512, K=1024.\n\n     We note that the grid is of size (ceil(M/BLOCK_M) * ceil(N/BLOCK_N)). Since M=128 is relatively small, we might want to use a larger BLOCK_M to reduce the grid size and improve occupancy.\n\n  3. **Precomputation of Swish**: The current kernel computes:\n        sig = tl.sigmoid(acc)\n        output = acc * sig * scaling_factor\n\n     This is efficient.\n\n  4. **Vectorized Memory Access**: We are using `tl.load` and `tl.store` with masks. We might be able to improve by ensuring that the loads are vectorized.\n\n     However, the current code does not explicitly use vectorized loads/stores. We can try to use `tl.dot` with vectorized input.\n\n  5. **Use of Tensor Cores**: The `tl.dot` instruction uses tensor cores when the block sizes are multiples of 16 (for FP16). But note that the current accumulation is in FP32.\n\n     We can try to change the accumulation to FP16? But that might harm numerical stability.\n\n     Alternatively, we can use mixed precision: load the inputs as FP16, do the dot product in FP32 accumulation? Actually, Triton's `tl.dot` allows specifying the input type and accumulation type.\n\n     The current kernel uses `allow_tf32=True` which uses TF32 tensor cores on Ampere and later. This is good.\n\n  6. **Blocking for K dimension**: We are iterating over K in blocks of BLOCK_K. We might try to adjust BLOCK_K to reduce the number of iterations and increase the amount of work per block.\n\n Given the above, we consider the following changes:\n\n  - We note that the current kernel already uses a good set of autotuning configurations. We might add more configurations that are specifically tailored for the problem size.\n\n    For example, since M=128 is small, we can try BLOCK_M=128 (so that we have only one block along M) and then focus on tiling N and K.\n\n    However, the autotuner already includes a config with BLOCK_M=128 and BLOCK_N=128, but note that N=512, so we would have 512/128=4 blocks along N.\n\n    Also, we have BLOCK_K=64, so we do 1024/64=16 iterations. We might try increasing BLOCK_K to 128 to reduce the number of iterations to 8.\n\n  - We can try to use a larger BLOCK_N to reduce the number of blocks and increase the work per block.\n\n    For example, BLOCK_N=256 would require 512/256=2 blocks along N. But note that the current autotuning configs include BLOCK_N=256 for some cases.\n\n  - We can try to use vectorized loads. Currently, the loads are for a block of [BLOCK_M, BLOCK_K] for x and [BLOCK_K, BLOCK_N] for w.\n\n    Triton can automatically vectorize if the data is contiguous and the block sizes are multiples of the vector width.\n\n    We might explicitly vectorize by setting the `cache` and `eviction_policy` and using `tl.make_block_ptr` for better memory access.\n\n    However, the current code does not use block pointers. We can try to rewrite using block pointers to hint to Triton about the access pattern.\n\n  - Another idea: use the input and weight matrices in a way that the tensor cores are fully utilized.\n\n    The tensor cores require the inner dimension to be aligned to 16. Our BLOCK_K must be a multiple of 16. The current configs have BLOCK_K=32, 64, 128, which are multiples of 16.\n\n Given that the current program is already working and has a speedup of 1.022, we want to make incremental changes.\n\n We decide to:\n\n  Option A: Increase the BLOCK_K in the autotuning configs to 128 and 256 to reduce the number of iterations.\n\n  But note that the current autotuning configs already include BLOCK_K=128 in some configs.\n\n  We might also add a config that uses BLOCK_M=128 (to cover the entire M dimension) and BLOCK_N=512 (to cover the entire N dimension) and BLOCK_K=256.\n\n  However, BLOCK_N=512 might be too large because the number of threads per block is BLOCK_M * BLOCK_N? Actually, no: the kernel uses a 2D block of [BLOCK_M, BLOCK_N] but note that the inner loop is over K. The number of threads per block is BLOCK_M * BLOCK_N? Actually, no: Triton uses a 1D grid and the kernel uses a 2D block of [BLOCK_M, BLOCK_N] but the hardware thread block is 1D? \n\n  Actually, the kernel is written in a way that each program is a 1D block of work? The kernel uses a 2D block of [BLOCK_M, BLOCK_N] but the program id is 1D. The kernel uses a 2D block of [BLOCK_M, BLOCK_N] and the inner loop over K. The total number of threads per block would be BLOCK_M * BLOCK_N? That is too many (e.g., 128*128=16384, but the maximum threads per block is 1024).\n\n  Correction: In Triton, the kernel is executed by a 1D grid of program ids, and each program id can represent a block of [BLOCK_M, BLOCK_N] elements. The kernel uses a 2D block of [BLOCK_M, BLOCK_N] and the inner loop over K. The work per program is BLOCK_M * BLOCK_N * BLOCK_K (for one iteration of the inner loop). The number of threads per program is not directly BLOCK_M * BLOCK_N; Triton uses a tiling and maps the block to threads. The `num_warps` parameter controls the number of warps (32 threads per warp) for the entire block.\n\n  We must ensure that the product of the block dimensions does not exceed the maximum number of threads per block? Actually, Triton handles this by internally tiling the block. We just specify the block dimensions and the number of warps.\n\n  However, note that the kernel uses `tl.arange(0, BLOCK_M)` and `tl.arange(0, BLOCK_N)`, which are two dimensions. The total number of elements in the block is BLOCK_M * BLOCK_N. This must be less than or equal to the number of threads per block (1024) multiplied by the vector width? Not exactly: Triton can handle blocks that are larger than the number of threads by using loop tiling internally.\n\n  But we are constrained by the number of warps. For example, if we set `num_warps=8`, then we have 256 threads. So we must have BLOCK_M * BLOCK_N <= 256? Actually, no: Triton can split the block into multiple threads. But the block dimensions must be chosen so that the product BLOCK_M * BLOCK_N is not too large to be inefficient.\n\n  We note that the current configs use up to 256*128=32768 elements per block? That doesn't seem right.\n\n  Actually, the kernel is written in a way that each program computes a [BLOCK_M, BLOCK_N] block of the output. The kernel uses nested loops over the K dimension. The block dimensions are the number of elements in the output block, not the number of threads.\n\n  The number of threads per block is determined by `num_warps` (each warp has 32 threads). So if we set `num_warps=8`, we have 256 threads. Triton will then parallelize the [BLOCK_M, BLOCK_N] block over these 256 threads.\n\n  Therefore, we must have BLOCK_M * BLOCK_N <= (some multiple of the number of threads) but Triton can handle blocks larger than the thread count by having each thread handle multiple elements.\n\n  However, for efficiency, we want the block to be divisible by the number of threads? Or at least not too much larger.\n\n  Given the above, we decide to:\n\n    - Keep the current kernel structure.\n    - Add a few more autotuning configurations that have larger BLOCK_K (like 256) and also try to cover the entire M dimension (BLOCK_M=128) and larger BLOCK_N (like 256) to reduce the grid size.\n\n    We add:\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 64}, num_warps=8),   # Note: BLOCK_N=512 might be too large? But N=512 so this would cover entire N in one block for that dimension.\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 128}, num_warps=8),\n\n    But note: when BLOCK_N=512, then the block would cover the entire N dimension. Then the grid would be (ceil(M/128), )? Actually, the grid is 1D: (ceil(M/BLOCK_M) * ceil(N/BLOCK_N)). For M=128, ceil(128/128)=1, ceil(512/512)=1, so one block.\n\n    However, the kernel must be able to handle any M and N? The problem says the input is (M, K) and weight is (N, K). The current kernel uses M and N as the dimensions.\n\n    We must be cautious: if we set BLOCK_N=512, then the kernel must handle the case when N is not divisible by 512? The kernel uses masks, so it's safe.\n\n    But the number of threads: 8 warps = 256 threads. The block has 128 * 512 = 65536 elements. Each thread would have to handle 65536/256=256 elements. This is acceptable.\n\n  - We also note that the tensor core operation `tl.dot` requires the inner dimension (K) to be at least 16. Our BLOCK_K is at least 32 in the current configs.\n\n  - We might also try to change the data type of the accumulation to FP16? But that might break correctness. We are currently using FP32 for the accumulation.\n\n    We note the reference PyTorch code uses FP32. So we must maintain FP32 precision.\n\n    However, we can use TF32 tensor cores, which is enabled by `allow_tf32=True`. This is already present.\n\n  - We might try to use the input in FP16 to get the full tensor core speed? But the input is in FP32. We can convert on the fly.\n\n    We can change the loads to convert to FP16:\n\n        x = tl.load(x_ptrs, mask=x_mask, other=0.0).to(tl.float16)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0).to(tl.float16)\n\n    and then do the dot product in FP32 accumulation? But note that the `tl.dot` operation for FP16 inputs will use FP16 accumulation by default? We want FP32.\n\n    We can do:\n\n        acc += tl.dot(x, w, allow_tf32=True, out_dtype=tl.float32)\n\n    But note: the current `tl.dot` already uses FP32 because `acc` is FP32? The Triton documentation says the dot product returns the same dtype as the accumulator. But we are doing:\n\n        acc = tl.zeros(..., dtype=tl.float32)\n        ... and then acc += tl.dot(...)\n\n        The `tl.dot` when given two FP16 tensors will return an FP32 tensor? Actually, the `tl.dot` operation has an `out_dtype` parameter. The default is the dtype of the input? We should set it explicitly.\n\n    Alternatively, we can leave it as is because the current kernel uses `allow_tf32=True` and the inputs are FP32? But the tensor cores are optimized for FP16. \n\n    We must consider: the input is FP32. We can convert to FP16 to use the tensor cores? But note that TF32 is a 19-bit format that is designed for FP32 inputs. So the current use of TF32 is appropriate.\n\n    However, if we convert to FP16, we might lose precision? The reference is FP32.\n\n    We are not told the tolerance. We might try to use FP16 for the matrix multiplication and then do the bias and activation in FP32? But the accumulation would be in FP16? That might be too lossy.\n\n    Given the potential for precision loss, we avoid this change for now.\n\n  - We try to add the new autotuning configurations and see if they help.\n\n  We also note that the current kernel does not use shared memory. The inputs are loaded directly from global memory. We might consider using shared memory to reduce global memory accesses? However, the current tiling already blocks the data and the L1 cache might be sufficient.\n\n  Since the problem is small (M=128, N=512, K=1024), the current blocking might be acceptable.\n\n  Proposed changes:\n\n    We add three new configurations to the autotuner:\n\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 128}, num_warps=8),\n\n    We note that the existing configs already cover many cases, so we are just adding a few more that are tailored for the problem size.\n\n    We also note that the current problem has M=128, so using BLOCK_M=128 is optimal for the M dimension.\n\n  We must be cautious: the kernel must work for any input size, not just the fixed problem. But the autotuner will choose the best config for the given M, N, K.\n\n  We also note that the kernel already has a mask for out-of-bound accesses, so it is safe.\n\n  We will change the autotuner configs by adding the three new configs.\n\n  We also note that the current kernel has a loop:\n\n        for k in range(0, K, BLOCK_K):\n\n    We might precompute the number of blocks to avoid the integer division? But the compiler should handle that.\n\n  We leave the rest of the kernel unchanged.\n\n  We output the entire code block.\n\n  IMPORTANT: We are only allowed to change the Triton kernel source within the EVOLVE-BLOCK. We must not change the function signatures, grid computation, or the ModelNew class.\n\n  Let's update the autotuner configs by adding the three new configs.\n\n  We also note that the current program has a grid function:\n\n        grid = lambda opt: (triton.cdiv(M, opt['BLOCK_M']) * triton.cdiv(N, opt['BLOCK_N']),)\n\n    This is correct.\n\n  We write the new code with the added configurations.\n\n  We also note that the current kernel uses:\n\n        x_ptrs = ... + tl.arange(0, BLOCK_K)[None, :] * stride_xk\n        w_ptrs = ... + tl.arange(0, BLOCK_K)[:, None] * stride_wk\n\n    and then updates the pointers by:\n\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n\n    This is correct.\n\n  We hope that the new configurations will be chosen for the problem size and improve performance.\n\n  We also note that the current best config might be one of the existing ones. By adding more configs we might find a better one.\n\n  We run the risk of making the autotuning process slower? But the problem is fixed size (M=128, N=512, K=1024) so it only autotunes once.\n\n  We output the entire code block with the updated autotuner configs.\n\n  If we see that the program still compiles and is correct, then we can measure the speedup.\n\n  We note that the current program has a speedup of 1.022. We hope to improve that.\n\n  Let's write the code.\n\n  Note: We are only allowed to change the Triton kernel and the autotuner configs. We must not change the rest.\n\n  We change the autotuner configs by adding the three new configs to the list.\n\n  We also note that the kernel code itself remains unchanged.\n\n  We also note that the current kernel uses:\n\n        # Apply bias\n        b = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n        acc += b[None, :]\n\n    This is correct.\n\n  We output the entire block.\n\n  IMPORTANT: The output must be exactly the same as the current program, except for the added autotuner configs and the kernel code if we changed it (but we are not changing the kernel code, only the autotuner configs).\n\n  We also note: the kernel code is long, so we must be careful.\n\n  We will copy the current program and then add the three new configs in the autotuner.\n\n  We also note that the current autotuner has 15 configs. We are adding 3, making 18.\n\n  We write:\n\n        configs=[\n            ... existing 15 configs ...,\n            triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n            triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 64}, num_warps=8),\n            triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 128}, num_warps=8),\n        ],\n\n  We hope this helps.\n\n  If we don't see improvement, we might consider other optimizations in the future.\n\n  We output the entire code block as required.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32, 'BLOCK_K': 32}, num_warps=4),\n        # New configurations optimized for problem dimensions\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 512, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['M', 'N', 'K'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # Strides\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_M: tl.constexpr, \n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    pid_m = pid // tl.cdiv(N, BLOCK_N)\n    pid_n = pid % tl.cdiv(N, BLOCK_N)\n    \n    # Offsets for output block\n    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n    \n    # Compute pointer offsets for input x and weights\n    x_ptrs = x_ptr + offs_m[:, None] * stride_xm + tl.arange(0, BLOCK_K)[None, :] * stride_xk\n    w_ptrs = w_ptr + offs_n[None, :] * stride_wn + tl.arange(0, BLOCK_K)[:, None] * stride_wk\n    \n    # Loop over K dimension\n    for k in range(0, K, BLOCK_K):\n        # Load input block\n        k_offs = k + tl.arange(0, BLOCK_K)\n        x_mask = (offs_m[:, None] < M) & (k_offs[None, :] < K)\n        x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        \n        # Load weight block\n        w_mask = (k_offs[:, None] < K) & (offs_n[None, :] < N)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        # Compute block matrix multiplication\n        acc += tl.dot(x, w, allow_tf32=True)\n        \n        # Update pointers for next block\n        x_ptrs += BLOCK_K * stride_xk\n        w_ptrs += BLOCK_K * stride_wk\n    \n    # Apply bias\n    b = tl.load(b_ptr + offs_n, mask=offs_n < N, other=0.0)\n    acc += b[None, :]\n    \n    # Apply Swish activation and scaling\n    sig = tl.sigmoid(acc)\n    output = acc * sig * scaling_factor\n    \n    # Write back result\n    out_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\n    out_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)\n    tl.store(out_ptrs, output, mask=out_mask)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    M, K = x.shape\n    N, _ = weight.shape\n    \n    # Allocate output\n    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n    \n    # Grid definition\n    grid = lambda opt: (triton.cdiv(M, opt['BLOCK_M']) * triton.cdiv(N, opt['BLOCK_N']),)\n    \n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        M, N, K,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}