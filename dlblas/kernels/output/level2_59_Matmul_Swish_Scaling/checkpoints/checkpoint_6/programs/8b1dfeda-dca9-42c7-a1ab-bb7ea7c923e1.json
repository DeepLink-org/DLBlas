{"id": "8b1dfeda-dca9-42c7-a1ab-bb7ea7c923e1", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_blocks_out = tl.cdiv(out_features, BLOCK_N)\n    total_programs = tl.cdiv(in_features, BLOCK_K) * num_blocks_out\n    if pid >= total_programs:\n        return\n\n    k_block = pid // num_blocks_out\n    out_block_idx = pid % num_blocks_out\n\n    batch_idx = tl.program_id(1)\n    offs_n = out_block_idx * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = k_block * BLOCK_K + tl.arange(0, BLOCK_K)\n    \n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n\n    input_ptrs = input_ptr + batch_idx * stride_input + offs_k\n    weight_ptrs = weight_ptr + offs_n[:, None] * stride_weight + offs_k[None, :]\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    \n    # Load input block (ensure within bounds)\n    input_block = tl.load(input_ptrs, mask=mask_k, other=0.0)\n    \n    # Load weight block (ensure within bounds)\n    weight_block = tl.load(weight_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n    \n    # Compute partial dot product\n    acc += tl.sum(weight_block * input_block[None, :], axis=1)\n    \n    # Use atomic add to accumulate results\n    output_ptrs = output_ptr + batch_idx * stride_output + offs_n\n    tl.atomic_add(output_ptrs, acc, mask=mask_n)\n\n    # After all K blocks, apply bias, swish, and scaling\n    tl.debug_barrier()\n    \n    if k_block == 0:\n        # Load accumulated result\n        out_val = tl.load(output_ptrs, mask=mask_n, other=0.0)\n        # Load bias\n        bias = tl.load(bias_ptr + offs_n, mask=mask_n, other=0.0)\n        # Add bias\n        out_val += bias\n        # Apply Swish activation\n        swish = out_val * tl.sigmoid(out_val)\n        # Apply scaling\n        result = swish * scaling_factor\n        # Store final result\n        tl.store(output_ptrs, result, mask=mask_n)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    \n    # Allocate output tensor\n    output = torch.zeros((batch, out_features), device=x.device, dtype=x.dtype)\n    \n    # Compute grid dimensions\n    grid = (triton.cdiv(in_features, 64) * triton.cdiv(out_features, 128), batch)\n    \n    # Launch kernel\n    fused_linear_swish_scale[grid](\n        x, weight, bias, output,\n        in_features, out_features,\n        scaling_factor,\n        x.stride(0), weight.stride(0), output.stride(0),\n        BLOCK_N=128, BLOCK_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "cfa6f593-d3a5-43b5-8c73-7fc129ce2827", "generation": 1, "timestamp": 1754573337.4180014, "iteration_found": 6, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_59_Matmul_Swish_Scaling", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp2d4zxy11.py\", line 126, in forward\n    return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n  File \"/tmp/tmp2d4zxy11.py\", line 103, in fused_linear_swish\n    fused_linear_swish_scale[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\n    raise ValueError(f\"Conflicting meta-parameters: {', '.join(conflicts)}.\"\nValueError: Conflicting meta-parameters: BLOCK_N, BLOCK_K. Make sure that you don't re-define auto-tuned symbols.\n", "runtime_error_name": "builtins.ValueError", "reference_timing_ms": 0.0746, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0548, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0746, "speed_up": 1.361, "custom_timing": 0.0548}}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: reference code\n- passed: 0.0000\n- score: 0.0000\n- speed_up: 1.0000\n- runtime_ms: 0.0548\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.361, 'custom_timing': 0.0548}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: reference code, passed: 0.0000, score: 0.0000, speed_up: 1.0000, runtime_ms: 0.0548, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.361, 'custom_timing': 0.0548}\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp_72t8jfk.py\", line 91, in forward\\n    fused_linear_swish_scale[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\\n    raise ValueError(f\"Conflicting meta-parameters: {\\', \\'.join(conflicts)}.\"\\nValueError: Conflicting meta-parameters: BLOCK_K, BLOCK_N. Make sure that you don\\'t re-define auto-tuned symbols.\\n', 'runtime_error_name': 'builtins.ValueError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 0.0000, score: 10.0000, stage: wrong_answer, verify_payload: {'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp06oz6x4h.py\", line 128, in forward\\n    return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\\n  File \"/tmp/tmp06oz6x4h.py\", line 96, in fused_linear_swish\\n    _fused_linear_swish_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\\n    raise ValueError(f\"Conflicting meta-parameters: {\\', \\'.join(conflicts)}.\"\\nValueError: Conflicting meta-parameters: BLOCK_SIZE_N, BLOCK_SIZE_K. Make sure that you don\\'t re-define auto-tuned symbols.\\n', 'runtime_error_name': 'builtins.ValueError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}}\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['out_features', 'in_features'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    batch_size, in_features, out_features,\n    # Strides\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Map program ids to the block of the output they should compute.\n    pid = tl.program_id(0)\n    num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n    batch_idx = pid // num_out_blocks\n    out_block_idx = pid % num_out_blocks\n\n    # This program will compute a block of the output for the given batch index and a block of the out_features.\n    offs_out = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Create pointers for the weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n    w_ptrs = w_ptr + offs_out[:, None] * stride_w0 + offs_k[None, :] * stride_w1\n\n    # Accumulator for the output block\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n    # Loop over the in_features dimension in blocks of BLOCK_SIZE_K\n    num_k_blocks = tl.cdiv(in_features, BLOCK_SIZE_K)\n    for k in range(0, num_k_blocks):\n        k_offs = k * BLOCK_SIZE_K\n        # Load a block of x for the current batch and the current K block.\n        x_ptrs = x_ptr + batch_idx * stride_x0 + (k_offs + offs_k) * stride_x1\n        mask_x = (k_offs + offs_k) < in_features\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n\n        # Load a block of weights for the current K block and the current out block.\n        mask_w = (offs_out[:, None] < out_features) & ((k_offs + offs_k)[None, :] < in_features)\n        w_block = tl.load(w_ptrs + k_offs * stride_w1, mask=mask_w, other=0.0)\n\n        # Compute the dot product for this block\n        acc += tl.sum(w_block * x_block[None, :], axis=1)\n\n    # Load bias for the current out block\n    b_ptrs = b_ptr + offs_out\n    mask_bias = offs_out < out_features\n    bias = tl.load(b_ptrs, mask=mask_bias, other=0.0)\n    acc += bias\n\n    # Apply Swish: acc * sigmoid(acc)\n    swish_output = acc * tl.sigmoid(acc)\n    # Scale\n    swish_output = swish_output * scaling_factor\n\n    # Write back the result\n    out_ptrs = output_ptr + batch_idx * stride_out0 + offs_out * stride_out1\n    tl.store(out_ptrs, swish_output, mask=mask_bias)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    # Allocate output\n    output = torch.empty((batch, out_features), device=x.device, dtype=x.dtype)\n    # The grid is batch * ceil(out_features / BLOCK_SIZE_N)\n    grid = (batch * triton.cdiv(out_features, 128),)  # we use 128 as a base BLOCK_SIZE_N for grid, but the kernel will use the autotuned one\n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        batch, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor,\n        BLOCK_SIZE_N=128,  # This will be overridden by autotuner if a config is provided\n        BLOCK_SIZE_K=32,    # same\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    Uses a fused Triton kernel for the operation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        # initialize the parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        # We use the fused kernel\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp06oz6x4h.py\", line 128, in forward\\n    return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\\n  File \"/tmp/tmp06oz6x4h.py\", line 96, in fused_linear_swish\\n    _fused_linear_swish_kernel[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\\n    raise ValueError(f\"Conflicting meta-parameters: {\\', \\'.join(conflicts)}.\"\\nValueError: Conflicting meta-parameters: BLOCK_SIZE_N, BLOCK_SIZE_K. Make sure that you don\\'t re-define auto-tuned symbols.\\n', 'runtime_error_name': 'builtins.ValueError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n### Program 2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4, num_stages=3),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8, num_stages=3),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8, num_stages=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4, num_stages=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8, num_stages=3),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_bias,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid_b = tl.program_id(0)\n    pid_oc = tl.program_id(1)\n    \n    oc_offs = pid_oc * BLOCK_N + tl.arange(0, BLOCK_N)\n    mask_oc = oc_offs < out_features\n    \n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    bias = tl.load(bias_ptr + oc_offs, mask=mask_oc, other=0.0)\n    \n    for k in range(0, in_features, BLOCK_K):\n        k_offs = k + tl.arange(0, BLOCK_K)\n        mask_k = k_offs < in_features\n        \n        input_vals = tl.load(\n            input_ptr + pid_b * stride_input + k_offs,\n            mask=mask_k,\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_vals = tl.load(\n            weight_ptr + oc_offs[:, None] * stride_weight + k_offs[None, :],\n            mask=mask_oc[:, None] & mask_k[None, :],\n            other=0.0\n        ).to(tl.float16)\n        \n        weight_matrix = tl.reshape(weight_vals, (BLOCK_N, BLOCK_K))\n        input_vector = tl.reshape(input_vals, (BLOCK_K, 1))\n        acc += tl.dot(weight_matrix, input_vector).to(tl.float32)\n    \n    acc = tl.reshape(acc, (BLOCK_N,)) + bias\n    sig = 1.0 / (1.0 + tl.exp(-acc))\n    result = acc * sig * scaling_factor\n    \n    tl.store(\n        output_ptr + pid_b * stride_output + oc_offs,\n        result,\n        mask=mask_oc\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n        self.bias = nn.Parameter(torch.Tensor(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        output = torch.empty((x.size(0), self.out_features), device=x.device, dtype=x.dtype)\n        grid = (x.size(0), triton.cdiv(self.out_features, 128))\n        \n        fused_linear_swish_scale[grid](\n            x, self.weight, self.bias, output,\n            self.in_features, self.out_features,\n            self.scaling_factor,\n            x.stride(0), self.weight.stride(0), 0, output.stride(0),\n            BLOCK_N=128, BLOCK_K=64\n        )\n        return output\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (0.0000), Performs well on score (10.0000), Performs well on stage (wrong_answer), Performs well on verify_payload ({'id': 'level2_59_Matmul_Swish_Scaling', 'result': {'compiled': True, 'correctness': False, 'metadata': {'hardware': 'NVIDIA L20Y', 'device': 'cuda:5', 'runtime_error': 'Traceback (most recent call last):\\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\\n    output_new = model_new(*inputs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/tmp/tmp_72t8jfk.py\", line 91, in forward\\n    fused_linear_swish_scale[grid](\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\\n    benchmark()\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\\n    raise ValueError(f\"Conflicting meta-parameters: {\\', \\'.join(conflicts)}.\"\\nValueError: Conflicting meta-parameters: BLOCK_K, BLOCK_N. Make sure that you don\\'t re-define auto-tuned symbols.\\n', 'runtime_error_name': 'builtins.ValueError', 'reference_timing_ms': 0.0746, 'speed_up': -1.0, 'custom_timing': -1.0}, 'runtime': -1.0, 'runtime_stats': {}}})\n\n\n### Program 3 (Score: 0.0000)\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (reference code), Performs well on passed (0.0000), Performs well on score (0.0000), Performs well on speed_up (1.0000), Performs well on runtime_ms (0.0548), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.0746, 'speed_up': 1.361, 'custom_timing': 0.0548})\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 10.0000, Type: High-Performer)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n# Triton kernel for fused linear + swish + scale\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32}, num_warps=8),\n        triton.Config({'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64}, num_warps=8),\n    ],\n    key=['out_features', 'in_features'],\n)\n@triton.jit\ndef _fused_linear_swish_kernel(\n    # Pointers to matrices\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    # Matrix dimensions\n    batch_size, in_features, out_features,\n    # Strides\n    stride_x0, stride_x1,\n    stride_w0, stride_w1,\n    stride_out0, stride_out1,\n    scaling_factor: tl.constexpr,\n    # Meta-parameters\n    BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n):\n    # Map program ids to the block of the output they should compute.\n    pid = tl.program_id(0)\n    num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n    batch_idx = pid // num_out_blocks\n    out_block_idx = pid % num_out_blocks\n\n    # This program will compute a block of the output for the given batch index and a block of the out_features.\n    offs_out = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n\n    # Create pointers for the weight block: [BLOCK_SIZE_N, BLOCK_SIZE_K]\n    w_ptrs = w_ptr + offs_out[:, None] * stride_w0 + offs_k[None, :] * stride_w1\n\n    # Accumulator for the output block\n    acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n    # Loop over the in_features dimension in blocks of BLOCK_SIZE_K\n    num_k_blocks = tl.cdiv(in_features, BLOCK_SIZE_K)\n    for k in range(0, num_k_blocks):\n        k_offs = k * BLOCK_SIZE_K\n        # Load a block of x for the current batch and the current K block.\n        x_ptrs = x_ptr + batch_idx * stride_x0 + (k_offs + offs_k) * stride_x1\n        mask_x = (k_offs + offs_k) < in_features\n        x_block = tl.load(x_ptrs, mask=mask_x, other=0.0)\n\n        # Load a block of weights for the current K block and the current out block.\n        mask_w = (offs_out[:, None] < out_features) & ((k_offs + offs_k)[None, :] < in_features)\n        w_block = tl.load(w_ptrs + k_offs * stride_w1, mask=mask_w, other=0.0)\n\n        # Compute the dot product for this block\n        acc += tl.sum(w_block * x_block[None, :], axis=1)\n\n    # Load bias for the current out block\n    b_ptrs = b_ptr + offs_out\n    mask_bias = offs_out < out_features\n    bias = tl.load(b_ptrs, mask=mask_bias, other=0.0)\n    acc += bias\n\n    # Apply Swish: acc * sigmoid(acc)\n    swish_output = acc * tl.sigmoid(acc)\n    # Scale\n    swish_output = swish_output * scaling_factor\n\n    # Write back the result\n    out_ptrs = output_ptr + batch_idx * stride_out0 + offs_out * stride_out1\n    tl.store(out_ptrs, swish_output, mask=mask_bias)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    # Check sizes\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    # Allocate output\n    output = torch.empty((batch, out_features), device=x.device, dtype=x.dtype)\n    # The grid is batch * ceil(out_features / BLOCK_SIZE_N)\n    grid = (batch * triton.cdiv(out_features, 128),)  # we use 128 as a base BLOCK_SIZE_N for grid, but the kernel will use the autotuned one\n    # Launch kernel\n    _fused_linear_swish_kernel[grid](\n        x, weight, bias, output,\n        batch, in_features, out_features,\n        x.stride(0), x.stride(1),\n        weight.stride(0), weight.stride(1),\n        output.stride(0), output.stride(1),\n        scaling_factor,\n        BLOCK_SIZE_N=128,  # This will be overridden by autotuner if a config is provided\n        BLOCK_SIZE_K=32,    # same\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    Uses a fused Triton kernel for the operation.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        # initialize the parameters\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, x):\n        # We use the fused kernel\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```\nUnique approach: Modification: Full rewrite, Excellent compiled (1.000), Alternative correctness approach\n\n\n\n# Current Program\n```python\n\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Simple model that performs a matrix multiplication, applies Swish activation, and scales the result.\n    \"\"\"\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.matmul = nn.Linear(in_features, out_features)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = self.matmul(x)\n        x = x * torch.sigmoid(x)  # Swish activation\n        x = x * self.scaling_factor\n        return x\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given a reference PyTorch model that uses nn.Linear followed by Swish and scaling.\n The goal is to write a Triton kernel that fuses the linear (matmul + bias), Swish activation, and scaling operations.\n\n The current program is the reference PyTorch code. We are to replace it with a Triton implementation.\n\n Steps:\n 1. We note that the reference code uses:\n        x = self.matmul(x)   # which is: x @ weight.T + bias\n        x = x * torch.sigmoid(x)   # Swish\n        x = x * self.scaling_factor\n\n 2. We must design a Triton kernel that does:\n        For each row in the input x (of shape [batch, in_features]), we compute the output row (of shape [batch, out_features])\n        by: output = ( (x_row @ weight.T + bias) * sigmoid(x_row @ weight.T + bias) ) * scaling_factor\n\n 3. We can break the kernel into:\n        - Loading a block of the input (for a given batch element) and the entire weight matrix (but in blocks) and bias.\n        - Computing the dot product for a block of output features (to allow parallelism over out_features).\n\n 4. We have two levels of parallelism:\n        a) Over batch (we can assign each batch to a program, but note that we also need to split over output features if the output feature dimension is large).\n        b) Over output features (we can split the output feature dimension into blocks).\n\n 5. We choose to map each program to a block of output features for a given batch.\n\n        pid = program_id(0)   # we can use a 1D grid for simplicity: total programs = batch * ceil(out_features / BLOCK_SIZE_N)\n\n        batch_idx = pid // num_blocks_out\n        out_block_idx = pid % num_blocks_out\n\n        where num_blocks_out = ceil(out_features / BLOCK_SIZE_N)\n\n 6. The kernel will:\n        - Load a block of the input for the current batch (if we are using shared memory, we might load the entire input row, but we are going to block over K as well).\n        - For each block in K (in_features dimension), load a block of the input and a block of the weight (for the current output block) and accumulate the dot product.\n        - Then add bias for the current output block.\n        - Apply Swish: output = output * sigmoid(output)\n        - Then scale by scaling_factor.\n        - Write the output block.\n\n 7. We must be cautious about the data types and masking for boundaries.\n\n 8. We will use autotuning for BLOCK_SIZE_N (output feature block) and BLOCK_SIZE_K (input feature block).\n\n 9. We note that the previous attempts (Program 1 and Program 2) had compilation errors due to conflicting meta-parameters in autotuner.\n    The error was: \"Conflicting meta-parameters: ...\". This happens when we define a `tl.constexpr` parameter that is also used in autotuning and then we try to pass it as a fixed value in the kernel launch.\n\n    How to fix:\n        - In the kernel launch, we should not pass the autotuned parameters (BLOCK_SIZE_N, BLOCK_SIZE_K) as fixed values. Instead, we let the autotuner override them.\n        - We can set the base values in the kernel launch to some default, but they will be overridden by the autotuner.\n\n    However, note that in the kernel, we have:\n        @triton.jit\n        def kernel(..., BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr)\n\n    And in the autotuner, we have:\n        triton.Config({'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32}, ...)\n\n    Then in the kernel launch, we must not set them by keyword? Actually, the autotuner will set them. We can pass them as arguments without setting them to a fixed value? But the autotuner will override.\n\n    However, the error says: we are re-defining auto-tuned symbols. This means that in the kernel launch we are passing the same parameters again by keyword? And that causes a conflict.\n\n    Solution: In the kernel launch, we do not pass the autotuned parameters by keyword. Instead, we pass them as part of the config. We can simply omit them from the kernel launch? But note: the kernel requires them.\n\n    Actually, the autotuner will generate a new kernel for each config. We don't need to pass them again.\n\n    How we launch:\n        kernel[grid](..., BLOCK_SIZE_N=128, BLOCK_SIZE_K=32)   # This is wrong because we are setting them again and they are already set by autotuner.\n\n    Instead, we should not set them at the launch if they are autotuned? But note: the autotuner will set them. However, we must provide a default for the kernel when no autotuning is done? The autotuner will override the default.\n\n    But the error is that we are defining them twice: once in the autotuner and then again in the launch.\n\n    We can fix by not passing them in the launch? But then the kernel will not have them. We must pass them because they are required.\n\n    Alternatively, we can pass them by position and not by keyword? But the autotuner will set the values, so we can use the default values we set in the function signature? Actually, no.\n\n    The correct way is to let the autotuner override the values. We can pass the default values in the launch, but if a config is chosen, then the autotuner will override. However, the autotuner expects that the parameters it is tuning are passed as keyword arguments? And if we pass them again by keyword, it causes conflict.\n\n    So we must remove the keyword arguments for the autotuned parameters in the kernel launch? But then how do we set them?\n\n    Actually, the autotuner will take care of passing the correct values for the autotuned parameters. We don't need to pass them in the launch. We can remove the BLOCK_SIZE_N and BLOCK_SIZE_K from the kernel launch.\n\n    However, the kernel requires them. So we must pass them. The solution is to pass them without the keywords? But the function signature in Triton expects them by keyword? Actually, no: Triton kernels are called with both positional and keyword arguments.\n\n    But note: the autotuner will override the values of the autotuned parameters. We can pass them as positional? But the kernel has many arguments.\n\n    Alternatively, we can use the following in the launch:\n\n        _fused_linear_swish_kernel[grid](\n            ...,\n            scaling_factor,\n            BLOCK_SIZE_N=config.BLOCK_SIZE_N,   # This is not what we want because we don't have config here\n        )\n\n    We cannot do that. The autotuner will set the parameters for us. Therefore, we should not set them in the launch if they are autotuned? But then the kernel would not have them.\n\n    Actually, the autotuner will replace the kernel with a version that has the parameters set. So we don't need to pass them again.\n\n    How to do it:\n\n        We remove the BLOCK_SIZE_N and BLOCK_SIZE_K from the kernel launch arguments.\n\n    But then the kernel expects them? They are part of the function signature. We must pass them.\n\n    The solution is to let the autotuner handle the parameters. We do not pass them in the launch. The autotuner will pre-bind them.\n\n    However, if we look at the Triton autotuner example, they do:\n\n        kernel[grid](input, output, ...)\n\n    without the autotuned parameters.\n\n    So we change:\n\n        In the kernel launch, we remove the two lines that set BLOCK_SIZE_N and BLOCK_SIZE_K.\n\n    But note: the kernel also has other constexpr arguments (like the scaling_factor) that are not autotuned? We still pass the scaling_factor.\n\n    So the corrected launch:\n\n        _fused_linear_swish_kernel[grid](\n            x, weight, bias, output,\n            batch, in_features, out_features,\n            x.stride(0), x.stride(1),\n            weight.stride(0), weight.stride(1),\n            output.stride(0), output.stride(1),\n            scaling_factor,\n        )\n\n    And the kernel function signature remains the same.\n\n    But note: the kernel function signature has the two parameters as constexpr. The autotuner will set them.\n\n    We must also remove the default values in the kernel launch? Because we are not passing them.\n\n    However, the autotuner will set them to the values in the config.\n\n 10. We design the kernel:\n\n        pid = tl.program_id(0)\n        batch_size = ...   # passed as argument\n        num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n        batch_idx = pid // num_out_blocks\n        out_block_idx = pid % num_out_blocks\n\n        offs_n = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        mask_n = offs_n < out_features\n\n        # We will accumulate the result for the current batch and current output block\n        acc = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n\n        # Pointers for the current batch of input\n        x_ptr = x_ptr + batch_idx * stride_x0   # stride_x0 is the batch stride for x\n\n        # Loop over K (in_features) in blocks of BLOCK_SIZE_K\n        for k in range(0, in_features, BLOCK_SIZE_K):\n            offs_k = k + tl.arange(0, BLOCK_SIZE_K)\n            mask_k = offs_k < in_features\n\n            # Load a block of the input (for current batch and current K block)\n            x = tl.load(x_ptr + offs_k * stride_x1, mask=mask_k, other=0.0)\n\n            # Load a block of weights: for the current output block and current K block\n            w = tl.load(w_ptr + offs_n[:, None] * stride_w0 + offs_k[None, :] * stride_w1,\n                        mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n\n            # Compute the dot product: (BLOCK_SIZE_N, BLOCK_SIZE_K) * (BLOCK_SIZE_K) -> (BLOCK_SIZE_N)\n            acc += tl.sum(w * x[None, :], axis=1)\n\n        # Load bias for the current output block\n        b = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)\n        acc += b\n\n        # Swish: acc * sigmoid(acc)\n        swish = acc * tl.sigmoid(acc)\n        swish = swish * scaling_factor\n\n        # Write output\n        out_ptrs = output_ptr + batch_idx * stride_out0 + offs_n * stride_out1\n        tl.store(out_ptrs, swish, mask=mask_n)\n\n 11. However, note that the above loop over K does a reduction by iterating and summing. This is not using tensor cores.\n\n     We can use tensor cores by using tl.dot. But note: the input x is a vector (1D) and the weight block is a matrix (2D). We can do:\n\n        w_block = w_ptr + offs_n[:, None] * stride_w0 + offs_k[None, :] * stride_w1   # [BLOCK_SIZE_N, BLOCK_SIZE_K]\n        x_block = x_ptr + batch_idx * stride_x0 + offs_k * stride_x1   # [BLOCK_SIZE_K]\n\n        Then we want: w_block @ x_block   -> [BLOCK_SIZE_N]\n\n        We can do:\n            x_block = tl.load(x_ptr + ...)   # shape (BLOCK_SIZE_K,)\n            w_block = tl.load(w_block_ptr, ...) # shape (BLOCK_SIZE_N, BLOCK_SIZE_K)\n\n        Then: acc += tl.dot(w_block, x_block)   # but note: tl.dot expects two matrices? Actually, we can do matrix-vector.\n\n        However, Triton's dot operation currently requires both operands to be 2D. We can reshape:\n\n            x_block = tl.reshape(x_block, (BLOCK_SIZE_K, 1))   # [BLOCK_SIZE_K, 1]\n            w_block = tl.reshape(w_block, (BLOCK_SIZE_N, BLOCK_SIZE_K)) # already\n\n            Then: product = tl.dot(w_block, x_block)   # [BLOCK_SIZE_N, 1]\n\n        Then we add the product to the accumulator (which is [BLOCK_SIZE_N]).\n\n        We can do: acc += tl.reshape(product, (BLOCK_SIZE_N,))\n\n     But note: using tl.dot requires that the data types are supported by tensor cores? We are using float32? Tensor cores are for FP16 and BF16.\n\n     We have two options:\n        Option 1: Use FP16 for the computation and then accumulate in FP32.\n        Option 2: Use FP32 and not use tensor cores.\n\n     Since the reference uses FP32, and we are not told the input dtype, we will assume the input can be FP32. But the Triton kernel can be written to support both.\n\n     However, note: the tensor cores require FP16/BF16. We can convert the loaded values to FP16 for the dot product and then convert back? But that might lose precision.\n\n     Alternatively, we can do without tensor cores for now, and rely on autotuning the block sizes.\n\n     Given the constraints (in_features=1024, out_features=512, batch_size=128) the problem is small enough that we can try without tensor cores.\n\n     But if we want to use tensor cores, we must use FP16 or BF16. The problem does not specify the dtype. The reference code uses the default (probably FP32).\n\n     We are going to stick to FP32 for correctness and simplicity.\n\n     However, the previous reference timing was 0.0746 ms and our Triton kernel without tensor cores might be slower? We need to optimize memory access.\n\n 12. We decide to use the non-tensor-core version for now (using a loop and sum) and then we can try to optimize with tensor cores in a later iteration if needed.\n\n 13. We must also note that the weight matrix is stored as [out_features, in_features]. So the weight block we load is [BLOCK_SIZE_N, BLOCK_SIZE_K].\n\n 14. We write the kernel accordingly.\n\n 15. We also note that the input x is of shape [batch, in_features]. We are loading one row of x at a time? Actually, we are loading a block of the row for the current K block.\n\n 16. We will try to write the kernel and then fix the autotuner conflict by removing the BLOCK_SIZE_N and BLOCK_SIZE_K from the kernel launch.\n\n 17. We also note that the grid is set as:\n\n        grid = (batch * triton.cdiv(out_features, BLOCK_SIZE_N),)\n\n    But we are not passing BLOCK_SIZE_N to the grid? We can use a fixed base block size for the grid? Because the autotuner will change the block size? But the grid must be set according to the block size we are using.\n\n    How to handle the grid? We can set the grid using the base block size (say 128) and then the autotuner will use the same grid for all configs? That would be incorrect.\n\n    We must set the grid dynamically for each config? The autotuner does not change the grid. We set the grid outside.\n\n    Therefore, we must compute the grid using the current block size? But we don't know the block size until the autotuner runs.\n\n    This is a problem. We have two options:\n\n        a) Use a fixed block size for the grid computation and hope that the autotuner will adjust the grid? But the autotuner does not adjust the grid.\n\n        b) Use the autotuner to also adjust the grid? But the grid is set at launch.\n\n    Actually, the grid is set at launch and we can compute it inside the function. We can do:\n\n        def fused_linear_swish(x, weight, bias, scaling_factor):\n            batch, in_features = x.shape\n            out_features, _ = weight.shape\n            output = torch.empty(...)\n\n            # We choose a base block size for the grid? But we want the grid to be based on the autotuned block size? We cannot because the autotuner hasn't run.\n\n            # Instead, we set the grid to the maximum possible? Or we use a fixed grid that is independent of the block size? That won't work.\n\n        This is a challenge.\n\n    How Triton's autotuner usually handles this? They set the grid to a function of the problem size and the block size, and the block size is set by the autotuner. But the grid must be set at launch.\n\n    We can do:\n\n        grid = (batch * triton.cdiv(out_features, BLOCK_SIZE_BASE), )\n\n    and then in the kernel, we have:\n\n        num_out_blocks = tl.cdiv(out_features, BLOCK_SIZE_N)\n\n        batch_idx = pid // num_out_blocks   # but note: we set the grid to batch * ceil(out_features / BLOCK_SIZE_BASE)\n\n        However, if the autotuner uses a different BLOCK_SIZE_N, then the number of programs we launch might be insufficient or excessive.\n\n    We must set the grid to the exact value: batch * ceil(out_features / BLOCK_SIZE_N). But we don't know BLOCK_SIZE_N until the autotuner runs.\n\n    The solution is to compute the grid inside the autotuner? But the grid is fixed at launch.\n\n    Alternatively, we can use a two-dimensional grid:\n\n        grid = (batch, triton.cdiv(out_features, BLOCK_SIZE_N))\n\n    and then in the kernel, we set:\n\n        pid_b = tl.program_id(0)\n        pid_oc = tl.program_id(1)\n\n        batch_idx = pid_b\n        out_block_idx = pid_oc\n\n    Then we don't need to compute the number of blocks in the kernel. And the grid is set as (batch, ceil(out_features / BLOCK_SIZE_N)).\n\n    This is more straightforward and avoids the issue.\n\n    We change the kernel to use two-dimensional grid:\n\n        pid_b = tl.program_id(0)\n        pid_oc = tl.program_id(1)\n\n        offs_n = pid_oc * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n        mask_n = offs_n < out_features\n\n        ... rest similar ...\n\n    And the grid becomes:\n\n        grid = (batch, triton.cdiv(out_features, BLOCK_SIZE_N))\n\n    But note: we are autotuning BLOCK_SIZE_N. How do we compute the grid? We cannot because BLOCK_SIZE_N is set by the autotuner.\n\n    We can set the grid to (batch, triton.cdiv(out_features, 128)) and then the autotuner will run with different block sizes? But the grid is fixed.\n\n    This is a problem because if the autotuner chooses a different block size, the grid might be too small or too large.\n\n    We must set the grid for each autotuning config? The autotuner does not let us change the grid per config.\n\n    How about: we set the grid to the maximum possible? Not efficient.\n\n    Alternatively, we can set the grid to (batch, triton.cdiv(out_features, min_BLOCK_SIZE_N)) and then mask out the extra programs? But that is messy.\n\n    The solution in Triton is to use a 1D grid and then compute the block index from the pid. And then set the grid to the maximum needed? But we don't know the block size.\n\n    Actually, we can compute the grid as:\n\n        grid = (batch * triton.cdiv(out_features, 1), )   # worst case: block size 1 -> maximum grid size\n\n    Then in the kernel:\n\n        num_blocks_out = tl.cdiv(out_features, BLOCK_SIZE_N)\n        batch_idx = pid // num_blocks_out\n        out_block_idx = pid % num_blocks_out\n\n        if batch_idx >= batch_size:\n            return\n\n    But that might be inefficient.\n\n    Another solution: we pass the grid as a function of the autotuned block size? But the autotuner doesn't let us change the grid per config.\n\n    We are stuck? How do other kernels do it? They often use a fixed block size for the grid computation and then the autotuner uses that same block size? But that defeats the purpose of autotuning the block size.\n\n    Actually, we can set the grid to (batch * triton.cdiv(out_features, config.kwargs['BLOCK_SIZE_N']), ) for each config? The autotuner allows that? Let's look at the autotuner API.\n\n    We see in the example: the grid is set outside the autotuner. So we cannot change the grid per config.\n\n    Therefore, we must use a fixed block size for the grid and then let the autotuner use that block size? But then the autotuning is not independent.\n\n    We decide to use the two-dimensional grid and set the grid to (batch, triton.cdiv(out_features, 128)) and then autotune with BLOCK_SIZE_N that divides 128? Not necessarily.\n\n    Alternatively, we can set the grid to (batch, 1000) and then mask? Not efficient.\n\n    We choose the 1D grid with worst-case size and then mask:\n\n        grid = (batch * triton.cdiv(out_features, 1), )\n\n        Then in the kernel:\n\n            pid = tl.program_id(0)\n            num_blocks_out = tl.cdiv(out_features, BLOCK_SIZE_N)\n            total_programs = batch * num_blocks_out\n            if pid >= total_programs:\n                return\n\n            batch_idx = pid // num_blocks_out\n            out_block_idx = pid % num_blocks_out\n\n    This is safe.\n\n 18. We write the kernel accordingly.\n\n 19. We also note: the kernel must be in FP32 to match the reference.\n\n 20. Let's write the code accordingly.\n\n 21. We will also remove the autotuned parameters from the kernel launch.\n\n 22. We note that the previous top programs had the autotuner conflict, so we avoid it.\n\n 23. We design:\n\n        @triton.autotune(...)\n        @triton.jit\n        def _fused_linear_swish_kernel(\n            x_ptr, w_ptr, b_ptr, output_ptr,\n            batch_size, in_features, out_features,\n            stride_x0, stride_x1, stride_w0, stride_w1, stride_out0, stride_out1,\n            scaling_factor: tl.constexpr,\n            BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n        ):\n            pid = tl.program_id(0)\n            num_blocks_out = tl.cdiv(out_features, BLOCK_SIZE_N)\n            total_programs = batch_size * num_blocks_out\n            if pid >= total_programs:\n                return\n\n            batch_idx = pid // num_blocks_out\n            out_block_idx = pid % num_blocks_out\n\n            offs_n = out_block_idx * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n            mask_n = offs_n < out_features\n\n            offs_k = tl.arange(0, BLOCK_SIZE_K)\n            # ... rest ...\n\n 24. We also note that we are not using tensor cores, so we can accumulate in FP32.\n\n 25. We must be cautious with the memory access patterns.\n\n 26. We will try to write the kernel and then test.\n\n 27. Since the current program is the reference, we are replacing the entire block.\n\n 28. We also note that the ModelNew class must be redefined to use our kernel.\n\n 29. We will write a helper function `fused_linear_swish` that calls the kernel.\n\n 30. We note that the input and weight might not be contiguous, so we use strides.\n\n 31. We write the code accordingly.\n\n 32. We hope to avoid the autotuner conflict by not passing BLOCK_SIZE_N and BLOCK_SIZE_K in the kernel launch.\n\n 33. We also set the grid to be large enough (batch * ceil(out_features/1)).\n\n 34. We note: ceil(out_features/1) = out_features, so the grid is (batch * out_features). This might be too large? But we have an early return.\n\n 35. We write the code.\n\n 36. We note that the kernel launch becomes:\n\n        grid = (batch * out_features, )   # worst-case: one output feature per block? But we are using blocks. We set grid to (batch * ceil(out_features/1)) = batch * out_features.\n\n        But we are using blocks of size BLOCK_SIZE_N, so the grid should be (batch * ceil(out_features / BLOCK_SIZE_N)). However, we are using the worst-case grid (batch * out_features) and then the kernel will return early for programs beyond the required.\n\n        This is safe but might launch more blocks than necessary.\n\n        Alternatively, we can compute the grid as (batch * triton.cdiv(out_features, 1)) which is the same.\n\n        But note: we are autotuning BLOCK_SIZE_N, so we cannot compute the grid exactly without knowing BLOCK_SIZE_N.\n\n        We choose to use:\n\n            grid = (batch * triton.cdiv(out_features, 1), )\n\n        which is (batch * out_features, ). This might be too large? For out_features=512 and batch=128, it is 65536, which is acceptable.\n\n 37. We write the code.\n\n 38. We also note that the kernel must be initialized with the proper strides.\n\n 39. We assume the input x is contiguous? We can make it contiguous in the helper function.\n\n 40. We will make sure the input is contiguous and the weight is contiguous? Or use the strides.\n\n 41. We use the provided strides.\n\n 42. We write the kernel.\n\n 43. We note that the bias is a 1D tensor, so its stride is 1.\n\n 44. We write the kernel accordingly.\n\n 45. We also note: the scaling_factor is a scalar, passed as a constant.\n\n 46. We are ready to write.\n\n 47. We will also initialize the model parameters as in the reference.\n\n 48. We hope for correctness and then we can optimize.\n\n 49. We write the code.\n\n 50. We remove the autotuned parameters from the kernel launch.\n\n Let's write the code:\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=4),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=4),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 128, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 256, 'BLOCK_K': 128}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 64}, num_warps=8),\n        triton.Config({'BLOCK_N': 64, 'BLOCK_K': 128}, num_warps=8),\n    ],\n    key=['in_features', 'out_features'],\n)\n@triton.jit\ndef fused_linear_swish_scale(\n    input_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_features,\n    out_features,\n    scaling_factor,\n    stride_input,\n    stride_weight,\n    stride_output,\n    BLOCK_N: tl.constexpr,\n    BLOCK_K: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_blocks_out = tl.cdiv(out_features, BLOCK_N)\n    total_programs = tl.cdiv(in_features, BLOCK_K) * num_blocks_out\n    if pid >= total_programs:\n        return\n\n    k_block = pid // num_blocks_out\n    out_block_idx = pid % num_blocks_out\n\n    batch_idx = tl.program_id(1)\n    offs_n = out_block_idx * BLOCK_N + tl.arange(0, BLOCK_N)\n    offs_k = k_block * BLOCK_K + tl.arange(0, BLOCK_K)\n    \n    mask_n = offs_n < out_features\n    mask_k = offs_k < in_features\n\n    input_ptrs = input_ptr + batch_idx * stride_input + offs_k\n    weight_ptrs = weight_ptr + offs_n[:, None] * stride_weight + offs_k[None, :]\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    \n    # Load input block (ensure within bounds)\n    input_block = tl.load(input_ptrs, mask=mask_k, other=0.0)\n    \n    # Load weight block (ensure within bounds)\n    weight_block = tl.load(weight_ptrs, mask=mask_n[:, None] & mask_k[None, :], other=0.0)\n    \n    # Compute partial dot product\n    acc += tl.sum(weight_block * input_block[None, :], axis=1)\n    \n    # Use atomic add to accumulate results\n    output_ptrs = output_ptr + batch_idx * stride_output + offs_n\n    tl.atomic_add(output_ptrs, acc, mask=mask_n)\n\n    # After all K blocks, apply bias, swish, and scaling\n    tl.debug_barrier()\n    \n    if k_block == 0:\n        # Load accumulated result\n        out_val = tl.load(output_ptrs, mask=mask_n, other=0.0)\n        # Load bias\n        bias = tl.load(bias_ptr + offs_n, mask=mask_n, other=0.0)\n        # Add bias\n        out_val += bias\n        # Apply Swish activation\n        swish = out_val * tl.sigmoid(out_val)\n        # Apply scaling\n        result = swish * scaling_factor\n        # Store final result\n        tl.store(output_ptrs, result, mask=mask_n)\n\ndef fused_linear_swish(x, weight, bias, scaling_factor):\n    batch, in_features = x.shape\n    out_features, _ = weight.shape\n    \n    # Allocate output tensor\n    output = torch.zeros((batch, out_features), device=x.device, dtype=x.dtype)\n    \n    # Compute grid dimensions\n    grid = (triton.cdiv(in_features, 64) * triton.cdiv(out_features, 128), batch)\n    \n    # Launch kernel\n    fused_linear_swish_scale[grid](\n        x, weight, bias, output,\n        in_features, out_features,\n        scaling_factor,\n        x.stride(0), weight.stride(0), output.stride(0),\n        BLOCK_N=128, BLOCK_K=64\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scaling_factor = scaling_factor\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        self.bias = nn.Parameter(torch.empty(out_features))\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        bound = 1 / math.sqrt(in_features) if in_features > 0 else 0\n        nn.init.uniform_(self.bias, -bound, bound)\n    \n    def forward(self, x):\n        x = x.contiguous()\n        return fused_linear_swish(x, self.weight, self.bias, self.scaling_factor)\n\nbatch_size = 128\nin_features = 1024\nout_features = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}