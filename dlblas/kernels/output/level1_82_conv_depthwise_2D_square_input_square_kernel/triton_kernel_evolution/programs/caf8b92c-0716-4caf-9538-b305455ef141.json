{"id": "caf8b92c-0716-4caf-9538-b305455ef141", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv2d_kernel(\n    x_ptr,\n    w_ptr,\n    b_ptr,\n    output_ptr,\n    stride_xb, stride_xc, stride_xh, stride_xw,\n    stride_wc, stride_wh, stride_ww,\n    stride_ob, stride_oc, stride_oh, stride_ow,\n    height, width, kernel_size, padding, stride,\n    out_height, out_width,\n    in_channels,\n    BLOCK_H: tl.constexpr, BLOCK_W: tl.constexpr\n):\n    pid_bc = tl.program_id(0)\n    pid_oh = tl.program_id(1)\n    pid_ow = tl.program_id(2)\n    \n    batch_idx = pid_bc // in_channels\n    channel_idx = pid_bc % in_channels\n    \n    oh_start = pid_oh * BLOCK_H\n    ow_start = pid_ow * BLOCK_W\n    \n    h_start = oh_start * stride - padding\n    w_start = ow_start * stride - padding\n    \n    output_tile = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n    \n    input_ptr = x_ptr + batch_idx * stride_xb + channel_idx * stride_xc\n    weight_ptr = w_ptr + channel_idx * stride_wc\n    \n    # Preload kernel weights\n    weights = tl.zeros((kernel_size, kernel_size), dtype=tl.float32)\n    for kh in range(kernel_size):\n        for kw in range(kernel_size):\n            weights = tl.store(weights, [kh, kw], \n                              tl.load(weight_ptr + kh * stride_wh + kw * stride_ww))\n    \n    # Compute output tile\n    for kh in range(kernel_size):\n        for kw in range(kernel_size):\n            h_idx = h_start + kh + tl.arange(0, BLOCK_H) * stride\n            w_idx = w_start + kw + tl.arange(0, BLOCK_W) * stride\n            \n            h_mask = (h_idx >= 0) & (h_idx < height)\n            w_mask = (w_idx >= 0) & (w_idx < width)\n            mask_2d = h_mask[:, None] & w_mask[None, :]\n            \n            offsets = h_idx[:, None] * stride_xh + w_idx[None, :] * stride_xw\n            input_vals = tl.load(input_ptr + offsets, mask=mask_2d, other=0.0)\n            \n            weight_val = tl.load(weights + [kh, kw])\n            output_tile += input_vals * weight_val\n    \n    # Add bias if present\n    if b_ptr is not None:\n        bias_val = tl.load(b_ptr + channel_idx)\n        output_tile += bias_val\n    \n    # Store output tile\n    oh_indices = oh_start + tl.arange(0, BLOCK_H)\n    ow_indices = ow_start + tl.arange(0, BLOCK_W)\n    \n    mask_oh = (oh_indices < out_height)\n    mask_ow = (ow_indices < out_width)\n    mask_out = mask_oh[:, None] & mask_ow[None, :]\n    \n    output_ptr_channel = output_ptr + batch_idx * stride_ob + channel_idx * stride_oc\n    output_offsets = oh_indices[:, None] * stride_oh + ow_indices[None, :] * stride_ow\n    tl.store(output_ptr_channel + output_offsets, output_tile, mask=mask_out)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, \n                               stride=stride, padding=padding, \n                               groups=in_channels, bias=bias)\n        self.stride = stride\n        self.padding = padding\n        self.kernel_size = kernel_size\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if not x.is_cuda:\n            return self.conv2d(x)\n            \n        weight = self.conv2d.weight\n        bias = self.conv2d.bias\n        \n        batch_size, in_channels, height, width = x.shape\n        \n        # Calculate output dimensions\n        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n        \n        # Create output tensor\n        output = torch.empty(batch_size, in_channels, out_height, out_width, \n                            device=x.device, dtype=x.dtype)\n        \n        # Define block sizes\n        BLOCK_H, BLOCK_W = 16, 16\n        \n        # Compute grid dimensions\n        grid = (batch_size * in_channels, \n                triton.cdiv(out_height, BLOCK_H), \n                triton.cdiv(out_width, BLOCK_W))\n        \n        # Launch kernel\n        depthwise_conv2d_kernel[grid](\n            x, weight, bias, output,\n            *x.stride(),\n            *weight.stride(),\n            *output.stride(),\n            height, width, self.kernel_size, self.padding, self.stride,\n            out_height, out_width,\n            in_channels,\n            BLOCK_H, BLOCK_W\n        )\n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nkernel_size = 3\nwidth = 256\nheight = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "38297091-6272-4caa-b6dd-818c59449b0d", "generation": 1, "timestamp": 1754645358.9094675, "iteration_found": 3, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_82_conv_depthwise_2D_square_input_square_kernel", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpilemk5ef.py\", line 115, in forward\n    depthwise_conv2d_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 561, in run\n    bound_args, specialization, options = binder(*args, **kwargs)\nTypeError: dynamic_func() takes 25 positional arguments but 26 were given\n", "runtime_error_name": "builtins.TypeError", "reference_timing_ms": 0.0289, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0434, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.666, "custom_timing": 0.0434}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}