{"id": "a1750843-e669-4983-8a6e-19ae3b0f3b6a", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_channels,\n    height,\n    width,\n    kernel_size,\n    stride,\n    padding,\n    h_out,\n    w_out,\n    has_bias: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n    x_stride_n, x_stride_c, x_stride_h, x_stride_w,\n    weight_stride_c, weight_stride_h, weight_stride_w,\n    output_stride_n, output_stride_c, output_stride_h, output_stride_w,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    pid2 = tl.program_id(2)\n    \n    n = pid0 // in_channels\n    c = pid0 % in_channels\n    i = pid1\n    j = pid2\n    \n    # Precompute base pointers\n    base_x = x_ptr + n * x_stride_n + c * x_stride_c\n    base_w = weight_ptr + c * weight_stride_c\n    base_out = output_ptr + n * output_stride_n + c * output_stride_c\n    \n    i0 = i * stride - padding\n    j0 = j * stride - padding\n    \n    acc = 0.0\n    # Use regular range instead of static_range\n    for di in range(kernel_size):\n        h_idx = i0 + di\n        for dj in range(kernel_size):\n            w_idx = j0 + dj\n            within_bounds = (h_idx >= 0) & (h_idx < height) & (w_idx >= 0) & (w_idx < width)\n            x_offset = h_idx * x_stride_h + w_idx * x_stride_w\n            w_offset = di * weight_stride_h + dj * weight_stride_w\n            \n            x_val = tl.load(base_x + x_offset, mask=within_bounds, other=0.0)\n            w_val = tl.load(base_w + w_offset)\n            acc += x_val * w_val\n    \n    if has_bias:\n        bias_val = tl.load(bias_ptr + c)\n        acc += bias_val\n        \n    # Store result\n    out_offset = i * output_stride_h + j * output_stride_w\n    tl.store(base_out + out_offset, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        self.stride = stride\n        self.padding = padding\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, height, width = x.shape\n        kernel_size = self.conv2d.kernel_size[0]\n        stride = self.stride\n        padding = self.padding\n        \n        h_out = (height + 2 * padding - kernel_size) // stride + 1\n        w_out = (width + 2 * padding - kernel_size) // stride + 1\n        \n        output = torch.empty((batch_size, in_channels, h_out, w_out), device=x.device, dtype=x.dtype)\n        weight = self.conv2d.weight.squeeze(1)\n        bias = self.conv2d.bias\n        has_bias = bias is not None\n        \n        grid = (batch_size * in_channels, h_out, w_out)\n        depthwise_conv_kernel[grid](\n            x, weight, bias, output,\n            in_channels, height, width, kernel_size, stride, padding, h_out, w_out,\n            has_bias,\n            BLOCK_SIZE=1,\n            x_stride_n=x.stride(0), x_stride_c=x.stride(1), x_stride_h=x.stride(2), x_stride_w=x.stride(3),\n            weight_stride_c=weight.stride(0), weight_stride_h=weight.stride(1), weight_stride_w=weight.stride(2),\n            output_stride_n=output.stride(0), output_stride_c=output.stride(1), output_stride_h=output.stride(2), output_stride_w=output.stride(3),\n        )\n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nkernel_size = 3\nwidth = 256\nheight = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "d9818459-5b03-4a47-9546-ed3406e6162c", "generation": 4, "timestamp": 1754649626.7757168, "iteration_found": 25, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.006, "runtime_ms": 4.8, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.006, "custom_timing": 4.8}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_82_conv_depthwise_2D_square_input_square_kernel", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "max_difference": ["19.793497", "20.044807", "20.611692", "20.935814", "24.650032"], "avg_difference": ["2.751173", "2.753757", "2.752247", "2.751206", "2.750983"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0289, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}