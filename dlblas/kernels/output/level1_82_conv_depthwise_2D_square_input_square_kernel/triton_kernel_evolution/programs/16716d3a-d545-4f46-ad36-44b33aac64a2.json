{"id": "16716d3a-d545-4f46-ad36-44b33aac64a2", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_channels,\n    height,\n    width,\n    kernel_size,\n    stride,\n    padding,\n    h_out,\n    w_out,\n    has_bias: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n    x_stride_n, x_stride_c, x_stride_h, x_stride_w,\n    weight_stride_c, weight_stride_h, weight_stride_w,\n    output_stride_n, output_stride_c, output_stride_h, output_stride_w,\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    pid2 = tl.program_id(2)\n    \n    n = pid0 // in_channels\n    c = pid0 % in_channels\n    i = pid1\n    j = pid2\n    \n    # Precompute base pointers\n    x_base = x_ptr + n * x_stride_n + c * x_stride_c\n    w_base = weight_ptr + c * weight_stride_c\n    output_base = output_ptr + n * output_stride_n + c * output_stride_c\n    \n    acc = 0.0\n    i0 = i * stride - padding\n    j0 = j * stride - padding\n    \n    # Vectorized accumulation\n    for di in range(kernel_size):\n        for dj in range(0, kernel_size, 4):\n            # Create vector of dj offsets\n            dj_vec = dj + tl.arange(0, 4)\n            valid_dj = dj_vec < kernel_size\n            \n            # Compute positions and mask\n            h_idx = i0 + di\n            w_idx = j0 + dj_vec\n            within_bounds = (h_idx >= 0) & (h_idx < height) & (w_idx >= 0) & (w_idx < width) & valid_dj\n            \n            # Vectorized load inputs\n            x_offset = h_idx * x_stride_h + w_idx * x_stride_w\n            x_vals = tl.load(x_base + x_offset, mask=within_bounds, other=0.0)\n            \n            # Vectorized load weights\n            w_offset = di * weight_stride_h + dj_vec * weight_stride_w\n            w_vals = tl.load(w_base + w_offset, mask=valid_dj, other=0.0)\n            \n            # Accumulate\n            acc += tl.sum(x_vals * w_vals)\n    \n    if has_bias:\n        bias_val = tl.load(bias_ptr + c)\n        acc += bias_val\n        \n    # Store result\n    out_offset = i * output_stride_h + j * output_stride_w\n    tl.store(output_base + out_offset, acc)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        self.stride = stride\n        self.padding = padding\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, height, width = x.shape\n        kernel_size = self.conv2d.kernel_size[0]\n        stride = self.stride\n        padding = self.padding\n        \n        h_out = (height + 2 * padding - kernel_size) // stride + 1\n        w_out = (width + 2 * padding - kernel_size) // stride + 1\n        \n        output = torch.empty((batch_size, in_channels, h_out, w_out), device=x.device, dtype=x.dtype)\n        weight = self.conv2d.weight.squeeze(1)\n        bias = self.conv2d.bias\n        has_bias = bias is not None\n        \n        grid = (batch_size * in_channels, h_out, w_out)\n        depthwise_conv_kernel[grid](\n            x, weight, bias, output,\n            in_channels, height, width, kernel_size, stride, padding, h_out, w_out,\n            has_bias,\n            BLOCK_SIZE=1,\n            x_stride_n=x.stride(0), x_stride_c=x.stride(1), x_stride_h=x.stride(2), x_stride_w=x.stride(3),\n            weight_stride_c=weight.stride(0), weight_stride_h=weight.stride(1), weight_stride_w=weight.stride(2),\n            output_stride_n=output.stride(0), output_stride_c=output.stride(1), output_stride_h=output.stride(2), output_stride_w=output.stride(3),\n        )\n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nkernel_size = 3\nwidth = 256\nheight = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "8fc1a208-cd97-4cd5-a763-da779d020abf", "generation": 2, "timestamp": 1754647037.4629202, "iteration_found": 10, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.01, "runtime_ms": 2.95, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.01, "custom_timing": 2.95}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.006, "runtime_ms": 4.51, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.006, "custom_timing": 4.51}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}