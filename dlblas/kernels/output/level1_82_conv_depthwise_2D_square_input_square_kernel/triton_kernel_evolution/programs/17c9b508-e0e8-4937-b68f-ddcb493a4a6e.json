{"id": "17c9b508-e0e8-4937-b68f-ddcb493a4a6e", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef depthwise_conv_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    in_channels,\n    height,\n    width,\n    kernel_size,\n    stride,\n    padding,\n    h_out,\n    w_out,\n    has_bias: tl.constexpr,\n    BLOCK_H: tl.constexpr,\n    BLOCK_W: tl.constexpr,\n    x_stride_n, x_stride_c, x_stride_h, x_stride_w,\n    weight_stride_c, weight_stride_h, weight_stride_w,\n    output_stride_n, output_stride_c, output_stride_h, output_stride_w,\n):\n    pid0 = tl.program_id(0)  # batch*channels\n    pid1 = tl.program_id(1)  # output height tile index\n    pid2 = tl.program_id(2)  # output width tile index\n\n    # Compute batch and channel indices\n    batch_idx = pid0 // in_channels\n    channel_idx = pid0 % in_channels\n\n    # Starting indices for the output tile\n    oh_start = pid1 * BLOCK_H\n    ow_start = pid2 * BLOCK_W\n\n    # Starting indices for the input window\n    h_start = oh_start * stride - padding\n    w_start = ow_start * stride - padding\n\n    # Initialize accumulator for the output tile\n    acc = tl.zeros((BLOCK_H, BLOCK_W), dtype=tl.float32)\n\n    # Precompute weight offset for this channel\n    weight_offset = channel_idx * weight_stride_c\n\n    # Loop over kernel\n    for kh in range(kernel_size):\n        for kw in range(kernel_size):\n            # Compute input coordinates for the entire tile\n            h_idx = h_start + kh + tl.arange(0, BLOCK_H) * stride\n            w_idx = w_start + kw + tl.arange(0, BLOCK_W) * stride\n\n            # Boundary checks for input\n            mask_h = (h_idx >= 0) & (h_idx < height)\n            mask_w = (w_idx >= 0) & (w_idx < width)\n            mask = mask_h[:, None] & mask_w[None, :]\n\n            # Compute input offsets\n            x_offsets = (\n                batch_idx * x_stride_n + \n                channel_idx * x_stride_c + \n                h_idx[:, None] * x_stride_h + \n                w_idx[None, :] * x_stride_w\n            )\n\n            # Load input values with masking\n            x_val = tl.load(\n                x_ptr + x_offsets, \n                mask=mask,\n                other=0.0\n            )\n\n            # Load weight value\n            w_val = tl.load(\n                weight_ptr + weight_offset + \n                kh * weight_stride_h + \n                kw * weight_stride_w\n            )\n\n            # Accumulate\n            acc += x_val * w_val\n\n    # Add bias if present\n    if has_bias:\n        bias_val = tl.load(bias_ptr + channel_idx)\n        acc += bias_val\n\n    # Compute output coordinates for the tile\n    oh_indices = oh_start + tl.arange(0, BLOCK_H)\n    ow_indices = ow_start + tl.arange(0, BLOCK_W)\n\n    # Boundary checks for output\n    mask_oh = (oh_indices < h_out)\n    mask_ow = (ow_indices < w_out)\n    mask_out = mask_oh[:, None] & mask_ow[None, :]\n\n    # Compute output offsets\n    output_offsets = (\n        batch_idx * output_stride_n + \n        channel_idx * output_stride_c + \n        oh_indices[:, None] * output_stride_h + \n        ow_indices[None, :] * output_stride_w\n    )\n\n    # Store results with boundary masking\n    tl.store(\n        output_ptr + output_offsets, \n        acc, \n        mask=mask_out\n    )\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv2d = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n        self.stride = stride\n        self.padding = padding\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        batch_size, in_channels, height, width = x.shape\n        kernel_size = self.conv2d.kernel_size[0]\n        stride = self.stride\n        padding = self.padding\n        \n        h_out = (height + 2 * padding - kernel_size) // stride + 1\n        w_out = (width + 2 * padding - kernel_size) // stride + 1\n        \n        output = torch.empty((batch_size, in_channels, h_out, w_out), device=x.device, dtype=x.dtype)\n        weight = self.conv2d.weight.squeeze(1)\n        bias = self.conv2d.bias\n        has_bias = bias is not None\n        \n        # Define tile sizes\n        BLOCK_H, BLOCK_W = 16, 16\n        \n        # Compute grid dimensions\n        grid = (\n            batch_size * in_channels,\n            triton.cdiv(h_out, BLOCK_H),\n            triton.cdiv(w_out, BLOCK_W)\n        )\n        \n        # Launch kernel with tile-based computation\n        depthwise_conv_kernel[grid](\n            x, weight, bias, output,\n            in_channels, height, width, kernel_size, stride, padding, h_out, w_out,\n            has_bias,\n            BLOCK_H, BLOCK_W,\n            x_stride_n=x.stride(0), x_stride_c=x.stride(1), x_stride_h=x.stride(2), x_stride_w=x.stride(3),\n            weight_stride_c=weight.stride(0), weight_stride_h=weight.stride(1), weight_stride_w=weight.stride(2),\n            output_stride_n=output.stride(0), output_stride_c=output.stride(1), output_stride_h=output.stride(2), output_stride_w=output.stride(3),\n        )\n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 3\nkernel_size = 3\nwidth = 256\nheight = 256\nstride = 1\npadding = 0\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height, width)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, kernel_size, stride, padding]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "65a3ba6c-c4e9-48fa-b9e0-792ba681a205", "generation": 4, "timestamp": 1754650005.4114363, "iteration_found": 28, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.334, "runtime_ms": 0.0865, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.334, "custom_timing": 0.0865}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.006, "runtime_ms": 4.77, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0289, "speed_up": 0.006, "custom_timing": 4.77}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}