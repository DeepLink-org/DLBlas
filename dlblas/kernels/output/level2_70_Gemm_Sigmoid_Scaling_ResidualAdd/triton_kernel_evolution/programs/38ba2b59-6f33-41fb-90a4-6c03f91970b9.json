{"id": "38ba2b59-6f33-41fb-90a4-6c03f91970b9", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({\"BLOCK_SIZE_H\": 256, \"BLOCK_SIZE_K\": 64}, num_warps=4, num_stages=3),\n        triton.Config({\"BLOCK_SIZE_H\": 128, \"BLOCK_SIZE_K\": 128}, num_warps=4, num_stages=3),\n        triton.Config({\"BLOCK_SIZE_H\": 512, \"BLOCK_SIZE_K\": 32}, num_warps=8, num_stages=3),\n        triton.Config({\"BLOCK_SIZE_H\": 64, \"BLOCK_SIZE_K\": 256}, num_warps=2, num_stages=3),\n    ],\n    key=[\"hidden_size\", \"input_size\"],\n)\n@triton.jit\ndef _forward_kernel(\n    x_ptr,\n    weight_ptr,\n    bias_ptr,\n    output_ptr,\n    input_size,\n    hidden_size,\n    scaling_factor,\n    BLOCK_SIZE_H: tl.constexpr,\n    BLOCK_SIZE_K: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_hidden = tl.program_id(1)\n    \n    hidden_offsets = pid_hidden * BLOCK_SIZE_H + tl.arange(0, BLOCK_SIZE_H)\n    hidden_mask = hidden_offsets < hidden_size\n    \n    acc = tl.zeros((BLOCK_SIZE_H,), dtype=tl.float32)\n    \n    for k in range(0, input_size, BLOCK_SIZE_K):\n        k_offsets = k + tl.arange(0, BLOCK_SIZE_K)\n        k_mask = k_offsets < input_size\n        \n        x_block = tl.load(x_ptr + pid_batch * input_size + k_offsets, mask=k_mask, other=0.0)\n        \n        weight_block_ptr = weight_ptr + hidden_offsets[:, None] * input_size + k_offsets[None, :]\n        weight_block = tl.load(weight_block_ptr, mask=hidden_mask[:, None] & k_mask[None, :], other=0.0)\n        \n        acc += tl.sum(weight_block * x_block, axis=1)\n    \n    bias_block = tl.load(bias_ptr + hidden_offsets, mask=hidden_mask, other=0.0)\n    acc += bias_block\n    \n    sig = tl.sigmoid(acc)\n    acc = acc + scaling_factor * sig\n    \n    output_block_ptr = output_ptr + pid_batch * hidden_size + hidden_offsets\n    tl.store(output_block_ptr, acc, mask=hidden_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, scaling_factor):\n        super(ModelNew, self).__init__()\n        self.gemm = nn.Linear(input_size, hidden_size)\n        self.scaling_factor = scaling_factor\n\n    def forward(self, x):\n        x = x.contiguous()\n        batch_size, input_size_ = x.shape\n        hidden_size = self.gemm.out_features\n        \n        output = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)\n        \n        weight = self.gemm.weight.contiguous()\n        bias = self.gemm.bias\n        if bias is not None:\n            bias = bias.contiguous()\n        else:\n            bias = torch.zeros(hidden_size, device=x.device, dtype=x.dtype)\n        \n        grid = (batch_size, triton.cdiv(hidden_size, 256))\n        _forward_kernel[grid](\n            x, weight, bias, output,\n            input_size_, hidden_size, self.scaling_factor\n        )\n        return output\n\nbatch_size = 128\ninput_size = 1024\nhidden_size = 512\nscaling_factor = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, scaling_factor]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "2ea3fa0d-ab87-4509-9611-21f24c7f0ed1", "generation": 1, "timestamp": 1754576651.5164642, "iteration_found": 2, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_70_Gemm_Sigmoid_Scaling_ResidualAdd", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "max_difference": ["2.454946", "1.797221", "2.435942", "1.826802"], "avg_difference": ["0.230264", "0.500491", "0.231116", "0.500116"], "correctness_issue": "Output mismatch", "correctness_trials": "(1 / 5)", "reference_timing_ms": 0.0561, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0584, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0561, "speed_up": 0.961, "custom_timing": 0.0584}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}