{"id": "17d98853-1cd1-49aa-a810-869875d330ac", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef gru_kernel(\n    x_ptr,\n    h_prev_ptr,\n    w_ih_ptr,\n    w_hh_ptr,\n    b_ih_ptr,\n    b_hh_ptr,\n    output_ptr,\n    input_size: tl.constexpr,\n    hidden_size: tl.constexpr,\n    batch_size: tl.constexpr,\n    stride_xs,\n    stride_xb,\n    stride_hs,\n    stride_hb,\n    stride_wi,\n    stride_wh,\n    stride_os,\n    stride_ob,\n    stride_od,\n    BLOCK_M: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid = tl.num_programs(0)\n    \n    # Parallelize across sequence and batch dimensions\n    seq_idx = pid // batch_size\n    batch_idx = pid % batch_size\n    \n    # Offsets for current sequence and batch\n    x_offsets = seq_idx * stride_xs + batch_idx * stride_xb + tl.arange(0, input_size)\n    h_offsets = batch_idx * stride_hb + tl.arange(0, hidden_size)\n    \n    # Load input and previous hidden state\n    x = tl.load(x_ptr + x_offsets, mask=tl.arange(0, input_size) < input_size, other=0.0)\n    h_prev = tl.load(h_prev_ptr + h_offsets, mask=tl.arange(0, hidden_size) < hidden_size, other=0.0)\n    \n    # Initialize gates\n    reset_gate = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    update_gate = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    new_gate = tl.zeros((BLOCK_N,), dtype=tl.float32)\n    \n    # Compute input contributions with vectorization\n    for block_idx in range(0, input_size, BLOCK_M):\n        offsets = block_idx + tl.arange(0, BLOCK_M)\n        mask = offsets < input_size\n        x_val = tl.load(x_ptr + x_offsets + block_idx, mask=mask, other=0.0)\n        \n        # Reset gate\n        w_reset = tl.load(w_ih_ptr + offsets, mask=mask, other=0.0)\n        reset_gate += tl.sum(x_val * w_reset, axis=0)\n        \n        # Update gate\n        w_update = tl.load(w_ih_ptr + hidden_size + offsets, mask=mask, other=0.0)\n        update_gate += tl.sum(x_val * w_update, axis=0)\n        \n        # New gate\n        w_new = tl.load(w_ih_ptr + 2*hidden_size + offsets, mask=mask, other=0.0)\n        new_gate += tl.sum(x_val * w_new, axis=0)\n    \n    # Add hidden state contributions\n    for block_idx in range(0, hidden_size, BLOCK_M):\n        offsets = block_idx + tl.arange(0, BLOCK_M)\n        mask = offsets < hidden_size\n        h_val = tl.load(h_prev_ptr + h_offsets + block_idx, mask=mask, other=0.0)\n        \n        # Reset gate\n        w_reset = tl.load(w_hh_ptr + offsets, mask=mask, other=0.0)\n        reset_gate += tl.sum(h_val * w_reset, axis=0)\n        \n        # Update gate\n        w_update = tl.load(w_hh_ptr + hidden_size + offsets, mask=mask, other=0.0)\n        update_gate += tl.sum(h_val * w_update, axis=0)\n        \n        # New gate\n        w_new = tl.load(w_hh_ptr + 2*hidden_size + offsets, mask=mask, other=0.0)\n        new_gate += tl.sum((reset_gate * h_val) * w_new, axis=0)\n    \n    # Add biases\n    if b_ih_ptr is not None:\n        reset_gate += tl.load(b_ih_ptr + tl.arange(0, BLOCK_N) % hidden_size)\n        update_gate += tl.load(b_ih_ptr + hidden_size + tl.arange(0, BLOCK_N) % hidden_size)\n        new_gate += tl.load(b_ih_ptr + 2*hidden_size + tl.arange(0, BLOCK_N) % hidden_size)\n    \n    if b_hh_ptr is not None:\n        reset_gate += tl.load(b_hh_ptr + tl.arange(0, BLOCK_N) % hidden_size)\n        update_gate += tl.load(b_hh_ptr + hidden_size + tl.arange(0, BLOCK_N) % hidden_size)\n        new_gate += tl.load(b_hh_ptr + 2*hidden_size + tl.arange(0, BLOCK_N) % hidden_size)\n    \n    # Apply activation functions\n    reset_gate = tl.sigmoid(reset_gate)\n    update_gate = tl.sigmoid(update_gate)\n    new_gate = tl.tanh(new_gate)  # Fixed to use Triton's built-in tanh\n    \n    # Compute new hidden state\n    h_new = (1 - update_gate) * new_gate + update_gate * h_prev\n    \n    # Store results\n    output_offsets = seq_idx * stride_os + batch_idx * stride_ob + tl.arange(0, hidden_size)\n    tl.store(output_ptr + output_offsets, h_new, mask=tl.arange(0, hidden_size) < hidden_size)\n\nclass ModelNew(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers=3, bias=True, batch_first=False):\n        super(ModelNew, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.bias = bias\n        self.batch_first = batch_first\n        \n        # Create GRU weights for each layer\n        self.weight_ih = nn.ParameterList()\n        self.weight_hh = nn.ParameterList()\n        self.bias_ih = nn.ParameterList()\n        self.bias_hh = nn.ParameterList()\n        \n        for i in range(num_layers):\n            # Forward layer weights\n            self.weight_ih.append(nn.Parameter(torch.empty(3 * hidden_size, input_size if i == 0 else 2 * hidden_size)))\n            self.weight_hh.append(nn.Parameter(torch.empty(3 * hidden_size, hidden_size)))\n            # Backward layer weights\n            self.weight_ih.append(nn.Parameter(torch.empty(3 * hidden_size, input_size if i == 0 else 2 * hidden_size)))\n            self.weight_hh.append(nn.Parameter(torch.empty(3 * hidden_size, hidden_size)))\n            \n            if bias:\n                self.bias_ih.append(nn.Parameter(torch.empty(3 * hidden_size)))\n                self.bias_ih.append(nn.Parameter(torch.empty(3 * hidden_size)))\n                self.bias_hh.append(nn.Parameter(torch.empty(3 * hidden_size)))\n                self.bias_hh.append(nn.Parameter(torch.empty(3 * hidden_size)))\n        \n        self.reset_parameters()\n        # Initialize hidden state with proper shape\n        self.register_buffer('h0', torch.zeros(num_layers * 2, 1, hidden_size))\n    \n    def reset_parameters(self):\n        for param in self.weight_ih:\n            nn.init.xavier_uniform_(param)\n        for param in self.weight_hh:\n            nn.init.orthogonal_(param)\n        if self.bias:\n            for param in self.bias_ih:\n                nn.init.zeros_(param)\n            for param in self.bias_hh:\n                nn.init.zeros_(param)\n    \n    def forward(self, x):\n        if self.batch_first:\n            x = x.transpose(0, 1)\n            \n        seq_len, batch_size, _ = x.shape\n        device = x.device\n        \n        # Initialize hidden states for all layers\n        h0 = self.h0.expand(-1, batch_size, -1).to(device)\n        layer_input = x\n        output = torch.zeros(seq_len, batch_size, self.hidden_size * 2, device=device, dtype=x.dtype)\n        \n        # Process each layer\n        for layer_idx in range(self.num_layers):\n            h_forward = h0[layer_idx * 2].clone()\n            h_backward = h0[layer_idx * 2 + 1].clone()\n            layer_output = torch.zeros(seq_len, batch_size, self.hidden_size * 2, device=device, dtype=x.dtype)\n            \n            # Process forward direction\n            for t in range(seq_len):\n                grid = (batch_size,)\n                gru_kernel[grid](\n                    layer_input[t], h_forward, \n                    self.weight_ih[layer_idx * 2], \n                    self.weight_hh[layer_idx * 2],\n                    self.bias_ih[layer_idx * 2] if self.bias else None,\n                    self.bias_hh[layer_idx * 2] if self.bias else None,\n                    layer_output[t, :, :self.hidden_size],\n                    self.input_size if layer_idx == 0 else self.hidden_size * 2,\n                    self.hidden_size,\n                    batch_size,\n                    layer_input.stride(0), layer_input.stride(1),\n                    h_forward.stride(0), h_forward.stride(1),\n                    self.weight_ih[layer_idx * 2].stride(0), \n                    self.weight_hh[layer_idx * 2].stride(0),\n                    layer_output.stride(0), layer_output.stride(1), layer_output.stride(2),\n                    BLOCK_M=64, BLOCK_N=128\n                )\n                h_forward = layer_output[t, :, :self.hidden_size].clone()\n            \n            # Process backward direction\n            for t in range(seq_len-1, -1, -1):\n                grid = (batch_size,)\n                gru_kernel[grid](\n                    layer_input[t], h_backward, \n                    self.weight_ih[layer_idx * 2 + 1], \n                    self.weight_hh[layer_idx * 2 + 1],\n                    self.bias_ih[layer_idx * 2 + 1] if self.bias else None,\n                    self.bias_hh[layer_idx * 2 + 1] if self.bias else None,\n                    layer_output[t, :, self.hidden_size:],\n                    self.input_size if layer_idx == 0 else self.hidden_size * 2,\n                    self.hidden_size,\n                    batch_size,\n                    layer_input.stride(0), layer_input.stride(1),\n                    h_backward.stride(0), h_backward.stride(1),\n                    self.weight_ih[layer_idx * 2 + 1].stride(0), \n                    self.weight_hh[layer_idx * 2 + 1].stride(0),\n                    layer_output.stride(0), layer_output.stride(1), layer_output.stride(2),\n                    BLOCK_M=64, BLOCK_N=128\n                )\n                h_backward = layer_output[t, :, self.hidden_size:].clone()\n            \n            # Prepare input for next layer\n            layer_input = layer_output\n        \n        output = layer_input\n        \n        if self.batch_first:\n            output = output.transpose(0, 1)\n            \n        return output\n\n# Test code\nbatch_size = 10\nseq_len = 512\ninput_size = 128\nhidden_size = 256\nnum_layers = 6\n\ndef get_inputs():\n    return [torch.randn(seq_len, batch_size, input_size)]\n\ndef get_init_inputs():\n    return [input_size, hidden_size, num_layers]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "21515c55-16fe-4ebd-97d3-c42bd01a3aa2", "generation": 4, "timestamp": 1754596284.8860176, "iteration_found": 22, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_41_GRUBirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmp120zt51r.py\", line 175, in forward\n    gru_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language' has no attribute 'tanh'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 68.4, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level3_41_GRUBirectional", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpxfsip517.py\", line 141, in forward\n    gru_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 594, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 281, in compile\n    key = f\"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/compiler/compiler.py\", line 78, in hash\n    key = f\"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}\"\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 696, in cache_key\n    dependencies_finder.visit(self.parse())\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 163, in visit_FunctionDef\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 426, in generic_visit\n    self.visit(item)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 217, in visit_Assign\n    self.generic_visit(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 428, in generic_visit\n    self.visit(value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 151, in visit_Attribute\n    lhs = self.visit(node.value)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/ast.py\", line 418, in visit\n    return visitor(node)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 156, in visit_Attribute\n    ret = getattr(lhs, node.attr)\nAttributeError: module 'triton.language' has no attribute 'libdevice'\n", "runtime_error_name": "builtins.AttributeError", "reference_timing_ms": 68.4, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}