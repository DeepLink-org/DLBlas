{"id": "b2d2b5f9-640f-4c14-ac8b-4bef61717c61", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _argmin_kernel(\n    x_ptr,\n    output_ptr,\n    stride_x,\n    stride_out,\n    dim_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n    DIM: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    offsets = pid * stride_x + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < dim_size\n\n    # Load block of values\n    values = tl.load(x_ptr + offsets, mask=mask, other=float('inf'))\n    # Find local min index\n    local_min_idx = tl.argmin(values, axis=0)\n    # Convert to global index\n    global_min_idx = local_min_idx + pid * BLOCK_SIZE\n    tl.store(output_ptr + pid * stride_out, global_min_idx)\n\nclass ModelNew(nn.Module):\n    def __init__(self, dim: int):\n        super(ModelNew, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Original shape and dimension handling\n        orig_shape = x.shape\n        dim_size = orig_shape[self.dim]\n        \n        # Permute reduction dimension to last\n        x = x.transpose(self.dim, -1).contiguous()\n        x = x.view(-1, dim_size)\n        \n        # Output tensor for indices\n        output = torch.empty(x.shape[0], dtype=torch.int64, device=x.device)\n        \n        # Kernel configuration\n        BLOCK_SIZE = min(triton.next_power_of_2(dim_size), 1024)\n        grid = (x.shape[0],)\n        \n        # Launch kernel\n        _argmin_kernel[grid](\n            x_ptr=x,\n            output_ptr=output,\n            stride_x=x.stride(0),\n            stride_out=0,\n            dim_size=dim_size,\n            BLOCK_SIZE=BLOCK_SIZE,\n            DIM=self.dim,\n        )\n        \n        # Reshape to original dimensions (without reduced dim)\n        output_shape = list(orig_shape)\n        del output_shape[self.dim]\n        return output.view(output_shape)\n\nbatch_size = 16\ndim1 = 256\ndim2 = 256\ndim = 1\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [dim]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b351c499-a8ac-42fa-b6e0-f5ba3c2dcf8a", "generation": 1, "timestamp": 1754639162.0517159, "iteration_found": 1, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_52_Argmin_over_a_dimension", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 742, in run_and_check_correctness\n    avg_diff = torch.mean(torch.abs(output - output_new)).item()\nRuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n", "runtime_error_name": "builtins.RuntimeError", "reference_timing_ms": 0.0201, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0241, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0201, "speed_up": 0.834, "custom_timing": 0.0241}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}