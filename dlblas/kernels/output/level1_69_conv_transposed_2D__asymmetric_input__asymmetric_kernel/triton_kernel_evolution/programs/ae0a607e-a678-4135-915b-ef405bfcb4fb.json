{"id": "ae0a607e-a678-4135-915b-ef405bfcb4fb", "code": "\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Performs a transposed 2D convolution operation with asymmetric input and kernel size.\n\n    Args:\n        in_channels (int): Number of channels in the input tensor.\n        out_channels (int): Number of channels produced by the convolution.\n        kernel_size (tuple): Tuple of integers representing the kernel size (height, width).\n        stride (tuple, optional): Tuple of integers representing the stride of the convolution. Defaults to (1, 1).\n        padding (tuple, optional): Tuple of integers representing the padding applied to the input. Defaults to (0, 0).\n        output_padding (tuple, optional): Tuple of integers representing the additional size added to one side of the output shape. Defaults to (0, 0).\n        dilation (tuple, optional): Tuple of integers representing the spacing between kernel elements. Defaults to (1, 1).\n        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.\n        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), output_padding: tuple = (0, 0), dilation: tuple = (1, 1), groups: int = 1, bias: bool = False):\n        super(ModelNew, self).__init__()\n        self.conv_transpose2d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, dilation=dilation, groups=groups, bias=bias)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Performs the transposed 2D convolution.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, height_in, width_in).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, height_out, width_out).\n        \"\"\"\n        return self.conv_transpose2d(x)\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight_in = 16\nwidth_in = 32\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization\n# =================== EVOLVE-BLOCK-END ===================\n", "language": "python", "parent_id": null, "generation": 0, "timestamp": 1754645041.3385203, "iteration_found": 0, "metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0479, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0435, "speed_up": 0.908, "custom_timing": 0.0479}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 0}, "artifacts_json": null, "artifact_dir": null}