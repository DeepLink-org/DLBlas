{"id": "85867d9a-fad8-4ed0-8696-d83bf469923f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\nimport math\n\n@triton.jit\ndef _conv_transpose2d_kernel(\n    input_ptr, weight_ptr, bias_ptr, output_ptr,\n    batch_size, in_channels, out_channels, \n    input_height, input_width, output_height, output_width,\n    kernel_h, kernel_w,\n    stride_h, stride_w,\n    padding_h, padding_w,\n    output_padding_h, output_padding_w,\n    dilation_h, dilation_w,\n    groups,\n    input_batch_stride, input_channel_stride, input_height_stride, input_width_stride,\n    weight_in_channel_stride, weight_out_channel_stride, weight_height_stride, weight_width_stride,\n    output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n    BLOCK_SIZE_IC: tl.constexpr,\n    BLOCK_SIZE_OC: tl.constexpr,\n    BLOCK_SIZE_H: tl.constexpr,\n    BLOCK_SIZE_W: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    num_pid_h = tl.cdiv(output_height, BLOCK_SIZE_H)\n    num_pid_w = tl.cdiv(output_width, BLOCK_SIZE_W)\n    \n    pid_batch = pid // (num_pid_h * num_pid_w * out_channels // BLOCK_SIZE_OC)\n    pid_oc = (pid % (num_pid_h * num_pid_w * out_channels // BLOCK_SIZE_OC)) // (num_pid_h * num_pid_w)\n    pid_h = (pid % (num_pid_h * num_pid_w)) // num_pid_w\n    pid_w = pid % num_pid_w\n\n    # Initialize output block offsets\n    output_h_start = pid_h * BLOCK_SIZE_H\n    output_w_start = pid_w * BLOCK_SIZE_W\n    oc_start = pid_oc * BLOCK_SIZE_OC\n    \n    # Offsets for the current block\n    output_h_offsets = output_h_start + tl.arange(0, BLOCK_SIZE_H)\n    output_w_offsets = output_w_start + tl.arange(0, BLOCK_SIZE_W)\n    oc_offsets = oc_start + tl.arange(0, BLOCK_SIZE_OC)\n    \n    # Masks for boundary checks\n    h_mask = output_h_offsets < output_height\n    w_mask = output_w_offsets < output_width\n    oc_mask = oc_offsets < out_channels\n    \n    # Initialize accumulator\n    acc = tl.zeros((BLOCK_SIZE_OC, BLOCK_SIZE_H, BLOCK_SIZE_W), dtype=tl.float32)\n    \n    # Loop over input channels in blocks\n    for ic_start in range(0, in_channels, BLOCK_SIZE_IC):\n        ic_offsets = ic_start + tl.arange(0, BLOCK_SIZE_IC)\n        ic_mask = ic_offsets < in_channels\n        \n        # Loop over kernel positions\n        for kh in range(kernel_h):\n            for kw in range(kernel_w):\n                # Compute input positions\n                input_h_offsets = (output_h_offsets + padding_h - kh * dilation_h) // stride_h\n                input_w_offsets = (output_w_offsets + padding_w - kw * dilation_w) // stride_w\n                \n                # Create masks for valid positions\n                valid_h = (output_h_offsets + padding_h - kh * dilation_h) % stride_h == 0\n                valid_w = (output_w_offsets + padding_w - kw * dilation_w) % stride_w == 0\n                input_valid = valid_h[:, None] & valid_w[None, :] \n                input_h_mask = (input_h_offsets >= 0) & (input_h_offsets < input_height)\n                input_w_mask = (input_w_offsets >= 0) & (input_w_offsets < input_width)\n                input_mask = input_valid & input_h_mask[:, None] & input_w_mask[None, :]\n                \n                # Load input block\n                input_ptrs = (\n                    input_ptr + \n                    pid_batch * input_batch_stride + \n                    ic_offsets[:, None, None] * input_channel_stride + \n                    input_h_offsets[None, :, None] * input_height_stride + \n                    input_w_offsets[None, None, :] * input_width_stride\n                )\n                input_block = tl.load(\n                    input_ptrs, \n                    mask=ic_mask[:, None, None] & input_mask[None, :, :], \n                    other=0.0\n                )\n                \n                # Load weight block\n                weight_ptrs = (\n                    weight_ptr + \n                    ic_offsets[:, None, None, None] * weight_in_channel_stride + \n                    oc_offsets[None, :, None, None] * weight_out_channel_stride + \n                    kh * weight_height_stride + \n                    kw * weight_width_stride\n                )\n                weight_block = tl.load(\n                    weight_ptrs, \n                    mask=ic_mask[:, None, None, None] & oc_mask[None, :, None, None], \n                    other=0.0\n                )\n                \n                # Reshape weight for broadcasting\n                weight_block = tl.reshape(weight_block, (BLOCK_SIZE_IC, BLOCK_SIZE_OC, 1, 1))\n                \n                # Accumulate\n                acc += tl.sum(input_block[:, None, :, :] * weight_block, axis=0)\n    \n    # Add bias if present\n    if bias_ptr is not None:\n        bias = tl.load(bias_ptr + oc_offsets, mask=oc_mask, other=0.0)\n        acc += bias[None, :, None, None]\n    \n    # Write back output\n    output_ptrs = (\n        output_ptr + \n        pid_batch * output_batch_stride + \n        oc_offsets[:, None, None] * output_channel_stride + \n        output_h_offsets[None, :, None] * output_height_stride + \n        output_w_offsets[None, None, :] * output_width_stride\n    )\n    tl.store(\n        output_ptrs, \n        acc, \n        mask=oc_mask[:, None, None] & h_mask[None, :, None] & w_mask[None, None, :]\n    )\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=(1, 1), padding=(0, 0), \n                 output_padding=(0, 0), dilation=(1, 1), groups=1, bias=False):\n        super(ModelNew, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        self.output_padding = output_padding\n        self.dilation = dilation\n        self.groups = groups\n        \n        # Weight parameters\n        self.weight = torch.nn.Parameter(\n            torch.empty(\n                in_channels, \n                out_channels // groups, \n                kernel_size[0], \n                kernel_size[1]\n            )\n        )\n        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        \n        # Bias parameters\n        if bias:\n            self.bias = torch.nn.Parameter(torch.empty(out_channels))\n            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            torch.nn.init.uniform_(self.bias, -bound, bound)\n        else:\n            self.register_parameter('bias', None)\n    \n    def forward(self, x):\n        # Compute output shape\n        h_in, w_in = x.shape[2], x.shape[3]\n        h_out = (h_in - 1) * self.stride[0] - 2 * self.padding[0] + self.dilation[0] * (self.kernel_size[0] - 1) + self.output_padding[0] + 1\n        w_out = (w_in - 1) * self.stride[1] - 2 * self.padding[1] + self.dilation[1] * (self.kernel_size[1] - 1) + self.output_padding[1] + 1\n        \n        # Create output tensor\n        output = torch.empty(\n            x.size(0), \n            self.out_channels, \n            h_out, \n            w_out, \n            device=x.device, \n            dtype=x.dtype\n        )\n        \n        # Get strides\n        input_batch_stride, input_channel_stride, input_height_stride, input_width_stride = x.stride()\n        weight_in_channel_stride, weight_out_channel_stride, weight_height_stride, weight_width_stride = self.weight.stride()\n        output_batch_stride, output_channel_stride, output_height_stride, output_width_stride = output.stride()\n        \n        # Launch kernel\n        grid = lambda opt: (\n            x.size(0) * \n            triton.cdiv(self.out_channels, opt.BLOCK_SIZE_OC) * \n            triton.cdiv(h_out, opt.BLOCK_SIZE_H) * \n            triton.cdiv(w_out, opt.BLOCK_SIZE_W), \n        )\n        \n        _conv_transpose2d_kernel[grid](\n            x, self.weight, self.bias, output,\n            x.size(0), self.in_channels, self.out_channels, \n            h_in, w_in, h_out, w_out,\n            self.kernel_size[0], self.kernel_size[1],\n            self.stride[0], self.stride[1],\n            self.padding[0], self.padding[1],\n            self.output_padding[0], self.output_padding[1],\n            self.dilation[0], self.dilation[1],\n            self.groups,\n            input_batch_stride, input_channel_stride, input_height_stride, input_width_stride,\n            weight_in_channel_stride, weight_out_channel_stride, weight_height_stride, weight_width_stride,\n            output_batch_stride, output_channel_stride, output_height_stride, output_width_stride,\n            BLOCK_SIZE_IC=32, BLOCK_SIZE_OC=64, BLOCK_SIZE_H=16, BLOCK_SIZE_W=16\n        )\n        \n        return output\n\n# Test code\nbatch_size = 16\nin_channels = 32\nout_channels = 64\nkernel_size = (3, 5)\nheight_in = 16\nwidth_in = 32\n\ndef get_inputs():\n    x = torch.randn(batch_size, in_channels, height_in, width_in)\n    return [x]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size]  # Provide in_channels, out_channels, kernel_size for initialization\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "ae0a607e-a678-4135-915b-ef405bfcb4fb", "generation": 1, "timestamp": 1754646171.1140163, "iteration_found": 2, "metrics": {"compiled": false, "correctness": false, "score": -100.0, "stage": "infra_error", "exception": "500 Server Error: Internal Server Error for url: http://localhost:8011/verify_plus"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.0479, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0435, "speed_up": 0.908, "custom_timing": 0.0479}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}