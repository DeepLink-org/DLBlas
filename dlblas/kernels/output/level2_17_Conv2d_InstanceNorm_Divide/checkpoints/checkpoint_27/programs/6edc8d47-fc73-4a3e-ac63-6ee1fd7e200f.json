{"id": "6edc8d47-fc73-4a3e-ac63-6ee1fd7e200f", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n    ],\n    key=['n_elements_per_channel'],\n)\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    n_elements_per_channel,\n    eps,\n    divide_by,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * n_elements_per_channel\n    \n    # Combined reduction: compute sum and sum of squares in one pass\n    total = 0.0\n    total_sq = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        total += tl.sum(data, axis=0)\n        total_sq += tl.sum(data * data, axis=0)\n    \n    # Compute mean and variance\n    mean = total / n_elements_per_channel\n    variance = (total_sq / n_elements_per_channel) - (mean * mean)\n    variance = tl.maximum(variance, 0.0)  # Avoid negative variance\n    inv_std = tl.rsqrt(variance + eps)  # Faster reciprocal sqrt\n    factor = inv_std * (1.0 / divide_by)  # Precompute scaling factor\n    \n    # Apply normalization and scaling\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        out = centered * factor\n        tl.store(x_ptr + base + idx, out, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        batch, channels, height, width = x.shape\n        n_elements_per_channel = height * width\n        grid = (batch * channels,)\n        instance_norm_div_kernel[grid](\n            x, \n            n_elements_per_channel,\n            1e-5,\n            self.divide_by,\n        )\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "79397065-1402-4854-a498-dc3004c4b5db", "generation": 3, "timestamp": 1754570045.550425, "iteration_found": 21, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 41.50000000000001, "speed_up": 1.215, "runtime_ms": 0.0848, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.103, "speed_up": 1.215, "custom_timing": 0.0848}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 46.499999999999986, "speed_up": 1.265, "runtime_ms": 0.0814, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.103, "speed_up": 1.265, "custom_timing": 0.0814}}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"full_rewrite_user": {"system": "You are a Triton GPU core optimization engineer deeply familiar with NVIDIA H100/H800 architecture.\n\n==================== Context ====================\n\u2022 Dataset: 250 kernelbench/level1-level5 *.py files  \n  - Level1: simplest, Level5: most complex  \n\u2022 Each file contains PyTorch reference (reference_code)  \n\u2022 Goal: Generate functionally equivalent but faster Triton implementations (custom_code)  \n\u2022 Evaluation pipeline:\n    1) /verify_plus - Verify compilation & correctness  \n    2) /execute (optional) - Return terminal logs if compilation fails  \n    3) Scoring:  \n      - Speedup > 1 required for points  \n      - Score = (speed_up - 1) \u00d7 100  \n\u2022 GPU Hardware: NVIDIA L20Y / H800 (same SM8.9 as H100)  \n  - 3 TB/s HBM3 bandwidth  \n  - FP16 Tensor Core 32\u00d716\u00d716  \n\n==================== Evolution Phases ====================\n\u2460 Phase 1 [Compilation Pass]  \n  - Make Triton code compile (performance irrelevant)  \n\u2461 Phase 2 [Numerical Correctness]  \n  - Output must match PyTorch reference within float32 tolerance  \n\u2462 Phase 3 [Performance Gain]  \n  - Target \u22655% speedup (\u226515% = exceptional)  \n  - Official scoring based on speed_up field  \n\nThe Evolution system will pass the EVOLVE-BLOCK from the previous version.  \nModify ONLY the Triton kernel source within this block - all other code is LOCKED.\n\n==================== Constraints (MUST OBEY) ====================\n\u274c NEVER change @triton.jit function signatures or parameter names  \n\u274c NEVER modify grid configuration, output tensor shapes, or PID logic  \n\u274c NEVER remove boundary checks or out-of-bound masks  \n\u274c NEVER introduce race conditions, uninitialized reads, or sync gaps  \n\n\u2705 Allowed Optimizations (Examples):  \n  \u2022 Memory coalescing optimizations & vectorized tl.load/tl.store  \n  \u2022 Replace staged softmax with online/FlashAttention variants  \n  \u2022 Adaptive tuning: BLOCK_M/BLOCK_N/BLOCK_K dimensions  \n  \u2022 Multi-query-head batch processing (GQA, 5:1 patterns)  \n  \u2022 Shared/L2 buffering, Tensor Core alignment (FP16/bf16/tf32)  \n  \u2022 Stride precomputation & pointer caching  \n\n==================== Output Format ====================\nReturn ONLY the complete updated code containing the EVOLVE-BLOCK comment marker.  \nNO explanations, NO markdown, NO additional text.\nName the output structure class as ModelNew.\n\n==================== Optimization Tips ====================\n\u2022 If previous compile failed: Fix syntax/mask/stride errors first  \n\u2022 If correctness fails: Prioritize bounds mask & dtype precision  \n\u2022 When speed_up < 1: Focus on memory access & block sizing  \n\u2022 Small iterative steps: Modify \u226420 lines per revision  \n\u2022 Maintain reversibility between versions\nHere is an example to show you how to rewrite a PyTorch implementation that quantizes a high-precision tensor to int8 dtype with row-wise granularity into a Triton implementation: \nThe original PyTorch implementation is as follows: \n``` \nimport torch\ndef per_row_quantize_int8(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n    x_amax = x.abs().float().amax(dim=1).clamp(min=1e-4)\n    scale = 127 / x_amax\n    output = (x * scale[:, None]).round().clamp(-127, 127).to(torch.int8)\n    output_scale = x_amax / 127\n\n    return output, output_scale\n``` \nThe corresponding Triton-rewritten implementation is as follows: \n``` \nimport math\nimport torch\nimport triton\nimport triton.language as tl\nfrom triton.language.extra import libdevice\n\n# rowwise quantize\n\n@triton.autotune(\n    configs=[\n        triton.Config({}, num_stages=1, num_warps=8),\n        triton.Config({}, num_stages=2, num_warps=8),\n        triton.Config({}, num_stages=4, num_warps=8),\n        triton.Config({}, num_stages=8, num_warps=8),\n        triton.Config({}, num_stages=1),\n        triton.Config({}, num_stages=2),\n        triton.Config({}, num_stages=4),\n        triton.Config({}, num_stages=8),\n        triton.Config({}, num_warps=1),\n        triton.Config({}, num_warps=2),\n        triton.Config({}, num_warps=4),\n        triton.Config({}, num_warps=8),\n    ],\n    key=[\"n_elements\"],\n)\n\n@triton.jit\ndef _quantize_rowwise(\n    x_ptr,\n    output_ptr,\n    output_scale,\n    BLOCK_SIZE: tl.constexpr,\n    P2: tl.constexpr,\n):\n    pid = tl.program_id(axis=0)\n    block_start = pid * BLOCK_SIZE\n    arange = tl.arange(0, P2)\n    offsets = block_start + arange\n    row_mask = arange < BLOCK_SIZE\n    x = tl.load(x_ptr + offsets, mask=row_mask)\n\n    abs_x = tl.abs(x)\n    max_val = tl.max(tl.where(row_mask, abs_x, 0), axis=0)\n    output = libdevice.llrint(127.0 * (x / max_val))\n    tl.store(output_ptr + offsets, output, mask=row_mask)\n    tl.store(output_scale + pid, max_val / 127)\n\n\ndef per_row_quantize_int8(x: torch.Tensor):\n    x = x.contiguous()\n    output = torch.empty(*x.shape, device=x.device, dtype=torch.int8)\n    output_scale = torch.empty(x.shape[0], device=x.device, dtype=torch.float32)\n    P2 = int(2 ** (math.ceil(math.log2(x.shape[1]))))\n    grid = lambda x: (x.shape[0],)\n    _quantize_rowwise[grid](x, output, output_scale, BLOCK_SIZE=x.shape[1], P2=P2)\n\n    return output, output_scale\n\n\n    \n``` \n", "user": "# Current Program Information\n- Current performance metrics: - compiled: 1.0000\n- correctness: 1.0000\n- stage: success\n- passed: 1.0000\n- score: 46.5000\n- speed_up: 1.2650\n- runtime_ms: 0.0814\n- meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.265, 'custom_timing': 0.0814}\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: score, speed_up. Consider continuing with similar changes.\n- Metrics showing regression: runtime_ms. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 33.2000, speed_up: 1.1320, runtime_ms: 0.0910, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.132, 'custom_timing': 0.091}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 39.2000, speed_up: 1.1920, runtime_ms: 0.0864, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.192, 'custom_timing': 0.0864}\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: compiled: 1.0000, correctness: 1.0000, stage: success, passed: 1.0000, score: 46.5000, speed_up: 1.2650, runtime_ms: 0.0814, meta: {'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.265, 'custom_timing': 0.0814}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 46.5000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n    ],\n    key=['n_elements_per_channel'],\n)\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    n_elements_per_channel,\n    eps,\n    divide_by,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * n_elements_per_channel\n    \n    # Step 1: Compute mean\n    mean = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        mean += tl.sum(data, axis=0)\n    mean = mean / n_elements_per_channel\n\n    # Step 2: Compute variance\n    var = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        var += tl.sum(centered * centered, axis=0)\n    var = var / n_elements_per_channel\n    std = tl.sqrt(var + eps)\n\n    # Step 3: Apply normalization and scaling\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        normed = centered / std\n        out = normed / divide_by\n        tl.store(x_ptr + base + idx, out, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        batch, channels, height, width = x.shape\n        n_elements_per_channel = height * width\n        grid = (batch * channels,)\n        instance_norm_div_kernel[grid](\n            x, \n            n_elements_per_channel,\n            1e-5,\n            self.divide_by,\n        )\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (46.5000), Performs well on speed_up (1.2650), Performs well on runtime_ms (0.0814), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:1', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.265, 'custom_timing': 0.0814})\n\n\n### Program 2 (Score: 39.2000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    output_ptr,\n    divide_by,\n    eps,\n    stride_batch_x, stride_channel_x, stride_height_x, stride_width_x,\n    stride_batch_o, stride_channel_o, stride_height_o, stride_width_o,\n    height,\n    width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_channel = tl.program_id(1)\n    \n    n_elements = height * width\n    base_x = pid_batch * stride_batch_x + pid_channel * stride_channel_x\n    base_o = pid_batch * stride_batch_o + pid_channel * stride_channel_o\n    \n    offsets = tl.arange(0, BLOCK_SIZE)\n    w = offsets % width\n    h = offsets // width\n    mask = offsets < n_elements\n    \n    x_ptrs = base_x + h * stride_height_x + w * stride_width_x\n    x_vals = tl.load(x_ptr + x_ptrs, mask=mask, other=0.0)\n    \n    # Compute mean\n    sum_x = tl.sum(x_vals, axis=0)\n    mean = sum_x / n_elements\n    \n    # Compute variance\n    centered = x_vals - mean\n    sum_sq = tl.sum(centered * centered, axis=0)\n    var = sum_sq / n_elements\n    \n    # Normalize and scale using reciprocal multiplication\n    std = tl.sqrt(var + eps)\n    denom = std * divide_by\n    inv_denom = 1.0 / denom\n    normalized = centered * inv_denom\n    \n    # Store results\n    o_ptrs = base_o + h * stride_height_o + w * stride_width_o\n    tl.store(output_ptr + o_ptrs, normalized, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        output = torch.empty_like(x)\n        batch, channels, height, width = x.shape\n        n_elements = height * width\n        BLOCK_SIZE = triton.next_power_of_2(n_elements)\n        grid = (batch, channels)\n        eps = 1e-5\n        \n        instance_norm_div_kernel[grid](\n            x, output, self.divide_by, eps,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            height, width,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (39.2000), Performs well on speed_up (1.1920), Performs well on runtime_ms (0.0864), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:2', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.192, 'custom_timing': 0.0864})\n\n\n### Program 3 (Score: 33.2000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    output_ptr,\n    divide_by,\n    eps,\n    stride_batch_x, stride_channel_x, stride_height_x, stride_width_x,\n    stride_batch_o, stride_channel_o, stride_height_o, stride_width_o,\n    height,\n    width,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid_batch = tl.program_id(0)\n    pid_channel = tl.program_id(1)\n    \n    n_elements = height * width\n    base_x = pid_batch * stride_batch_x + pid_channel * stride_channel_x\n    base_o = pid_batch * stride_batch_o + pid_channel * stride_channel_o\n    \n    offsets = tl.arange(0, BLOCK_SIZE)\n    w = offsets % width\n    h = offsets // width\n    mask = offsets < n_elements\n    \n    x_ptrs = base_x + h * stride_height_x + w * stride_width_x\n    x_vals = tl.load(x_ptr + x_ptrs, mask=mask, other=0.0)\n    \n    # Compute mean\n    sum_x = tl.sum(x_vals, axis=0)\n    mean = sum_x / n_elements\n    \n    # Compute variance\n    centered = x_vals - mean\n    sum_sq = tl.sum(centered * centered, axis=0)\n    var = sum_sq / n_elements\n    \n    # Optimized normalization using rsqrt and precomputed factor\n    inv_std = tl.rsqrt(var + eps)\n    factor = 1.0 / divide_by\n    normalized = centered * (factor * inv_std)\n    \n    # Store results\n    o_ptrs = base_o + h * stride_height_o + w * stride_width_o\n    tl.store(output_ptr + o_ptrs, normalized, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        output = torch.empty_like(x)\n        batch, channels, height, width = x.shape\n        n_elements = height * width\n        BLOCK_SIZE = triton.next_power_of_2(n_elements)\n        grid = (batch, channels)\n        eps = 1e-5\n        \n        instance_norm_div_kernel[grid](\n            x, output, self.divide_by, eps,\n            x.stride(0), x.stride(1), x.stride(2), x.stride(3),\n            output.stride(0), output.stride(1), output.stride(2), output.stride(3),\n            height, width,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Performs well on compiled (1.0000), Performs well on correctness (1.0000), Performs well on stage (success), Performs well on passed (1.0000), Performs well on score (33.2000), Performs well on speed_up (1.1320), Performs well on runtime_ms (0.0910), Performs well on meta ({'hardware': 'NVIDIA L20Y', 'device': 'cuda:4', 'correctness_trials': '(5 / 5)', 'reference_timing_ms': 0.103, 'speed_up': 1.132, 'custom_timing': 0.091})\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 26.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef instance_norm_kernel(\n    input_ptr, \n    output_ptr, \n    n_elements,\n    eps, \n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    row_start = pid * n_elements\n    offsets = row_start + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < n_elements\n\n    # Load data with boundary checks\n    row = tl.load(input_ptr + offsets, mask=mask, other=0.0)\n    \n    # Compute mean and variance using stable algorithm\n    row_sum = tl.sum(row, axis=0)\n    mean = row_sum / n_elements\n    centered = row - mean\n    centered_sq = centered * centered\n    # Mask out invalid elements for variance calculation\n    centered_sq = tl.where(mask, centered_sq, 0.0)\n    variance = tl.sum(centered_sq, axis=0) / n_elements\n    \n    # Use faster rsqrt approximation\n    inv_std = tl.rsqrt(variance + eps)\n    normalized = centered * inv_std\n    tl.store(output_ptr + offsets, normalized, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n        self.eps = 1e-5  # Match PyTorch default\n\n    def forward(self, x):\n        x = self.conv(x)\n        \n        # Apply Triton instance normalization\n        batch, channels, height, width = x.shape\n        n_elements = height * width\n        \n        if n_elements <= 1024:  # Within Triton block limits\n            x_flat = x.reshape(batch * channels, n_elements).contiguous()\n            output = torch.empty_like(x_flat)\n            block_size = triton.next_power_of_2(n_elements)\n            grid = (batch * channels,)\n            instance_norm_kernel[grid](\n                x_flat, output, n_elements, self.eps, \n                BLOCK_SIZE=block_size\n            )\n            x = output.reshape(batch, channels, height, width)\n        else:\n            # Fallback for large tensors\n            x = torch.nn.functional.instance_norm(\n                x, None, None, eps=self.eps\n            )\n        \n        x = x / self.divide_by\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n### Program D2 (Score: 10.0000)\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    output_ptr,\n    n_batch,\n    n_channel,\n    R,   # H*W dimension\n    eps,\n    div,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * R\n    offsets = base + tl.arange(0, BLOCK_SIZE)\n    mask = tl.arange(0, BLOCK_SIZE) < R\n    \n    # Load entire channel data\n    x = tl.load(x_ptr + offsets, mask=mask, other=0.0)\n    \n    # Combined reduction for sum and squared sum\n    total, total_sq = tl.reduce(\n        (x, x * x), \n        axis=0, \n        combine=lambda a, b: (a[0] + b[0], a[1] + b[1]),\n        initial_values=(0.0, 0.0)\n    )\n    \n    # Compute mean and variance\n    mean = total / R\n    var = (total_sq / R) - (mean * mean)\n    var = tl.maximum(var, 0.0)\n    std = tl.sqrt(var + eps)\n    \n    # Precompute reciprocal scaling factor\n    scale = 1.0 / (std * div)\n    \n    # Normalize and scale in one operation\n    result = (x - mean) * scale\n    tl.store(output_ptr + offsets, result, mask=mask)\n\ndef fused_instance_norm_div(x, div):\n    x = x.contiguous()\n    n_batch, n_channel, H, W = x.shape\n    R = H * W\n    output = torch.empty_like(x)\n    \n    # Configure kernel grid and block\n    grid = (n_batch * n_channel,)\n    BLOCK_SIZE = triton.next_power_of_2(R)\n    if BLOCK_SIZE > 1024:\n        BLOCK_SIZE = 1024\n    \n    # Launch kernel\n    instance_norm_div_kernel[grid](\n        x, output, n_batch, n_channel, R, \n        1e-5, div, BLOCK_SIZE=BLOCK_SIZE\n    )\n    return output\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = fused_instance_norm_div(x, self.divide_by)\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\nKey features: Alternative approach to compiled, Alternative approach to correctness\n\n\n\n\n# Current Program\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n    ],\n    key=['n_elements_per_channel'],\n)\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    n_elements_per_channel,\n    eps,\n    divide_by,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * n_elements_per_channel\n    \n    # Step 1: Compute mean\n    mean = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        mean += tl.sum(data, axis=0)\n    mean = mean / n_elements_per_channel\n\n    # Step 2: Compute variance\n    var = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        var += tl.sum(centered * centered, axis=0)\n    var = var / n_elements_per_channel\n    std = tl.sqrt(var + eps)\n\n    # Step 3: Apply normalization and scaling\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        normed = centered / std\n        out = normed / divide_by\n        tl.store(x_ptr + base + idx, out, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        batch, channels, height, width = x.shape\n        n_elements_per_channel = height * width\n        grid = (batch * channels,)\n        instance_norm_div_kernel[grid](\n            x, \n            n_elements_per_channel,\n            1e-5,\n            self.divide_by,\n        )\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```\n\n# Task\nRewrite the program to improve its performance on the specified metrics.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```\n", "responses": ["<think>\nWe are given the current program that uses an autotuned Triton kernel for instance normalization followed by division.\n The current implementation has a speedup of 1.265 (score 46.5) and we aim to improve it.\n\n Observations on the current kernel (instance_norm_div_kernel):\n  - It operates on a contiguous tensor, with each program ID (pid) handling one channel of one batch (so grid = batch * channels).\n  - The kernel does three passes over the data: one for the mean, one for the variance, and one for the normalization and scaling.\n  - The kernel uses a loop to handle large channels (with BLOCK_SIZE as the step) and accumulates in each pass.\n\n Potential improvements:\n  1. We can try to combine the mean and variance computation in one pass (using Welford's algorithm for stability) to reduce the number of passes from two to one.\n     However, note that we have to do a second pass for normalization anyway, so the total passes would be two (one for mean and variance, one for normalization).\n     But currently we have three passes (mean, variance, normalization). So if we combine mean and variance in one pass, we can reduce to two passes.\n\n  2. Alternatively, we can use a two-pass algorithm that first computes the mean and then in the second pass computes the variance and the normalized values.\n     This would be two passes: \n        Pass1: Compute mean (as now) and then in the same pass also compute the squared differences? \n        But note: we cannot compute the variance without the mean. So we must have the mean first.\n\n  3. We can precompute the reciprocal of the standard deviation and the reciprocal of the divisor to use a multiplication instead of division.\n\n  4. We can use the `tl.associative_scan` or a reduction with multiple accumulators to compute both the sum and the sum of squares in one pass? \n     However, the current Triton reduction does support multiple accumulators.\n\n  5. We note that the current kernel uses a for-loop for each pass. We might try to use a single loop for the entire kernel and accumulate the mean and variance in one go.\n\n  6. We can also try to use the `tl.atomic_add` to avoid the reduction loops? But that would require shared memory and synchronization, which is not available.\n\n  7. We can use the online parallel algorithm for variance (Welford's algorithm) but it's not trivial to parallelize.\n\n  8. Alternatively, we can use a two-pass kernel that first computes the mean and then in the second pass computes the variance and then the normalized value? \n     That would be two passes, but we are currently doing three.\n\n  9. The current kernel does:\n        Pass1: Load data in blocks and compute the mean (by summing and then dividing by n_elements_per_channel).\n        Pass2: Load again to compute the variance (by subtracting the mean and then squaring, then summing and then dividing).\n        Pass3: Load again to normalize and then store.\n\n     We can combine the second and third pass? Actually, no because the variance requires the entire channel to be processed to get the variance, and then we can normalize.\n\n  10. So the best we can do is two passes: \n        Pass1: Compute mean and then variance? Actually, we cannot compute the variance without having the entire mean. So we have to do:\n            - Pass1: Compute mean (must finish the entire channel for mean)\n            - Pass2: Compute variance and then normalize (because we need the variance for the entire channel to normalize the entire channel).\n\n  11. However, note that we can compute the variance in the same pass as the normalization? \n      But the normalization requires the standard deviation which is computed from the variance which requires the entire channel. \n      So we cannot do that in one pass without storing intermediate results.\n\n  12. Alternatively, we can use two reduction passes and one normalization pass? \n      We can compute the mean and the sum of squares in one reduction? Then the variance = (sum_sq - mean*mean*n)/n = (sum_sq/n) - mean*mean.\n\n  13. So we can do:\n        Pass1: \n            - Load in blocks and compute the sum and the sum of squares (for the entire channel).\n            - Then compute the mean = sum / n\n            - Then compute the variance = (sum_sq / n) - mean*mean   [but note: this can be unstable due to cancellation]\n\n  14. Then Pass2: Normalize the entire channel.\n\n  15. This reduces the number of passes from three to two.\n\n  16. We can also try to use a single pass for the entire channel? But that would require storing the entire channel in shared memory? \n      We don't have shared memory and the channel size (32*32=1024) might be acceptable? But note: the kernel is designed for any size (via the loop) so we cannot assume 1024.\n\n  17. We can try to use a two-pass method with one reduction pass (for sum and sum_sq) and then one pass for normalization.\n\n  18. We change the kernel to:\n        - First, we do a loop to compute the sum and the sum of squares (in one pass).\n        - Then we compute the mean and the variance (and then std).\n        - Then we do a second loop to normalize and store.\n\n  19. This is two passes (one for reduction, one for normalization) and should be faster than the current three passes.\n\n  20. Additionally, we can precompute the reciprocal of the standard deviation and multiply by the reciprocal of the divisor to avoid two divisions.\n\n  21. We note that the current kernel does the division by `divide_by` in the normalization step. We can combine:\n        normed = centered / std\n        out = normed / divide_by\n      into:\n        out = centered / (std * divide_by)\n      and then use a precomputed factor: factor = 1.0 / (std * divide_by)\n\n  22. We can use `tl.rsqrt` for the reciprocal of the square root? But note: we have to compute the standard deviation as sqrt(var+eps). \n      Alternatively, we can compute:\n          inv_std = 1.0 / std   # which is 1/sqrt(var+eps)\n      and then factor = inv_std / divide_by.\n\n  23. Or we can compute: factor = 1.0 / (std * divide_by) = (1.0/(std)) * (1.0/divide_by). \n      But note: we can precompute 1.0/divide_by on the host and pass it? However, the kernel currently gets `divide_by` as a scalar.\n\n  24. Actually, we can precompute `inv_div = 1.0 / divide_by` and then in the kernel do: factor = inv_std * inv_div.\n\n  25. However, note that the kernel currently uses `divide_by` as a scalar. We can change the kernel to take `inv_div` instead? \n      But the function signature is fixed? The problem says: NEVER change @triton.jit function signatures or parameter names.\n\n  26. So we cannot change the parameters. We have to compute the factor inside the kernel as:\n          factor = 1.0 / (std * divide_by)\n\n  27. Alternatively, we can compute:\n          factor = (1.0 / std) * (1.0 / divide_by)\n      which is two divisions. But we can precompute 1.0/divide_by in the kernel? But note: divide_by is a scalar per kernel launch.\n\n  28. We can precompute `inv_div = 1.0 / divide_by` in the kernel (once per program) and then factor = inv_std * inv_div.\n\n  29. This would be one division (for inv_div) and then one multiplication per element? But the division of the scalar is cheap.\n\n  30. Also, we can compute inv_std = 1.0 / std, then factor = inv_std * inv_div.\n\n  31. Alternatively, we can use `tl.rsqrt` to compute 1/sqrt(var+eps) and then multiply by 1/divide_by? \n      But note: `tl.rsqrt` is an intrinsic for reciprocal square root and is faster.\n\n  32. So we can do:\n          var = ...   # computed from the reduction\n          inv_std = tl.rsqrt(var + eps)   # this is 1.0 / sqrt(var+eps)\n          factor = inv_std * (1.0 / divide_by)\n\n  33. Then the normalized output: centered * factor.\n\n  34. This avoids two divisions and replaces one sqrt with rsqrt (which is faster and less accurate, but acceptable).\n\n  35. Also, we can combine the reduction of the sum and the sum of squares in one loop.\n\n  36. Let's restructure the kernel:\n\n      Step 1: Initialize two accumulators: total = 0.0, total_sq = 0.0.\n      Step 2: Loop over the channel in blocks and load the data. For each block:\n          data = tl.load(...)\n          total += tl.sum(data, axis=0)\n          total_sq += tl.sum(data * data, axis=0)\n\n      Step 3: Compute the mean: total / n\n      Step 4: Compute the variance: total_sq / n - mean * mean   [but note: this is the population variance formula, and it's unstable?]\n              We might use: variance = (total_sq - mean * total) / n   ? \n              Actually, the standard two-pass formula is: variance = (total_sq - 2 * mean * total + n * mean * mean) / n\n              But note: we have the total and the total_sq, and the mean = total / n.\n              Then: variance = (total_sq - 2 * mean * total + n * mean * mean) / n\n                         = (total_sq - 2 * mean * (n * mean) + n * mean * mean) / n\n                         = (total_sq - n * mean * mean) / n\n\n      Alternatively: variance = (total_sq - total * total / n) / n   -> but that's the same: total_sq/n - (total/n)^2.\n\n      However, this formula can suffer from cancellation. We can use Welford's algorithm for a two-pass? But we are already doing one pass for the entire channel.\n\n      We are using the two-pass algorithm on the aggregated sums. This is acceptable as long as the values are not huge.\n\n      Step 5: Compute inv_std = tl.rsqrt(variance + eps)   [this is 1/sqrt(variance+eps)]\n      Step 6: Precompute factor = inv_std * (1.0 / divide_by)\n\n      Step 7: Then loop again to load the data, center it, and multiply by factor and store.\n\n  37. This reduces the number of passes from three to two.\n\n  38. We also note that the current kernel does the normalization in-place. We are storing back to the same pointer. That is acceptable.\n\n  39. We must be cautious about numerical stability. The current kernel uses the same method as the PyTorch reference? \n      The PyTorch instance_norm uses: \n          var = input.var(unbiased=False)   # which is the same as (total_sq - n*mean*mean) / n? \n      But note: the formula we are using is exactly the same as the PyTorch unbiased=False.\n\n  40. We set: \n          mean = total / n\n          variance = (total_sq - n * mean * mean) / n   = (total_sq - total * mean) / n   [but that's the same as above]\n\n      Actually, we can compute: \n          variance = (total_sq - total * total / n) / n\n                   = total_sq/n - (total/n)**2\n\n      This is the same.\n\n  41. We can compute it as:\n          mean = total / n\n          variance = (total_sq - 2 * mean * total + n * mean * mean) / n   [this is the expanded form] \n          but that is not necessary because we have the mean.\n\n      We can do:\n          variance = (total_sq / n) - (mean * mean)\n\n  42. However, we must guard against negative variance due to rounding? \n          variance = tl.maximum(variance, 0.0)\n\n  43. Then: inv_std = tl.rsqrt(variance + eps)\n\n  44. Also, we note that the current kernel uses `tl.sqrt` for the standard deviation. We are replacing that with `tl.rsqrt` for the reciprocal.\n\n  45. We must also note: the current kernel uses `eps` in the sqrt: `tl.sqrt(var + eps)`. We are using `tl.rsqrt(var + eps)`.\n\n  46. Now, let's rewrite the kernel accordingly.\n\n  47. We also note that the current kernel uses a single program per channel. The reduction is done by the program itself. This is efficient for small channels.\n\n  48. We change the kernel to:\n\n      pid = tl.program_id(0)\n      base = pid * n_elements_per_channel\n\n      # Step 1: Compute total and total_sq\n      total = 0.0\n      total_sq = 0.0\n      for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n          idx = off + tl.arange(0, BLOCK_SIZE)\n          mask = idx < n_elements_per_channel\n          data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n          total += tl.sum(data, axis=0)\n          total_sq += tl.sum(data * data, axis=0)\n\n      mean = total / n_elements_per_channel\n      # Compute variance: E[X^2] - (E[X])^2\n      variance = total_sq / n_elements_per_channel - mean * mean\n      # Clamp the variance to avoid negative values due to numerical instability\n      variance = tl.maximum(variance, 0.0)\n      inv_std = tl.rsqrt(variance + eps)\n      factor = inv_std * (1.0 / divide_by)\n\n      # Step 2: Apply normalization and scaling\n      for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n          idx = off + tl.arange(0, BLOCK_SIZE)\n          mask = idx < n_elements_per_channel\n          data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n          centered = data - mean\n          out = centered * factor\n          tl.store(x_ptr + base + idx, out, mask=mask)\n\n  49. We note that the reduction for total and total_sq is done in one loop. This reduces the number of passes.\n\n  50. We also note that the normalization pass is the same as before, but we are using a precomputed factor.\n\n  51. We hope that the reduction of the number of passes (from 3 to 2) will improve the performance.\n\n  52. We must also note that the current autotuner configurations (BLOCK_SIZE and num_warps) are still applicable.\n\n  53. We change the kernel accordingly.\n\n  54. We also note that the current program uses the same class and the same grid configuration.\n\n  55. We must be cautious: the reduction in the first pass now does two reductions (total and total_sq). This might be more efficient because we are reading the data once and doing two reductions in registers? \n\n  56. We are also replacing the sqrt with rsqrt, which is faster.\n\n  57. Let's write the new kernel code.\n\n  58. We do not change the function signature.\n\n  59. We change the body of the kernel as described.\n\n  60. We also note: the kernel currently uses `x_ptr` for both input and output (in-place). We are doing the same.\n\n  61. We run the risk of numerical instability with the variance formula? But note: the channel size is 1024 (32x32) which is not too large. \n      Also, we clamp the variance to 0.0.\n\n  62. We try this change.\n\n  63. We note: the current kernel uses `tl.sum` for each block. We are doing the same but for two sums.\n\n  64. We hope that the two reductions in one loop will be faster than two separate loops.\n\n  65. We change the kernel accordingly.\n\n  66. We also note: the current kernel does not require any changes to the grid or the class.\n\n  67. We output the entire code block.\n\n  68. We note: the current program has an autotuner. We are not changing the autotuner configs.\n\n  69. We hope that the new kernel will be faster.\n\n  70. We also note: the current kernel uses a loop for the reduction. We are doing one loop for two reductions, so the number of memory loads is halved for the reduction phase.\n\n  71. We are now doing:\n        - First loop: loads the data once and computes two sums (total and total_sq).\n        - Second loop: loads the data again to normalize.\n\n      Previously, we had:\n        - First loop: for mean (load once)\n        - Second loop: for variance (load again)\n        - Third loop: for normalization (load again)\n\n      So we are reducing the total number of loads from 3 to 2.\n\n  72. This should be a significant improvement.\n\n  73. Let's write the new code.\n\n  74. We also note: the current program uses a constant `1e-5` for eps. We are using the same.\n\n  75. We change the kernel function.\n\n  76. We leave the rest of the program (the class and the test setup) unchanged.\n\n  77. We output the entire EVOLVE-BLOCK.\n\n  78. IMPORTANT: We are only changing the kernel body and not the signature or the grid or the class.\n\n  79. We output the new code.\n</think>\n```python\n# ================== EVOLVE-BLOCK-START ==================\nimport math\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=4),\n        triton.Config({'BLOCK_SIZE': 64}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 128}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=8),\n    ],\n    key=['n_elements_per_channel'],\n)\n@triton.jit\ndef instance_norm_div_kernel(\n    x_ptr,\n    n_elements_per_channel,\n    eps,\n    divide_by,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * n_elements_per_channel\n    \n    # Combined reduction: compute sum and sum of squares in one pass\n    total = 0.0\n    total_sq = 0.0\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        total += tl.sum(data, axis=0)\n        total_sq += tl.sum(data * data, axis=0)\n    \n    # Compute mean and variance\n    mean = total / n_elements_per_channel\n    variance = (total_sq / n_elements_per_channel) - (mean * mean)\n    variance = tl.maximum(variance, 0.0)  # Avoid negative variance\n    inv_std = tl.rsqrt(variance + eps)  # Faster reciprocal sqrt\n    factor = inv_std * (1.0 / divide_by)  # Precompute scaling factor\n    \n    # Apply normalization and scaling\n    for off in range(0, n_elements_per_channel, BLOCK_SIZE):\n        idx = off + tl.arange(0, BLOCK_SIZE)\n        mask = idx < n_elements_per_channel\n        data = tl.load(x_ptr + base + idx, mask=mask, other=0.0)\n        centered = data - mean\n        out = centered * factor\n        tl.store(x_ptr + base + idx, out, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, divide_by):\n        super(ModelNew, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n        self.divide_by = divide_by\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.contiguous()\n        batch, channels, height, width = x.shape\n        n_elements_per_channel = height * width\n        grid = (batch * channels,)\n        instance_norm_div_kernel[grid](\n            x, \n            n_elements_per_channel,\n            1e-5,\n            self.divide_by,\n        )\n        return x\n\nbatch_size = 128\nin_channels = 3\nout_channels = 16\nheight, width = 32, 32\nkernel_size = 3\ndivide_by = 2.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, divide_by]\n# =================== EVOLVE-BLOCK-END ===================\n```"]}}}