{"id": "ac73ea48-3591-48df-96fd-5c94d395d80a", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef max_reduction_kernel(\n    x_ptr,\n    output_ptr,\n    reduction_dim_size: tl.constexpr,\n    stride_x: tl.constexpr,\n    BLOCK_R: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    base = pid * stride_x\n    offsets = base + tl.arange(0, BLOCK_R)\n    mask = tl.arange(0, BLOCK_R) < reduction_dim_size\n    row = tl.load(x_ptr + offsets, mask=mask, other=-float('inf'))\n    row_max = tl.max(row, axis=0)\n    tl.store(output_ptr + pid, row_max)\n\nclass ModelNew(nn.Module):\n    def __init__(self, dim: int):\n        super(ModelNew, self).__init__()\n        self.dim = dim\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        non_reduced_dims = []\n        total_non_reduced = 1\n        for i in range(x.dim()):\n            if i != self.dim:\n                non_reduced_dims.append(x.shape[i])\n                total_non_reduced *= x.shape[i]\n                \n        reduction_dim_size = x.shape[self.dim]\n        if total_non_reduced == 0:\n            return torch.empty(non_reduced_dims, device=x.device, dtype=x.dtype)\n            \n        x_2d = x.contiguous().view(total_non_reduced, reduction_dim_size)\n        output_1d = torch.empty(total_non_reduced, device=x.device, dtype=x.dtype)\n        \n        if reduction_dim_size <= 1024 and x.is_cuda:\n            BLOCK_R = triton.next_power_of_2(reduction_dim_size)\n            grid = (total_non_reduced,)\n            num_warps = min(32, (BLOCK_R + 31) // 32)\n            max_reduction_kernel[grid](\n                x_2d, output_1d,\n                reduction_dim_size,\n                x_2d.stride(0),\n                BLOCK_R=BLOCK_R,\n                num_warps=num_warps\n            )\n        else:\n            output_1d = torch.max(x_2d, dim=1)[0]\n        \n        return output_1d.view(non_reduced_dims)\n\nbatch_size = 16\ndim1 = 256\ndim2 = 256\n\ndef get_inputs():\n    x = torch.randn(batch_size, dim1, dim2)\n    return [x]\n\ndef get_init_inputs():\n    return [1]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "875e51d9-66fd-4339-96d7-5dc5f20f4d74", "generation": 3, "timestamp": 1754644034.5411053, "iteration_found": 24, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_49_Max_reduction_over_a_dimension", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "max_difference": ["2.264827", "2.442272", "2.510905", "2.618153", "2.129538"], "avg_difference": ["0.441387", "0.431262", "0.434644", "0.438554", "0.426405"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0239, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_49_Max_reduction_over_a_dimension", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:2", "max_difference": ["2.264827", "2.442272", "2.510905", "2.618153", "2.129538"], "avg_difference": ["0.441387", "0.431262", "0.434644", "0.438554", "0.426405"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0239, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}