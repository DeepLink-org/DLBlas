{"id": "6b107718-4e99-4319-b5eb-8247dbd6c04e", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef clamp_softmax_multiply_kernel(\n    x_ptr,\n    output_ptr,\n    clamp_min,\n    clamp_max,\n    C,\n    n_spatial,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(axis=0)\n    batch_id = pid // n_spatial\n    spatial_id = pid % n_spatial\n    c_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = c_offsets < C\n    \n    # Calculate base pointer position\n    base_ptr = batch_id * C * n_spatial + spatial_id\n    ptrs = x_ptr + base_ptr + c_offsets * n_spatial\n    vec = tl.load(ptrs, mask=mask, other=-float('inf'))\n    \n    # Clamp values\n    clamped = tl.minimum(tl.maximum(vec, clamp_min), clamp_max)\n    \n    # Compute softmax\n    max_val = tl.max(clamped, axis=0)\n    exp_vals = tl.exp(clamped - max_val)\n    sum_exp = tl.sum(exp_vals, axis=0)\n    softmax_out = exp_vals / sum_exp\n    \n    # Multiply by 2 and store\n    result = softmax_out * 2.0\n    tl.store(output_ptr + base_ptr + c_offsets * n_spatial, result, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.avg_pool(x)\n        \n        # Get tensor dimensions\n        batch, C, D, H, W = x.shape\n        n_spatial = D * H * W\n        \n        # Prepare for Triton kernel\n        x_contig = x.contiguous()\n        output = torch.empty_like(x_contig)\n        \n        # Launch kernel only if there are elements to process\n        if batch * n_spatial > 0 and C > 0:\n            grid = (batch * n_spatial,)\n            BLOCK_SIZE = triton.next_power_of_2(C)\n            clamp_softmax_multiply_kernel[grid](\n                x_contig, output, self.clamp_min, self.clamp_max, C, n_spatial,\n                BLOCK_SIZE=BLOCK_SIZE\n            )\n        else:\n            output = x_contig\n            \n        return output\n\nbatch_size = 16\nin_channels = 8\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "d2f5eb9d-dd7f-468d-8858-34d3e4b64292", "generation": 1, "timestamp": 1754569426.0558262, "iteration_found": 1, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.119, "runtime_ms": 0.827, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.119, "custom_timing": 0.827}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "reference code", "passed": false, "score": 0.0, "speed_up": 1.0, "runtime_ms": 0.71, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.138, "custom_timing": 0.71}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}