{"id": "28032fd8-99ac-430d-8531-6d96fbd78d8b", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, average pooling, clamping, softmax, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.avg_pool(x)\n        x = self._fused_ops(x, self.clamp_min, self.clamp_max)\n        return x\n\n    @staticmethod\n    @triton.jit\n    def _fused_ops_kernel(\n        x_ptr,\n        output_ptr,\n        clamp_min,\n        clamp_max,\n        C,\n        num_rows,\n        BLOCK_SIZE: tl.constexpr\n    ):\n        row_idx = tl.program_id(0)\n        if row_idx >= num_rows:\n            return\n            \n        row_start = row_idx * C\n        offsets = row_start + tl.arange(0, BLOCK_SIZE)\n        mask = tl.arange(0, BLOCK_SIZE) < C\n\n        x_vals = tl.load(x_ptr + offsets, mask=mask, other=-float('inf'))\n        clamped = tl.minimum(tl.maximum(x_vals, clamp_min), clamp_max)\n        max_val = tl.max(clamped, axis=0)\n        exp_vals = tl.exp(clamped - max_val)\n        sum_exp = tl.sum(exp_vals, axis=0)\n        softmax_out = exp_vals / sum_exp\n        out_vals = softmax_out * 2.0\n        tl.store(output_ptr + offsets, out_vals, mask=mask)\n\n    def _fused_ops(self, x, clamp_min, clamp_max):\n        batch, num_channels, depth, height, width = x.shape\n        n_spatial = depth * height * width\n        total_rows = batch * n_spatial\n        \n        # Transpose to [B, D, H, W, C] for contiguous channel access\n        x_perm = x.permute(0, 2, 3, 4, 1).contiguous()\n        output_perm = torch.empty_like(x_perm)\n        \n        if total_rows > 0 and num_channels > 0:\n            grid = (total_rows,)\n            BLOCK_SIZE = triton.next_power_of_2(num_channels)\n            ModelNew._fused_ops_kernel[grid](\n                x_perm, output_perm, clamp_min, clamp_max, num_channels, total_rows,\n                BLOCK_SIZE=BLOCK_SIZE\n            )\n        else:\n            output_perm = x_perm\n            \n        # Transpose back to original shape [B, C, D, H, W]\n        output = output_perm.permute(0, 4, 1, 2, 3).contiguous()\n        return output\n\nbatch_size = 16\nin_channels = 8\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "ed228017-84e9-40ee-8c96-43864fdd7053", "generation": 2, "timestamp": 1754573903.1012874, "iteration_found": 17, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.115, "runtime_ms": 0.857, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.115, "custom_timing": 0.857}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.117, "runtime_ms": 0.843, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.117, "custom_timing": 0.843}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}