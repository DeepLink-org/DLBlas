{"id": "192eee21-4dfc-468f-a6cf-bf10d9eecb76", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\nclass ModelNew(nn.Module):\n    \"\"\"\n    Model that performs a 3D transposed convolution, average pooling, clamping, softmax, and multiplication.\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max):\n        super(ModelNew, self).__init__()\n        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)\n        self.avg_pool = nn.AvgPool3d(pool_kernel_size)\n        self.clamp_min = clamp_min\n        self.clamp_max = clamp_max\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, height, width).\n\n        Returns:\n            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth, height, width).\n        \"\"\"\n        x = self.conv_transpose(x)\n        x = self.avg_pool(x)\n        x = self._fused_ops(x, self.clamp_min, self.clamp_max)\n        return x\n\n    @staticmethod\n    @triton.jit\n    def _fused_ops_kernel(\n        x_ptr,\n        output_ptr,\n        clamp_min,\n        clamp_max,\n        batch_size,\n        num_channels,\n        depth,\n        height,\n        width,\n        n_spatial,\n        BLOCK_SIZE: tl.constexpr,\n    ):\n        pid = tl.program_id(0)\n        total_elements = batch_size * n_spatial\n        \n        if pid >= total_elements:\n            return\n\n        batch_idx = pid // n_spatial\n        spatial_idx = pid % n_spatial\n\n        base_offset = batch_idx * (num_channels * n_spatial) + spatial_idx\n        offsets = base_offset + tl.arange(0, BLOCK_SIZE) * n_spatial\n        mask = tl.arange(0, BLOCK_SIZE) < num_channels\n\n        x_vals = tl.load(x_ptr + offsets, mask=mask, other=float('-inf'))\n        clamped = tl.minimum(tl.maximum(x_vals, clamp_min), clamp_max)\n        max_val = tl.max(clamped, axis=0)\n        exp_vals = tl.exp(clamped - max_val)\n        sum_exp = tl.sum(exp_vals, axis=0)\n        softmax_out = exp_vals / sum_exp\n        out_vals = softmax_out * 2.0\n        tl.store(output_ptr + offsets, out_vals, mask=mask)\n\n    def _fused_ops(self, x, clamp_min, clamp_max):\n        x = x.contiguous()\n        output = torch.empty_like(x)\n        batch_size, num_channels, depth, height, width = x.shape\n        n_spatial = depth * height * width\n        total_elements = batch_size * n_spatial\n\n        if total_elements == 0:\n            return output\n\n        BLOCK_SIZE = triton.next_power_of_2(num_channels)\n        \n        grid = (total_elements,)\n        ModelNew._fused_ops_kernel[grid](\n            x, output, clamp_min, clamp_max,\n            batch_size, num_channels, depth, height, width,\n            n_spatial,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 16\nin_channels = 8\nout_channels = 16\ndepth, height, width = 16, 32, 32\nkernel_size = 3\nstride = 2\npadding = 1\noutput_padding = 1\npool_kernel_size = 2\nclamp_min = 0.0\nclamp_max = 1.0\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_channels, depth, height, width)]\n\ndef get_init_inputs():\n    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, pool_kernel_size, clamp_min, clamp_max]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "ed228017-84e9-40ee-8c96-43864fdd7053", "generation": 2, "timestamp": 1754571401.565278, "iteration_found": 8, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.119, "runtime_ms": 0.827, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.119, "custom_timing": 0.827}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.117, "runtime_ms": 0.843, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0983, "speed_up": 0.117, "custom_timing": 0.843}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}