{"id": "5e1cf446-d211-413e-8c71-18f40861a186", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef fused_residual_mult_kernel(\n    x_ptr,\n    y_ptr,\n    output_ptr,\n    out_features: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    row_start = pid * out_features\n    offsets = tl.arange(0, BLOCK_SIZE)\n    mask = offsets < out_features\n\n    x_vals = tl.load(x_ptr + row_start + offsets, mask=mask, other=0.0)\n    y_vals = tl.load(y_ptr + row_start + offsets, mask=mask, other=0.0)\n\n    result = (x_vals + y_vals) * y_vals\n    tl.store(output_ptr + row_start + offsets, result, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.linear = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n        self.out_features = out_features\n\n    def forward(self, x, y):\n        x = self.linear(x)\n        x = x.unsqueeze(1).unsqueeze(1)\n        x = self.instance_norm(x)\n        x = x.squeeze(1).squeeze(1)\n        \n        output = torch.empty_like(x)\n        batch_size = x.size(0)\n        n_cols = x.size(1)\n        \n        grid = (batch_size,)\n        BLOCK_SIZE = triton.next_power_of_2(n_cols)\n        fused_residual_mult_kernel[grid](\n            x, y, output,\n            n_cols,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return output\n\nbatch_size = 128\nin_features = 64\nout_features = 128\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features), torch.randn(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "a68b9c6d-959f-496e-ad92-ec316ccbcbd6", "generation": 3, "timestamp": 1754570695.373028, "iteration_found": 22, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.846, "runtime_ms": 0.116, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0981, "speed_up": 0.846, "custom_timing": 0.116}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_28_BMM_InstanceNorm_Sum_ResidualAdd_Multiply", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmpumnedd24.py\", line 50, in forward\n    bias = torch.zeros_like(self.instance_norm.weight)\nTypeError: zeros_like(): argument 'input' (position 1) must be Tensor, not NoneType\n", "runtime_error_name": "builtins.TypeError", "reference_timing_ms": 0.0981, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}