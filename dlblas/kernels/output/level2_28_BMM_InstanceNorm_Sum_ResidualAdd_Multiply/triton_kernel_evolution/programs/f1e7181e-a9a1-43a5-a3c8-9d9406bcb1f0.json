{"id": "f1e7181e-a9a1-43a5-a3c8-9d9406bcb1f0", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef _forward_kernel(\n    x_ptr,          # normalized_x output from instance norm\n    y_ptr,          # residual input\n    output_ptr,     # result tensor\n    stride_x0, stride_x1,\n    stride_y0, stride_y1,\n    stride_out0, stride_out1,\n    out_features, \n    batch_size,\n    BLOCK_SIZE: tl.constexpr,\n):\n    pid = tl.program_id(0)\n    start_idx = pid * BLOCK_SIZE\n    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < batch_size * out_features\n    \n    feature_id = offsets % out_features\n    batch_id = offsets // out_features\n    \n    # Load normalized_x and residual y with vectorized access\n    x_vals = tl.load(x_ptr + batch_id * stride_x0 + feature_id * stride_x1, mask=mask)\n    y_vals = tl.load(y_ptr + batch_id * stride_y0 + feature_id * stride_y1, mask=mask)\n    \n    # Compute: (normalized_x + y) * y with fused operations\n    out_vals = (x_vals + y_vals) * y_vals\n    \n    tl.store(output_ptr + batch_id * stride_out0 + feature_id * stride_out1, out_vals, mask=mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.bmm = nn.Linear(in_features, out_features)\n        self.instance_norm = nn.InstanceNorm2d(out_features, eps=eps, momentum=momentum)\n    \n    def forward(self, x, y):\n        # Compute normalized_x: bmm -> reshape -> instance norm -> reshape back\n        normalized_x = self.bmm(x)\n        normalized_x = self.instance_norm(\n            normalized_x.unsqueeze(1).unsqueeze(1)\n        ).squeeze(1).squeeze(1)\n        \n        batch_size, out_features = normalized_x.shape\n        \n        # Ensure contiguous memory layout for optimal access\n        normalized_x = normalized_x.contiguous()\n        y = y.contiguous()\n        output = torch.empty_like(y)\n        \n        total_elements = batch_size * out_features\n        grid = lambda meta: (triton.cdiv(total_elements, meta['BLOCK_SIZE']),)\n        \n        # Optimized block size for H100 architecture\n        _forward_kernel[grid](\n            normalized_x, y, output,\n            normalized_x.stride(0), normalized_x.stride(1),\n            y.stride(0), y.stride(1),\n            output.stride(0), output.stride(1),\n            out_features, batch_size,\n            BLOCK_SIZE=128  # Reduced block size for better parallelism\n        )\n        return output\n\nbatch_size = 128\nin_features = 64\nout_features = 128\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features), torch.randn(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "35529338-466b-48db-82a7-4e0a606e340c", "generation": 4, "timestamp": 1754570278.2194526, "iteration_found": 20, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.677, "runtime_ms": 0.145, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:0", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0981, "speed_up": 0.677, "custom_timing": 0.145}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": false, "score": 20, "speed_up": 0.696, "runtime_ms": 0.141, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:5", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0981, "speed_up": 0.696, "custom_timing": 0.141}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}