{"id": "6f91be36-02aa-40ea-a630-3aebb1097556", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport torch.nn as nn\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef linear_kernel(\n    x_ptr, w_ptr, b_ptr, output_ptr,\n    M, N, K,\n    stride_xm, stride_xk,\n    stride_wn, stride_wk,\n    stride_om, stride_on,\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr\n):\n    pid0 = tl.program_id(0)\n    pid1 = tl.program_id(1)\n    \n    offs_m = pid0 * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_n = pid1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    \n    x_ptrs = x_ptr + (offs_m[:, None] * stride_xm + offs_k[None, :] * stride_xk)\n    w_ptrs = w_ptr + (offs_k[:, None] * stride_wk + offs_n[None, :] * stride_wn)\n    \n    acc = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        k_remaining = K - k * BLOCK_SIZE_K\n        k_valid = tl.minimum(BLOCK_SIZE_K, k_remaining)\n        \n        x_mask = (offs_m[:, None] < M) & (offs_k[None, :] < k_valid)\n        w_mask = (offs_k[:, None] < k_valid) & (offs_n[None, :] < N)\n        \n        x = tl.load(x_ptrs, mask=x_mask, other=0.0)\n        w = tl.load(w_ptrs, mask=w_mask, other=0.0)\n        \n        acc += tl.dot(x, w, allow_tf32=True)\n        x_ptrs += BLOCK_SIZE_K * stride_xk\n        w_ptrs += BLOCK_SIZE_K * stride_wn\n    \n    b_ptrs = b_ptr + offs_n\n    b = tl.load(b_ptrs, mask=offs_n < N, other=0.0)\n    acc += b[None, :]\n    \n    offs_m_out = offs_m[:, None]\n    offs_n_out = offs_n[None, :]\n    out_ptrs = output_ptr + stride_om * offs_m_out + stride_on * offs_n_out\n    out_mask = (offs_m_out < M) & (offs_n_out < N)\n    tl.store(out_ptrs, acc, mask=out_mask)\n\n@triton.jit\ndef elementwise_kernel(\n    x_ptr,\n    y_ptr,\n    gamma_ptr,\n    beta_ptr,\n    output_ptr,\n    eps: tl.constexpr,\n    out_features: tl.constexpr,\n    batch_size: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    row_start = pid * out_features\n    offsets = tl.arange(0, BLOCK_SIZE)\n    col_mask = offsets < out_features\n    \n    # Load inputs\n    x_vals = tl.load(x_ptr + row_start + offsets, mask=col_mask)\n    y_vals = tl.load(y_ptr + row_start + offsets, mask=col_mask)\n    gamma_vals = tl.load(gamma_ptr + offsets, mask=col_mask)\n    beta_vals = tl.load(beta_ptr + offsets, mask=col_mask)\n    \n    # Instance normalization calculation\n    mean = tl.sum(x_vals, axis=0) / out_features\n    diff = x_vals - mean\n    var = tl.sum(diff * diff, axis=0) / out_features\n    inv_std = 1.0 / tl.sqrt(var + eps)\n    normalized = gamma_vals * (x_vals - mean) * inv_std + beta_vals\n    \n    # Residual connection and multiplication\n    result = (normalized + y_vals) * y_vals\n    \n    # Store results\n    tl.store(output_ptr + row_start + offsets, result, mask=col_mask)\n\nclass ModelNew(nn.Module):\n    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):\n        super(ModelNew, self).__init__()\n        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n        self.bias = nn.Parameter(torch.randn(out_features))\n        self.gamma = nn.Parameter(torch.ones(out_features))\n        self.beta = nn.Parameter(torch.zeros(out_features))\n        self.eps = eps\n        self.out_features = out_features\n\n    def forward(self, x, y):\n        # Linear transformation\n        M, K = x.shape\n        N, _ = self.weight.shape\n        linear_out = torch.empty((M, N), device=x.device, dtype=x.dtype)\n        \n        grid = lambda META: (\n            triton.cdiv(M, META['BLOCK_SIZE_M']),\n            triton.cdiv(N, META['BLOCK_SIZE_N'])\n        )\n        \n        linear_kernel[grid](\n            x, self.weight, self.bias, linear_out,\n            M, N, K,\n            x.stride(0), x.stride(1),\n            self.weight.stride(0), self.weight.stride(1),\n            linear_out.stride(0), linear_out.stride(1),\n            BLOCK_SIZE_M=64, BLOCK_SIZE_N=64, BLOCK_SIZE_K=32,\n            num_warps=4\n        )\n        \n        # Element-wise operations (instance norm + residual + multiply)\n        batch_size = y.size(0)\n        output = torch.empty_like(y)\n        BLOCK_SIZE = triton.next_power_of_2(self.out_features)\n        grid = (batch_size,)\n        \n        elementwise_kernel[grid](\n            linear_out,\n            y,\n            self.gamma,\n            self.beta,\n            output,\n            self.eps,\n            self.out_features,\n            batch_size,\n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        \n        return output\n\nbatch_size = 128\nin_features = 64\nout_features = 128\n\ndef get_inputs():\n    return [torch.randn(batch_size, in_features), torch.randn(batch_size, out_features)]\n\ndef get_init_inputs():\n    return [in_features, out_features]\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "3de331bb-34a4-4f7e-b974-174ba81b689d", "generation": 3, "timestamp": 1754571595.80024, "iteration_found": 25, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_28_BMM_InstanceNorm_Sum_ResidualAdd_Multiply", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:3", "max_difference": ["14.984737", "11.059138", "16.416086", "12.884068", "11.540602"], "avg_difference": ["0.969868", "0.971501", "0.970228", "0.973037", "0.968272"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0981, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level2_28_BMM_InstanceNorm_Sum_ResidualAdd_Multiply", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:4", "max_difference": ["10.688047", "11.964792", "8.808855", "7.593657", "8.034429"], "avg_difference": ["0.639038", "0.633621", "0.640269", "0.639946", "0.630824"], "correctness_issue": "Output mismatch", "correctness_trials": "(0 / 5)", "reference_timing_ms": 0.0981, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "island": 0}, "artifacts_json": null, "artifact_dir": null}