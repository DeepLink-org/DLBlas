{"id": "63ef5127-d9b1-4a84-a2ed-15f2b08a2660", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\n\nclass ModelNew(torch.nn.Module):\n    def __init__(self, margin=1.0):\n        super(ModelNew, self).__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n        # Ensure contiguous memory access\n        anchor = anchor.contiguous()\n        positive = positive.contiguous()\n        negative = negative.contiguous()\n        \n        batch_size, feat_dim = anchor.shape\n        losses = torch.empty(batch_size, device=anchor.device, dtype=anchor.dtype)\n        \n        # Configure kernel launch parameters\n        grid = (batch_size,)\n        BLOCK_SIZE = 1024  # Optimal block size for memory access\n        \n        # Launch optimized Triton kernel\n        self._triplet_kernel[grid](\n            anchor, positive, negative, \n            losses, self.margin,\n            batch_size, feat_dim, \n            BLOCK_SIZE=BLOCK_SIZE\n        )\n        return losses.mean()\n\n    @staticmethod\n    @triton.jit\n    def _triplet_kernel(\n        anchor_ptr, pos_ptr, neg_ptr, loss_ptr, margin, \n        n_triplets, feat_dim, \n        BLOCK_SIZE: tl.constexpr\n    ):\n        # Get current program ID\n        pid = tl.program_id(0)\n        if pid >= n_triplets:\n            return\n        \n        # Initialize accumulators\n        ap_acc = 0.0\n        an_acc = 0.0\n        \n        # Process feature vectors in blocks\n        for offset in range(0, feat_dim, BLOCK_SIZE):\n            idxs = tl.arange(0, BLOCK_SIZE)\n            base = pid * feat_dim + offset\n            offsets = base + idxs\n            mask = (offset + idxs) < feat_dim\n            \n            # Load vectors with coalesced access\n            a = tl.load(anchor_ptr + offsets, mask=mask, other=0.0)\n            p = tl.load(pos_ptr + offsets, mask=mask, other=0.0)\n            n = tl.load(neg_ptr + offsets, mask=mask, other=0.0)\n            \n            # Compute squared differences\n            ap_diff = a - p\n            an_diff = a - n\n            \n            # Accumulate squared distances\n            ap_acc += tl.sum(ap_diff * ap_diff)\n            an_acc += tl.sum(an_diff * an_diff)\n        \n        # Compute Euclidean distances\n        d_ap = tl.sqrt(ap_acc)\n        d_an = tl.sqrt(an_acc)\n        \n        # Calculate triplet loss\n        loss_val = tl.maximum(d_ap - d_an + margin, 0.0)\n        tl.store(loss_ptr + pid, loss_val)\n\nbatch_size = 128\ninput_shape = (4096,)\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), \n            torch.randn(batch_size, *input_shape), \n            torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [1.0]  # Default margin\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b58db39c-1a73-4521-a6a8-af5ad26f1060", "generation": 3, "timestamp": 1754997571.0350516, "iteration_found": 24, "metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 51.60000000000001, "speed_up": 1.316, "runtime_ms": 0.055, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:1", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0724, "speed_up": 1.316, "custom_timing": 0.055}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 42.10000000000001, "speed_up": 1.221, "runtime_ms": 0.0593, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0724, "speed_up": 1.221, "custom_timing": 0.0593}}, "island": 2}, "artifacts_json": null, "artifact_dir": null}