{"id": "94924736-29da-4775-9de1-d1d1e7fcb5c5", "code": "# ================== EVOLVE-BLOCK-START ==================\nimport torch\nimport triton\nimport triton.language as tl\nimport torch.nn as nn\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE': 256}, num_warps=8),\n        triton.Config({'BLOCK_SIZE': 512}, num_warps=16),\n        triton.Config({'BLOCK_SIZE': 1024}, num_warps=32),\n    ],\n    key=['feature_size', 'batch_size'],\n)\n@triton.jit\ndef triplet_margin_kernel(\n    anchor_ptr, positive_ptr, negative_ptr,\n    loss_ptr,\n    margin,\n    feature_size,\n    batch_size,\n    BLOCK_SIZE: tl.constexpr\n):\n    pid = tl.program_id(0)\n    if pid >= batch_size:\n        return\n    \n    d_ap_sq = 0.0\n    d_an_sq = 0.0\n    \n    for offset in range(0, feature_size, BLOCK_SIZE):\n        idx = offset + tl.arange(0, BLOCK_SIZE)\n        mask = idx < feature_size\n        \n        a = tl.load(anchor_ptr + pid * feature_size + idx, mask=mask, other=0.0)\n        p = tl.load(positive_ptr + pid * feature_size + idx, mask=mask, other=0.0)\n        n = tl.load(negative_ptr + pid * feature_size + idx, mask=mask, other=0.0)\n        \n        diff_ap = a - p\n        diff_an = a - n\n        d_ap_sq += tl.sum(diff_ap * diff_ap, axis=0)\n        d_an_sq += tl.sum(diff_an * diff_an, axis=0)\n    \n    d_ap = tl.sqrt(d_ap_sq)\n    d_an = tl.sqrt(d_an_sq)\n    loss_val = tl.maximum(d_ap - d_an + margin, 0.0)\n    tl.store(loss_ptr + pid, loss_val)\n\nclass ModelNew(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ModelNew, self).__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n        anchor = anchor.contiguous()\n        positive = positive.contiguous()\n        negative = negative.contiguous()\n        \n        batch_size, feature_size = anchor.shape\n        losses = torch.empty(batch_size, device=anchor.device, dtype=anchor.dtype)\n        \n        if batch_size == 0:\n            return torch.tensor(0.0, device=anchor.device)\n        \n        grid = (triton.cdiv(batch_size, 1),)\n        \n        triplet_margin_kernel[grid](\n            anchor, positive, negative,\n            losses,\n            self.margin,\n            feature_size,\n            batch_size,\n            BLOCK_SIZE=1024\n        )\n        \n        return losses.mean()\n\nbatch_size = 128\ninput_shape = (4096, )\ndim = 1\n\ndef get_inputs():\n    return [torch.randn(batch_size, *input_shape), torch.randn(batch_size, *input_shape), torch.randn(batch_size, *input_shape)]\n\ndef get_init_inputs():\n    return [1.0]  # Default margin\n\n# =================== EVOLVE-BLOCK-END ===================", "language": "python", "parent_id": "b58db39c-1a73-4521-a6a8-af5ad26f1060", "generation": 3, "timestamp": 1754997340.3920805, "iteration_found": 18, "metrics": {"compiled": true, "correctness": false, "score": 10, "stage": "wrong_answer", "verify_payload": {"id": "level1_99_TripletMarginLoss", "result": {"compiled": true, "correctness": false, "metadata": {"hardware": "NVIDIA L20Y", "device": "cuda:6", "runtime_error": "Traceback (most recent call last):\n  File \"/cpfs01/shared/llm_kernel/hujiakai/KernelLLM/validation_api_server/helpers/evaluations.py\", line 720, in run_and_check_correctness\n    output_new = model_new(*inputs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/tmparv33bk_.py\", line 67, in forward\n    triplet_margin_kernel[grid](\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/jit.py\", line 390, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 239, in run\n    benchmark()\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in benchmark\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 228, in <dictcomp>\n    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}\n  File \"/home/lijiaxing/.conda/envs/api/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 135, in _bench\n    raise ValueError(f\"Conflicting meta-parameters: {', '.join(conflicts)}.\"\nValueError: Conflicting meta-parameters: BLOCK_SIZE. Make sure that you don't re-define auto-tuned symbols.\n", "runtime_error_name": "builtins.ValueError", "reference_timing_ms": 0.0724, "speed_up": -1.0, "custom_timing": -1.0}, "runtime": -1.0, "runtime_stats": {}}}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"compiled": true, "correctness": true, "stage": "success", "passed": true, "score": 42.10000000000001, "speed_up": 1.221, "runtime_ms": 0.0593, "meta": {"hardware": "NVIDIA L20Y", "device": "cuda:7", "correctness_trials": "(5 / 5)", "reference_timing_ms": 0.0724, "speed_up": 1.221, "custom_timing": 0.0593}}, "island": 1}, "artifacts_json": null, "artifact_dir": null}